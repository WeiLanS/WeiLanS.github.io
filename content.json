{"meta":{"title":"HelloJohn","subtitle":"功不唐捐，殊途同归。","description":null,"author":"Hello John","url":"https://weilans.github.io","root":"/"},"pages":[{"title":"[404]","date":"2019-07-21T14:56:15.913Z","updated":"2019-07-21T14:54:11.884Z","comments":true,"path":"404.html","permalink":"https://weilans.github.io/404.html","excerpt":"","text":""},{"title":"about","date":"2019-07-21T14:46:30.967Z","updated":"2019-07-21T14:46:30.967Z","comments":true,"path":"about/index.html","permalink":"https://weilans.github.io/about/index.html","excerpt":"","text":"你要忍，忍到春暖花开； 你要走，走到灯火通明； 你要看过世界辽阔，再评判是好是坏； 你要卯足劲变好，再旗鼓相当站在不敢想象的人身边； 你要变成想象中的样子，这件事，一步都不能让。"}],"posts":[{"title":"Apache Calcite 1 - CSV Adapter","slug":"Apache-Calcite-Adapter-入门","date":"2020-02-20T09:03:34.000Z","updated":"2020-02-21T05:21:28.490Z","comments":true,"path":"2020/02/20/Apache-Calcite-Adapter-入门/","link":"","permalink":"https://weilans.github.io/2020/02/20/Apache-Calcite-Adapter-入门/","excerpt":"","text":"接触 Calcite 的时间不算长，感觉 Calcite 还是很难的，越往下看查询优化部分就很难看的下去。不过工作方面暂时只用到了Adapter部分，而且由于通用性的考量，使用的Table也是ScannableTable。一下子接触太多东西会受不了也容易忘，所以还是从头开始记笔记，一边完成工作上的事一边继续学习吧，一蹴而就不可取。 org.apache.calcite.jdbc.Driver jdbc:calcite:","categories":[],"tags":[]},{"title":"大数据入门草稿 - Hive","slug":"大数据入门草稿-Hive","date":"2020-01-06T02:00:21.000Z","updated":"2020-01-06T07:15:25.098Z","comments":true,"path":"2020/01/06/大数据入门草稿-Hive/","link":"","permalink":"https://weilans.github.io/2020/01/06/大数据入门草稿-Hive/","excerpt":"","text":"Hive简介Hive是Hadoop的数据仓库工具，可将结构化的数据文件映射为一张表，提供类SQL的查询功能。其本质是将HQL转化为MapReduce程序。 Hive会将SQL中的重用操作使用MapReduce写成很多模块，当用户根据业务需求编写SQL语句时，可以通过Hive匹配出相应的MapReduce模板。运行MapReduce程序，生成分析结果。 Hive处理的数据存储在HDFS中。 Hive分析数据的默认实现是MapReduce（可以改成Spark)。 Hive执行程序运行在Yarn上。 Hive 适用于数据分析场景以及对实时性要求不高的场合。其优势在于处理大数据，对于小数据处理没有优势，Hive的执行延迟较高（MapReduce 本身具有较高的延迟）。Hive还支持用户自定义函数。此外，Hive拥有较高扩展性，Hive是建立在Hadoop之上的，因此Hive的可扩展性是和Hadoop的可扩展性是一致的。 Hive的缺点在于两点：HQL表达能力有限，迭代式算法无法表达（计算结果再次处理），故在数据挖掘方面并不擅长；执行效率较低，生成的MR任务通常不够智能，且调优困难。 Hive为数仓设计，数仓内容为读多写少，因此，Hive中不建议对数据的改写，所有的数据都是在加载的时候确定好的。当然增和删是可以做到的。 Hive 架构 command-line shell：通过 hive 命令行的的方式来操作数据； thrift／jdbc：通过 thrift 协议按照标准的 JDBC 的方式操作数据； Metastore: 元数据涉及到：表名、表所属的数据库（默认是default）、表的拥有者、列/分区字段、表的类型（是否是外部表）、表的数据所在目录等； Driver: 主要包括以下四个: SQL Parser 解析器：将SQL字符串转换成抽象语法树AST，这一步一般都用第三方工具库完成，比如antlr；对AST进行语法分析，比如表是否存在、字段是否存在、SQL语义是否有误。 Physical Plan 编译器：将AST编译生成逻辑执行计划。 Query Optimizer 优化器：对逻辑执行计划进行优化。 Execution 执行器：把逻辑执行计划转换成可以运行的物理计划。对于Hive来说，就是MR/Spark。","categories":[{"name":"BigData","slug":"BigData","permalink":"https://weilans.github.io/categories/BigData/"}],"tags":[]},{"title":"[HikariCP] HikariCP 配置项 ","slug":"HikariCP-2-HikariCP-配置项","date":"2019-12-18T01:42:48.000Z","updated":"2019-12-19T11:51:59.166Z","comments":true,"path":"2019/12/18/HikariCP-2-HikariCP-配置项/","link":"","permalink":"https://weilans.github.io/2019/12/18/HikariCP-2-HikariCP-配置项/","excerpt":"HikariCP 的全部配置介绍来自其首页，主要分为必填项和可选项，对于大部分配置项，HikariCP会有默认设置，官方建议在使用时无需过多的调整。 一些非必要属性的配置说明来自《HikariCP数据库连接池实战》。","text":"HikariCP 的全部配置介绍来自其首页，主要分为必填项和可选项，对于大部分配置项，HikariCP会有默认设置，官方建议在使用时无需过多的调整。 一些非必要属性的配置说明来自《HikariCP数据库连接池实战》。 相比其他数据库连接池，HikariCP会少一些配置项，作者的原话是： In keeping with the simple is better or less is more design philosophy, some configuration axis are intentionally left out. 必填配置需填写三项： dataSourceClassName、jdbcUrl 二选一 username password dataSourceClassName顾名思义，该属性就是 JDBC 驱动中DataSource的名称。dataSourceClassName和jdbcUrl都是可以的，但作者更推荐 dataSourceClassName（DataSource-based），不过对于使用 Spring Boot 自动装配的用户，还是需使用jdbcUrl 配置。此外，MySQL DataSource 并不支持网络超按时，建议使用 jdbcUrl 的方式。 jdbcUrl表明 HikariCP 使用的是传统的DriverManager-based配置。虽然作者认为基于 dataSourceClassName 的配置更加优越，但在实际部署上两种方式并没有差别。当使用某些老的驱动程序时，可能还需要设置 driverClassName 属性，但首先尝试不使用该属性。 username &amp; password从驱动中获取连接时使用到的身份认证用户名和密码。对于 DataSource，其使用 DataSouce.getConnection(String username, String password)，但对于 DriverManager，由于每个 Driver 特征不同，HikariCP 会将 username 和 password属性配置在 Properties 文件中，使用的是getConnection(String url, java.util.Properties info)方法。当然也可也以跳过此步，使用addDataSourceProperty(&quot;username&quot;, ...)及addDataSourceProperty(&quot;pass&quot;, ...)。 可选配置常用配置autoCommit控制从池中返回的连接的默认自动提交行为。Default: true connectionTimeout（重要）控制客户端等待池中连接的最长毫秒数，如果在没有连接可用的情况下超过此时间，则抛出SQLException，最低可接受的连接超时为250ms，Default: 30000 (30s)。 idleTimeout控制连接允许被闲置在池中的最大时间（此设置仅适用于minimumIdle定义为比maximumPoolSize小）。当整个连接池数量在 minimumIdle 时，空闲连接将不会退役。空闲连接在这个超时时间之前不可能退役。该值为 0 表示空闲连接永远不可能从连接池中移除。该值允许的最小值是：10000(10s)，Default: 600000(10min)。 原文中还有一句Whether a connection is retired as idle or not is subject to a maximum variation of +30 seconds, and average variation of +15 seconds.并不太好理解其含义。可能是指在达到 idleTimeout 后还需要的部分时间（比如检测任务的间隔时间）进行辨别。 maxLifeTime（重要）控制池中连接的最大生命周期，使用中的连接永远不会退役，只有当它在关闭后在会被移除。作者强烈建议用户设置此值，并且它应该比任何数据源的连接源的连接限制短几秒。值为0表示无限期生存，Default: 1800000(30min)。 有些使用MySQL的应用会报如下的错误： The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server. 这个问题分两种情况来看，是立即发生还是一段时间以后发生？如果是一段时间以后发生，在数据库的wait_timeout短于HikariCP的maxLifetime值的时候，发生的情况并不少见。一般来说，可以将maxLifetime设置缩短到900000毫秒（15分钟）然而更好的方法是，确定MySQL配置的wait_timeout值是什么，并将HikariCP设置为比maxLifetime短几分钟。 connectionTestQuery作者强烈建议，如果驱动支持 JDBC4，请不要使用这个属性。这适用于不支持 JDBC4 的 Connection.isValid() 的驱动。该属性是一个检测查询，在数据库连接池给出连接之前进行查询，以验证与数据库的连接是否仍然存在且有效。 如果追求极致性能，建议不设置此值，当不配置此值时会通过ping命令进行检测，性能会更好。 Default: none minimumIdle控制HikariCP尝试在池中维护的最小空闲连接数，若空闲连接数低于此值且池中的总连接数小于maximumPoolSize，则HikariCP将尽最大努力有效添加其他连接。 为了最大提高性能和对峰值需求的响应能力，作者不建议设置此值，而是让HikariCP充当一个固定大小连接池。若该参数未设置，则置为 maximumPoolSize，当连接关闭时，将会在池中被替换。如果设置了此值，那 HikariCP 就是一个大小可变的池，即使使用情况上下浮动，连接池也会保持 minimumIdle 连接可用。Default: same as maximumPoolSize maximumPoolSize控制连接池到达的最大大小，包括空闲的和正在使用的连接，由此值控制后端的实际连接的最大数量。当池到达此大小且没有空闲连接可使用时，对 getConnection 的调用将阻塞至超时前 connectionTimeout 毫秒。 metricRegistry允许用户指定池使用的 MetricRegistry 示例，记录各种指标度量值。 healthCheckRegistry允许用户指定池使用的 HealthCheckRegistry 示例，报告当前系统的健康信息。(Micrometer不支持) poolName标识连接池的用户定义名称，主要用于显示在日志记录和JMX管理控制台上。Default: auto-generated 非常用配置initializationFailTimeout如果池无法成功初始化连接，则此属性控制池是否“快速失败”。任何正数都被认为是尝试获取初始连接的毫秒数；在此期间，应用程序线程将被阻塞。如果在超时发生之前无法获取连接，则将引发异常。initializationFailTimeout超时发生在connectionTimeout阶段之后。如果值为0，HikariCP将尝试获取并验证连接。如果获得连接但验证失败，则抛出异常，而不会启动池。但是，如果无法获得连接，则池将启动，但稍后获取连接的尝试会失败。小于0的值将绕过任何初始连接尝试，并且池将在尝试在后台获取连接时立即启动。因此，以后获得连接的尝试可能会失败。默认值：1。 感觉官网说的还是比较晦涩，建议看HikariPool#checkFailFast源码。 isolateInternalQueries此属性决定HikariCP是否在自己的事务中隔离内部池查询，例如连接存活测试。由于这些通常是只读查询，因此很少有必要将它们封装在自己的事务中。此属性仅在autoCommit禁用时适用。默认值：false。 allowPoolSuspension 此属性控制池是否可以通过JMX挂起和恢复。这对某些故障转移自动化方案很有用。当池被挂起时，调用getConnection()将不会超时，并将一直保持到池恢复为止。默认值：false。 readOnly此属性控制默认情况下从池中获取的Connections是否处于只读模式。请注意，某些数据库不支持只读模式的概念，而其他数据库在Connection设置为只读时提供查询优化。是否需要此属性将在很大程度上取决于那的应用程序和数据库。默认值：false。 registerMbeans此属性控制是否注册JMX管理Bean（“MBean”）。默认值：false。 catalog此属性为支持catalog的数据库设置默认catalog。如果未指定此属性，则使用JDBC驱动程序定义的默认catalog。默认值：driver default。 connectionInitSql此属性设置一个SQL语句，该语句将在每次创建新连接之后执行，然后再将该连接添加到池中。如果此SQL无效或抛出异常，它将被视为连接失败，并将遵循标准重试逻辑。默认值：无。 driverClassNameHikariCP将尝试仅基于jdbcUrl通过DriverManager解析驱动程序，但对于某些较旧的驱动程序必须指定driverClassName。除非用户收到明显的错误消息，表明未找到驱动程序，否则可忽略此属性。默认值：无。 transactionIsolation此属性控制从池返回的连接的默认事务隔离级别。若未指定，则用JDBC驱动程序定义的默认事务隔离级别。仅当有针对所有查询的特定隔离需求时，才使用此属性。此属性的值是Connection类的常量名，如TRANSACTION_READ_COMMITTED、TRANSACTION_REPEATABLE_READ等。默认值：driver default。 validationTimeout此属性控制连接测试活性的最长时间。该值必须小于connectionTimeout。最低可接受的验证超时为250毫秒。默认值：5000。 leakDetectionThreshold此属性控制连接在记录一条指示可能连接泄漏的消息之前流出池的时间。值为0表示禁用泄漏检测。启用泄漏检测的最低可接受值是2000（2秒）。默认值：0。 schema该属性为支持schema概念数据库设置默认schema。如果未指定此属性，则使用JDBC驱动程序定义的默认模式。默认值：driver default。 threadFactory此属性仅可通过编程配置或IoC容器获得。此属性允许设置java.util.concurrent.ThreadFactory将用于创建池使用的所有线程的实例。在注入线程只能通过应用程序容器提供的ThreadFactory创建的某些受限执行环境中使用它。默认值：无。 scheduledExecutor仅可通过编程配置或IoC容器获得。允许设置java.util.concurrent.Scheduled-ExecutorService用于各种内部调度任务的实例。如果向HikariCP提供ScheduledThread-PoolExecutor实例，建议设置setRemoveOnCancelPolicy(true)。默认值：无。","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"connection-pool","slug":"connection-pool","permalink":"https://weilans.github.io/tags/connection-pool/"},{"name":"db","slug":"db","permalink":"https://weilans.github.io/tags/db/"}]},{"title":"大数据入门草稿 - Hadoop","slug":"大数据入门草稿-Hadoop","date":"2019-12-16T03:18:02.000Z","updated":"2020-01-06T02:01:23.995Z","comments":true,"path":"2019/12/16/大数据入门草稿-Hadoop/","link":"","permalink":"https://weilans.github.io/2019/12/16/大数据入门草稿-Hadoop/","excerpt":"HDFS、YARN、MapReduce","text":"HDFS、YARN、MapReduce 大数据基础概述4VVolume 海量的数据规模；Variety 多样的数据类型；Velocity 快速的数据流转；Value 发现数据加载。 大数据在技术架构上带来的挑战对现有数据库管理技术的挑战（TB以上结构化的存储）；经典数据库技术没有考虑数据的多类别；实时性的技术挑战；网络架构、数据中心、运维的挑战。 大数据带来的额外挑战：数据隐私。 Google大数据技术存储容量 GFS；读写速度 BigTable；计算效率 MapReduce Hadoop开源的分布式存储+分布式计算平台，可以对多机器的海量数据进行分布式处理的框架。其拥有成熟的生态圈，可存储在廉价的机器上。 Hadoop 主要包括四部分： Hadoop Common：Hadoop 共用包； Hadoop Distributed File System(HDFS)：可提供高吞吐量的分布式文件系统； Hadoop YARN：工作调度 &amp; 资源管理； Hadoop MapReduce：基于 YARN 可并行处理大数据集的框架 狭义的Hadoop即为这三者的总和，而广义的Hadoop是指Hadoop生态系统，生态系统中的每一个子系统只解决某一个特定问题域，是多个小而精的系统。 HDFS特点：扩展性 &amp; 容错性 &amp; 海量数据存储 将文件切分成指定大小（可配置，默认128M）的数据块并以多副本的形式存储在多个机器上。 数据切分、多副本、容错等操作对用户是透明的。 YARNYet Another Resource Negotiator，负责整个集群资源的管理和调度（作业占用CPU及内存）。 特点：扩展性 &amp; 容错性（Task异常进行一定次数的重试）&amp; 多框架资源统一调度（跑Spark等额外类型的作业，14年Spark逐渐代替MapReduce称为Hadoop缺省执行引擎。） MapReduceHadoop MapReduce 是 Google MapReduce 的克隆版 特点：扩展性 &amp; 容错性 &amp; 海量数据离线处理 HDFS如果要自行设计一个简易的分布式文件系统，可能会将大小不同的文件以多副本的方式存在在多台机器上，并且记录文件存在哪台机器上等元数据。这样的缺点是：不管文件多大都直接放在一个节点上会造成网络瓶颈且很难进行并行数据处理；存储负载较难均衡，部分节点的利用率较低。 而HDFS的做法是将每个文件先进行拆分，每块大小可设置（如128M ），每个Block多副本的方式进行存储。大小一致的Block会让机器的存储负载好很多，且便于并行处理。 HDFS架构 1个Master(NameNode/NN) &amp; N个Slaves(DataNode/DN) NameNode：负责客户端请求的响应；负责元数据（文件的名称、副本系数、Block存放的DataNode）的管理； DataNode：存储用户文件对应的数据块（Block）；定期向NN发送心跳信息，汇报本身及所有Block信息，健康状况； 实际生产部署时， 一个机器部署NameNode，其他每个机器部署一个DataNode。 Replication Factor：副本系数（副本因子）。每个文件可以单独配置副本因子和 Block Size。 HDFS的文件只能写一次（除非 appends truncates），且在任意时间内只能有一个 writer 进行写操作，不支持多并发写。 Hadoop伪分布式安装 JDK安装并添加至环境变量 安装ssh，并配置免密登录 123sudo yum install sshssh-keygen -t rsacp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys 下载并解压 hadoop，hadoop-2.6.0-cdh5.7.0.tar.gz 更改 hadoop 配置 (hadoop_home/etc/hadoop) ： hadoop-env.sh 更改 JAVA_HOME 1export JAVA_HOME=... core-site.xml 12345678&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://xxx:8020&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/xxx/tmp-hadoop&lt;/value&gt;&lt;/property&gt; hdfs-site.xml 1234&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt;&lt;/property&gt; slaves 文件添加 slave 信息，此处不做变动 启动HDFS：格式化文件系统，进入bin目录，./hdfs namenode -format，之后启动 hdfs，sbin/start-dfs.sh，使用jps查看 DataNode 以及 NameNode 是否启动成功，或者通过浏览器端口 50070。 停止HDFS：sbin/stop-dfs.sh HDFS Shellhdfs dfs和hadoop fs指令相同，直接输入后可以看见其他后续指令。 123456789101112hdfs dfs -ls /hdfs dfs -put test.log / 向HDFS存放文件hdfs dfs -text /test.log 查看hdfs dfs -cat /test.log 查看hdfs dfs -mkdir /tthdfs dfs -mkdir -p /tt/a/b 递归创建hdfs dfs -ls /tt/ahdfs dfs -ls /tt/a/bhdfs dfs -ls -R / 递归查看hdfs dfs -get /test.log 从HDFS中获取文件hdfs dfs -rm /test.log 删除文件hdfs dfs -rm -R /tt 删除目录 HDFS Java API123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131public static final String HDFS_PATH = \"hdfs://10.211.55.6:8020\"; FileSystem fileSystem = null; Configuration configuration = null; @Before public void setUp() throws Exception &#123; System.out.println(\"HDFSApp.setUp\"); configuration = new Configuration(); fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration, \"parallels\"); &#125; @After public void tearDown() throws Exception &#123; configuration = null; fileSystem = null; System.out.println(\"HDFSApp.tearDown\"); &#125; /** * 创建HDFS目录 */ @Test public void mkdir() throws Exception &#123; fileSystem.mkdirs(new Path(\"/hdfsapi/test2\")); &#125; /** * 创建文件 */ @Test public void create() throws Exception &#123; FSDataOutputStream output = fileSystem.create(new Path(\"/hdfsapi/test2/a.txt\")); output.write(\"hello hadoop\".getBytes()); output.flush(); output.close(); &#125; /** * 查看HDFS文件的内容 */ @Test public void cat() throws Exception &#123; FSDataInputStream in = fileSystem.open(new Path(\"/hdfsapi/test2/a.txt\")); IOUtils.copyBytes(in, System.out, 1024); in.close(); &#125; /** * 重命名 */ @Test public void rename() throws Exception &#123; Path oldPath = new Path(\"/hdfsapi/test/a.txt\"); Path newPath = new Path(\"/hdfsapi/test/b.txt\"); fileSystem.rename(oldPath, newPath); &#125; /** * 上传文件到HDFS */ @Test public void copyFromLocalFile() throws Exception &#123; Path localPath = new Path(\"/Users/Finch/Downloads/springboot2.1.7.pom\"); Path hdfsPath = new Path(\"/hdfsapi/test\"); fileSystem.copyFromLocalFile(localPath, hdfsPath); &#125; /** * 上传文件到HDFS */ @Test public void copyFromLocalFileWithProgress() throws Exception &#123; InputStream in = new BufferedInputStream( new FileInputStream( new File(\"/Users/rocky/source/spark-1.6.1/spark-1.6.1-bin-2.6.0-cdh5.5.0.tgz\"))); FSDataOutputStream output = fileSystem.create(new Path(\"/hdfsapi/test/spark-1.6.1.tgz\"), new Progressable() &#123; public void progress() &#123; System.out.print(\".\"); //带进度提醒信息 &#125; &#125;); IOUtils.copyBytes(in, output, 4096); &#125; /** * 下载HDFS文件 */ @Test public void copyToLocalFile() throws Exception &#123; Path localPath = new Path(\"/Users/rocky/tmp/h.txt\"); Path hdfsPath = new Path(\"/hdfsapi/test/hello.txt\"); fileSystem.copyToLocalFile(hdfsPath, localPath); &#125; /** * 查看某个目录下的所有文件 * * 问题：我们已经在hdfs-site.xml中设置了副本系数为1，为什么此时查询文件看到的3呢？ * 如果你是通过hdfs shell的方式put的上去的那么，才采用默认的副本系数1 * 如果我们是java api上传上去的，在本地我们并没有手工设置副本系数，所以否则采用的是hadoop自己的副本系数 * * 【设置副本系数：configuration.set(\"dfs.replication\", \"1\");】 */ @Test public void listFiles() throws Exception &#123; FileStatus[] fileStatuses = fileSystem.listStatus(new Path(\"/hdfsapi/test\")); for(FileStatus fileStatus : fileStatuses) &#123; String isDir = fileStatus.isDirectory() ? \"文件夹\" : \"文件\"; short replication = fileStatus.getReplication(); long len = fileStatus.getLen(); String path = fileStatus.getPath().toString(); System.out.println(isDir + \"\\t\" + replication + \"\\t\" + len + \"\\t\" + path); &#125; &#125; /** * 删除 */ @Test public void delete() throws Exception&#123; fileSystem.delete(new Path(\"/\"), true); &#125; HDFS读写原理通过漫画轻松掌握HDFS工作原理 HDFS优缺点优点：数据冗余、硬件容错；可构建在廉价机器上；适合存储大文件。 缺点：数据访问延迟（想要极快进行数据检索并不现实）；不适合小文件存储（小文件太多会导致NameNode占用内存信息越多，增加了NameNode压力）。 YARN资源调度框架YARN在1.x时代只支持MapReduce任务，而在2.x之后可以让更多的计算框架（如Spark、Storm）运行在集群里面，不同的计算框架可以共享同一个HDFS的数据，享受整体的资源调度。 YARN架构 ResourceManager: RM 整个集群同一时间提供服务的RM只有一个（可以使用主从解决单点问题），负责集群资源的统一管理和调度 处理客户端的请求： 提交一个作业、杀死一个作业 监控我们的NM，一旦某个NM挂了，那么该NM上运行的任务需要告诉我们的AM来如何进行处理 NodeManager: NM 整个集群中有多个，负责自己本身节点资源管理和使用 定时向RM汇报本节点的资源使用情况 接收并处理来自RM的各种命令：启动Container 处理来自AM的命令 单个节点的资源管理 ApplicationMaster: AM 每个应用程序对应一个：MR、Spark，负责应用程序的管理 为应用程序向RM申请资源（core、memory），分配给内部task 需要与NM通信：启动/停止task，task是运行在container里面，AM也是运行在container里面 Container 封装了CPU、Memory等资源的一个容器 是一个任务运行环境的抽象 Client 提交作业 查询作业的运行进度 杀死作业 运行流程https://github.com/heibaiying/BigData-Notes/blob/master/notes/Hadoop-YARN.md Client 提交作业到 YARN 上； Resource Manager 选择一个 Node Manager，启动一个 Container 并运行 Application Master 实例； Application Master 根据实际需要向 Resource Manager 请求更多的 Container 资源（如果作业很小, 应用管理器会选择在其自己的 JVM 中运行任务）； Application Master 通过获取到的 Container 资源执行分布式计算。 YARN伪分布式环境搭建1）mapred-site.xml 1234&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt; 2）yarn-site.xml 1234&lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt; 3) 启动YARN相关的进程 1sbin/start-yarn.sh 4）验证 jps：ResourceManager 、NodeManager 访问8088端口 5）停止YARN相关的进程 1sbin/stop-yarn.sh 提交mr作业到YARN上运行： 使用Jar包：hadoop-2.6.0-cdh5.7.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.7.0.jar 使用命令hadoop jar，比如 hadoop jar hadoop-mapreduce-examples-2.6.0-cdh5.7.0.jar pi 2 3 MapReduce优点：海量数据离线处理 缺点：实时流式计算 入门案例：wordcount: 统计文件中每个单词出现的次数，借用 MapReduce 可以实现分而治之。 MapReduce 框架专门用于键值对处理，它将作业的输入视为一组对，并生成一组对作为输出。输出和输出的 key 和 value 都必须实现Writable 接口。 key classes 还必须实现 WritableComparable 接口。 1(input) &lt;k1, v1&gt; -&gt; map -&gt; &lt;k2, v2&gt; -&gt; combine -&gt; &lt;k2, v2&gt; -&gt; reduce -&gt; &lt;k3, v3&gt; (output) 核心概念Split: 交由MapReduce作业来处理的数据块，是MapReduce中最小的计算单元。HDFS中 blocksize 是HDFS中最小的存储单元 128M。默认情况下：他们两是一一对应的，当然我们也可以手工设置他们之间的关系（不建议） InputFormat: 将我们的输入数据进行分片(split): InputSplit[] getSplits(JobConf job, int numSplits) throws IOException;TextInputFormat: 处理文本格式的数据 OutputFormat: 输出 Combiner Partitioner MapReduce 2.x 架构 Java 版 WordCount1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.Mapper;import org.apache.hadoop.mapreduce.Reducer;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;import java.io.IOException;/** * 使用MapReduce开发WordCount应用程序 **/public class WordCountApp &#123; /** * Map: 读取输入的文件内容 */ public static class MyMapper extends Mapper&lt;LongWritable, Text, Text, LongWritable&gt; &#123; LongWritable one = new LongWritable(1); protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; // 接收到的每一行数据 String line = value.toString(); // 按照指定的分割符进行拆分 String[] words = line.split(\" \"); for (String word : words) &#123; // 通过上下文把map的处理结果输出 context.write(new Text((word)), one); &#125; &#125; &#125; /** * Reduce: 归并操作 */ public static class MyReducer extends Reducer&lt;Text, LongWritable, Text, LongWritable&gt; &#123; protected void reduce(Text key, Iterable&lt;LongWritable&gt; values, Context context) throws IOException, InterruptedException &#123; long sum = 0; for (LongWritable value : values) &#123; // 求key出现的次数总和 sum += value.get(); &#125; // 将最终的统计结果输出 context.write(key, new LongWritable(sum)); &#125; &#125; /** * 定义Driver：封装了MapReduce作业的所有信息 */ public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123; Configuration configuration = new Configuration(); // 准备清理已存在的输出目录, 在MR中，输出文件是不能事先存在的 Path outputPath = new Path(args[1]); FileSystem fileSystem = FileSystem.get(configuration); if (fileSystem.exists(outputPath)) &#123; fileSystem.delete(outputPath,true); System.out.println(\"output file exists, but is has deleted\"); &#125; // 创建Job，通过参数设置Job的名称 Job job = Job.getInstance(configuration, \"wordcount\"); // 设置Job的处理类 job.setJarByClass(WordCountApp.class); // 设置作业处理的输入路径 FileInputFormat.setInputPaths(job, new Path(args[0])); // 设置map相关参数 job.setMapperClass(MyMapper.class); job.setMapOutputKeyClass(Text.class); job.setMapOutputValueClass(LongWritable.class); // 设置reduce相关参数 job.setReducerClass(MyReducer.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(LongWritable.class); // 通过Job对象来设置Combiner处理类，在逻辑上和reduce是一样的 job.setCombinerClass(MyReducer.class); // 设置作业处理完成后的输出路径 FileOutputFormat.setOutputPath(job, new Path(args[1])); System.exit(job.waitForCompletion(true) ? 0 : 1); &#125;&#125; 执行: 1hadoop jar /home/hadoop/lib/hadoop-train-1.0.jar com.hadoop.mapreduce.WordCountApp hdfs://10.211.55.6:8020/hello.txt hdfs://10.211.55.6:8020/output/wc Combiner 本地的Reduce； 减少Map Tasks输出的数据量及数据网络传输量； 但适用场景有限，比如求和计数等，不适合求平均数等类似场景。 PartitionerPartitioner决定Map Task输出的数据交由哪个Reduce Task处理。默认实现：分发的key的hash值对Reduce Task个数取模。 案例：手机销量手机按品牌分类收集至各个文件中 123456789101112131415161718192021222324252627282930313233343536373839public static class MyMapper extends Mapper&lt;LongWritable, Text, Text, LongWritable&gt; &#123; protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; // 接收到的每一行数据 String line = value.toString(); // 按照指定的分割符进行拆分 String[] words = line.split(\" \"); // 通过上下文把map的处理结果输出 context.write(new Text((words[0])), new LongWritable(Long.parseLong(words[1]))); &#125; &#125; public static class MyPartitioner extends Partitioner&lt;Text, LongWritable&gt; &#123; public int getPartition(Text key, LongWritable value, int numPartitions) &#123; if(key.toString().equals(\"xiaomi\"))&#123; return 0; &#125; if(key.toString().equals(\"huawei\"))&#123; return 1; &#125; if(key.toString().equals(\"iphone7\")) &#123; return 2; &#125; return 3; &#125; &#125; public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123; ... // 设置Job的partition job.setPartitionerClass(MyPartitioner.class); // 设置4个reducer，每个分区一个 job.setNumReduceTasks(4); FileOutputFormat.setOutputPath(job, new Path(args[1])); System.exit(job.waitForCompletion(true) ? 0 : 1); &#125; JobHistoryJobHistory是一个Hadoop自带的历史服务器，它用于记录已运行完的MapReduce信息到指定的HDFS目录下。可以通过HTTP页面访问获得信息。 mapred-site.xml 添加： 12345678910111213141516171819202122&lt;!-- jobhistory的通信地址 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;192.168.77.130:10020&lt;/value&gt; &lt;description&gt;MapReduce JobHistory Server IPC host:port&lt;/description&gt;&lt;/property&gt;&lt;!-- jobhistory的web访问地址 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;192.168.77.130:19888&lt;/value&gt; &lt;description&gt;MapReduce JobHistory Server IPC host:port&lt;/description&gt;&lt;/property&gt;&lt;!-- 任务运行完成后，history信息所存放的目录 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.done-dir&lt;/name&gt; &lt;value&gt;/history/done&lt;/value&gt;&lt;/property&gt;&lt;!-- 任务运行中，history信息所存放的目录 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.intermediate-done-dir&lt;/name&gt; &lt;value&gt;/history/done_intermediate&lt;/value&gt;&lt;/property&gt; yarn-site.xml 添加： 12345&lt;!-- 开启聚合日志 --&gt;&lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; 之后需要重启YARN访问，stop-yarn.sh 以及 start-yarn.sh。 启动 sbin/mr-jobhistory-daemon.sh start historyserver，在19888端口处就可以看到接下来的执行信息了。 https://blog.51cto.com/zero01/2093445","categories":[{"name":"BigData","slug":"BigData","permalink":"https://weilans.github.io/categories/BigData/"}],"tags":[]},{"title":"[指标监控] 云原生监控系统 Prometheus","slug":"指标监控-2-云原生监控系统-Prometheus","date":"2019-12-07T18:44:30.000Z","updated":"2019-12-23T02:30:32.084Z","comments":true,"path":"2019/12/08/指标监控-2-云原生监控系统-Prometheus/","link":"","permalink":"https://weilans.github.io/2019/12/08/指标监控-2-云原生监控系统-Prometheus/","excerpt":"Prometheus 作为当前炙手可热的云原生监控系统，是继 Kubernetes 之后第二个加入云原生计算基金会的成员。其安装及使用也是相当便捷，有强大的扩展性和集成性，查询语言 PromQL 可以轻松完成指标数据的查询与聚和。","text":"Prometheus 作为当前炙手可热的云原生监控系统，是继 Kubernetes 之后第二个加入云原生计算基金会的成员。其安装及使用也是相当便捷，有强大的扩展性和集成性，查询语言 PromQL 可以轻松完成指标数据的查询与聚和。 监控的目标《SRE: Google运维解密》一书中指出，监控系统需要能够有效的支持白盒监控和黑盒监控：通过白盒能够了解其内部的实际运行状态，通过对监控指标的观察能够预判可能出现的问题，从而对潜在的不确定因素进行优化。而黑盒监控，常见的如HTTP探针，TCP探针等，可以在系统或者服务在发生故障时能够快速通知相关的人员进行处理。通过建立完善的监控体系，从而达到以下目的： 长期趋势分析：通过对监控样本数据的持续收集和统计，对监控指标进行长期趋势分析。例如，通过对磁盘空间增长率的判断，我们可以提前预测在未来什么时间节点上需要对资源进行扩容。 对照分析：两个版本的系统运行资源使用情况的差异如何？在不同容量情况下系统的并发和负载变化如何？通过监控能够方便的对系统进行跟踪和比较。 告警：当系统出现或者即将出现故障时，监控系统需要迅速反应并通知管理员，从而能够对问题进行快速的处理或者提前预防问题的发生，避免出现对业务的影响。 故障分析与定位：当问题发生后，需要对问题进行调查和处理。通过对不同监控监控以及历史数据的分析，能够找到并解决根源问题。 数据可视化：通过可视化仪表盘能够直接获取系统的运行状态、资源使用情况、以及服务运行状态等直观的信息。 为什么使用 Prometheus Prometheus核心部分只有一个单独的二进制文件，不存在任何的第三方依赖(数据库，缓存等等)。唯一需要的就是本地磁盘，因此不会有潜在级联故障的风险。(Prometheus 不仅仅是一个监控系统，同时也是一个时序数据库，Prometheus 不直接使用现有的时序数据库作为后端存储，就是希望监控系统有着时序数据库的特点，而且还需要部署和维护非常方便) Prometheus基于 Pull 模型的架构方式，可以在任何地方搭建我们的监控系统。对于一些复杂的情况，还可以使用Prometheus服务发现(Service Discovery)的能力动态管理监控目标。 拥有多维度数据模型：所有采集的监控数据均以指标(metric)的形式保存在内置的时间序列数据库当中(TSDB)。所有的样本除了基本的指标名称以外，还包含一组用于描述该样本特征的标签，一个时间序列由一个度量指标和多个标签值确定。 强大的查询语言 PromQL：Prometheus 内置了一个强大的数据查询语言 PromQL。 通过 PromQL 可以实现对监控数据的查询、聚合。同时 PromQL 也被应用于数据可视化(如Grafana)以及告警当中。通过PromQL可以轻松回答类似于以下问题： 在过去一段时间中95%应用延迟时间的分布范围？ 预测在4小时后，磁盘空间占用大致会是什么情况？ CPU占用率前5位的服务有哪些？(过滤) Prometheus可以高效地处理这些数据，对于单一 Prometheus Server 实例而言它可以处理：数以百万的监控指标；每秒处理数十万的数据点。 扩展性：每个数据中心、每个团队都可以运行独立的 Prometheus Sevrer。Prometheus 对于联邦集群的支持，可以让多个Prometheus实例产生一个逻辑集群，当单实例 Prometheus Server 处理的任务量过大时，通过使用 功能分区(sharding) + 联邦集群(federation) 可以对其进行扩展。 易于集成：支持多种语言客户端，基于这些SDK可以快速让应用程序纳入到Prometheus的监控当中，或者开发自己的监控数据收集程序。此外，还提供大量第三方提供的数据采集Exporters，比如：Oracle DB Exporter、PostgreSQL exporter、Redis exporter、NVIDIA GPU exporter、RabbitMQ exporter、Nginx metric library、JMX exporter等。 安装 Prometheus Serverdocker 安装 Prometheus Server： 1docker run -d -p 9090:9090 -v /etc/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus 打开 http://127.0.0.1:9090/ 就可以看到 Prometheus 主页了。 也可以直接下载安装包，解压后执行： 1./prometheus --config.file=prometheus.yml 在Prometheus的架构设计中，Prometheus Server 并不直接服务监控特定的目标，其主要任务负责数据的收集，存储并且对外提供数据查询支持。因此为了能够能够监控到某些东西，如主机的CPU使用率，我们需要使用到Exporter。为了能够采集到主机的运行指标如CPU, 内存，磁盘等信息，可以使用 Node Exporter。直接运行node_exporter，打开9100端口，在 http://localhost:9100/metrics 就可以看到相关信息。 想要主动拉取 Node 信息，需要配置 prometheus.yml，job_name 为 prometheus 为其自带的，暂且不管。metrics_path 默认为 /metrics，对于后续监控自己的系统，想要更改path，即添加或更改此属性。在下方新增 node job_name 启动后，就可以在 Prometheus 首页的 Expression 处搜索到 Node 信息了。 1234567scrape_configs: - job_name: 'prometheus' static_configs: - targets: ['localhost:9090'] - job_name: 'node' static_configs: - targets: ['localhost:9100'] Prometheus 架构 中间最核心的就是 Prometheus Server，最重要的功能就是数据的获取，主要是以 pull 的方式从 Jobs、Exporters 拉取，而寿命周期短的任务则可以存放数据至 Pushgateway 网关，再由 Prometheus Server 定期从网关中拉取。也可以通过 Service Discovery 发现需要主动监控的访问（当要监控特别多的节点，而这些节点也是动态变化的，可以采用这种方式） 。 Prometheus Server 会将数据存储存储在磁盘上，并对外暴露 HTTP 服务，供外部客户端进行 PromQL 查询。 此外，还可以配置一些报警条件，当条件满足时，报警信息会以 push 的方式推至 Alertmanager，由 Alertmanager 处理告警的通知（当然，实际的告警是 Prometheus 产生的），比如告警去重后以短信或者邮件的方式进行通知。 Prometheus 核心概念数据模型 Metric names and labels 指标名称及标签：每个时间序列由其指标名称和称为标签的可选键值对来进行唯一标识。 Sample 采样值：时序序列的数据即是样本，每个样本是一个float64数值，或者是一个精确到毫秒的时间戳。 Notation 标记/注解：实际上就是指标和标签组合的时间序列表示： 12&lt;metric name&gt;&#123;&lt;label name&gt;=&lt;label value&gt;, ...&#125;api_http_requests_total&#123;method=\"POST\", handler=\"/messages\"&#125; 度量指标 Counter 计数器 ： 是一个累计的指标，表示一个单调递增的计数器，比如用于任务请求数、成功或失败的任务数等。 Gauge 计量器：是一个数值可以上下移动的指标。 Histogram 直方图：主要用于采样分析，将范围分成一个个的桶，将数值放入桶中进行分布情况分析。 Summary 汇总：与 Histogram 类似，主要提供百分比分布情况。 任务和实例任务 Job、实例 Instance 一个任务可能有多个实例，比如要应用的某个指标，可以为这个应用建一个 Job，该应用可以有多台服务器，即有多个 Instance。当前在每一个Job中主要使用了静态配置(static_configs)的方式定义监控目标。除了静态配置每一个Job的采集Instance地址以外，Prometheus还支持与DNS、Consul、E2C、Kubernetes等进行集成实现自动发现Instance实例，并从这些Instance上获取监控数据。访问 /target 直接从Prometheus的UI中查看当前所有的任务以及每个任务对应的实例信息。 Prometheus 抓取采样值后，会自动给采样值添加一下标签和值：job 抓取所属任务、instance 抓取来源实例。 另外每次抓取时，Prometheus 还会自动在以下时序里插入采样值： up{job=&quot;&quot;, instance=&quot;&quot;}: 1 if the instance is healthy, i.e. reachable, or 0 if the scrape failed. scrape_duration_seconds{job=&quot;&quot;, instance=&quot;&quot;}: duration of the scrape. scrape_samples_post_metric_relabeling{job=&quot;&quot;, instance=&quot;&quot;}: the number of samples remaining after metric relabeling was applied. scrape_samples_scraped{job=&quot;&quot;, instance=&quot;&quot;}: the number of samples the target exposed. scrape_series_added{job=&quot;&quot;, instance=&quot;&quot;}: the approximate number of new series in this scrape. New in v2.10 Prometheus 配置完整配置文档 prometheus.yml 文件内容： 123456789101112131415161718192021222324global: # 全局配置，全局节点的配置对其他所有节点都有效，同时也是其他节点的默认值 scrape_interval: 15s # 抓取间隔 默认1min evaluation_interval: 15s # 规则评估间隔 默认1min # scrape_timeout # 抓取超时时间 默认10s alerting: # Alertmanager 的配置 alertmanagers: - static_configs: - targets: # - alertmanager:9093 rule_files: # 记录规则配置和告警规则配置 # - \"first_rules.yml\" # - \"second_rules.yml\" scrape_configs: # 抓取配置 - job_name: 'prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. static_configs: - targets: ['localhost:9090'] 抓取配置： 123456789101112131415161718192021222324252627282930313233# 任务名job_name: &lt;job_name&gt;# 抓取间隔，默认为全局配饰[ scrape_interval: &lt;duration&gt; | default = &lt;global_config.scrape_interval&gt; ]# 抓取超时时间，默认为全局配饰[ scrape_timeout: &lt;duration&gt; | default = &lt;global_config.scrape_timeout&gt; ]# 抓取地址的路径，默认为/metrics[ metrics_path: &lt;path&gt; | default = /metrics ]# 是否尊重抓取回来的标签[ honor_labels: &lt;boolean&gt; | default = false ]# 协议，默认http，可选https[ scheme: &lt;scheme&gt; | default = http ]# 抓取地址的参数params: [ &lt;string&gt;: [&lt;string&gt;, ...] ] # 目标配置 static_configs: [ - &lt;static_config&gt; ... ]# Sets the `Authorization` header on every scrape request with the# configured username and password.# password and password_file are mutually exclusive.basic_auth: [ username: &lt;string&gt; ] [ password: &lt;secret&gt; ] [ password_file: &lt;string&gt; ] ： 1234567# 目标地址列表targets: [ - '&lt;host&gt;' ]# 标签列表labels: [ &lt;labelname&gt;: &lt;labelvalue&gt; ... ] PromQLPromQL 语法数据类型 Instant vector 瞬时向量： 一组时序，每个时序只有一个采样值 Range vector 区间向量：一组时序，每个时序包含一段时间内的多个采样值 Scalar 标量：一个浮点数 String 字符串：一个字符串，暂时未用 时序选择器瞬时向量选择器选择一组时序在某个采用点的采样值。最简单的情况就是指定一个指标，选择出所有属于该度量指标的时序的当前采样值。 1http_requests_total 可以在后面添加用大括号包围起来的一组标签键值对来对时序进行过滤： 1http_requests_total&#123;job=\"prometheus\",group=\"canary\"&#125; 标签匹配时，可以使用值，也可以使用正则表达式，匹配操作符有如下四种： =: Select labels that are exactly equal to the provided string. !=: Select labels that are not equal to the provided string. =~: Select labels that regex-match the provided string. !~: Select labels that do not regex-match the provided string. 示例如下： 1http_requests_total&#123;environment=~\"staging|testing|development\",method!=\"GET\"&#125; 度量指标名称也可以使用使用内部标签__name__表示，表达式 http_requests_total 也可以写成 {__name__=&quot;http_requests_total&quot;}。表达式{__name__=~&quot;customized.*&quot;}匹配所有指标名称以customized打头的时序。 区间向量选择器与瞬时向量选择器不同的是，会在后面加上中括号包起来的指定区间长度： 1http_requests_total&#123;job=\"prometheus\"&#125;[5m] 时长单位为以下几种： s - seconds m - minutes h - hours d - days w - weeks y - years 偏移修饰器上两种选择器是是当前时间或从当前时间倒推的，若需要选择过去时间点或过去时间点倒推的，则使用偏移修饰器。 12345# 指标名称为 http_requests_total 的所有时序在5分钟前的采样值http_requests_total offset 5m# 指标名称为 http_requests_total 的在一周前的这个时间点过去5分钟的采样值http_requests_total[5m] offset 1w 二元操作符 + (addition) - (subtraction) * (multiplication) / (division) % (modulo) ^ (power/exponentiation) 传统二元运算符用在标量和标量之间，而这里可以用在向量和标量、向量和向量之间。二元操作符里的向量特指瞬时向量，不包含区间向量。 标量与标量：通常的算术运算。 向量与标量：把标量与向量里的每一个标量进行运算，结果组成一个新向量 向量与向量：左边向量里的每一个元素在右边向量里去找一个匹配元素（见向量匹配规则），然后两个匹配元素执行计算，计算结果组成一个新的向量。如果没有找到匹配元素，则该元素丢弃。 ![image-20191219181408718](/Users/john/Library/Application Support/typora-user-images/image-20191219181408718.png) 向量匹配规则有两种匹配规则：one-to-one，one-to-many/many-to-to： one-to-one：左边的向量的元素匹配到唯一一个右边元素。看标签键值对是否匹配（不看指标名称），ignoring忽略标签不参与匹配的标签，on指定参与匹配的标签。 123456789101112131415method_code:http_errors:rate5m&#123;method=\"get\", code=\"500\"&#125; 24method_code:http_errors:rate5m&#123;method=\"get\", code=\"404\"&#125; 30method_code:http_errors:rate5m&#123;method=\"put\", code=\"501\"&#125; 3method_code:http_errors:rate5m&#123;method=\"post\", code=\"500\"&#125; 6method_code:http_errors:rate5m&#123;method=\"post\", code=\"404\"&#125; 21method:http_requests:rate5m&#123;method=\"get\"&#125; 600method:http_requests:rate5m&#123;method=\"del\"&#125; 34method:http_requests:rate5m&#123;method=\"post\"&#125; 120查询：method_code:http_errors:rate5m&#123;code=\"500\"&#125; / ignoring(code) method:http_requests:rate5m执行结果：&#123;method=\"get\"&#125; 0.04 // 24 / 600&#123;method=\"post\"&#125; 0.05 // 6 / 120 one-to-many/many-to-one：某一边会有多个元素和另一边的元素匹配，需要使用group_left或group_right指明是左边还是右边元素较多： 1234567查询：method_code:http_errors:rate5m / ignoring(code) group_left method:http_requests:rate5m执行结果：&#123;method=\"get\", code=\"500\"&#125; 0.04 // 24 / 600&#123;method=\"get\", code=\"404\"&#125; 0.05 // 30 / 600&#123;method=\"post\", code=\"500\"&#125; 0.05 // 6 / 120&#123;method=\"post\", code=\"404\"&#125; 0.175 // 21 / 120 不过，这种方式过于复杂，要尽量避免使用，很多时候使用 ignoring 降为 one-to-one 的匹配。 聚和操作符用于聚和一个瞬时向量中的元素，将向量里的元素聚和的更少。 sum (calculate sum over dimensions) min (select minimum over dimensions) max (select maximum over dimensions) avg (calculate the average over dimensions) count (count number of elements in the vector) quantile (calculate φ-quantile (0 ≤ φ ≤ 1) over dimensions) stddev (calculate population standard deviation over dimensions) 标准差 stdvar (calculate population standard variance over dimensions) 方差 count_values (count number of elements with the same value) bottomk (smallest k elements by sample value) topk (largest k elements by sample value) without用来指定聚和时不需要保留的标签，by用来指定聚和时需要保留的标签（可以类比SQL中的 group by）。 http_requests_total有这三个标签 application, instance, and group ，以下两者相等： 12sum without (instance) (http_requests_total)sum by (application, group) (http_requests_total) 所有的进行求和： 1sum(http_requests_total) 函数完整见官方文档，常见的如下: abs 绝对值 sqrt 平方根 exp 指数计算 ln 自然对数 ceil 向上取整 floor 向下取整 round 四舍五入取整 delta 计算区间向量里每一个时序第一个和最后一个的差值 sort 排序 Referencehttps://songjiayang.gitbooks.io/prometheus/content/introduction/what.html https://www.bilibili.com/video/av22954995/ https://www.aneasystone.com/archives/2018/11/prometheus-in-action.html https://frezc.github.io/2019/08/03/prometheus-metrics/ https://yunlzheng.gitbook.io/prometheus-book/parti-prometheus-ji-chu/quickstart/why-monitor https://www.cnblogs.com/ryanyangcs/p/11309373.html","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"metrics","slug":"metrics","permalink":"https://weilans.github.io/tags/metrics/"}]},{"title":"[指标监控] JVM 指标框架 Micrometer","slug":"指标监控-1-JVM-指标框架-Micrometer","date":"2019-11-29T01:38:56.000Z","updated":"2019-12-19T02:26:15.761Z","comments":true,"path":"2019/11/29/指标监控-1-JVM-指标框架-Micrometer/","link":"","permalink":"https://weilans.github.io/2019/11/29/指标监控-1-JVM-指标框架-Micrometer/","excerpt":"作为 Micrometer + Prometheus + Grafana 的开篇，介绍Micrometer的基础应用。当前项目与数据库集打交道，但目前因为没有相关指标监控，项目运行情况一直是个黑盒。对于接口调用情况、连接池配置情况、性能情况若都是手动分析日志，则必然是不可行的。所以想要基于这三者搭建一台指标监控体系。","text":"作为 Micrometer + Prometheus + Grafana 的开篇，介绍Micrometer的基础应用。当前项目与数据库集打交道，但目前因为没有相关指标监控，项目运行情况一直是个黑盒。对于接口调用情况、连接池配置情况、性能情况若都是手动分析日志，则必然是不可行的。所以想要基于这三者搭建一台指标监控体系。 接触到Micrometer还是因为Spring Boot Actuator，在 Spring Boot 2.0之后，Micrometer 已经是 Actuator 的默认实现。文中默认有 Actuator 以及 Prometheus 的依赖，Actuator 在 1.x 和 2.x 区别较大，本文使用的版本是 2.1.7，且默认management.endpoints.web.exposure.include中包含 prometheus。 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;&lt;/dependency&gt; Metrics可以翻译成度量或者指标，这两者其实并无太大区别，只是各适用于特定场景而已，本文中统一叫作指标。 介绍Micrometer首页这么介绍自己： Micrometer provides a simple facade over the instrumentation clients for the most popular monitoring systems, allowing you to instrument your JVM-based application code without vendor lock-in. Think SLF4J, but for metrics. 不同的监控体系有不同的数据收集、命名规约、三方依赖，Micrometer 的定位就是监控系统的 Facade，类比于日志系统的 Slf4j，Micrometer 可以很好地完成针对不同监控系统的适配与切换，使指标数据可移植性最大化。在Maven仓库中，可以看到各类 Registry (mvn, github)。 RegistryMeter是 Micrometer 最基础的接口，使用 Micrometer 时最常用的 Timer、Counter、Guage、DistributionSummary就是继承自该接口，收集的系统数据就是用 Meter 来表示。Meter 在 Micrometer 中由 MeterRegistry创建并保存，每个支持的监控系统都有一个MeterRegistry实现（Prometheus的实现是PrometheusMeterRegistry）。如果事先没有指定监控系统，Micrometer 默认生成一个将 Meter 最新数据保留在内存的SimpleMeterRegistry。 在SimpleMetricsExportAutoConfiguration中就可以看到 SimpleMeterRegistry 的配置，该类包含: @ConditionalOnMissingBean(MeterRegistry.class)。 1234SimpleMeterRegistry simple = new SimpleMeterRegistry();Counter counter = simple.counter(\"counter\");counter.increment();System.out.println(counter.count()); // 1.0 除了作为基础实现的SimpleMeterRegistry外，Micrometer 提供CompositeMeterRegistry，可将多个 MeterRegistry 加入其中，使 Meter 数据同时发送到不同监控系统。 1234567891011121314CompositeMeterRegistry composite = new CompositeMeterRegistry();Counter compositeCounter = composite.counter(\"counter\");compositeCounter.increment(); // no opSystem.out.println(compositeCounter.count()); // 0.0SimpleMeterRegistry simple1 = new SimpleMeterRegistry();composite.add(simple1);SimpleMeterRegistry simple2 = new SimpleMeterRegistry();composite.add(simple2);compositeCounter.increment();System.out.println(simple1.counter(\"counter\").count()); // 1.0System.out.println(simple2.counter(\"counter\").count()); // 1.0 此外，Micrometer 还持有一个Global MeterRegistry：Metrics.globalRegistry，其也是一个 CompositeMeterRegistry。如果没有引入 Prometheus 的依赖，Metrics.globalRegistry 中包含的就是 SimpleMeterRegistry，MeterRegistryPostProcessor会将生成的系统初始生成的 SimpleMeterRegistry 注入进全局 Registry 中。如果引入了 Prometheus 的依赖，注入进全局 Registry 的就是 PrometheusMeterRegistry。 12345678public class Metrics &#123; public static final CompositeMeterRegistry globalRegistry = new CompositeMeterRegistry(); public static void addRegistry(MeterRegistry registry) &#123; globalRegistry.add(registry); &#125; //...&#125; 命名MeterMicrometer 中规定单词用.(dot)隔开，而不同监控系统的命名规范并不一致，例如在 Micrometer 中可以这样命名一个 Meter： 1registry.timer(\"http.server.requests\"); 在不同监控系统中则应该是： system name Prometheus http_server_requests_duration_seconds Atlas httpServerRequests Graphite http.server.requests InfluxDB http_server_requests 所以需要一种命名转换体系将 Micrometer 中的命名转为特定系统的规范命名，Micrometer 提供了 NamingConvention供各系统实现，开发者可以使用以下方式自定义命名规则： 1registry.config().namingConvention(myCustomNamingConvention); Tag既然有了指标，则必然包含维度的概念，只有使用不同的维度才能对指标进行更好的区分和收集。Micrometer 中 Tag 就扮演了这样的角色。 12registry.counter(\"database.calls\", \"db\", \"users\") // database.calls即为自行定义的指标, 而维度就是db, 含义即为db为users的数据库调用次数registry.counter(\"http.requests\", \"uri\", \"/api/users\") // uri为/api/users的http请求次数 Tag 参数必须以 TagKey=TagValue 的方式成对出现。当命名 Tag 时，也建议使用和 Meter 一样的 dot 命名方式。同时，Tag value 必须是非空。 此外，还有一种Common tags，对于每种 Meter，都会将 Tag 加入其中，一般用于指定 IP、实例、地区等信息，便于数据收集后进行区分。 1registry.config().commonTags(\"stack\", \"prod\", \"region\", \"us-east-1\"); Meter filtersMeterRegistry 提供 Meter Filter，可以控制 Meter 的注册以及忽略特定统计行为。官方示例如下： 123registry.config() .meterFilter(MeterFilter.ignoreTags(\"too.much.information\")) .meterFilter(MeterFilter.denyNameStartsWith(\"jvm\")); 针对Filter进行简单的试验： 1234567891011121314151617SimpleMeterRegistry simple1 = new SimpleMeterRegistry();simple1.config() .meterFilter(MeterFilter.ignoreTags(\"db2\", \"db3\")) .meterFilter(MeterFilter.denyNameStartsWith(\"jvm\"));Counter c1 = simple1.counter(\"database.calls\", \"db1\", \"users\");Counter c2 = simple1.counter(\"database.calls\", \"db2\", \"users\");Counter c3 = simple1.counter(\"database.calls\", \"db3\", \"users\");Counter c4 = simple1.counter(\"jvm.requests\", \"uri\", \"/api/users\");c1.increment();c2.increment();c3.increment();c4.increment();List&lt;Meter&gt; meters = simple1.getMeters();for (Meter meter : meters) &#123; System.out.println(meter.getId() + \" \" + meter.measure());&#125; 其输出结果为： 12MeterId&#123;name='database.calls', tags=[]&#125; [Measurement&#123;statistic='COUNT', value=2.0&#125;]MeterId&#123;name='database.calls', tags=[tag(db1=users)]&#125; [Measurement&#123;statistic='COUNT', value=1.0&#125;] 可以看见jvm.requests直接被过滤了，而 Tag db2和db3由于被忽略了，其值添加到了name=&#39;database.calls&#39;, tags=[]中，其 count值为 2.0。 Meter filters 有很多复杂的功能，此处就不展开了。 Meter类别CounterCounter 是最简单的 Meter，其含义即为单值递增计数器，值必须是正数。 对于每种 Meter 而言，各有一套 fluent api 创建实例，Counter 的示例如下： 1234567Counter counter = Counter .builder(\"counter\") .baseUnit(\"beans\") // optional .description(\"a description of what this counter does\") // optional .tags(\"region\", \"test\") // optional .register(registry);counter.increment(); FunctionCounter实际上和Counter本身差别不大，只是将计数的行为抽象成 ToDoubleFunction 接口。 比如上下文中有一个 AtomicInteger ，那么 FunctionCounter 可以直接使用这个原子类来完成相关计数操作。这样的好处是对程序上下文而言，不需要感知该 Meter 的存在。 12345678910111213141516MeterRegistry registry = new SimpleMeterRegistry();AtomicInteger ai = new AtomicInteger(0);FunctionCounter counter = FunctionCounter.builder(\"counter\", ai, AtomicInteger::get) .description(\"functionCounterTest\") .tag(\"region\", \"ABC\") .register(registry);ai.incrementAndGet();ai.incrementAndGet();ai.incrementAndGet();System.out.println(ai.get()); // 3System.out.println(counter.measure()); // [Measurement&#123;statistic='COUNT', value=3.0&#125;]ai.set(100);System.out.println(ai.get()); // 100System.out.println(counter.measure()); // [Measurement&#123;statistic='COUNT', value=100.0&#125;] Guage记录指标的当前值，其典型应用是集合或Map的大小、线程的数量、CPU或内存情况。Guages 主要适用于有上边界的指标，要将其和 Counter 区分开。其Fluent Api 接口同样是将计数逻辑交给 ToDoubleFunction 接口。 123456789List&lt;String&gt; list = new ArrayList&lt;&gt;();Gauge gauge = Gauge .builder(\"gauge\", list, List::size) .description(\"description\") // optional .tags(\"region\", \"test\") // optional .register(registry);System.out.println(gauge.measure()); // [Measurement&#123;statistic='VALUE', value=0.0&#125;]list.add(\"\");System.out.println(gauge.measure()); // [Measurement&#123;statistic='VALUE', value=1.0&#125;] 官方文档中还提供了用于观察数值、集合、Map的方法： 123456// &lt;T&gt; T gauge(String name, Iterable&lt;Tag&gt; tags, @Nullable T obj, ToDoubleFunction&lt;T&gt; valueFunction)List&lt;String&gt; list = registry.gauge(\"listGauge\", Collections.emptyList(), new ArrayList&lt;&gt;(), List::size); // &lt;T extends Collection&lt;?&gt;&gt; T gaugeCollectionSize(String name, Iterable&lt;Tag&gt; tags, T collection)List&lt;String&gt; list2 = registry.gaugeCollectionSize(\"listSize2\", Tags.empty(), new ArrayList&lt;&gt;()); // &lt;T extends Map&lt;?, ?&gt;&gt; T gaugeMapSize(String name, Iterable&lt;Tag&gt; tags, T map)Map&lt;String, Integer&gt; map = registry.gaugeMapSize(\"mapGauge\", Tags.empty(), new HashMap&lt;&gt;()); Micrometer 默认是不会创建对象的强引用（可以观察抽象类 MeterRegistry 的 newGauge 具体实现），如果 Guage 值无法观察到，那可能是对象已被执行垃圾回收。 TimerTimer 用于记录时间相对较短的事件延迟情况和事件发生的频率，Timer 的所有实现至少记录了事件总时间消耗以及次数。以记录请求延时情况为例，由于可能瞬时记录大量信息，所以Timer每秒将更新很多次。 123456789Timer timer = Timer .builder(\"my.timer\") .description(\"a description of what this timer does\") // optional .tags(\"region\", \"test\") // optional .register(registry);timer.record(12, TimeUnit.SECONDS);timer.record(2, TimeUnit.SECONDS);timer.record(23, TimeUnit.SECONDS);System.out.println(timer.measure()); // [Measurement&#123;statistic='COUNT', value=3.0&#125;, Measurement&#123;statistic='TOTAL_TIME', value=37.0&#125;, Measurement&#123;statistic='MAX', value=23.0&#125;] Timer 可以记录代码的执行耗时，其接收 Runnable 以及 Callable 参数。这个可以按照实际需要决定是否需要，个人不喜欢将执行代码的线程更换掉（还得考虑ThreadLocal及其他上下文情况），但不否认其拥有应用场景。 12345timer.record(() -&gt; dontCareAboutReturnValue());timer.recordCallable(() -&gt; returnValue());Runnable r = timer.wrap(() -&gt; dontCareAboutReturnValue());Callable c = timer.wrap(() -&gt; returnValue()); Timer 还有个内部类Timer.Sample，可以通过手动调用 start 和 stop 记录执行情况： 1234Timer.Sample sample = Timer.start(registry);// do stuffResponse response = ...sample.stop(registry.timer(\"my.timer\", \"response\", response.status())); Distribution summariesdistribution summary 用来追踪事件的分布情况，其结构和 Timer 类似，但是其值不是由时间单位表示，也可以认为 Timer 只是特例化的 distribution summary ，但是 Micrometer 会针对监控系统自动适配存放时间序列的基本单位，所以只要是关于时间的指标，官方建议都使用 Timer。 官方示例的 Fluent API 使用如下： 1234567DistributionSummary summary = DistributionSummary .builder(\"response.size\") .description(\"a description of what this summary does\") // optional .baseUnit(\"bytes\") // optional (1) .tags(\"region\", \"test\") // optional .scale(100) // optional (2) .register(registry); 添加 baseUnit 可以进一步提升整体的可移植性，因为 baseUnit 本身是监控系统命名转换的一部分，但如果省略它，也不会有负面影响。scale 作为比例因子，用来乘以所有的记录值。 Timers 和 distribution summaries 都支持收集数据后观察比例分布信息，有两种使用形式：一是直方图(histogram)，即分配一堆桶，观察数据在各个桶的分布情况；二是百分比(percentiles)，系统会为每一个 Meter 计算一个百分比近似值。以下面这个分布摘要在 Prometheus 中的展示为例： 1234567891011121314151617DistributionSummary summary = DistributionSummary.builder(\"ds.test\") .description(\"simple distribution summary\") .publishPercentiles(0.5, 0.6, 0.95) .publishPercentileHistogram() .minimumExpectedValue(1L) .maximumExpectedValue(30L) .register(meterRegistry);summary.record(2);summary.record(2);summary.record(2);summary.record(2);summary.record(2);summary.record(5);summary.record(5);summary.record(5);summary.record(5);summary.record(9); 除了 max / count / sum 这三种数据外，还会显示 quantile 信息以及直方图的桶信息。publishPercentiles即表示记录百分位数值，publishPercentileHistogram表示记录直方图信息，而桶的个数可以由minimumExpectedValue和maximumExpectedValue控制。 此外，还有一个sla方法，包含的桶信息会包含 sla 指定的数值。举例而言，下方的图中就包含了 18 和 19 两个桶。 12345678DistributionSummary summary = DistributionSummary.builder(\"ds.test\") .description(\"simple distribution summary\") .publishPercentiles(0.5, 0.6, 0.95) .publishPercentileHistogram() .minimumExpectedValue(1L) .maximumExpectedValue(30L) .sla(18, 19) .register(meterRegistry); Timer 的 Histogram 和 Percentiles 使用也完全类似： 1234567891011121314151617Timer timer = Timer.builder(\"my.timer\") .publishPercentiles(0.5, 0.95) .publishPercentileHistogram() .sla(Duration.ofMillis(200)) .minimumExpectedValue(Duration.ofMillis(1)) .maximumExpectedValue(Duration.ofSeconds(1)) .register(meterRegistry);timer.record(8, TimeUnit.MILLISECONDS);timer.record(9, TimeUnit.MILLISECONDS);timer.record(7, TimeUnit.MILLISECONDS);timer.record(8, TimeUnit.MILLISECONDS);timer.record(58, TimeUnit.MILLISECONDS);timer.record(56, TimeUnit.MILLISECONDS);timer.record(157, TimeUnit.MILLISECONDS);timer.record(299, TimeUnit.MILLISECONDS);timer.record(599, TimeUnit.MILLISECONDS);timer.record(1999, TimeUnit.MILLISECONDS); 其他简单吐槽一下，相同名称、不同 Tag 的数据不能聚和，其设计初衷可能就是让数据由上层应用处理。 Actuator 的 /metrics/logback.events 接口，对应的 Meter 是LogbackMetrics，可以看到内部 Meter 命名相同，但 Tag 不同。但是这个 uri 显示的 measurements 是聚和的，开始我以为有没发现的 API 操作，查看MetricsEndpoint后发现，聚和操作也是由该类自己完成的。 Referencehttps://micrometer.io/docs/concepts https://www.throwable.club/2018/11/17/jvm-micrometer-prometheus/ http://yongyao.li/blog/article/使用micrometer进行业务指标上报","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"metrics","slug":"metrics","permalink":"https://weilans.github.io/tags/metrics/"}]},{"title":"[回顾并发基础] 原子操作类","slug":"并发札记-8-原子操作类","date":"2019-10-08T10:49:34.000Z","updated":"2019-12-19T11:54:00.448Z","comments":true,"path":"2019/10/08/并发札记-8-原子操作类/","link":"","permalink":"https://weilans.github.io/2019/10/08/并发札记-8-原子操作类/","excerpt":"介绍了原子操作类，以AtomicLong介绍原子类的实现，并对原子类的分类和使用（基本数据类型、引用类型、对象属性更新器、数组、累加器）进行说明。","text":"介绍了原子操作类，以AtomicLong介绍原子类的实现，并对原子类的分类和使用（基本数据类型、引用类型、对象属性更新器、数组、累加器）进行说明。 简介JUC中对于简单的原子性问题提炼封装成一系列的原子类，这是一种无锁方案。相对于互斥锁而言，其最大的好处早会性能，互斥锁为了保证互斥性，需要执行加锁、解锁操作，而加锁、解锁操作本身就消耗性能；同时拿不到锁的线程还会进入阻塞状态，进而触发线程切换，线程切换对性能的消耗也很大。 相比之下，无锁方案则完全没有加锁、解锁的性能消耗，同时还能保证互斥性。 原子类使用到了硬件的支持，CPU为了解决并发问题，提供了CAS (Compare And Swap) 指令，CAS 指令包含三个参数：共享变量的内存地址 A、用于比较的值 B 和 共享变量的新值 C。只有内存地址中 A 处的值等于 B 时，才能将内存地址 A 处的值更新为新值 C。且作为一条 CPU 指令，CAS 本身能够保证原子性。 当然，CAS 不是完美无缺的。CAS 方案会有 ABA 问题，即值被更新后，后又被更新为原值。是否需要关系 ABA 问题也需要依照特定情况而言，可以使用版本号标识解决 ABA 问题，后续会进行介绍。 实现Atomic包里的类基本都是使用Unsafe实现的包装类。接下来以AtomicLong的方式先介绍典型实现。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class AtomicLong extends Number implements java.io.Serializable &#123; private static final long serialVersionUID = 1927816293512124184L; // 获取Unsafe示例 private static final Unsafe unsafe = Unsafe.getUnsafe(); // 存放变量value的偏移量 private static final long valueOffset; // 判断JVM是否支持Long类型无锁CAS static final boolean VM_SUPPORTS_LONG_CAS = VMSupportsCS8(); private static native boolean VMSupportsCS8(); static &#123; try &#123; // 获取value在AtomicLong中的偏移量 valueOffset = unsafe.objectFieldOffset(AtomicLong.class.getDeclaredField(\"value\")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; // 实际变量值value private volatile long value; public AtomicLong(long initialValue) &#123; value = initialValue; &#125; public AtomicLong() &#123;&#125; // 调用unsafe方法, 原子性设置value值为原始值＋1, 返回值为原始值。这里 this 和 valueOffset 两个参数可以唯一确定共享变量的内存地址。 public final long getAndIncrement() &#123; return unsafe.getAndAddLong(this, valueOffset, 1L); &#125; // 调用unsafe方法, 原子性设置value值为原始值＋1, 返回值为递增后的值 public final long incrementAndGet() &#123; return unsafe.getAndAddLong(this, valueOffset, 1L) + 1L; &#125; // 原子类的重要方法，更新成功返回true, 失败则返回false public final boolean compareAndSet(long expect, long update) &#123; return unsafe.compareAndSwapLong(this, valueOffset, expect, update); &#125; ...&#125;// Unsafe的getAndAddLong方法public final long getAndAddLong(Object var1, long var2, long var4) &#123; long var6; do &#123; var6 = this.getLongVolatile(var1, var2); &#125; while(!this.compareAndSwapLong(var1, var2, var6, var6 + var4)); return var6;&#125;// Unsafe的compareAndSwapLong方法public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6); 上述getAndAddLong方法就是 CAS 经典使用案例。可以看出，使用 CAS 来解决并发问题一般都会伴随着自旋。一般的无锁代码经常会采用如下的方式，使用的是compareAndSet方法。 123456do &#123; // 获取当前值 oldV = xxxx； // 根据当前值计算新值 newV = ...oldV...&#125; while (!compareAndSet(oldV, newV); 分类原子类可以按照以下的方式进行划分： 类型 具体类 基本数据类型 AtomicBoolean、AtomicInteger、AtomicLong 引用类型 AtomicReference、AtomicStampedReference、AtomicMarkableReference 对象属性更新器 AtomicIntegerFieldUpdater、AtomicLongFieldUpdater、AtomicReferenceFieldUpdater 数组 AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray 累加器 DoubleAccumulator、DoubleAdder、LongAccumulator、LongAdder AtomicIntegerArray将数组value传递给构造方法，然后会将当前数组复制一份，所以当AtomicIntegerArray对内部的数组元素进行修改时，不会影响传入的数组。 1234567public static void main(String[] args) &#123; int[] value = new int[]&#123;1, 2&#125;; AtomicIntegerArray ai = new AtomicIntegerArray(value); System.out.println(ai.getAndSet(0, 3)); // 1 System.out.println(ai.get(0)); // 3 System.out.println(value[0]); // 1&#125; 原子更新基本类型只能更新一个变量，如果要原子更新多个变量，就需要使用原子更新引用类型提供的类，以AtomicReference举例： 123456789101112131415161718192021222324252627public static void main(String[] args) &#123; AtomicReference&lt;User&gt; atomicUserRef = new AtomicReference&lt;&gt;(); User user = new User(\"user1\", 25); atomicUserRef.set(user); User updateUser = new User(\"user2\", 26); atomicUserRef.compareAndSet(user, updateUser); System.out.println(atomicUserRef.get().getName()); System.out.println(atomicUserRef.get().getAge());&#125;static class User &#123; private String name; private int age; public User(String name, int age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public int getAge() &#123; return age; &#125;&#125; 上文提到解决ABA问题可以使用版本号，只要保证版本号是递增的，那么即便 A 变成 B 之后再变回 A，版本号也不会变回来。AtomicStampedReference 实现的 CAS 方法就增加了版本号参数，方法签名如下： 12345boolean compareAndSet( V expectedReference, V newReference, int expectedStamp, int newStamp) 123456789public static void main(String[] args) &#123; // initialStamp 为 0 AtomicStampedReference&lt;String&gt; reference = new AtomicStampedReference&lt;&gt;(\"Atomic\", 0); int stamp = reference.getStamp(); String obj = reference.getReference(); System.out.println(reference.compareAndSet(obj, \"AtomicNew\", stamp, stamp + 1)); // true System.out.println(reference.getReference()); // AtomicNew System.out.println(reference.getStamp()); // 1&#125; AtomicMarkableReference 的实现机制则更简单，将版本号简化成了一个 Boolean 值，方法签名如下： 12345boolean compareAndSet( V expectedReference, V newReference, boolean expectedMark, boolean newMark) 如果需要原子地更新某个类里的某个字段时，可以使用原子更新字段类，以AtomicIntegerFieldUpdater举例： 1234567891011121314151617181920212223242526272829303132public static void main(String[] args) &#123; // 创建原子更新器, 并设置需要更新的对象类和对象的属性 AtomicIntegerFieldUpdater&lt;User&gt; updater = AtomicIntegerFieldUpdater .newUpdater(User.class, \"age\"); User conan = new User(\"user1\", 25); System.out.println(updater.getAndIncrement(conan)); System.out.println(updater.get(conan)); &#125; static class User &#123; private String name; /** * 更新类的属性必须使用 public volatile 修饰符 **/ public volatile int age; public User() &#123; &#125; public User(String name, int age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public int getAge() &#123; return age; &#125; &#125; DoubleAccumulator、DoubleAdder、LongAccumulator 和 LongAdder，这四个类仅仅用来执行累加操作，相比原子化的基本数据类型，速度更快，但是不支持 compareAndSet() 方法。如果你仅仅需要累加操作，使用原子化的累加器性能会更好。JDK8 之所以会新增这些类，是因为：原子类在高并发下大量线程会同时取竞争更新同一个原子变量，但由于只有一个线程 CAS 成功，就会造成大量线程竞争失败，会通过无限循环不断进行自旋尝试 CAS 操作，而这会浪费CPU资源。 以 LongAdder 为例，既然 AtomicLong 性能瓶颈在于多线程竞争一个变量的更新而产生的，那就把一个变量分解为多个变量，让多线程竞争多个资源。LongAdder 就是以这种方式进行设计的，其内部维护着一个延迟初始化的原子性更新数组（默认情况下Cell 数组是null）和一个基值变量base： 其内部维护多个 Cell 变量，每个 Cell 有一个初始值为 0 的 long 类型变量，同等并发量的情况下争夺单个变量的线程量会减少。 此外，多个线程争夺同一个 Cell 失败后并不会在当前在当前 Cell 变量上一直自旋 CAS 重试，而是尝试在其他 Cell 的变量上进行 CAS 尝试，以增加当前线程重试 CAS 成功的概率。 当最后获取累加值时就是将所有 Cell 变量的 value 值累加后加上 base 后返回的。 原子性数组元素的内存地址是连续的，所以数组内的多个元素能经常共享缓存行，因此使用＠sun.misc.Contended 注解对 Cell 类进行字节填充，以避免数组中多个元素共享缓存行（避免伪共享）。 关于伪共享 为了解决CPU和主内存间的速度差异，之间会添加一级或多级告诉缓冲存储器（Cache），而 Cache 内部是按行存储的，每行称为一个 Cache 行，Cache 行的大小一般为 2 的幂次数字节，这是 Cache 与主内存进行数据交换的单位。 当CPU访问变量不存在时，先去 Cache 中看存不存在，没有的话就去内存取，然后将该变量所在内存区域（大小相当于 Cache 行大小）复制到 Cache 中，注意不是复制单个变量而是复制内存块。当多个线程同时修改一个缓存行里面的多个变量时，由于每时刻只能有一个线程操作缓存行，所以相对于将每个变量放到单独缓存行中，性能会有所下降，这就是伪共享。 当两个不同线程同时进行操作时，线程1使用CPU1更新变量x，那么在缓存一致性协议下，CPU2中变量x对应的缓存行会失效，线程2想要对与x在同一缓存行中的y进行操作时，就只能去下一级缓存中寻找。 一般通过字节填充的方式解决伪共享，JDK8 中提供 @sun.misc.Contended注解就可解决伪共享，可用于修饰类，也可以修饰变量。此注解只能用于 rt 包下的核心类，用户类路径下想使用，需要添加 JVM 参数：-XX:-RestrictContended。填充的宽度默认为128 ，要自定义宽度则可以设置-XX:ContendedPaddingWidth 参数。 （from 《Java并发编程之美》） Referencehttps://time.geekbang.org/column/article/90515 《Java并发编程的艺术》 《Java并发编程之美》","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"https://weilans.github.io/tags/concurrent/"}]},{"title":"[回顾并发基础] JUC中的并发队列","slug":"并发札记-7-JUC中的并发队列","date":"2019-10-05T09:34:40.000Z","updated":"2019-12-19T11:53:54.952Z","comments":true,"path":"2019/10/05/并发札记-7-JUC中的并发队列/","link":"","permalink":"https://weilans.github.io/2019/10/05/并发札记-7-JUC中的并发队列/","excerpt":"SynchronousQueue: 一个不存储元素的阻塞队列；","text":"SynchronousQueue: 一个不存储元素的阻塞队列； JUC中的并发队列阻塞队列可以用于多线程间的数据共享，支持阻塞的插入（队列慢时，队列开始阻塞插入元素的线程，直到队列不满）以及阻塞的移除（队列为空时，获取元素线程会等待队列变为非空）。 方法/处理方式 抛出异常 返回特殊值 阻塞 超时退出 插入 add offer(e) put offer(e, time, unit) 移除 remove poll() take poll(time, unit) 查看 element peek \\ \\ 常见的阻塞队列包括： Class 描述 ArrayBlockingQueue 由数组结构组成的有界阻塞队列 LinkedBlockingQueue 由链表结构组成的有界阻塞队列 PriorityBlockingQueue 支持优先级排序的无界阻塞队列 DelayQueue 使用优先级队列实现的无界阻塞队列 SynchronousQueue 不存储元素的阻塞队列 LinkedTransferQueue 由链表结构组成的无界阻塞队列 LinkedBlockingDeque 由链表结构组成的双向阻塞队列 ArrayBlockingQueue数组实现，有界，阻塞由ReentrantLock实现，默认非公平。其代码是生产者消费者的典型实现。 其内部有一个数组 items 用来存放队列元素，putIndex 表示入队元素下标， takeIndex 表示出队下标， count 统计队列元素个数。且这些变量并没有使用 volatile 修饰，这也是因为访问这些变量都是在锁块内，加锁己经保证了锁块内变量的内存可见性了。另外， notEmpty 、notFull 条件变量用来进行出、入队的 Condition。 LinkedBlockingQueue链表实现，无界，默认及最大长度为Integer.MAX_VALUE，但用户可以指定容量，所以一定长度上来讲，LinkedBlockingQueue是有界阻塞的。 1234567891011121314151617/** The capacity bound, or Integer.MAX_VALUE if none */private final int capacity;/** Current number of elements */private final AtomicInteger count = new AtomicInteger();/** Head of linked list. Invariant: head.item == null */transient Node&lt;E&gt; head;/** Tail of linked list. Invariant: last.next == null */private transient Node&lt;E&gt; last;/** Lock held by take, poll, etc */private final ReentrantLock takeLock = new ReentrantLock();/** Wait queue for waiting takes */private final Condition notEmpty = takeLock.newCondition();/** Lock held by put, offer, etc */private final ReentrantLock putLock = new ReentrantLock();/** Wait queue for waiting puts */private final Condition notFull = putLock.newCondition(); LinkedBlockingQueue 使用单向链表实现，有分别代表队首和对尾的 Node，有一个记录队列元素个数的原子变量 count 和容量大小 capacity。此外，有两个 ReentrantLock，takeLock 用来控制只有一个线程可以从队列头部获取元素，putLock 用来控制同时只能有一个线程在队列尾部添加元素，故出队与入队可以同时进行。notEmpty 和 notFull 是对应两个锁的 Condition。 下面的代码看起来和 ArrayBlockingQueue 类似，实则思路完全不同。由于有两个锁，每个锁对应一个 Condition，需重点关注 Condition 的 await 和 signal 操作。 1234567891011121314151617181920212223242526272829303132333435363738public void put(E e) throws InterruptedException &#123; // null元素抛空指针错误 if (e == null) throw new NullPointerException(); int c = -1; // 构造节点，开始获取锁 Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try &#123; // 队满则等待 while (count.get() == capacity) &#123; notFull.await(); &#125; // 进队列 enqueue(node); // 递增计数 c = count.getAndIncrement(); // 若还可以继续放，则继续唤醒下一个 if (c + 1 &lt; capacity) notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125; // 队列里至少有一个元素了，通知非空 if (c == 0) signalNotEmpty();&#125;private void signalNotEmpty() &#123; final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try &#123; notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536public E take() throws InterruptedException &#123; E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; // 获取锁 takeLock.lockInterruptibly(); try &#123; // 无元素，挂起 while (count.get() == 0) &#123; notEmpty.await(); &#125; // 出队 计数减一 x = dequeue(); c = count.getAndDecrement(); // 若还可以继续拿的，则继续唤醒下一个 if (c &gt; 1) notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125; // 队列里至少有一个元素被拿掉，队列必不满，通知非满 if (c == capacity) signalNotFull(); return x;&#125;private void signalNotFull() &#123; final ReentrantLock putLock = this.putLock; putLock.lock(); try &#123; notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125;&#125; PriorityBlockingQueue带优先级的无界阻塞队列。 SynchronousQueue描述SynchronousQueue 是一个 不存储元素的阻塞队列，每一个 put 操作必须等待一个 take 操作，否则不能继续添加队列。其可以看作是一个传球手，负责把生产者线程处理的数据直接传递给消费者线程，队列本身不存储任何元素，非常适合传递性场景。SynchronousQueue 吞吐量高于 LinkedBlockingQueue 和 ArrayBlockingQueue。 由于没有容量，所以对应 peek、contains、clear、isEmpty 等方法其实是无效的：clear 是不执行任何操作的，contains始终返回false，peek始终返回null，peek方法直接返回null。 SynchronousQueue 直接使用 CAS 实现线程的安全访问，队列的实现策略分为公平模式和非公平模式，默认情况下线程采用非公平模式访问队列，是否公平可以在构造函数中指定。 方法 描述 void put(E o) 向队列提交一个元素,阻塞直到其他线程take或者poll此元素. boolean offer(E o) 向队列中提交一个元素,如果此时有其他线程正在被take阻塞(即其他线程已准备接收)或者”碰巧”有poll操作,那么将返回true,否则返回false E take() 获取并删除一个元素,阻塞直到有其他线程offer/put boolean poll() 获取并删除一个元素,如果此时有其他线程正在被put阻塞(即其他线程提交元素正等待被接收)或者”碰巧”有offer操作,那么将返回true,否则返回false E peek() 总会返回null,硬编码 比如，先offer一个值（其返回值是false），3s后进行 take 操作，则会一直阻塞。传统阻塞队列如 ArrayBlocking 则会在 offer 时返回 true，take 时成功拿到值并返回。 实现实现层面最关键的是E transfer(E e, boolean timed, long nanos)方法，put 和 take 方法都会使用该方法。当参数 e 为非空时，表示当前值传递给一个消费者，若为空则表示当前操作需要请求一个数据。timed 参数决定是否存在 timeout 时间， nanos 决定了 timeout 的时长。如果返回值非空，则表示数据已经接受或者正常提供，如果为空，则表示失败（超时或者中断）。 由于大量 CAS 代码，很难进行深层次细节理解，这里简单说明实现概述。主要使用LockSupport来控制线程，使用CAS来控制 head 元素。 公平模式： 内部实现为 TransferQueue，它有一个 head 和 tail 指针。生成新 TransferQueue 对象时时，head 和 tail 指向新生成的虚拟节点；线程 put1 执行 put()操作，由于当前没有配对的消费线程，创建节点，并阻塞进程（线程是 QNode 中的属性），tail 指向 put1；线程 put2 执行了 put() 操作，跟前面一样，执行阻塞操作，tail 指向 put2。当来了一个线程 take1，执行了 take 操作时，tail 指向的 put2 跟 take1 线程配对，但此时需要唤醒的是 put1线程（即队尾匹配队头出队）。 123456static final class QNode &#123; volatile QNode next; // next node in queue volatile Object item; // CAS'ed to or from null volatile Thread waiter; // to control park/unpark final boolean isData;&#125; 非公平模式： 内部实现为TransferStack，实现中用 head 指针指向栈顶。线程 put1 执行 put() 操作，由于当前没有配对的消费线程，所以 put1 线程会入栈，创建一个 node 为 DATA 的元素，并阻塞进程；线程 put2 再次执行 put() 操作，跟前面一样，put2 线程会建成节点并入栈；此时来了线程 take1，执行了 take 操作，这时候发现栈顶为 put2 线程，会创建 FULFILL 节点把 take1 线程入栈，并尝试设置 put2 为 take1 的匹配节点(tryMatch)，设置成功会激活等待线程，两个节点弹出。 123456789101112131415static final class SNode &#123; volatile SNode next; // next node in stack volatile SNode match; // the node matched to this volatile Thread waiter; // to control park/unpark Object item; // data; or null for REQUESTs int mode;&#125;/* Modes for SNodes, ORed together in node fields *//** Node represents an unfulfilled consumer */static final int REQUEST = 0;/** Node represents an unfulfilled producer */static final int DATA = 1;/** Node is fulfilling another unfulfilled DATA or REQUEST */static final int FULFILLING = 2; Referencehttps://www.iteye.com/blog/shift-alt-ctrl-1840385 https://zhuanlan.zhihu.com/p/29227508","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"https://weilans.github.io/tags/concurrent/"}]},{"title":"[HikariCP] HikariCP为什么快","slug":"HikariCP-1-高性能的秘密","date":"2019-10-04T10:12:07.000Z","updated":"2019-12-27T06:06:41.897Z","comments":true,"path":"2019/10/04/HikariCP-1-高性能的秘密/","link":"","permalink":"https://weilans.github.io/2019/10/04/HikariCP-1-高性能的秘密/","excerpt":"“Simplicity is prerequisite for reliability.”","text":"“Simplicity is prerequisite for reliability.” HikariCP 的诞生Hikari日语发音是Hi-ka-li，翻译成“光”，赋予两个含义：速度快，代码量少。作者 Brett Wooldridge 在工作时发现使用已有连接池时发现死锁问题，检查源码时发现存在大量的锁和嵌套。此外，Brett Wooldridge 研究的所有池都以多种方式违反了JDBC规约。当连接关闭或者返回，或者清除警告，或者回滚未提交的事务时，这些连接池并不会自动关闭语句Statements。并且它们不会重置用户更改的属性，如自动提交或事务隔离级别，以及更多的一些参数，从而导致下一个消费者获得将“脏”连接。“难道这就是 Java 20 年后生态系统中连接池的状态？”出于挫败感和必要性，Brett Wooldridge 创建了 HikariCP。目前，SpringBoot 2.x 已经官方宣布使用 HikariCP 作为 SpringBoot 默认的数据库连接池。 HikariCP 为什么快HikariCP是一款快到极致的数据库连接池。在 HikariCP Github Wiki 详细了介绍HikariCP所做的优化，总结如下： 优化并精简字节码、优化代码和拦截器。 使用 FastList 替代 ArrayList。 更好的并发集合类实现 ConcurrentBag。 其他针对BoneCP缺陷的优化，比如对于耗时超过一个CPU时间片的方法调用的研究。 FastList执行完数据库操作之后，往往需要依次关闭 ResultSet、Statement、Connection，而开发者经常只关闭了 Connection，而忘了关闭 ResultSet 和 Statement。为了解决这种问题，最好的办法是当关闭 Connection 时，能够自动关闭 Statement。为了达到这个目标，Connection 就需要跟踪创建的 Statement，因此可以将创建的 Statement 保存在 List 里，这样当关闭 Connection 的时候，就可以依次将 List 里所有 Statement 关闭。 HikariCP 觉得 ArrayList 存在不足，自己开发了一个 List 接口的精简实现 —— FastList： ArrayList 每次调用 get() 方法时都会进行rangeCheck，检查索引是否越界，FastList 的实现中去除了这一检查。 1234567891011121314// In ArrayListpublic E get(int index) &#123; rangeCheck(index); return elementData(index);&#125;private void rangeCheck(int index) &#123;//这里有rangeCheck if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;// In FastListpublic T get(int index) &#123;//这里的get方法取消了rangeCheck return elementData[index]; &#125; 当 Statement 关闭或 Connection 关闭时需要将对应的 Statement 从 List 中移除。通常情况下，JDBC 在同一个 Connection 创建了多个 Statement 时，后打开的 Statement 会先关闭，这种情况从尾部开始扫描将表现更好，FastList 从尾部到头部执行移除扫描。 1234567891011121314151617181920212223242526272829303132// In ArrayListpublic boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) // 从头到尾遍历 if (elementData[index] == null) &#123; fastRemove(index);// 从头到尾移除 return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false;&#125;// In FastListpublic boolean remove(Object element) &#123; for (int index = size - 1; index &gt;= 0; index--) &#123; // 从尾部遍历 if (element == elementData[index]) &#123; final int numMoved = size - index - 1; if (numMoved &gt; 0) &#123; System.arraycopy(elementData, index + 1, elementData, index, numMoved); &#125; elementData[--size] = null; return true; &#125; &#125; return false;&#125; 所以整体来看，FastList 的优化点还是很简单的。 ConcurrentBag","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"connection-pool","slug":"connection-pool","permalink":"https://weilans.github.io/tags/connection-pool/"},{"name":"db","slug":"db","permalink":"https://weilans.github.io/tags/db/"}]},{"title":"[HikariCP] DBPool & JDBC基础","slug":"HikariCP-0-DBPool & JDBC基础","date":"2019-10-03T10:01:06.000Z","updated":"2019-12-19T11:52:19.053Z","comments":true,"path":"2019/10/03/HikariCP-0-DBPool & JDBC基础/","link":"","permalink":"https://weilans.github.io/2019/10/03/HikariCP-0-DBPool & JDBC基础/","excerpt":"工作中负责了一个和数据源交互很重的模块，并独立开启重写任务。其中一个很重要的变化就是将 15 年源代码中所采用的一代 DBCP 换成 HikariCP。因为这个模块与池的交互实在太深了，所以我必须要比常人对 HikariCP 有更好的理解，所以想写一篇纪要进行总结，文章很多内容来自《HikariCP数据库连接池实战》。","text":"工作中负责了一个和数据源交互很重的模块，并独立开启重写任务。其中一个很重要的变化就是将 15 年源代码中所采用的一代 DBCP 换成 HikariCP。因为这个模块与池的交互实在太深了，所以我必须要比常人对 HikariCP 有更好的理解，所以想写一篇纪要进行总结，文章很多内容来自《HikariCP数据库连接池实战》。 DB Pool 基础为何需要连接池以访问MySQL为例，执行一个SQL语句的完整TCP流程共经历：TCP三次握手建立连接、MySQL三次握手认证、SQL语句执行、MySQL关闭、TCP四次挥手关闭连接5个步骤。 不用连接池的主要问题： 创建连接和关闭连接的过程比较耗时，并发时系统会变得很卡顿。 数据库同时支持的连接总数是有限的，如果并发量很大，那么数据库连接的总数就会被消耗光，增加数据库的负载，新的数据库连接请求就会失败。这样就会极大地浪费数据库的资源，极易造成数据库服务器内存溢出、宕机。 为了执行一条SQL，却产生了很多我们并不关心的网络IO。 应用如果频繁地创建连接和关闭连接，会导致JVM临时对象较多，GC频繁。 频繁关闭连接后，会出现大量TIME_WAIT的TCP状态（在2个MSL之后关闭），这点很棘手。 应用的响应时间及QPS较低。 因此，使用连接池的优点就是相对的：资源重用节省开销、系统能有更快的相应、可以进行统一的连接管理、更便于进行系统调优。 数据库连接池原理 在系统初始化的时候，在内存中开辟一片空间，将一定数量的数据库连接作为对象存储在对象池里，并对外提供数据库连接的获取和归还方法。 用户访问数据库时，并不是建立一个新的连接，而是从数据库连接池中取出一个已有的空闲连接对象；使用完毕归还后的连接也不会马上被关闭，而是由数据库连接池统一管理回收，为下一次借用做好准备。 如果由于高并发请求导致数据库连接池中的连接被借用完毕，其他线程就会等待，直到有连接被归还。 数据库连接池还可以通过设置其参数来控制连接池中的初始连接数、连接的上下限数，以及每个连接的最大使用次数、最大空闲时间等，也可以通过其自身的管理机制来监视数据库连接的数量、使用情况等。 连接的创建、获取和归涉及两项技术：一是连接使用List之类的集合进行初始化、装载和归还，二是使用动态代理来把资源归回给List集合。而HikariCP之所以这么快，也主要是将这两项技术做到了极致。 连接池的构成一款商用的数据库连接池除了连接池的建立和释放两大核心功能外，还支持： 并发（锁性能优化乃至无锁） 连接数控制（不同的系统对连接数有不同的需求） 监控（一些自身管理机制来监视连接的数量及使用情况等） 外部配置（各种主流数据库连接池官方文档最核心的部分） 资源重用（数据库连接池的核心思想） 检测及容灾（面对一些网络、时间等问题的自愈） 多库多服务（如不同的数据库、不同的用户名和密码、分库分表等情况） 事务处理（对数据库的操作符合ALL-ALL-NOTHING原则）、定时任务（如空闲检查、最小连接数控制） 缓存（如PSCache等避免对SQL重复解析） 异常处理（对JDBC访问的异常统一处理） 组件维护（如连接状态、JDBC封装的维护）等。 JDBC简述JDBC API是Java编程语言与各种数据库之间数据库无关连接的行业标准。JDBC API是一种执行SQL语句的API，JDBC驱动才是真正的接口实现，所有的网络逻辑和特定于数据库的通信协议都隐藏于、独立于供应商的JDBC API后面。Sun公司只是提供了JDBC API，每个数据库厂商都有自己的驱动来连接自己公司的数据库。 JDBC API采用了桥接的设计模式。JDBC接口相当于实现化角色接口，数据库厂商实现的驱动相当于具体实现化子类；应用程序相当于抽象化角色，内部持有一个实现化角色的对象。桥接模式将实现化和抽象化解耦，从而让两个部分可以沿着不同的方向拓展，只要遵循接口即可。 JDBC API主要位于JDK中的java.sql包中，扩展的内容位于javax.sql包中。了解JDBC，关注点更多的还是java.sql.*包，在这个包里，有4个核心接口（Driver、Connection、Statement和ResultSet）和两个核心类（DriverManager和SQLException）。 Statement关闭会导致ResultSet关闭，但是Connection关闭却不一定会导致Statement关闭。在数据库连接池里，Connection关闭并不是物理关闭，只是归还连接池，所以Statement和ResultSet有可能被持有，并且实际占用相关的数据库的游标资源。所以在关闭Connection前，需要关闭所有相关的Statement和ResultSet。这就是HikariCP作者所强调的JDBC的最基本的规范，也是他创造HikariCP的原因，数据库连接池一定不能违背这样的规则。最好方案就是顺序关闭ResultSet、Statement、Connection；在rs.close()和stmt.close()后面加上rs=null和stmt=null来防止内存泄漏。 Statement和PreparedStatementPreparedStatement在企业开发中被强烈推荐使用，原因主要有以下方面： Statement会频繁编译SQL。如果JDBC驱动支持的话（一般来说数据库系统库系统初次分析、编译时会对查询语句做最大的性能优化），PreparedStatement可对SQL进行预编译，提高效率，预编译的SQL存储在PreparedStatement对象中。从这个意义上来说，PreparedStatement比Statement更快，使用PreparedStatement也可以降低生产环境的数据库负载。 Statement对象编译SQL语句时，如果SQL语句有变量，就需要使用分隔符来隔开，如果变量非常多，就会使SQL变得非常复杂。PreparedStatement可以使用占位符，通过动态参数化的查询来简化SQL的编写。 PreparedStatement可防止SQL注入。 JDBC的最佳实践 使用PrearedStatement，通过预编译的方式避免在拼接SQL时造成SQL注入，使用“？”或其他占位符等变量绑定的形式可以使用不同的参数执行相同的查询也能防止SQL注入。 禁用自动提交，这样可以将数据库操作放在一个事务中，而不是每次执行SQL语句都在执行结束时提交自己独立的事务。 JDBC批处理可以降低数据库传输频率，进而提升性能。 使用列名而不是列序号获取ResultSet中的数据，避免invalidColumIndexError，从而提升程序的健壮性、可读性。 在Java 7中，可以通过Automatic Resource Management Block来自动关闭资源。要记得关闭所有的Connection、Statement等资源。 使用标准的SQL语句（如标准的ANSI SQL），避免数据库对SQL支持的差异。 JDBC与SPIJDBC 4.0以前，开发人员还需要基于Class.forName(“xxx”)的方式来装载驱动，而JDBC 4.0基于SPI机制来发现驱动提供商，可以通过META-INF/services/java.sql.Driver文件里指定实现类的方式来暴露驱动提供者。开发者只需要编写一行代码，使用不同厂商的jar包，就可以轻松创建连接了。 1Connection conn = DriverManager.getConnection(URL,USER,PASSWORD)； 关于SPI在Java中根据一个子类获取其父类或接口信息非常方便，但是根据一个接口获取该接口的所有实现类却没那么容易。有一种比较笨的办法就是扫描classpath下所有的class与jar包中的class，接着用ClassLoader加载进来，再判断是否是给定接口的子类。但是这种方法的代价太大，一般不会使用。根据这个问题，Java推出了ServiceLoader类来提供服务发现机制，动态地为某个接口寻找服务实现。当服务的提供者提供了服务接口的一种实现之后，必须根据SPI约定在META-INF/services/目录里创建一个以服务接口命名的文件，该文件里写的就是实现该服务接口的具体实现类。当程序调用ServiceLoader的load方法的时候，ServiceLoader能够通过约定的目录找到指定的文件，并装载实例化，完成服务的发现。 ServiceLoader是JDK6里面引进的一个特性，通过它可以具体实现代码的解耦，实现类似于IOC的效果。针对ServiceLoader还有一个特定的限制，就是具体实现类必须提供无参数的构造函数，否则ServiceLoader就会报错。 DriverManager的SPI实现DriverManager 中有一个静态代码块： 1234static &#123; loadInitialDrivers(); println(\"JDBC DriverManager initialized\");&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445private static void loadInitialDrivers() &#123; String drivers; try &#123; drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() &#123; public String run() &#123; // 1)处理系统属性jdbc.drivers配置的值 return System.getProperty(\"jdbc.drivers\"); &#125; &#125;); &#125; catch (Exception ex) &#123; drivers = null; &#125; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; // 2)处理通过ServiceLoader加载的Driver类 ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); // 加载配置在META-INF/services/java.sql.Driver文件里的Driver实现类 try&#123; while(driversIterator.hasNext()) &#123; driversIterator.next(); &#125; &#125; catch(Throwable t) &#123; // 什么都不做 &#125; return null; &#125; &#125;); println(\"DriverManager.initialize: jdbc.drivers = \" + drivers); if (drivers == null || drivers.equals(\"\")) &#123; return; &#125; String[] driversList = drivers.split(\":\"); println(\"number of Drivers:\" + driversList.length); for (String aDriver : driversList) &#123; try &#123; println(\"DriverManager.Initialize: loading \" + aDriver); // 3)加载Driver类 Class.forName(aDriver, true, ClassLoader.getSystemClassLoader()); &#125; catch (Exception ex) &#123; println(\"DriverManager.Initialize: load failed: \" + ex); &#125; &#125;&#125; MySQL的Driver实现在初始化的时候也是在 static 方法里就将自己的com.mysql.jdbc.Driver直接注册到了java.sql.DriverManager中。 12345678910public class Driver extends NonRegisteringDriver implements java.sql.Driver &#123; static &#123; try &#123;//强调!这个new Driver是com.mysql.jdbc.Driver!!! java.sql.DriverManager.registerDriver(new Driver()); &#125; catch (SQLException E) &#123; throw new RuntimeException(\"Can't register driver!\"); &#125; &#125; public Driver() throws SQLException &#123;&#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"connection-pool","slug":"connection-pool","permalink":"https://weilans.github.io/tags/connection-pool/"},{"name":"db","slug":"db","permalink":"https://weilans.github.io/tags/db/"}]},{"title":"[回顾并发基础] CopyOnWriteArrayList & ConcurrentHashMap","slug":"Java并发札记-6. CopyOnWriteArrayList & ConcurrentHashMap","date":"2019-09-21T17:41:36.000Z","updated":"2019-12-19T11:54:42.808Z","comments":true,"path":"2019/09/22/Java并发札记-6. CopyOnWriteArrayList & ConcurrentHashMap/","link":"","permalink":"https://weilans.github.io/2019/09/22/Java并发札记-6. CopyOnWriteArrayList & ConcurrentHashMap/","excerpt":"CopyOnWriteArrayList： 基于写时复制策略的线程安全的 List； ConcurrentHashMap：由分段锁(jdk7)实现发展为 CAS+synchronized+红黑树(jdk8) 的线程安全的 Map；","text":"CopyOnWriteArrayList： 基于写时复制策略的线程安全的 List； ConcurrentHashMap：由分段锁(jdk7)实现发展为 CAS+synchronized+红黑树(jdk8) 的线程安全的 Map； 并发List —— CopyOnWriteArrayList描述在很多应用场景中，读操作可能会远远大于写操作。 由于读操作根本不会修改原有的数据，因此对于每次读取都进行加锁其实是一种资源浪费。为了将读取的性能发挥到极致，JDK中提供了CopyOnWriteArrayList类。读取是完全不用加锁的，并且写入也不会阻塞读取操作，只有写入和写入之间需要进行同步等待，这样便可以使读操作的性能就会大幅度提升。 并发包中的并发List 只有 CopyOnWriteArrayList。CopyOnWri teArray List 是一个线程安全的 ArrayList ，对其进行的修改操作都是在底层的一个复制的数组（快照）上进行的，也就是使用了写时复制策略。 实现CopyOnWriteArrayList 有两个成员变量，lock 是用在写时锁的实现，数据则存储在 array 数组中。 12345/** The lock protecting all mutators */final transient ReentrantLock lock = new ReentrantLock();/** The array, accessed only via getArray/setArray. */private transient volatile Object[] array; 1. 初始化1234567891011121314151617181920public CopyOnWriteArrayList() &#123; setArray(new Object[0]);&#125;public CopyOnWriteArrayList(Collection&lt;? extends E&gt; c) &#123; Object[] elements; if (c.getClass() == CopyOnWriteArrayList.class) elements = ((CopyOnWriteArrayList&lt;?&gt;)c).getArray(); else &#123; elements = c.toArray(); // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elements.getClass() != Object[].class) elements = Arrays.copyOf(elements, elements.length, Object[].class); &#125; setArray(elements);&#125;public CopyOnWriteArrayList(E[] toCopyIn) &#123; setArray(Arrays.copyOf(toCopyIn, toCopyIn.length, Object[].class));&#125; 无参构造器创建了一个大小为 0 的Object数组作为 array 初始值。而有参构造器则是将数组或集合的副本作为 array 初始值。 2. 添加元素1234567891011121314151617181920212223public boolean add(E e) &#123; final ReentrantLock lock = this.lock; // 1. 获取独占锁 lock.lock(); try &#123; // 2. 获取 array Object[] elements = getArray(); // 3. 复制 array 到新数组, 添加元素到新数组 int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; // 4. 使用新数组替换添加前的数组 setArray(newElements); return true; &#125; finally &#123; // 5. 释放独占锁 lock.unlock(); &#125;&#125;final Object[] getArray() &#123; return array;&#125; 删除及修改同添加操作一样，首先获取独占锁以保证其他线程不能对 array 进行修改，之后再释放锁。 3. 获取指定位置元素1234567private E get(Object[] a, int index) &#123; return (E) a[index];&#125;public E get(int index) &#123; return get(getArray(), index);&#125; 当用户调用get(x)时，有两步操作：1. 获取数组；2.依照数组下标获取值。如果在两部之间，另一个线程对数组有增/删/改操作，那么对get(x)不会有影响，因为步骤2操作的数组依然是之前的数组。这就是写时复制策略产生的弱一致性。 4. 迭代器CopyOnWriteArrayList 的迭代器是弱一致性的，即返回迭代器后，其他线程对 list 的增删该操作对迭代器是不可见的。 1234567891011121314151617181920212223242526272829public Iterator&lt;E&gt; iterator() &#123; return new COWIterator&lt;E&gt;(getArray(), 0);&#125;static final class COWIterator&lt;E&gt; implements ListIterator&lt;E&gt; &#123; // Snapshot of the array private final Object[] snapshot; // 数组下标 private int cursor; // 构造函数 private COWIterator(Object[] elements, int initialCursor) &#123; cursor = initialCursor; snapshot = elements; &#125; // 是否遍历结束 public boolean hasNext() &#123; return cursor &lt; snapshot.length; &#125; // 获取 next public E next() &#123; if (! hasNext()) throw new NoSuchElementException(); return (E) snapshot[cursor++]; &#125; ...&#125; COWIterator 对象的 snapshot 变量保存了当前 list 的内容， cursor 是遍历 list 时数据的下标。如果在遍历期间其他线程对该 list 进行修改，那么 snapshot 即表示为快照，因为增删改后数组被新数组替换了，而老数组被 snapshot 引用。 5. 应用场景 CopyOnWriteArrayList 仅适用于写操作非常少的场景，而且能够容忍读写的短暂不一致，即写入的新元素并不能立刻被遍历到。 此外，CopyOnWriteArrayList 迭代器是只读的，不支持增删改，迭代器遍历的仅仅是一个快照。 6. 重看COWCOW 适用于数据库连接池这种读操作远远多于修改操作的场景，它反映出3个很重要的分布式理念：读写分离；最终一致；使用额外空间解决办法冲突。 当然 COW 的弱点是很明显的：随着 CopyOnWriteArrayList 中元素的增加，其修改代价将越来越昂贵，在高性能的互联网应用中，这种操作很容易引起故障。设置合理的初始化值、减少扩容开销、使用批量添加减少容器复制次数都是值得考虑的性能优化点。 Linux中也存在CopyOnWrite技术，除了有名的文件系统Brtfs外，基本的fork命令也使用了这项技术。fork()之后，kernel把父进程中所有的内存页的权限都设为read-only，然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，于是触发页异常中断（page-fault），陷入kernel的一个中断例程。中断例程中，kernel就会把触发的异常的页复制一份，于是父子进程各自持有独立的一份。这项技术可以减少分配和复制大量资源时带来的瞬间延时，也可以减少不必要的资源分配。 ConcurrentHashMap在 JDK7 和 JDK8 中的实现有些许变化，不过很多材料谈的都是 JDK7 。ConcurrentHashMap本身实现也是十分复杂，包含注释大约 6000+ 行，相比之前的笔记，不会贴代码，主要关注它实现思路，细节层面不会非常细。 HashMap回顾 ConcurrentHashMap 之前，国际惯例回顾下HashMap吧。JDK7中 HashMap 采用的是数组位桶+链表的方式，每个键值对封装在 Entry (static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt;) 里面，而 HashMap 维持着 Entry 数组，这就是数组位桶；而 Entry 本身也有 next 属性指向下一个 Entry，这可以看作是单向链表。 get()方法通过hash()函数得到对应 bucket 的下标hash(k)&amp;(table.length-1)，然后依次遍历冲突链表，通过key.equals(k)方法来判断是否是要找的那个 Entry。 put()方法先检查是否包含这个key，不包含则采用头插法(JDK8是尾插)，在链表头部插入新的 Entry。当然新增Entry可能导致HashMap的实际容量超过阈值，需要扩容。当Entry 的数量超过 capacity(当前容量)* load_factor 时，容器将自动扩容并重新哈希，哈希表将具有大约两倍的桶数。 HashMap 的扩容时机选在了插入之后判断阈值是否扩容，若后续无插入则浪费了。而 ConcurrentHashMap 的实现是在插入元素前就判断是否超过阈值。 而 JDK8 的实现最大改进就是链表元素数量超过一定值后，将其转为红黑树，避免大量节点存在链表上时的O(n)查找时间。所以说 JDK8 使用的是 数组位桶+链表/红黑树的形式。JDK8使用Node代替 Entry，Node 可以被扩展成TreeNode，如果 node 的数目多于 8 个，那么链表就会被转换成红黑树；如果 node 的数目小于 6个，那么红黑树就会被转换成链表。 HashMap 不支持并发，主要场景是多线程同时put时，如果同时触发了rehash操作，会导致 HashMap 中的链表中出现循环节点(一个线程 rehash 完毕，另一个线程还没开始)，进而使得后面 get 的时候出现死循环，CPU达到100%。 并发Map —— ConcurrentHashMapJDK7ConcurrentHashMap 使用分段锁技术，将数据分成一段一段的存储（分成一个个Segment，每个 Segment 包含HashEntry数组，Segment extends ReentrantLock本质上是一个可重入的互斥锁），当一个线程对 HashEntry 数组的数据进行修改时，必须获得与之对应的 Segment 锁，其他段的数据也能被其他线程访问。 get(): 对 key.hashCode 进行再散列，通过这个散列值取高位定位到正确的 Segment，再使用再散列值与数组长度减一相与定位 HashEntry。接着遍历该 HashEntry 链表。get 过程不需要加锁，get 方法里使用到的共享变量都定义成了volatile类型（如当前 Segment 的大小字段 count 以及存储值的 HashEntry 中的 value），Happens-before规定了对 volatile 字段的写入先于读操作，所以 get 操作总能拿到最新值。 put(): 首先定位到 Segment 获取锁，之后定位到 HashEntry 索引位置进行遍历，有重复 key 则替换，若没有则插入头部。需要注意的是，插入操作需先判断 HashEntry 数组是否超过容量需扩容，扩容时只会针对这个 Segment 进行，数组容量是原先两倍。 size(): 先尝试2次不加锁的统计各个 Segment 大小，如果统计过程中 count 变化（modCount，在 put / remove / clean 时加 1），采用加锁的方式统计所有Segment的大小。 JDK8 Referencehttps://read.douban.com/reader/ebook/122245168/ 《Java并发编程之美》","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"https://weilans.github.io/tags/concurrent/"}]},{"title":"[回顾并发基础] 常用并发工具类","slug":"Java并发札记-5-常用并发工具类","date":"2019-09-21T17:30:47.000Z","updated":"2019-12-31T11:13:55.057Z","comments":true,"path":"2019/09/22/Java并发札记-5-常用并发工具类/","link":"","permalink":"https://weilans.github.io/2019/09/22/Java并发札记-5-常用并发工具类/","excerpt":"","text":"SemaphoreSemaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源。 Semaphore 有 Lock 不易实现的功能：Semaphore 可以允许多个线程访问一个临界区。 123456789101112public Semaphore(int permits);public Semaphore(int permits, boolean fair);public void acquire() throws InterruptedException;public void acquireUninterruptibly();public void acquire(int permits) throws InterruptedException;public void acquireUninterruptibly(int permits);public boolean tryAcquire();public boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException;public boolean tryAcquire(int permits);public boolean tryAcquire(int permits, long timeout, TimeUnit unit) throws InterruptedException;public void release()；public void release(int permits); 其他方法： 12345public int availablePermits(); // 返回此信号量中当前可用的许可证public final int getQueueLength(); // 返回正在等待获取许可证的线程数public final boolean hasQueuedThreads(); // 是否有线程正在等待获取许可证protected void reducePermits(int reduction); // 减少reduction个许可证protected Collection&lt;Thread&gt; getQueuedThreads(); // 返回所有等待获取许可证的线程集合 应用示例示例一：共10个线程，每次只有两个线程可以获取到资源。 1234567891011121314151617181920public class SemaphoreTest &#123; private static final int THREAD_COUNT = 10; private static ExecutorService threadPool = Executors.newFixedThreadPool(THREAD_COUNT); private static Semaphore s = new Semaphore(2); public static void main(String[] args) &#123; for (int i = 0; i &lt; THREAD_COUNT; i++) &#123; threadPool.execute(() -&gt; &#123; try &#123; s.acquire(); TimeUnit.SECONDS.sleep(2); System.out.println(\"save data\"); s.release(); &#125; catch (InterruptedException e) &#123; &#125; &#125;); &#125; threadPool.shutdown(); &#125;&#125; 示例二：Semaphore的许可量为0，后两个线程分别release，使得acquire(2)的线程可以继续下去。 1234567891011121314151617181920212223public class SemaphoreTest &#123; private static Semaphore semaphore = new Semaphore(0); public static void main(String[] args) throws InterruptedException &#123; ExecutorService executorService = Executors.newFixedThreadPool(2); executorService.submit(() -&gt; &#123; try &#123; System.out.println(Thread.currentThread() + \" over \"); semaphore.release(); &#125; catch (Exception e) &#123; &#125; &#125;); executorService.submit(() -&gt; &#123; try &#123; System.out.println(Thread.currentThread() + \" over \"); semaphore.release(); &#125; catch (Exception e) &#123; &#125; &#125;); semaphore.acquire(2); System.out.println(\"all child thread over \"); executorService.shutdown(); &#125;&#125; 示例三：官方示例 Semaphores are often used to restrict the number of threads than can access some (physical or logical) resource. For example, here is a class that uses a semaphore to control access to a pool of items: 123456789101112131415161718192021222324252627282930313233343536373839404142class Pool &#123; private static final int MAX_AVAILABLE = 100; private final Semaphore available = new Semaphore(MAX_AVAILABLE, true); public Object getItem() throws InterruptedException &#123; available.acquire(); return getNextAvailableItem(); &#125; public void putItem(Object x) &#123; if (markAsUnused(x)) available.release(); &#125; // Not a particularly efficient data structure; just for demo protected Object[] items = ... whatever kinds of items being managed protected boolean[] used = new boolean[MAX_AVAILABLE]; protected synchronized Object getNextAvailableItem() &#123; for (int i = 0; i &lt; MAX_AVAILABLE; ++i) &#123; if (!used[i]) &#123; used[i] = true; return items[i]; &#125; &#125; return null; // not reached &#125; protected synchronized boolean markAsUnused(Object item) &#123; for (int i = 0; i &lt; MAX_AVAILABLE; ++i) &#123; if (item == items[i]) &#123; if (used[i]) &#123; used[i] = false; return true; &#125; else return false; &#125; &#125; return false; &#125;&#125; 实现Semaphore 还是使用 AQS 实现的。Sync 只是对 AQS 的一个修饰，并且 Sync 有两个实现类(NonfairSync,FairSync)，用来指定获取信号量时是否采用公平策略，默认采用非公平策略。相对而言，比较简单，这里不赘述。把源码的文档注释删掉，其实也就是一百多行。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176public class Semaphore implements java.io.Serializable &#123; private static final long serialVersionUID = -3222578661600680210L; private final Sync sync; abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 1192457210091910933L; Sync(int permits) &#123; setState(permits); &#125; final int getPermits() &#123; return getState(); &#125; final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125; protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; int current = getState(); int next = current + releases; if (next &lt; current) // overflow throw new Error(\"Maximum permit count exceeded\"); if (compareAndSetState(current, next)) return true; &#125; &#125; final void reducePermits(int reductions) &#123; for (;;) &#123; int current = getState(); int next = current - reductions; if (next &gt; current) // underflow throw new Error(\"Permit count underflow\"); if (compareAndSetState(current, next)) return; &#125; &#125; final int drainPermits() &#123; for (;;) &#123; int current = getState(); if (current == 0 || compareAndSetState(current, 0)) return current; &#125; &#125; &#125; static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = -2694183684443567898L; NonfairSync(int permits) &#123; super(permits); &#125; protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires); &#125; &#125; static final class FairSync extends Sync &#123; private static final long serialVersionUID = 2014338818796000944L; FairSync(int permits) &#123; super(permits); &#125; protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; if (hasQueuedPredecessors()) return -1; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125; &#125; public Semaphore(int permits) &#123; sync = new NonfairSync(permits); &#125; public Semaphore(int permits, boolean fair) &#123; sync = fair ? new FairSync(permits) : new NonfairSync(permits); &#125; public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; public void acquireUninterruptibly() &#123; sync.acquireShared(1); &#125; public boolean tryAcquire() &#123; return sync.nonfairTryAcquireShared(1) &gt;= 0; &#125; public boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout)); &#125; public void release() &#123; sync.releaseShared(1); &#125; public void acquire(int permits) throws InterruptedException &#123; if (permits &lt; 0) throw new IllegalArgumentException(); sync.acquireSharedInterruptibly(permits); &#125; public void acquireUninterruptibly(int permits) &#123; if (permits &lt; 0) throw new IllegalArgumentException(); sync.acquireShared(permits); &#125; public boolean tryAcquire(int permits) &#123; if (permits &lt; 0) throw new IllegalArgumentException(); return sync.nonfairTryAcquireShared(permits) &gt;= 0; &#125; public boolean tryAcquire(int permits, long timeout, TimeUnit unit) throws InterruptedException &#123; if (permits &lt; 0) throw new IllegalArgumentException(); return sync.tryAcquireSharedNanos(permits, unit.toNanos(timeout)); &#125; public void release(int permits) &#123; if (permits &lt; 0) throw new IllegalArgumentException(); sync.releaseShared(permits); &#125; public int availablePermits() &#123; return sync.getPermits(); &#125; public int drainPermits() &#123; return sync.drainPermits(); &#125; protected void reducePermits(int reduction) &#123; if (reduction &lt; 0) throw new IllegalArgumentException(); sync.reducePermits(reduction); &#125; public boolean isFair() &#123; return sync instanceof FairSync; &#125; public final boolean hasQueuedThreads() &#123; return sync.hasQueuedThreads(); &#125; public final int getQueueLength() &#123; return sync.getQueueLength(); &#125; protected Collection&lt;Thread&gt; getQueuedThreads() &#123; return sync.getQueuedThreads(); &#125; public String toString() &#123; return super.toString() + \"[Permits = \" + sync.getPermits() + \"]\"; &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"https://weilans.github.io/tags/concurrent/"}]},{"title":"[回顾并发基础] ReentrantLock & ReentrantReadWriteLock & StampedLock","slug":"Java并发札记-4-常用Lock实现类","date":"2019-09-21T17:12:31.000Z","updated":"2019-12-19T11:54:29.623Z","comments":true,"path":"2019/09/22/Java并发札记-4-常用Lock实现类/","link":"","permalink":"https://weilans.github.io/2019/09/22/Java并发札记-4-常用Lock实现类/","excerpt":"","text":"ReentrantLock描述ReentrantLock，支持重进入的锁，表示该锁能够支持一个线程对资源的重复加锁。该锁还支持公平和非公平选择。如果是公平锁，唤醒阻塞队列中节点的策略就是谁等待的时间长就唤醒谁；如果是非公平锁，则不提供这个公平保证，默认是非公平的。（synchronized关键字隐式的支持重进入，且是非公平的。） AQS 的 state 状态值表示线程获取该锁的可重入次数， 在默认情况下， state的值为 0 表示当前锁没有被任何线程持有。当一个线程第一次获取该锁时会尝试使用CAS设置state 的值为 1 ，如果 CAS 成功则记录该锁的持有者为当前线程。在该线程没有释放锁的情况下第二次获取该锁后，状态值被设置为2 ， 这就是可重入次数。在该线程释放该锁时，会尝试使用CAS 让状态值减1， 如果减1 后状态值为0，则当前线程释放该锁。 Lock的可见性保证可以使用ReentrantLock来举例。ReentrantLock 内部持有一个 volatile 的成员变量 state，获取锁的时候，会读写 state 的值；解锁的时候，也会读写 state 的值。可以通过 volatile 变量规则、顺序性规则以及传递性规则推导出 前一个线程在加锁时对变量的修改 Happens-Before 于另一个线程的加锁操作。 实现（1）获取锁ReentrantLock 的 lock() 方法直接调用 sync.lock() 方法。ReentrantLock 中有继承 AQS 的抽象类Sync，内部有NonfairSync，FairSync分别代表非公平实现和公平实现。在AQS中，我们知道tryAcquire方法是要自己实现的。 先以非公平锁开始，调用 Lock 的线程通过 CAS 设置状态值为1成功后，则表示当前线程获取到了锁， 然后 setExclusiveOwnerThread 设置该锁持有者是当前线程。后续线程会调用 acquire方法，其内部既先调用tryAcquire，从而调用nonfairTryAcquire，这个方法就是获取锁的关键： 当 state 为 0 时，代表锁空闲，尝试 CAS 获取后再设置持有者线程为当前线程，便成功返回。 当 state 非 0 时，即锁已被占用，若持有线程不是当前线程便直接返回失败，后放入 AQS 阻塞队列；若是当前线程，则状态值加一。需要注意的是，nextc &lt; 0 是指可重入次数溢出了。 这里的非公平性体现在何处呢？若线程A持有锁后，线程B持有失败，进入阻塞队列。此时线程A释放锁的同时，线程C到来，其尝试 CAS 成功后，便获取到了锁。或者刚释放锁的线程A想要再次获取锁时，其成功几率也会非常大。 公平锁的tryAcquire和nonfairTryAcquire几乎一致，只是多了一个 !hasQueuedPredecessors() ，该方法判断当前线程节点是否有前驱节点。使用公平锁时，任何线程一进来不会让你 CAS 成功就获取到锁，而是进入 tryAcquire中进行判断队列中是否有线程在等待，若没有等待的线程且CAS成功，则代表获取到锁，设置持有者线程后便返回 true。公平锁保证了锁的获取按照FIFO原则，而代价是进行大量的线程切换。非公平性锁虽然可能造成线程“饥饿”，但极少的线程切换，保证了其更大的吞吐量。 123456789101112131415161718192021222324252627282930313233343536// NonfairSync 实现static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else // AQS 中的 acquire 方法 acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; // 代码实现在 Sync 抽象类中，具体实现见下 return nonfairTryAcquire(acquires); &#125;&#125;final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false;&#125; 12345678910111213141516171819202122232425262728293031323334353637// FairSync 实现static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; // AQS 中的 acquire 方法 acquire(1); &#125; // 与 nonfairTryAcquire 的唯一区别在于多了 !hasQueuedPredecessors() 判断 protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; &#125;&#125; public final boolean hasQueuedPredecessors() &#123; Node t = tail; Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread()); &#125; （2）释放锁ReentrantLock.unlock() 调用的是：sync.release(1)，方法内会调用tryRelease方法（实现是在Sync中，即公平和非公平都是同一种实现）。该方法中，当前线程非持有者线程立即报错。当检查 state 若减去 release 值为 0 后，则清空持有者线程， 正式设置 state 为 0。 123456789101112131415161718192021222324// in AQS public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125;// in ReentrantLockprotected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; ReentrantReadWriteLock读写锁维护了一对锁，一个读锁和一个写锁，通过分离读锁和写锁，使得并发性相比一般的排他锁有了很大提升，能够简化读写交互场景的编程方式。 ReentrantReadWriteLock支持公平性/非公平性选择、重进入、锁降级。样例如下： 12345678910111213141516171819202122232425262728293031323334public class ReadWriteLockTest &#123; static Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); static ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); static Lock r = rwl.readLock(); static Lock w = rwl.writeLock(); // 获取一个key对应的value public static final Object get(String key) &#123; r.lock(); try &#123; return map.get(key); &#125; finally &#123; r.unlock(); &#125; &#125; // 设置key对应的value，并返回旧的value public static final Object put(String key, Object value) &#123; w.lock(); try &#123; return map.put(key, value); &#125; finally &#123; w.unlock(); &#125; &#125; // 清空所有的内容 public static final void clear() &#123; w.lock(); try &#123; map.clear(); &#125; finally &#123; w.unlock(); &#125; &#125;&#125; 关于读写状态读写锁同样依赖自定义同步器来实现同步功能，而读写状态就是其同步器的同步状态。读写锁的自定义同步器需要在同步状态（一个整型变量）上维护多个读线程和一个写线程的状态。如果在一个整型变量上维护多种状态，就一定需要“按位切割使用”这个变量，读写锁将变量切分成了两个部分，高16位表示读，低16位表示写 写锁的获取与释放写锁是一个支持重进入的排它锁。如果当前线程已经获取了写锁，则增加写状态。如果当前线程在获取写锁时，读锁已经被获取（读状态不为0）或者该线程不是已经获取写锁的线程，则当前线程进入等待状态。如果存在读锁，则写锁不能被获取，原因在于：读写锁要确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。写锁的释放与ReentrantLock的释放过程基本类似，等待的读写线程能够继续访问读写锁，同时前次写线程的修改对后续读写线程可见。 读锁的获取与释放读锁是一个支持重进入的共享锁，它能够被多个线程同时获取。读锁总会被成功地获取，而所做的也只是（线程安全的）增加读状态。如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。读锁的每次释放（线程安全，可能有多个读线程同时释放读锁）均减少读状态，减少的值是（1&lt;&lt;16）。 锁降级锁降级是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程。 锁降级示例：因为数据不常变化，所以多个线程可以并发地进行数据处理，当数据变更后，如果当前线程感知到数据变化，则进行数据的准备工作，同时其他处理线程被阻塞，直到当前线程完成数据的准备工作。 123456789101112131415161718192021222324public void processData() &#123; readLock.lock(); if (!update) &#123; // 必须先释放读锁 readLock.unlock(); // 锁降级从写锁获取到开始 writeLock.lock(); try &#123; if (!update) &#123; // 准备数据的流程（略） update = true; &#125; readLock.lock(); &#125; finally &#123; writeLock.unlock(); &#125; // 锁降级完成，写锁降级为读锁 &#125; try &#123; // 使用数据的流程（略） &#125; finally &#123; readLock.unlock(); &#125; &#125; 当数据发生变更后，update变量（布尔类型且volatile修饰）被设置为false，此时所有访问processData()方法的线程都能够感知到变化，但只有一个线程能够获取到写锁，其他线程会被阻塞在读锁和写锁的lock()方法上。当前线程获取写锁完成数据准备之后，再获取读锁，随后释放写锁，完成锁降级。 锁降级中读锁的获取是否必要呢？答案是必要的。主要是为了保证数据的可见性，如果当前线程不获取读锁而是直接释放写锁，假设此刻另一个线程（记作线程T）获取了写锁并修改了数据，那么当前线程无法感知线程T的数据更新。如果当前线程获取读锁，即遵循锁降级的步骤，则线程T将会被阻塞，直到当前线程使用数据并释放读锁之后，线程T才能获取写锁进行数据更新。 RentrantReadWriteLock不支持锁升级（把持读锁、获取写锁，最后释放读锁的过程）。目的也是保证数据可见性，如果读锁已被多个线程获取，其中任意线程成功获取了写锁并更新了数据，则其更新对其他获取到读锁的线程是不可见的。 示例18个读线程 + 2个写线程，读写操作都是耗时1s，最终耗时3s。换成 ReentrantLock 则为 20s。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class ReadWriteLockDemo &#123; private static Lock lock = new ReentrantLock(); private static ReentrantReadWriteLock readWriteLock = new ReentrantReadWriteLock(); private static Lock readLock = readWriteLock.readLock(); private static Lock writeLock = readWriteLock.writeLock(); /** 用于计时 */ private static CountDownLatch latch = new CountDownLatch(20); public Object handleRead(Lock lock) throws InterruptedException &#123; try &#123; lock.lock(); System.out.println(\"start read\"); Thread.sleep(1000); return null; &#125; finally &#123; latch.countDown(); lock.unlock(); &#125; &#125; public void handleWrite(Lock lock) throws InterruptedException &#123; try &#123; lock.lock(); System.out.println(\"start write\"); Thread.sleep(1000); &#125; finally &#123; latch.countDown(); lock.unlock(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; final ReadWriteLockDemo demo = new ReadWriteLockDemo(); Runnable readRunnale = () -&gt; &#123; try &#123; demo.handleRead(readLock); // demo.handleRead(lock); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;; Runnable writeRunnale = () -&gt; &#123; try &#123; demo.handleWrite(writeLock); // demo.handleWrite(lock); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;; Instant i1 = Instant.now(); for (int i = 0; i &lt; 18; i++) &#123; new Thread(readRunnale).start(); &#125; for (int i = 18; i &lt; 20; i++) &#123; new Thread(writeRunnale).start(); &#125; latch.await(); Instant i2 = Instant.now(); System.out.println(Duration.between(i1, i2).toMillis()); &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"https://weilans.github.io/tags/concurrent/"}]},{"title":"[回顾并发基础] Lock & AQS","slug":"Java并发札记-3-Lock & AQS","date":"2019-09-20T17:13:48.000Z","updated":"2019-12-19T11:54:23.709Z","comments":true,"path":"2019/09/21/Java并发札记-3-Lock & AQS/","link":"","permalink":"https://weilans.github.io/2019/09/21/Java并发札记-3-Lock & AQS/","excerpt":"回顾 Java Lock 基础，详细介绍了 AbstractQueuedSynchronizer的实现；并说明了Condition的原理以及LockSupport的底层作用。","text":"回顾 Java Lock 基础，详细介绍了 AbstractQueuedSynchronizer的实现；并说明了Condition的原理以及LockSupport的底层作用。 1. LockLock接口123456789101112// 获取锁，当锁获得后，从该方法处返回void lock(); // 获取锁的过程能够响应中断 void lockInterruptibly() throws InterruptedException；// 非阻塞式获取锁，获取锁放回true反之返回fasle boolean tryLock();// 超时获取锁，在超时内或者未中断的情况下能够获取锁boolean tryLock(long time, TimeUnit unit) throws InterruptedException; // 释放锁void unlock(); // 获取与lock绑定的等待通知组件，当前线程必须获得了锁才能进行等待，进行等待时会先释放锁，当再次获取锁时才能从等待中返回Condition newCondition(); Lock与synchronized相比拥有的优势 可响应中断。synchronized 会在线程持有锁 A 后，如果尝试获取锁 B 失败，那么线程就进入阻塞状态，而且一旦发生死锁，就没有任何机会来唤醒阻塞的线程。lockInterruptibly()可响应中断信号，可以在锁的获取过程中中断当前线程，调用thread.interrupt()方法能够中断线程的等待过程。 支持超时。tryLock(long time, TimeUnit unit)方法在拿不到锁时会等待一定的时间，在时间期限之内如果还拿不到锁，就返回 false。如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回 true。 非阻塞获取锁。 tryLock()方法会尝试获取锁，如果获取成功则返回true，如果获取失败则返回 false，也就说这个方法无论如何都会立即返回。 除此之外，synchronized 会隐式获取锁，且会自动释放锁，而 Lock 是显式的获取锁，手工释放（synchronized 固化了锁的获取和释放，而 Lock相对的提供了更好的拓展性）；Lock可以绑定多个条件：Condition，await，signal。synchronized的wait，notify只可以实现一种条件。 2. AbstractQueuedSynchronizer队列同步器AbstractQueuedSynchronizer是用来构建锁或者其他同步组件的基础框架,它使用了一个int成员变量表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作。同步器面向的是锁的实现者，它简化了锁的实现方式，屏蔽了同步状态管理、线程排队、等待与唤醒等底层操作细节。同步器的主要使用方式是继承，子类被推荐为自定义同步组件的静态内部类。 a. 基础描述双向队列AQS 内部通过 head 和 tail记录队首和队尾元素，队列元素的类型是 Node。在 Node 类型中：prev和next分别记录当前节点的前驱和后置节点；thread变量用来存放进入AQS队列里的线程；waitStatus记录当前线程的等待状态：CANCELLED 线程被取消、SIGNAL 线程需要被唤醒、CONDITION 线程在条件队列里面等待、PROPAGATE 释放共享资源时需要通知其他节点。 状态信息在AQS 中维持了一个单一的状态信息state，可以通过getState 、setState 、compareAndSetState 函数修改其值。 根据state 是否属于一个线程，操作state 的方式分为独占方式和共享方式。在独占方式下获取和释放资源使用的方法为 acquire / acquirelnterruptibly / release 。在共享方式下获取和释放资源的方法为： acquireShared / acquireSharedInterruptibly / releaseShared。 对于ReentrantLock 的实现来说， state 可以用来表示当前线程获取锁的可重入次数；对于读写锁ReentrantReadWriteLock 来说， state 的高16位表示读状态，也就是获取该读锁的次数，低16 位表示获取到写锁的线程的可重入次数；对于semaphore 来说， state 用来表示当前可用信号的个数：对于CountDownlatch 来说，state 用来表示计数器当前的值。 ConditionAQS 有个内部类ConditionObject ， 用来结合锁实现线程同步。ConditionObject 可以直接访问 AQS 对象内部的变量，比如 state 状态值和 AQS 队列。ConditionObject 是条件变量， 每个条件变量对应一个条件队列（单向链表队列），其用来存放调用条件变量的 await 方法后被阻塞的线程，这个条件队列的头、尾元素分别为自 firstWaiter 和 lastWaiter 。 b. AQS可重写的方法 方法名称 描述 tryAcquire(int arg) 独占获取同步状态，实现该方法需要查询当前状态，并判断同步状态是否符合预期状态，然后再进行CAS设置同步状态。 tryRelease(int arg) 独占式释放同步状态，等待获取同步状态的线程将有机会获取同步状态 tryAcquireShared(int arg) 共享式获取同步状态，返回大于等于0的值，表示获取成功，反之失败 tryReleaseShared(int arg) 共享式释放同步状态 isHeldExclusively() 当前同步器是否在独占模式下被线程占用，一般该方法表示是否被当前线程所独占 AQS提供的模板方法： c. AQS使用示例示例来自AQS官方文档（ non-reentrant mutual exclusion lock）。 12345678910111213141516171819202122232425262728293031323334353637383940class Mutex implements Lock &#123; // 静态内部类，自定义同步器 private static class Sync extends AbstractQueuedSynchronizer &#123; // 是否处于占用状态 protected boolean isHeldExclusively() &#123; return getState() == 1; &#125; // 当状态为0的时候获取锁 public boolean tryAcquire(int acquires) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; // 释放锁，将状态设置为0 protected boolean tryRelease(int releases) &#123; if (getState() == 0) throw new IllegalMonitorStateException(); setExclusiveOwnerThread(null); setState(0); return true; &#125; // 返回一个Condition，每个condition都包含了一个condition队列 Condition newCondition() &#123; return new ConditionObject(); &#125; &#125; // 仅需要将操作代理到Sync上即可 private final Sync sync = new Sync(); public void lock() &#123; sync.acquire(1); &#125; public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; public void unlock() &#123; sync.release(1); &#125; public Condition newCondition() &#123; return sync.newCondition(); &#125; public boolean isLocked() &#123; return sync.isHeldExclusively(); &#125; public boolean hasQueuedThreads() &#123; return sync.hasQueuedThreads(); &#125; public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125; d. 独占式与共享式如果论述AQS完整实现比较麻烦的话，单独描述下独占式和共享式资源获取与释放，也是可以看清楚AQS的核心的。 独占式：如果一个线程获取到了资源，会标记是这个线程获取到了，其他线程再尝试操作 state 获取资源时会发现当前该资源不是自己持有的，就会在获取失败后被阻塞。比如独占锁ReentrantLock， 当一个线程获取了ReerrantLock 的锁后，AQS 内部会首先使用CAS 操作把 state 状态值从0变为1 ，然后设置当前锁的持有者为当前线程，当该线程再次获取锁时发现它就是锁的持有者，会把状态值从1变为2 ，也就是设置可重入次数，而当另外一个线程获取锁时发现自己并不是该锁的持有者就会被放入AQS 阻塞队列后挂起。 共享式：当多个线程去请求资源时通过 CAS 方式竞争获取资源，当一个线程获取到了资源后，另外一个线程再次去获取时如果当前资源还能满足它的需要，则当前线程只需要使用 CAS 方式进行获取即可。比如Semaphore 信号量， 当一个线程通过acquire方法获取信号量时，会首先看当前信号量个数是否满足需要， 不满足则把当前线程放入阻塞队列，如果满足则通过 CAS 获取信号量。 e. AQS实现独占式资源获取与释放（1）获取12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 上述代码主要完成了同步状态获取、节点构造、加入同步队列以及在同步队列中自旋等待的相关工作，其主要逻辑是： tryAcquire(int arg)，该方法保证线程安全的获取同步状态，具体就是设置状态变量 state 的值，成功则直接返回； 如果同步状态获取失败，则构造同步节点（独占式Node.EXCLUSIVE）并通过addWaiter(Node node)方法将该节点加入到AQS阻塞队列的尾部； 最后调用acquireQueued方法，使用 LockSupport.park(this) 挂起自己，使得该节点以“死循环”的方式获取同步状态。 123456789101112131415private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // 快速尝试在尾部添加 Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 同步器通过死循环来保证节点的正确添加 enq(node); return node;&#125; 设置尾节点：加入队列的过程必须要保证线程安全，因此同步器提供了一个基于CAS的设置尾节点的方法：compareAndSetTail(Node expect,Node update)，它需要传递当前线程“认为”的尾节点和当前节点，只有设置成功后，当前节点才正式与之前的尾节点建立关联。 第一个线程想要获取锁时，直接返回，不会进入阻塞队列的逻辑。第二个线程获取锁时，在addWaiter中的enq方法中，会在阻塞队列头部塞入一个新的空Node（也可以成为“哨兵Node”），第二个线程封装为Node后，放在该空Node后面；之后第二个线程在acquireQueued方法中的shouldParkAfterFailedAcquire中返回false，但waitStatus置为了SIGNAL，再次循环进入shouldParkAfterFailedAcquire方法，由于waitStatus等于SIGNAL，返回true，故使用LockSupport阻塞第二个线程。 当第一个线程返回时，调用release方法，此时head还是之前的空Node，unparkSuccessor(head)会唤醒head的后继者，即第二个线程。第二个线程在acquireQueued方法中的tryAcquire方法中成功返回，会将head设为自己。 若在第二个线程之后，还有n个线程在队列中，在第二个线程release时，会唤醒head的后继者，即队列后续线程，以此类推。 （2）释放同步器的release(int arg)方法可以释放同步状态）。 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 设置首节点：首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，将会唤醒后继节点，而后继节点将会在获取同步状态成功时将自己设置为首节点。设置首节点是通过获取同步状态成功的线程来完成的，由于只有一个线程能够成功获取到同步状态，因此设置头节点的方法并不需要使用CAS来保证。 在unparkSuccessor的方法中，会对节点的后续节点线程调用LockSupport.unpark方法以激活后续线程。被激活的线程则使用tryAcquire 尝试，看当前状态变量state的值是否能满足自己的需要，满足则该线程被激活，然后继续向下运行，否则还是会被放入 AQS 队列并被挂起。 共享式资源获取与释放（1）获取当线程调用acquireShared获取共享资源时，会首先使用tryAcquireShared尝试获取资源， 具体是设置状态变量 state 的值，成功则直接返回（成功获取到同步状态并退出自旋的条件就是 tryAcquireShared 方法返回值大于等于0），失败则将当前线程封装为类型为 Node.SHARED 的 Node 节点后插入到 AQS 阻塞队列的尾部，并使用LockSupport.park(this） 方法挂起自己。 1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; （2）释放线程调用releaseShared时会尝试使用tryReleaseShared操作释放资源，这里是设置状态变量 state 的值，然后在unparkSuccessor中使用LockSupport.unpark激活后续线程 。被激活的线程则使用tryAcquireShared查看当前状态变量 state 的值是否能满足自己的需要，满足则继续向下运行，否则还是会被放入AQS 队列并被挂起。 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; 共享式前N个可以获取资源的线程直接返回， 不会进入阻塞队列的逻辑。后续线程无法获取到资源时，在doAcquireShared的第一行就是addWaiter方法，后续大体逻辑和独占式类似。 自定义同步组件 TwinsLockTwinsLock: 只允许至多两个线程访问，超过两个线程的访问将被阻塞 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class TwinsLock implements Lock &#123; /** * 自定义的同步器，能够有两个线程同时获取资源 */ private final Sync sync = new Sync(2); private static final class Sync extends AbstractQueuedSynchronizer &#123; Sync(int count) &#123; if (count &lt;= 0) &#123; throw new IllegalArgumentException(\"count must large than zero.\"); &#125; setState(count); &#125; @Override public int tryAcquireShared(int reduceCount) &#123; for (; ; ) &#123; int current = getState(); int newCount = current - reduceCount; if (newCount &lt; 0 || compareAndSetState(current, newCount)) &#123; return newCount; &#125; &#125; &#125; @Override public boolean tryReleaseShared(int returnCount) &#123; for (; ; ) &#123; int current = getState(); int newCount = current + returnCount; if (compareAndSetState(current, newCount)) &#123; // 将释放的资源返回 return true; &#125; &#125; &#125; Condition newCondtion() &#123; return new ConditionObject(); &#125; &#125; @Override public void lock() &#123; sync.acquireShared(1); &#125; @Override public void lockInterruptibly() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; @Override public boolean tryLock() &#123; return sync.tryAcquireShared(1) &gt;= 0; &#125; @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(time)); &#125; @Override public void unlock() &#123; sync.releaseShared(1); &#125; @Override public Condition newCondition() &#123; return sync.newCondtion(); &#125;&#125; 3. ConditionAPI1234567void await() throws InterruptedException;void awaitUninterruptibly();long awaitNanos(long nanosTimeout) throws InterruptedException;boolean await(long time, TimeUnit unit) throws InterruptedException;boolean awaitUntil(Date deadline) throws InterruptedException;void signal();void signalAll(); await() 方法会使当前线程等待，同时释放当前锁，当其他线程中使用signal()或者signalAll()方法时，线程会重新获得锁并继续执行。或者当线程被中断时，也能跳出等待。这和Object.wait()方法很相似； awaitUninterruptibly() 方法与 await() 方法基本相同，但是它并不会在等待过程中响应中断； singal() 用于唤醒一个在等待中的线程； singalAll() 方法会唤醒所有在等待中的线程，和Obejct.notify()方法很类似； 使用范式123456789101112131415161718Lock lock = new ReentrantLock();Condition condition = lock.newCondition();public void conditionWait() throws InterruptedException &#123; lock.lock(); try &#123; condition.await(); &#125; finally &#123; lock.unlock(); &#125;&#125; public void conditionSignal() throws InterruptedException &#123; lock.lock(); try &#123; condition.signal(); &#125; finally &#123; lock.unlock(); &#125;&#125; 官方示例范式中 lock() 并没有放在 try {} 中，应该是因为不排除获取锁(比如自定义锁)的过程中产生异常后，却调用了unlock() 方法。 和Object.wait()和notify()方法一样，当线程使用Condition.await()时，要求线程持有相关的重入锁，在Condition.await()调用后，这个线程会释放这把锁。 在Condition.signal()方法调用时，也要求线程先获得相关的锁。在signal()方法调用后，系统会从当前Condition对象的等待队列中，唤醒一个线程。一旦线程被唤醒，它会重新尝试获得与之绑定的重入锁，一旦成功获取，就可以继续执行了。因此，在signal()方法调用之后，一般需要释放相关的锁，谦让给被唤醒的线程，让它可以继续执行。 ArrayBlockingQueue 中 Lock 及 Condition 的使用1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889final Object[] items;int takeIndex;int putIndex;int count;final ReentrantLock lock;private final Condition notEmpty;private final Condition notFull;this.items = new Object[capacity];lock = new ReentrantLock(fair);notEmpty = lock.newCondition();notFull = lock.newCondition();public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == 0) notEmpty.await(); return dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125;private E dequeue() &#123; final Object[] items = this.items; E x = (E) items[takeIndex]; items[takeIndex] = null; if (++takeIndex == items.length) takeIndex = 0; count--; // 如果迭代器itrs不为null，则需要维护下该迭代器。可忽略 if (itrs != null) itrs.elementDequeued(); notFull.signal(); return x;&#125;public void put(E e) throws InterruptedException &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; // while loop防止意外的通知，只有条件符合才能退出循环 while (count == items.length) notFull.await(); enqueue(e); &#125; finally &#123; lock.unlock(); &#125;&#125;private void enqueue(E x) &#123; final Object[] items = this.items; items[putIndex] = x; if (++putIndex == items.length) putIndex = 0; count++; notEmpty.signal();&#125;// 补充public E poll() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; return (count == 0) ? null : dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125;// 补充public boolean offer(E e) &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lock(); try &#123; if (count == items.length) return false; else &#123; enqueue(e); return true; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125; Condition实现lock.newCondition() 的作用其实是 new 了一个在AQS 内部声明的 ConditionObject 对象， ConditionObject 是AQS 的内部类，可以访问 AQS 内部的变量和方法。每个Condition对象都包含着一个队列（等待队列），用来存放调用条件变量的 await() 方法时被阻塞的线程。这个条件队列和 AQS 的同步队列不是一回事，该队列是Condition对象实现等待/通知功能的关键。 等待队列 一个 Condition 包含一个等待队列，Condition拥有首节点（firstWaiter）和尾节点（lastWaiter）。当前线程调用Condition.await()方法，将会以当前线程构造节点，将原有的尾节点 nextWaiter 指向它，并且更新尾节点即可。引用更新的过程并没有使用CAS保证，原因在于调用await()方法的线程必定是获取了锁的线程，也就是说该过程是由锁来保证线程安全的。 在Object的监视器模型上，一个对象拥有一个同步队列和等待队列，而并发包中的Lock（更确切地说是同步器）拥有一个同步队列和多个等待队列。 await() 调用Condition的await()方法（或者以await开头的方法），会构造一个类型为Node.CONDITION 的node 节点，然后将该节点插入条件队列末尾并释放锁，同时当前线程也会被阻塞挂起。之后唤醒同步队列中的后继节点，然后当前线程会进入等待状态。 123456789101112131415161718192021public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 创建新 node 节点，插入到条件队列末尾 Node node = addConditionWaiter(); // 释放当前线程获得到的锁 int savedState = fullyRelease(node); int interruptMode = 0; // 调用 park 方法阻塞当前线程 while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); &#125; signal()signal() 方法会进行isHeldExclusively()检查，确认当前线程是获取锁的线程。接着会把条件队列里头节点从条件队列里面移除并放入 AQS 的同步队列里面，然后使用 LockSupport 唤醒节点中的线程。 l o ck（） 方法获取锁） ， 在内部会把条件队列里面队头的一个线程节点从条件队列里面移除并 被唤醒后的线程，将从 await() 方法中的while循环中退出（isOnSyncQueue方法返回true，节点已经在同步队列中），进而调用同步器的 acquireQueued() 方法加入到获取同步状态的竞争中。 123456789public final void signal() &#123; // 确认当前线程是获取锁的线程 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) // 将条件队列头元素移动到AQS队列 doSignal(first);&#125; Condition的signalAll()方法，相当于对等待队列中的每个节点均执行一次signal()方法，效果就是将等待队列中所有节点全部移动到同步队列中，并唤醒每个节点的线程。 4. LockSupport线程阻塞类工具，可以在线程内任何位置让线程阻塞。1. 和Thread.suspend()相比，它弥补了由于resume()在前发生，导致线程无法继续执行的情况。2. 和Object.wait()相比，它不需要先获得某个对象的锁。3. 也不会抛出InterruptedException异常。 LockSupport的静态方法park()可以阻塞当前线程，类似的还有parkNanos()、parkUntil()等方法，它们实现了一个限时的等待。 unpark(Thread thread)方法原来唤醒一个被阻塞的线程。 1234567891011121314151617181920212223242526272829public class LockSupportDemo &#123; public static Object u = new Object(); static ChangeObjectThread t1 = new ChangeObjectThread(\"t1\"); static ChangeObjectThread t2 = new ChangeObjectThread(\"t2\"); public static class ChangeObjectThread extends Thread &#123; public ChangeObjectThread(String name) &#123; super.setName(name); &#125; @Override public void run() &#123; synchronized (u) &#123; System.out.println(\"in \" + getName()); LockSupport.park(); &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; t1.start(); Thread.sleep(100); t2.start(); LockSupport.unpark(t1); LockSupport.unpark(t2); t1.join(); t2.join(); &#125;&#125; 虽然无法保证unpark()方法发生在park()方法之后。但以上代码自始至终都可以正常的结束，不会因为park()方法而导致线程永久性的挂起。这是因为LockSupport类使用类似信号量的机制。它为每一个线程准备了一个许可，如果许可可用，那么park()函数会立即返回，并且消费这个许可（也就是将许可变为不可用），如果许可不可用，就会阻塞。而unpark()则使得一个许可变为可用（但是和信号量不同的是，许可不能累加，你不可能拥有超过一个许可，它永远只有一个）。这个特点使得：即使unpark()操作发生在park()之前，它也可以使下一次的park()操作立即返回。 如果使用park(Object)函数，还可以为当前线程设置一个阻塞对象。这个阻塞对象会出现在线程Dump中。这样在分析问题时，就更加方便了。 LockSupport.park()还能支持中断响应，如果其他线程调用了阻塞线程的interrupt()方法，设置了中断标志，则阻塞线程会返回。和其他接收中断的函数很不一样，LockSupport.park()不会抛出InterruptedException异常。它只是会默默的返回，我们可以从Thread.interrupted()等方法获得中断标记。 5. 使用锁的最佳实践并发大师 Doug Lea《Java 并发编程：设计原则与模式》一书中，推荐的三个用锁的最佳实践： 永远只在更新对象的成员变量时加锁 永远只在访问可变的成员变量时加锁 永远不在调用其他对象的方法时加锁 关于最后一条同样是尽量要去遵守：调用其他对象的方法，实在是太不安全了，也许其他方法里面有线程 sleep() 的调用，也可能会有奇慢无比的 I/O 操作，这些都会严重影响性能。更可怕的是，其他类的方法可能也会加锁，然后双重加锁就可能导致死锁。 6. CaseQ：下面的代码是否存在死锁？ A：不出现死锁，但会出现活锁（主动将资源释放给他人使用，那么就会出现资源不断在两个线程中跳动，而没有一个线程可以同时拿到所有资源而正常执行）。 1234567891011121314151617181920212223class Account &#123; private int balance; private final Lock lock = new ReentrantLock(); // 转账 void transfer(Account tar, int amt)&#123; while (true) &#123; if(this.lock.tryLock()) &#123; try &#123; if (tar.lock.tryLock()) &#123; try &#123; this.balance -= amt; tar.balance += amt; &#125; finally &#123; tar.lock.unlock(); &#125; &#125;//if &#125; finally &#123; this.lock.unlock(); &#125; &#125;//if &#125;//while &#125;//transfer&#125; Reference 《Java并发编程的艺术》 《Java并发编程之美》 https://time.geekbang.org/column/article/87779","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"https://weilans.github.io/tags/concurrent/"}]},{"title":"使用自定义ClassLoader加载SpringBoot打包文件中嵌套jar驱动","slug":"使用ClassLoader在SpringBoot打包文件中获取嵌套jar","date":"2019-09-11T06:25:51.000Z","updated":"2019-10-06T12:51:04.397Z","comments":true,"path":"2019/09/11/使用ClassLoader在SpringBoot打包文件中获取嵌套jar/","link":"","permalink":"https://weilans.github.io/2019/09/11/使用ClassLoader在SpringBoot打包文件中获取嵌套jar/","excerpt":"需求：针对某些DB不同版本的冲突问题，采用自定义类加载器的方式自行加载 Driver，驱动包放至 jdbc module 下，而 web module 在使用 Spring Boot 打成 jar 包后，需要获取到内部 jdbc module 中的驱动包。Spring Boot jar 包启动时，自定义类加载需要能够读到驱动包资源。","text":"需求：针对某些DB不同版本的冲突问题，采用自定义类加载器的方式自行加载 Driver，驱动包放至 jdbc module 下，而 web module 在使用 Spring Boot 打成 jar 包后，需要获取到内部 jdbc module 中的驱动包。Spring Boot jar 包启动时，自定义类加载需要能够读到驱动包资源。 曾几何时，我以为所谓的Spring Boot 启动原理这些知识点最多就是面试时候可能问到的东西，后来在工作时还真用到了。 前期尝试这种需求，本以为并不难做，毕竟针对 jar 包内部的 jar，Java URL 协议中本身就有jar:file:前缀提供支持。使用PathMatchingResourcePatternResolver获取到 URL 后，直接赋给 URLClassLoader 应该是可行的。这种方式在 IDE 中运行时没有问题的，urls 中的 URL 都是以file:为前缀，运行正常；而打成 jar 包运行时，URL的格式变为jar:file:/...web.jar!/BOOT-INF/lib/...jdbc.jar!/.../hive/2.1.1/hive-common-2.1.1.jar，运行时出现了java.lang.ClassNotFoundException。 12345678String location = \"classpath:drivers/hive/2.1.1/*.jar\"; PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver();Resource[] resources = resolver.getResources(locationPattern);URL[] urls = new URL[resources.length];for (int i = 0; i &lt; resources.length; i++) &#123; urls[i] = resources[i].getURL();&#125;return new URLClassLoader(urls, getClassLoader()); 重新调试我选择在一个单独的调试项目下对刚才生成的jar包进行调试。第一直觉是 URLClassloader 是不是不支持这种 jar:file前缀 URL，不过并没有找到相关描述信息，不过倒是发现刚才的jar:file的URL中没有加上!/后缀（这表示在 jar 包内部就行查找）。实际上，对于原始的JarFile URL，只支持一个!/。那 Spring Boot 是怎么做到的呢，他是怎么做到能够读取到 jar in jar 呢，原来 Spring Boot 扩展了协议，使其能够支持读取嵌套 jar。于是在调试项目下，我引入了spring-boot-loader的依赖进行试验。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-loader&lt;/artifactId&gt;&lt;/dependency&gt; 由于一般 Spring Boot 打成的 jar 包中的META-INF/MANIFEST.MF文件中会包含Main-Class: org.springframework.boot.loader.JarLauncher。即指定了 Main Class 为 JarLauncher。在其 launch 方法中发现，Spring Boot 就是在 JarFile.registerUrlProtocolHandler()注册了URLStreamHandler的实现：org.springframework.boot.loader.jar.Handler。 123456789101112131415// in Launcherprotected void launch(String[] args) throws Exception &#123; JarFile.registerUrlProtocolHandler(); ClassLoader classLoader = createClassLoader(getClassPathArchives()); launch(args, getMainClass(), classLoader);&#125;// in JarFileprivate static final String PROTOCOL_HANDLER = \"java.protocol.handler.pkgs\";public static void registerUrlProtocolHandler() &#123; String handlers = System.getProperty(PROTOCOL_HANDLER, \"\"); System.setProperty(PROTOCOL_HANDLER, (\"\".equals(handlers) ? HANDLERS_PACKAGE : handlers + \"|\" + HANDLERS_PACKAGE)); resetCachedUrlHandlers();&#125; 在测试项目下，由于是 IDE 运行，我先在 main 方法中加入了JarFile.registerUrlProtocolHandler()。在Handle的openConnection方法中调用了JarURLConnection的get(URL url, JarFile jarFile)方法，真正报错的地方在于内部的jarFile.getNestedJarFile(jarEntry)，这个信息在java.lang.ClassNotFoundException的堆栈中是没有显示的： 1java.lang.IllegalStateException: Unable to open nested entry '....jar'. It has been compressed and nested jar files must be stored without compression. Please check the mechanism used to create your executable jar file 显示是 Jar 包压缩的问题？于是我在 jdbc module 的 pom 文件中加了这么一段，compress 置为了false，结果发现终于成功了。 12345678910111213&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;compress&gt;false&lt;/compress&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 最终实现到最后发现实际上改的地方不多，但是如果自己不去调试 Spring Boot 的启动包，也发现不了真正的原因。 改动1就是 jdbc module 加入了maven-jar-plugin插件且compress置为 false。 改动2是在一开始实现的 for 循环中，对于jar:file开头的URL加了!/后缀。 123456789for (int i = 0; i &lt; resources.length; i++) &#123; String urlStr = resources[i].getURL().toString(); if (StringUtils.isNotBlank(urlStr) &amp;&amp; urlStr.startsWith(\"jar:file\")) &#123; urlStr = urlStr + \"!/\"; &#125; URL url = ResourceUtils.getURL(urlStr); urls[i] = url; log.info(url.toString());&#125; 实际上代码中不需要加JarFile.registerUrlProtocolHandler()注册协议，由于刚才的调试项目的main方法运行的，所以才加上。而在正式项目代码处，若打包运行的话，jar 包启动时本身就执行了注册协议；若在 IDE 里运行，file:前缀则不需要走此协议。当然如果不是加上这句话进行调试，也发现不了问题。 Reference https://benjaminwhx.com/2018/07/14/说说Spring中的资源文件的读取/ https://segmentfault.com/a/1190000013532009 https://blog.iooo.tech/2018/06/19/SpringBoot可执行文件解析/","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://weilans.github.io/tags/jvm/"},{"name":"spring","slug":"spring","permalink":"https://weilans.github.io/tags/spring/"}]},{"title":"JVM 类加载机制解析","slug":"JVM-类加载机制","date":"2019-09-07T05:40:20.000Z","updated":"2019-10-04T10:33:24.027Z","comments":true,"path":"2019/09/07/JVM-类加载机制/","link":"","permalink":"https://weilans.github.io/2019/09/07/JVM-类加载机制/","excerpt":"“与那些在编译时需要进行连接工作的语言不同，在Java语言里面，类型的加载、连接和初始化过程都是在程序运行期间完成的，这种策略虽然会令类加载时稍微增加一些性能开销，但是会为Java应用程序提供高度的灵活性，Java里天生可以动态扩展的语言特性就是依赖运行期动态加载和动态连接这个特点实现的。”","text":"“与那些在编译时需要进行连接工作的语言不同，在Java语言里面，类型的加载、连接和初始化过程都是在程序运行期间完成的，这种策略虽然会令类加载时稍微增加一些性能开销，但是会为Java应用程序提供高度的灵活性，Java里天生可以动态扩展的语言特性就是依赖运行期动态加载和动态连接这个特点实现的。” 类加载机制类加载时机以前初学的时候，以为在Web程序启动时，静态代码块中的内容就会执行。其实这是没有理解类是何时进行初始化的。 加载、验证、准备、初始化和卸载这5个阶段的顺序是确定的，类的加载过程必须按照这种顺序按部就班地开始，而解析阶段则不一定：它在某些情况下可以在初始化阶段之后再开始，这是为了支持Java语言的动态绑定。Java虚拟机规范中没有强制规定类何时初始化，但是对于初始化阶段，则严格规定以下情况必须立即对类进行“初始化”（加载、验证、准备自然需要在此之前开始）： 遇到new、getstatic、putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令的最常见的Java代码场景是：使用new关键字实例化对象的时候、读取或设置一个类的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。（而一个接口在初始化时，并不要求其父接口全部都完成了初始化，只有在真正使用到父接口的时候（如引用接口中定义的常量）才会初始化。） 当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。” 当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。” 这五种场景称为“主动引用”，而引用类的方法不会触发初始化的则称为“被动引用”。被动引用具体有以下三种例子： 通过子类引用父类的静态字段，不会导致子类初始化。（对于静态字段，只有直接定义这个字段的类才会初始化，因此只会触发父类的初始化。） 通过数组定义来引用类，不会触发此类的初始化。 常量在编译阶段会存入调用类的常量池中，本质上没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。 类加载过程类装载主要涉及三个步骤：加载、连接（验证、准备、解析）、初始化 加载 (Class-Loading) 通过类的全限定名取得类的二进制流 将字节流所代表的静态存储结构转为方法区数据结构 在Java堆中生成对应的java.lang.Class对象 连接 - 验证其目标是保证Class文件字节流的格式是正确的，符合虚拟机的要求，主要涉及： 文件格式的验证 是否以0xCAFEBABE开头 版本号是否合理 元数据验证：对字节码描述的信息进行语义分析，以保证符合 Java 语言规范的要求 该类是否有父类（除了 Object，所有类都应当有父类） 该类是否继承了不允许被继承的类（被 final 修饰的类） 非抽象类是否实现了所有该实现的抽象方法 字节码验证 (很复杂)：对类的方法体进行校验分析，以保证方法执行时不会危害虚拟机安全 运行检查 栈数据类型和操作码数据参数吻合 保证跳转指令不会跳转到方法体以外的字节码指令上 保证方法体中的类型转换是有效的 符号引用验证：发生在将符号引用转化为直接引用的时候，动作发生在连接第三阶段 - 解析的过程中。像java.lang.NoSuchFieldError，java.lang.NoSuchMethodError都是发生在此阶段。 符号引用中通过字符串描述的全限定名是否能找到对应的类 在指定类中是否存在符合方法的字段描述符以及简单名称所描述的方法和字段 访问的方法或字段是否存在且有足够的权限 连接 - 准备分配内存，并为类变量设置初始值，变量所使用的内存都在方法区中进行分配。 内存分配仅为类变量 (static 修饰)，而不包括实例变量，实例变量将会在对象示例化时随着对象一起分配在 Java 堆中。如public static int v=1;在准备阶段中，v会被设置为0。在初始化的&lt;clinit&gt;中才会被设置为1。 对于static final类型，在准备阶段就会被赋上正确的值public static final int v=1; 连接 - 解析将符号引用转为直接引用的过程。 符号引用：符号可以是任何形式的字面量，引用的目标不一定已经加载到内存中。 直接引用：直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。 初始化到了初始化阶段，才真正开始执行类中定义的 Java 程序代码。 执行类构造器&lt;clinit&gt; static变量 赋值语句 static{} 语句 子类的&lt;clinit&gt;调用前保证父类的&lt;clinit&gt;被调用 &lt;clinit&gt;是线程安全的。虚拟机会保证一个类的＜clinit＞方法在多线程环境中被正确地加锁、同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的＜clinit＞方法，其他线程都需要阻塞等待，直到活动线程执行＜clinit＞()方法完毕。 类加载器对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机中的唯一性。否则，即使这两个类来源于同一个Class文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。“相等”包括代表类的Class对象的equals()方法、isAssignableFrom()方法、isInstance()方法的返回结果，也包括使用instanceof关键字做对象所属关系判定等情况。 什么是类装载器ClassLoader ClassLoader是一个抽象类； ClassLoader的实例将读入Java字节码将类装载到JVM中； ClassLoader可以定制，满足不同的字节码流获取方式； ClassLoader负责类装载过程中的加载阶段。 ClassLoader的重要方法12345678// 载入并返回一个Classpublic Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException// 定义一个类，不公开调用protected final Class&lt;?&gt; defineClass(byte[] b, int off, int len)// loadClass回调该方法，自定义ClassLoader的推荐做法 protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException// 寻找已经加载的类protected final Class&lt;?&gt; findLoadedClass(String name) ClassLoader分类 BootStrap ClassLoader （启动ClassLoader） 负责将存放在＜JAVA_HOME＞\\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的类库加载到虚拟机内存中。 Extension ClassLoader （扩展ClassLoader） 负责加载＜JAVA_HOME＞\\lib\\ext目录中的，或者被java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。 App ClassLoader （应用ClassLoader/系统ClassLoader） 负责加载用户类路径ClassPath上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 Custom ClassLoader(自定义ClassLoader) Custom ClassLoader的简单示例从特定路径找到特定类的class文件，获取其字节数组后调用defineClass方法来定义类。 123456789101112131415public class CustomClassLoader extends ClassLoader &#123; private String path; public CustomClassLoader(String path) &#123; this.path = path; &#125; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; // 自己实现的方法：由 path + name + \".class\" 获取class文件字节数组 byte[] classBytes = loadClassData(name); return defineClass(name, classBytes, 0, classBytes.length); &#125;&#125; 双亲委派模型 上图中的类加载器之间的层次关系即为类加载器的双亲委派模型：自底向上检查类是否被加载，自顶向下尝试加载类。 类加载器不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。 好处是：Java类随着它的类加载器一起具备了一种带有优先级的层次关系。Object无论哪一个类加载器要加载这个类，最终都是委派给启动类加载器进行加载，各种类加载器环境中都是同一个类。若没有使用双亲委派模型，用户自己编写了一个Object类，并放在程序的ClassPath中，那系统中将会出现多个不同的Object类，Java类型体系中最基础的行为也就无法保证，应用程序也将会变得一片混乱。 以下代码就是 ClassLoader.loadClass方法，可以看到双亲委派的具体实现。 123456789101112131415161718192021222324252627282930313233343536373839protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; // 可能涉及到多个线程调用同一个classLoader来加载同一个类 synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; // 由 Bootstrap ClassLoader 找是否加载个这个类 c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 破坏双亲委派模型First该模型虽然解决了各个类加载器基础类的统一问题，但如果基础类要调用用户的代码则无法实现。如SPI的定义在rt.jar(即BootStrap ClassLoader)中，而实现类在AppClassLoader中。 解决方式为线程上下文类加载器(Thread Context ClassLoader)，基本思想是，在顶层ClassLoader中，传入底层ClassLoader的实例。这个类加载器可以通过java.lang.Thread类的setContextClassLoaser()方法进行设置，如果创建线程时还未设置，它将会从父线程中继承一个，如果在应用程序的全局范围内都没有设置过的话，那这个类加载器默认就是应用程序类加载器。读取即为Thread.currentThread().getContextClassLoader()。 Second双亲委派模式是默认的模式，但不是必须这么做，破坏双亲委派模型也可以自定义实现ClassLoader： Tomcat 的 WebappClassLoader 就会先加载自己的Class，找不到再委托parent； OSGi 的 ClassLoader形成网状结构，根据需要自由加载Class。 loadClass和forName之间的区别ClassLoader.loadClass(name)调用重载方法loadClass(name, false)，第二个参数为 resolve，其含义就是是否进行解析(连接的解析阶段)，若是 true，会调用 resolveClass，开始连接指定的类。所以 loadClass 不会连接类。 而Class.forName内部调用 forname0 方法，其第二个布尔值参数代表是否初始化这个类， 而调用时使用的是 true，即会初始化这个类。 所以结论是，Class.forName 得到的是 class 是已经初始化的；而 ClassLoader.loadClass 得到的 Class 是还没有进行连接的。可以自定义一个类，类中加一个静态代码块进行确认是否进行了初始化。 loadClass 可以在 Spring IOC 中看到身影，这么做的原因是和 Spring 的 lazy loading 有关。为了加快类加载速度，大量使用延时加载技术，loadClass不需要执行类中的初始化代码且不需要连接，类的初始化工作留到实际使用到这个类的时候才去进行。 Tomcat 类加载器结构主流Java服务器都实现了自定义的类加载器，因为一个健全的Web服务器需要解决以下几个问题： 部署在同一个服务器上的两个Web应用程序所使用的Java类库可以实现相互隔离。 部署在同一个服务器上的两个Web应用程序所使用的Java类库可以互相共享。如果类库不能共享，虚拟机的方法区就会很容易出现过度膨胀的风险。 服务器需要尽可能地保证自身的安全不受部署的Web应用程序影响。一般来说，基于安全考虑，服务器所使用的类库应该与应用程序的类库互相独立。 支持JSP应用的Web服务器，大多数都需要支持HotSwap功能。 因为上述问题的存在，所以Web服务器一般都会划分出好几个类路径。以Tomcat为例： /common目录：类库可被Tomcat和所有的Web应用程序共同使用。 /server目录：类库可被Tomcat使用，对所有的Web应用程序都不可见。 /shared目录：类库可被所有的Web应用程序共同使用，但对Tomcat自己不可见。 /WebApp/WEB-INF目录：类库仅仅可以被此Web应用程序使用，对Tomcat和其他Web应用程序都不可见。 为了支持这套目录结构，并对目录里面的类库进行加载和隔离，Tomcat自定义了多个类加载器。CommonClassLoader、CatalinaClassLoader、SharedClassLoader和WebappClassLoader则是Tomcat自己定义的类加载器，它们分别加载/common/*、/server/*、/shared/*和/WebApp/WEB-INF/*中的Java类库。其中WebApp类加载器和Jsp类加载器通常会存在多个实例，每一个Web应用程序对应一个WebApp类加载器，每一个JSP文件对应一个Jsp类加载器。 思维导图 Reference周志明. 深入理解Java虚拟机：JVM高级特性与最佳实践","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://weilans.github.io/tags/jvm/"}]},{"title":"[回顾并发基础] Java并发编程基础","slug":"Java并发札记-2-Java并发编程基础","date":"2019-08-24T16:01:46.000Z","updated":"2019-12-27T09:15:20.578Z","comments":true,"path":"2019/08/25/Java并发札记-2-Java并发编程基础/","link":"","permalink":"https://weilans.github.io/2019/08/25/Java并发札记-2-Java并发编程基础/","excerpt":"","text":"并发概念同步（Synchronous） 异步（Asynchronous） 同步和异步通常用来形容一次方法调用。同步方法调用一旦开始，调用者必须等到方法调用返回后，才能继续后续的行为。异步方法调用更像一个消息传递，一旦开始，方法调用就会立即返回，调用者就可以继续后续的操作。而异步方法通常会在另外一个线程中“真实”地执行。整个过程，不会阻碍调用者的工作。如果异步调用需要返回结果，那么当这个异步调用真实完成时，则会通知调用者。 阻塞（Blocking） 非阻塞（NonBlocking） 阻塞和非阻塞通常用来形容多线程间的相互影响。比如一个线程占用了临界区资源，那么其他所有需要这个资源的线程就必须在这个临界区中进行等待。等待会导致线程挂起，这种情况就是阻塞。如果占用资源的线程一直不愿意释放资源，那么其他所有阻塞在这个临界区上的线程都不能工作。非阻塞的意思与之相反，它强调没有一个线程可以妨碍其他线程执行。所有的线程都会尝试不断前向执行。 死锁（Deadlock）、饥饿（Starvation）和活锁（Livelock） 死锁、饥饿和活锁都属于多线程的活跃性问题。 饥饿：指某一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行。比如它的线程优先级可能太低，而高优先级的线程不断抢占它需要的资源。或者某一个线程一直占着关键资源不放，导致其他需要这个资源的线程无法正常执行。 活锁：主动将资源释放给他人使用，那么就会出现资源不断在两个线程中跳动，而没有一个线程可以同时拿到所有资源而正常执行。 死锁：资源竞争而产生的相互等待的情况。主要原因是资源有限以及竞争不当。四个必要条件：互斥、占有且等待、不可抢占、循环等待（存在一个进程链，使得每个进程都占有下一个进程所需的至少一种资源）。避免死锁可以使用银行家算法。 并发（Concurrency）和并行（Parallelism） 严格意义上来说，并行的多个任务是真实的同时执行，而对于并发来说，这个过程只是交替的，一会儿运行任务A一会儿执行任务B，系统会不停地在两者间切换。但对于外部观察者来说，即使多个任务之间是串行并发的，也会造成多任务间是并行执行的错觉。 Java 并发编程基础线程线程是比进程更轻量级的调度执行单位，线程的引入，可以把一个进程的资源分配和执行调度分开，各个线程既可以共享进程资源（内存地址、文件I/O等），又可以独立调度（线程是CPU调度的基本单位）。 线程的状态见于 Thread.State 枚举类： 初始(NEW) - 新创建了一个线程对象，但还没有调用start()方法。 运行(RUNNABLE) - Java线程中将就绪(ready)和运行中(running)两种状态笼统的成为“运行中”。（等待被线程调度选中获取cpu的使用权，处于就绪状态(ready)；就绪的线程在获得cpu 时间片后变为运行中状态(running)）。 阻塞(BLOCKED) - 表示线程阻塞于锁。 等待(WAITING) - 进入该状态的线程需要等待其他线程做出一些特定动作（通知或中断）。 超时等待(TIME_WAITING) - 该状态不同于WAITING，它可以在指定的时间内自行返回。 终止(TERMINATED) - 表示该线程已经执行完毕。 构造线程新构造的线程对象是由其parent线程来进行空间分配的，而child线程继承了parent是否为Daemon、优先级和加载资源的 ContextClassLoader 以及可继承的ThreadLocal，同时还会分配一个唯一的ID来标识这个child线程。至此，一个能够运行的线程对象就初始化好了，在堆内存中等待着运行。 虽然可以使用匿名内部类重载run()方法来新建一个线程。但考虑到Java是单继承的，也就是说继承本身也是一种很宝贵的资源，因此，主要使用Runnable接口来实现同样的操作。 终止线程stop()方法太过于暴力，强行把执行到一半的线程终止，并不会保证线程资源的正常释放，通常没有给予线程完成资源释放工作的机会，可能会引起一些数据不一致的问题，导致程序可能工作在不确定状态下。 suspend(), resume(), stop()都标注为过期方法，暂停以及恢复操作可以使用等待/通知机制代替。suspend()方法在导致线程暂停的同时，并不会去释放任何锁资源，任何线程想要访问锁都会被牵连，导致无法正常继续运行。 中断线程中断可以理解为是线程的一个标志位属性。线程中断并不会使线程立即退出，而是给线程发送一个通知，告知目标线程，有人希望你退出。至于目标线程接到通知后如何处理，则完全由目标线程自行决定。 123456// 中断线程public void Thread.interrupt() // 判断是否被中断public boolean Thread.isInterrupted() // 判断是否被中断，并清除当前中断状态public static boolean Thread.interrupted() 许多声名抛出InterruptedException的方法在抛出InterruptedException之前，Java虚拟机会先将该线程的中断标识位清除，然后抛出InterruptedException，此时调用isInterrupted()方法将会返回false。 123456789101112131415161718192021222324public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread() &#123; @Override public void run() &#123; while (true) &#123; if (Thread.currentThread().isInterrupted()) &#123; System.out.println(\"Interruted!\"); break; &#125; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; System.out.println(\"Interruted When Sleep\"); //设置中断状态 Thread.currentThread().interrupt(); &#125; Thread.yield(); &#125; &#125; &#125;; t1.start(); Thread.sleep(2000); t1.interrupt();&#125; 如果线程被中断程序会抛出异常，进入catch子句，为了后续逻辑处理，执行了Thread.interrupt()方法再次中断自己，置上中断标记位。只有这么做，在中断检查中，才能发现当前线程已经被中断了。 安全地终止线程：中断操作是一种简单的线程间交互方式，此种交互方式最适合用来取消或停止任务。除了中断之外，还可以利用一个boolean变量控制是否需要停止任务并终止该线程。示例代码中可以通过标识位或者中断的方式使线程在终止时有机会去清理资源。 123456789101112131415161718192021222324252627282930313233public class Shutdown &#123; public static void main(String[] args) throws Exception &#123; Runner one = new Runner(); Thread countThread = new Thread(one, \"CountThread\"); countThread.start(); // 睡眠1秒，main线程对CountThread进行中断，使CountThread能够感知中断而结束 TimeUnit.SECONDS.sleep(1); countThread.interrupt(); Runner two = new Runner(); countThread = new Thread(two, \"CountThread\"); countThread.start(); // 睡眠1秒，main线程对Runner two进行取消，使CountThread能够感知on为false而结束 TimeUnit.SECONDS.sleep(1); two.cancel(); &#125; private static class Runner implements Runnable &#123; private long i; private volatile boolean on = true; @Override public void run() &#123; while (on &amp;&amp; !Thread.currentThread().isInterrupted()) &#123; i++; &#125; System.out.println(\"Count i = \" + i); &#125; public void cancel() &#123; on = false; &#125; &#125;&#125; 线程组ThreadGroup不属于Java并发包中的内容，它是java.lang中的内容。主要用于对线程方便进行统一管理，线程组可以进行复制，快速定位到一个线程，统一进行异常设置等。 activeCount()可以获得活动线程的总数，但由于线程是动态的，因此这个值只是一个估计值，无法确定精确，list()方法可以打印这个线程组中所有的线程信息，对调试有一定帮助。 ThreadGroup中有一个uncaughtException()方法。当线程组中某个线程发生Unchecked exception异常时，由执行环境调用此方法进行相关处理，如果有必要，可以重新定义此方法。 123456789101112131415161718192021public static void main(String[] args) &#123; ThreadGroup threadGroup1 = // 匿名类写法 new ThreadGroup(\"group1\") &#123; // 继承ThreadGroup并重新定义以下方法 // 在线程成员抛出unchecked exception 会执行此方法 public void uncaughtException(Thread t, Throwable e) &#123; System.out.println(t.getName() + \": \" + e.getMessage()); &#125; &#125;; // 匿名类写法 Thread thread1 = // 这个线程是threadGroup1的一员 new Thread(threadGroup1, new Runnable() &#123; public void run() &#123; // 抛出unchecked异常 throw new RuntimeException(\"测试异常\"); &#125; &#125;); thread1.start();&#125; 守护线程Daemon线程：是一种支持型线程，主要用作程序后台调度以及支持性工作。当一个Java虚拟机中不存在非Daemon线程的守护，Java虚拟机会退出。可以通过在启动之前设置Thread.setDaemon(true)来设置。 构建Daemon线程时，不能依靠构建finally块中的内容来确保执行关闭或清理资源的逻辑。 12345678910111213141516171819202122public class DaemonDemo &#123; public static class DaemonT extends Thread &#123; @Override public void run() &#123; while (true) &#123; System.out.println(\"I am alive\"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Thread t = new DaemonT(); t.setDaemon(true); t.start(); Thread.sleep(3000); // 在main线程休眠3秒后退出时，整个程序会随之结束 &#125;&#125; 线程优先级123public final static int MIN_PRIORITY = 1;public final static int NORM_PRIORITY = 5;public final static int MAX_PRIORITY = 10; 优先级的范围是1~10，默认优先级是5。 线程的优先级调度和底层操作系统有密切的关系，在各个平台上表现不一，并且这种优先级产生的后果也可能不容易预测，无法精准控制，操作系统可能完全不会理会Java线程对优先级的设定。 synchronized原理同步代码块的实现会使用 monitorenter 和 monitorexit 指令，同步方法则依靠方法修饰符上的 ACC_SYNCHRONIZED 来完成的。无论是何种方式，本质上是对一个对象的监视器 (moitor) 进行获取，任何对象都有一个monitor与之关联，这个过程是排他的，每个对象都拥有自己的监视器，同一时刻只能一个线程获得对象监视器。 monitorenter 指令是在编译后插入到同步代码块的开始位置，monitorexit 是插入到方法结束处和异常处（JVM保证了每个monitorenter 有对应的 monitorexit 与之配对）。当执行 monitorenter 指令时，执行线程必须先获取到该对象的监视器才能进入，没有获取到监视器的线程会阻塞在同步块或同步方法的入口处没进入 BLOCKED 状态。 执行 monitorenter 时获取对象的锁，会把锁的计数器+1（可重入），在执行 monitorexit 时锁计数器会－1，当计数器为0会释放锁。 synchronized 用的锁是存在Java对象头里的，加锁本质就是在锁对象的对象头中写入当前线程id。 案例 当修饰静态方法的时候，锁定的是当前类的 Class 对象； 当修饰非静态方法的时候，锁定的是当前实例对象 this。 case1123456789class SafeCalc &#123; long value = 0L; long get() &#123; return value; &#125; synchronized void addOne() &#123; value += 1; &#125;&#125; 执行 addOne()方法后，value值对于get()方法是没有可见性保证的，需要在 get 方法上也加上 synchronized。 case2123456789class SafeCalc &#123; static long value = 0L; synchronized long get() &#123; return value; &#125; synchronized static void addOne() &#123; value += 1; &#125;&#125; 上面的代码是用两个锁保护一个资源。这个受保护的资源就是静态变量 value，两个锁分别是 this 和 SafeCalc.class。由于临界区 get() 和 addOne() 是用两个锁保护的，因此这两个临界区没有互斥关系，临界区 addOne() 对 value 的修改对临界区 get() 也没有可见性保证，这就导致并发问题了。 case3123456pulbic class Something &#123; public synchronized void isSyncA()&#123;&#125; public synchronized void isSyncB()&#123;&#125; public static synchronized void cSyncA()&#123;&#125; public static synchronized void cSyncB()&#123;&#125;&#125; x.isSyncA()与x.isSyncB() 不能被同时访问。因为isSyncA()和isSyncB()都是访问同一个对象(对象x)的同步锁； x.isSyncA()与y.isSyncA() 可以同时被访问。因为访问的不是同一个对象的同步锁，x.isSyncA()访问的是x的同步锁，而y.isSyncA()访问的是y的同步锁； x.cSyncA()与y.cSyncB() 不能被同时访问。因为cSyncA()和cSyncB()都是static类型，x.cSyncA()相当于Something.isSyncA()，y.cSyncB()相当于Something.isSyncB()，因此它们共用一个同步锁，不能被同时反问； x.isSyncA()与Something.cSyncA()可以被同时访问。因为isSyncA()是实例方法，x.isSyncA()使用的是对象x的锁；而cSyncA()是静态方法，Something.cSyncA()可以理解对使用的是“类的锁”。因此，它们是可以被同时访问的。 死锁转账案例12345678910class Account &#123; private int balance; // 转账 synchronized void transfer(Account target, int amt)&#123; if (this.balance &gt; amt) &#123; this.balance -= amt; target.balance += amt; &#125; &#125; &#125; 上述代码用于多Account转账是不正确的，因为 synchronized 使用的是 this 这把锁可以保护自己的余额 this.balance，但是保护不了别人的余额 target.balance。 所以可以使用 Account.class作为共享的锁。但会将所有Account的操作串行，性能会很差。 123456789101112class Account &#123; private int balance; // 转账 void transfer(Account target, int amt)&#123; synchronized(Account.class) &#123; if (this.balance &gt; amt) &#123; this.balance -= amt; target.balance += amt; &#125; &#125; &#125; &#125; 于是可以采用如下方式，使用两把锁： 12345678910111213141516class Account &#123; private int balance; // 转账 void transfer(Account target, int amt)&#123; // 锁定转出账户 synchronized(this) &#123; // 锁定转入账户 synchronized(target) &#123; if (this.balance &gt; amt) &#123; this.balance -= amt; target.balance += amt; &#125; &#125; &#125; &#125; &#125; 但这样就会造成死锁，A要向B转账，B也要向A转账，同时拿到第一个锁，但无法等到第二个锁。 死锁发生条件 互斥，共享资源 X 和 Y 只能被一个线程占用； 占有且等待，线程 T1 已经取得共享资源 X，在等待共享资源 Y 的时候，不释放共享资源 X； 不可抢占，其他线程不能强行抢占线程 T1 占有的资源； 循环等待，线程 T1 等待线程 T2 占有的资源，线程 T2 等待线程 T1 占有的资源，就是循环等待。 避免死锁只要破坏上述其中一个条件，死锁就不会发生。互斥条件无法破坏，其他三种有方法破坏： 对于“占用且等待”这个条件，我们可以一次性申请所有的资源，这样就不存在等待了。 对于“不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可抢占这个条件就破坏掉了。 对于“循环等待”这个条件，可以靠按序申请资源来预防。所谓按序申请，是指资源是有线性顺序的，申请的时候可以先申请资源序号小的，再申请资源序号大的，这样线性化后自然就不存在循环了。 关于1，可以添加一个账本管理员，必须通过账本管理员拿到所有资源才会提供给相关方，通过这种方案保证一次申请所有资源。 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Allocator &#123; private List&lt;Object&gt; als = new ArrayList&lt;&gt;(); // 一次性申请所有资源 synchronized boolean apply(Object from, Object to)&#123; if (als.contains(from) || als.contains(to))&#123; return false; &#125; else &#123; als.add(from); als.add(to); &#125; return true; &#125; // 归还资源 synchronized void free(Object from, Object to)&#123; als.remove(from); als.remove(to); &#125;&#125;class Account &#123; // actr 应该为单例 private Allocator actr; private int balance; // 转账 void transfer(Account target, int amt)&#123; // 一次性申请转出账户和转入账户，直到成功 while(!actr.apply(this, target)) ； try&#123; // 锁定转出账户 synchronized(this)&#123; // 锁定转入账户 synchronized(target)&#123; if (this.balance &gt; amt)&#123; this.balance -= amt; target.balance += amt; &#125; &#125; &#125; &#125; finally &#123; actr.free(this, target) &#125; &#125; &#125; 关于2，可以使用Lock。 关于3，可以对每个账号ID进行排序，按照从小到大的顺序锁账号，这样便不会出现循环等待的情况了。破坏循环等待条件的成本在这种场景下是最低的。 1234567891011121314151617181920212223class Account &#123; private int id; private int balance; // 转账 void transfer(Account target, int amt)&#123; Account left = this; Account right = target; if (this.id &gt; target.id) &#123; left = target; right = this; &#125; // 锁定序号小的账户 synchronized(left)&#123; // 锁定序号大的账户 synchronized(right)&#123; if (this.balance &gt; amt)&#123; this.balance -= amt; target.balance += amt; &#125; &#125; &#125; &#125; &#125; 如果Account对象中只有转账业务的话，while(actr.apply(this, target) 和 synchronized(Account.class)的性能优势几乎看不出来，synchronized(Account.class)方案由于 synchronized 三次，性能可能更差；但是如果Account对象中如果还有其它业务，比如查看余额等功能也加了synchronized(Account.class)修饰，那还是while的方式效率更高。此外，如果转账操作非常慢，也是while更有优势。 等待 / 通知 机制线程A调用对象O的wait方法进入等待状态，线程B调用对象O的notify或notifyAll方法后，线程A收到通知后从对象O的wait方法返回，进而执行后续操作。 典型范式等待方（加锁，循环，处理逻辑）1）获取对象的锁。2）如果条件不满足，那么调用对象的wait()方法，被通知后仍要检查条件。3）条件满足则执行对应的逻辑。 123456 synchronized(对象) &#123; while(条件不满足时) &#123; 对象.wait() &#125; 对应的逻辑&#125; 之所以使用while loop，因为可能有其他线程执行对象的notify()或notify()方法，但是条件不满足。即“条件曾经满足过”。当 wait() 返回时，有可能条件已经发生变化了，曾经条件满足，但是现在已经不满足了，所以要重新检验条件是否满足。范式，意味着是经典做法，所以没有特殊理由不要尝试换个写法。 通知方1）获得对象的锁。2）改变条件。3）通知所有等待在对象上的线程。 1234synchronized(对象) &#123; 改变条件 对象.notifyAll()&#125; 如何工作 调用wait()方法后，线程状态由RUNNING变为WAITING，并将当前线程放置到对象的等待队列。 notify()方法将等待队列中的一个等待线程从等待队列中移到同步队列中，而notifyAll()方法则是将等待队列中所有的线程全部移到同步队列，被移动的线程状态由WAITING变为BLOCKED。 注意点： 使用wait()、notify()和notifyAll()时需要先对调用对象加锁。 notify()或notifyAll()方法调用后，等待线程依旧不会从wait()返回，要调用notify()或notifAll()的线程释放锁之后，等待线程才有机会从wait()返回。 wait()、notify()、notifyAll() 方法操作的等待队列是互斥锁的等待队列，所以如果 synchronized 锁定的是 this，那么对应的一定是 this.wait()、this.notify()、this.notifyAll()；如果 synchronized 锁定的是 其他target，那么对应的一定是 target.wait()、target.notify()、target.notifyAll() 。而且 wait()、notify()、notifyAll() 这三个方法能够被调用的前提是已经获取了相应的互斥锁，所以我们会发现 wait()、notify()、notifyAll() 都是在 synchronized{}内部被调用的。如果在 synchronized{}外部调用，或者锁定的 this，而用 target.wait() 调用的话，JVM 会抛出一个运行时异常：java.lang.IllegalMonitorStateException。 典型描述： WaitThread首先获取了对象的锁，然后调用对象的wait()方法，从而放弃了锁并进入了对象的等待队列WaitQueue中，进入等待状态。由于WaitThread释放了对象的锁，NotifyThread随后获取了对象的锁，并调用对象的notify()方法，将WaitThread从WaitQueue移到SynchronizedQueue中，此时WaitThread的状态变为阻塞状态。NotifyThread释放了锁之后，WaitThread再次获取到锁并从wait()方法返回继续执行。 案例改写将前文中提到的转账例子可以改写为： 123456789101112131415161718192021class Allocator &#123; private List&lt;Object&gt; als; // 一次性申请所有资源 synchronized void apply(Object from, Object to)&#123; // 经典写法 while(als.contains(from) || als.contains(to))&#123; try&#123; wait(); &#125;catch(Exception e)&#123; &#125; &#125; als.add(from); als.add(to); &#125; // 归还资源 synchronized void free(Object from, Object to)&#123; als.remove(from); als.remove(to); notifyAll(); &#125;&#125; 同时需尽量使用notifyAll()方法，notify()会随机通知一个等待队列中的一个线程，notifyAll()会通知等待队列中的所有线程。 依然基于上面的例子，假设线程 1 申请到了 AB，线程 2 申请到了 CD，此时线程 3 申请 AB，会进入等待队列，线程 4 申请 CD 也会进入等待队列。假设之后线程 1 归还了资源 AB，如果使用 notify() 来通知等待队列中的线程，有可能被通知的是线程 4，但线程 4 申请的是 CD，所以此时线程 4 还是会继续等待，而真正该唤醒的线程 3 就再也没有机会被唤醒了。 join一个线程A执行了thread.join()时代表当前线程A等待线程终止后才从thread.join()返回。 12public final void join() throws InterruptedExceptionpublic final synchronized void join(long millis) throws InterruptedException 第一个join()方法表示无限等待，它会一直阻塞当前线程，直到目标线程执行完毕。第二个方法给出了一个最大等待时间，如果超过给定时间目标线程还在执行，当前线程也会因为“等不及了”，而继续往下执行。 其方法内部使用等待/通知机制，不停检查join线程是否存活，如果join线程存活则让当前线程永远等待。当join线程终止时，会调用线程自身的notifyAll()方法，通知所有等待在该线程上的线程。 1234567public final synchronized void join(long millis) throws InterruptedException &#123; // 条件不满足，继续等待 while (isAlive()) &#123; wait(0); &#125; // 条件满足，方法返回&#125; 上述代码和等待 / 通知经典范式一致，即加锁、循环、处理逻辑三个步骤。 值得注意的一点是：不要在应用程序中，在Thread对象实例上使用类似wait()或者notify()等方法，因为这很有可能会影响系统API的工作，或者被系统API所影响。 yield1public static native void yield(); Thread.yield() 是一个静态方法，一旦执行，它会使当前线程让出CPU。但要注意，让出 CPU 并不表示当前线程不执行了。当前线程在让出CPU后，还会进行CPU资源的争夺，但是是否能够再次被分配到，就不一定了。因此，对Thread.yield()的调用就好像是在说：我已经完成一些最重要的工作了，我应该是可以休息一下了，可以给其他线程一些工作机会。 如果一个线程不那么重要，或者优先级非常低，而且又害怕它会占用太多的CPU资源，那么可以在适当的时候调用Thread.yield()，给予其他重要线程更多的工作机会。 Case下面代码会得到小20000000很多的数值，原因是Integer属于不变对象。也就是对象一旦被创建，就不可能被修改。 i++ 在真实执行时变成了 i=Integer.valueOf(i.intValue()+1); i++ 的本质是，创建一个新的Integer对象，并将它的引用赋值给i。锁加到不同的对象实例上了。 123456789101112131415161718192021public class BadLockOnInteger implements Runnable &#123; public static Integer i = 0; static BadLockOnInteger instance = new BadLockOnInteger(); @Override public void run() &#123; for (int j = 0; j &lt; 10000000; j++) &#123; synchronized (i) &#123; i++; &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(instance); Thread t2 = new Thread(instance); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(i); &#125;&#125; Reference《实战Java高并发程序设计》 《Java并发编程的艺术》 https://time.geekbang.org/column/article/84601","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"https://weilans.github.io/tags/concurrent/"}]},{"title":"[回顾并发基础] Java内存模型","slug":"Java并发札记-1-Java内存模型","date":"2019-08-24T16:01:46.000Z","updated":"2019-12-19T11:54:13.254Z","comments":true,"path":"2019/08/25/Java并发札记-1-Java内存模型/","link":"","permalink":"https://weilans.github.io/2019/08/25/Java并发札记-1-Java内存模型/","excerpt":"","text":"Java内存模型JMM控制线程间的通信，定义了工作内存和主内存的抽象关系，每个线程有私有工作内存，保留该线程使用的变量的主内存副本拷贝，读写都在工作内存中进行。若要通信的话需把本地内存刷新到主内存中，另一个线程从主内存中读取。 模型三种特征JMM的关键点都是围绕着多线程的原子性、可见性和有序性来建立的。（即为JMM如何解决前篇文中提到的并发问题） 原子性基本数据类型的访问读写是具备原子性的（例外32位系统中long和double的读写是非原子性）。若应用场景需要更大规模的原子性保证，JVM提供了两个高级的字节码指令monitorenter和monitorexit。这两个字节码指令反映到Java代码中就是同步块——synchronized关键字，因此在synchronized块之间的操作也具备原子性。 可见性指当一个线程修改了共享变量的值，其他线程能够立即得知这个修改。volatile可以保证可见性。普通变量与volatile变量的区别是，volatile的特殊规则保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。因此，可以说volatile保证了多线程操作时变量的可见性，而普通变量则不能保证这一点。Java中的synchronized和final两个关键字也可以实现可见性。 synchronized规定，线程在加锁时，先清空工作内存→在主内存中拷贝最新变量的副本到工作内存→执行完代码→将更改后的共享变量的值刷新到主内存中→释放互斥锁。 synchronized 的可见性也可以通过 Happens-Before 推断：“对一个锁解锁 Happens-Before 后续对这个锁的加锁”，指的是前一个线程的解锁操作对后一个线程的加锁操作可见，综合 Happens-Before 的传递性原则，我们能得出前一个线程在临界区修改的共享变量（该操作在解锁之前），对后续进入临界区（该操作在加锁之后）的线程是可见的。 final关键字的可见性是指：被final修饰的字段在构造器中一旦初始化完成，并且构造器没有把”this”的引用传递出去（this引用逃逸是一件很危险的事情，其他线程有可能通过这个引用访问到“初始化了一半”的对象），那在其他线程中就能看见final字段的值。 有序性程序在执行时，可能会进行指令重排序，重排后的指令与原指令的顺序未必一致。 重排序在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型： 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术（ ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 如果在单线程内观察，所有的操作都是有序的，这就是“线程内表现为串行的语义”（Within-Thread As-If-Serial Semantics）。而重排序对多线程则会有影响，重排序只保证单线程串行语义一直，没有义务保证多线程的语义也一致。 在Java中，可以使用volatile和synchronized来保证多线程之间操作的有序性。实现方式有所区别：volatile关键字会禁止指令重排。synchronized关键字保证同一时刻只允许一条线程操作。 as-if-serial语义不管怎么重排序（编译器和处理器为了提高并行度），单线程程序的执行结果不能被改变。编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被编译器和处理器重排序。as-if-serial语义把单线程程序保护了起来。 指令重排也是有原则的，并非所有指令都可以随意重排，Happens-before 可以指定两个操作之间的顺序。Happens-Before 并不是说前面一个操作发生在后续操作的前面，它真正要表达的是：前面一个操作的结果对后续操作是可见的。 Happens-Before 原则下面的这些原则是指令重排不可违背的： 程序顺序原则：在一个线程中，前面的操作 Happens-Before 于后面任何操作。 管程锁定规则：对一个锁的解锁 Happens-Before于后续对这个锁的加锁。 传递性：如果 A happens- before B，且 B happens- before C，那么 A happens- before C。 volatile变量规则：对一个volatile变量的写操作 Happens-Before 于后面对这个变量的读操作。 线程启动规则：Thread对象的start()方法 Happens-Before 于此线程的每一个动作。 线程终止规则：线程中所有操作都 Happens-Before 于此线程的终结。 对象终结规则：对象的构造函数执行结束 Happens-Before 于finalize方法。 这些先行发生关系无须使用任何同步手段就能成立，可以在编码中直接使用，这是Java内存模型对程序员的保证。如果两个操作之间的关系不在此列，并且无法从下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们随意地进行重排序。 123456789101112131415161718192021222324//////////程序启动规则示例/////////Thread B = new Thread(()-&gt;&#123; // 主线程调用 B.start() 之前 // 所有对共享变量的修改，此处皆可见 // 此例中，var==77&#125;);// 此处对共享变量 var 修改var = 77;// 主线程启动子线程B.start();//////////线程终止规则示例/////////Thread B = new Thread(()-&gt;&#123; // 此处对共享变量 var 修改 var = 66;&#125;);// 例如此处对共享变量修改，// 则这个修改结果对线程 B 可见// 主线程启动子线程B.start();B.join()// 子线程所有对共享变量的修改// 在主线程调用 B.join() 之后皆可见// 此例中，var==66 volatile使用volatile关键字修饰的变量，保证了其在多线程之间的可见 性，即当一个线程修改了这个变量的值，新值对于其他线程来说是可以立即得到的： 当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存（写语义）； 当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效，线程接下来将从主内存中读取共享变量（读语义）。 使用volatile的主要原因是其另一个特性：禁止指令重排序优化。比如说执行完某个操作时将布尔值设定为true，若没有volatile则会存在重排序的可能，设为true的操作会提前执行。编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。 “基于volatile变量的运算在并发下是安全的”不准确。20个线程，对volatile修饰的变量进行10000次自增，结果会小于200000。自增操作在加一时，变量值可能已经过期了。Volatile++ 此种复合操作无法保证原子性。 CaseQ: java 单例模式中双重检查锁定 volatile 的作用 1234567891011121314public class Singleton &#123; private Singleton() &#123;&#125; private volatile static Singleton instance; public Singleton getInstance() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if(instance == null)&#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; instance = new Singleton(); 包含了三个操作：1.分配对象的内存空间；2.初始化对象；3.设置instance指向刚分配的内存地址。但由于存在重排序的问题，2和3可能进行重排序。用volatile修饰的话就可以禁止2和3操作重排序，从而避免这种情况。 那volatile是否起到了可见性的作用？否，第二次非null判断是在加锁以后，可见性已经由synchronized来保证了。 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。 Referencehttps://time.geekbang.org/column/article/84017 《Java并发编程的艺术》 《深入理解Java虚拟机》","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"https://weilans.github.io/tags/concurrent/"}]},{"title":"[回顾并发基础] 并发问题的根源","slug":"Java并发札记-0-并发问题的根源","date":"2019-08-24T08:46:48.000Z","updated":"2019-12-19T11:54:08.597Z","comments":true,"path":"2019/08/24/Java并发札记-0-并发问题的根源/","link":"","permalink":"https://weilans.github.io/2019/08/24/Java并发札记-0-并发问题的根源/","excerpt":"","text":"正式开启并发的回顾整理，札记主要记录知识点、典型Case、自己的想法、思维导图以及好的文章，侧重于知识的理解与整理，毕竟要在并发上有自己独到的理解还是欠火候的。以后回顾或学习到新内容，会不断对文章进行更新，以作长期知识储备。 并发编程问题的根源1. CPU缓存导致“可见性”问题单核时代，所有线程操作同一个CPU的缓存，CPU缓存和内存间不会存在数据不一致问题。 一个线程对共享变量的修改，另一个线程能立刻看到，即为“可见性”。 多核时代，每个CPU都有自己的缓存，这就容易造成数据一致性问题。例如对应特定变量V，线程A操作CPU1上V的缓存，线程B操作CPU2上V的缓存，前者对V的操作于后者而言不具备可见性。这就是缓存一致性问题。 缓存一致性(Cache Coherence)计算机的CPU与内存间有一层高速缓存作为缓冲，用于解决处理器与内存之间的速度矛盾。在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存。如果某一处理器将数据写会内存，其他处理器上的值是旧的，执行计算操作会有问题。为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期。 样例：多线程并发执行count += 1，结果往往可能和想象结果不一样。两个相同的线程同时执行，第一次都会将 count = 0 读入自己的CPU缓存，执行完之后各自的CPU缓存中的值都是1，同时写入内存后，内存中的值为1。 2. 线程切换带来的“原子性”问题现代操作系统的CPU调度都是使用时间片算法，经过特定时间片之后便会进行任务切换。曾经的操作系统基于进程调度CPU，不同进程不共享内存空间，进程切换要切换内存映射地址。而进程内的所有线程共享同一个内存区间，使用线程进行任务切换成本较低，所以现代操作系统更多基于轻量的线程进行调度，常说的CPU任务切换特指线程切换。 高级语言中的一条语句往往需要多个CPU指令完成。如 count += 1，需要三条指令： 将 count 值从内存中加载到CPU的寄存器中； 在CPU寄存器中执行 +1 操作； 将结果写会内存（也可能写回 CPU 高速缓存）。 而操作系统的任务切换是可以发生在任何一条CPU指令执行完，而非高级语言的一条语句。如果两个线程执行 count 操作，线程A执行指令1后，CPU切换到线程B，线程执行完 +1 操作后，将1写回内存，后又切换至线程A，线程A执行 +1 命令的结果是1，后又将count=1的结果写入内存。 一个或者多个操作在 CPU 执行的过程中不被中断的特性称为“原子性”。CPU 能保证的原子操作是 CPU 指令级别的，而不是高级语言的操作符。 3. 编译优化带来的“有序性”问题编译器有时为了优化性能，有时会更改代码中的先后执行顺序。 示例：双重检查锁（无volatile） 123456789101112public class Singleton &#123; static Singleton instance; static Singleton getInstance()&#123; if (instance == null) &#123; synchronized(Singleton.class) &#123; if (instance == null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 执行new操作实际上执行的是： 分配一块内存M； 在内存M上初始化对象； 将 M 的地址赋值给示例对象。 但优化后的执行路径可能将2与3互换，当一个线程执行到内存地址赋值，切换到另一个线程，它会在第一个为空判断时直接返回 instance 对象，但 instance 对象没有初始化过，这时使用 instance 可能发生空指针异常。 CaseQ: 32位机器对 long 类型变量进行加减操作存在并发隐患的原因。 A: 因为64位的 long 类型在32位的机器上的操作必然是由多条CPU指令组合而成，是无法保证原子性的。 Referencehttps://time.geekbang.org/column/article/83682","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"https://weilans.github.io/tags/concurrent/"}]},{"title":"Spring Data Redis 实践 (v2.1.7)","slug":"Spring-Data-Redis-实践-v2-1-7","date":"2019-08-15T12:59:09.000Z","updated":"2019-08-15T15:38:23.976Z","comments":true,"path":"2019/08/15/Spring-Data-Redis-实践-v2-1-7/","link":"","permalink":"https://weilans.github.io/2019/08/15/Spring-Data-Redis-实践-v2-1-7/","excerpt":"","text":"最近重写一个项目，在 SpringBoot 用的是最新的 GA 版本 2.1.7，缓存层使用了 Spring Data Redis。其实使用它是因为上一个项目也是用的这个框架，了解的程度还行，但不算细致。此外，因为以前直接使用 Redisson 的时候出现了内存泄漏（实际上也不是人家的锅，算是依赖的 Netty 版本的 bug），对 Redisson 总会心有余悸。但我真的得承认，Redisson 非常好用，如果项目中需要使用一些分布式的 API，比如分布式锁、优先级阻塞队列等，Redisson 是不二之选。其实与Redisson 做横向对比的应该是 Jedis，Spring Data Redis 是在 Jedis 上架了一层（boot 1.x）。但是这个项目对 Redis 的API 操作比较简单，所以就当仔细学习一下 Spring Data Redis了。 POM因为 Boot 版本升了 2.X，Spring Data Redis 的默认框架从 Jedis 换成了 Lettuce，后者主要突出基于 Netty 的事件驱动，容易发挥异步优势。但是由于真不了解以及学习成本的考量，还是使用了 Jedis。 POM文件中需移除 lettuce 的依赖，引入 Jedis。具体版本在 2.1.7.RELEASE 的 spring-boot-dependencies 文件中（lettuce 版本 5.1.8.RELEASE，jedis 版本 2.9.3）。 1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;io.lettuce&lt;/groupId&gt; &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt;&lt;/dependency&gt; ConfigRedisConnectionFactory12345678910111213141516@Beanpublic RedisConnectionFactory redisConnectionFactory() &#123; redisConf = ...; RedisStandaloneConfiguration standaloneConf = new RedisStandaloneConfiguration( redisConf.getHost(), redisConf.getPort()); if (!Strings.isNullOrEmpty(redisConf.getPassword())) &#123; standaloneConf.setPassword(redisConf.getPassword()); &#125; JedisConnectionFactory jedisConnectionFactory = new JedisConnectionFactory(standaloneConf); GenericObjectPoolConfig poolConfig = jedisConnectionFactory.getPoolConfig(); poolConfig.setMaxTotal(30); poolConfig.setMinIdle(0); poolConfig.setMaxIdle(10); poolConfig.setMaxWaitMillis(3000); return jedisConnectionFactory;&#125; 2.x 的配置也和之前有所区别，JedisConnectionFactory的setXxx方法大多已是 Deprecated，如：setHostName、setPort、setPassword等。文档的提示内容是： since 2.0, configure the password using {@link RedisStandaloneConfiguration}, {@link RedisSentinelConfiguration} or {@link RedisClusterConfiguration}. 所以，在 JedisConnectionFactory 构造参数中设置RedisStandaloneConfiguration。而 pool 信息可以从 factory 中获取，从而进行设置。从 JedisConnectionFactory 构造函数中，我们发现它构造了MutableJedisClientConfiguration对象。该对象的 poolConfig 在 变量声名中就 new 出了JedisPoolConfig，我们可以对这个对象进行连接池设置。 123public JedisConnectionFactory(RedisStandaloneConfiguration standaloneConfig) &#123; this(standaloneConfig, new MutableJedisClientConfiguration());&#125; 当然设置 pool 信息不单只有这一种，MutableJedisClientConfiguration是JedisClientConfiguration接口的实现类，该接口下面还有接口JedisPoolingClientConfigurationBuilder，也可以使用它的实现类DefaultJedisClientConfigurationBuilder，JedisClientConfiguration.builder()返回的就是这个类实例。 感觉到了 2.x，手动建 Factory 配置有点麻烦啊… RedisTemplateRedisTemplate 的 配置比较简单，注入 RedisConnectionFactory Bean 对象即可，但是要注意的序列化方案。 12345678@Beanpublic RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) &#123; RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(factory); setSerializer(redisTemplate); redisTemplate.afterPropertiesSet(); return redisTemplate;&#125; 序列化12345678private void setSerializer(RedisTemplate&lt;String, Object&gt; template) &#123; GenericJackson2JsonRedisSerializer genericJackson2JsonRedisSerializer = new GenericJackson2JsonRedisSerializer(); template.setKeySerializer(new StringRedisSerializer()); template.setValueSerializer(genericJackson2JsonRedisSerializer); template.setHashKeySerializer(new StringRedisSerializer()); template.setHashValueSerializer(genericJackson2JsonRedisSerializer);&#125; 在 redisTemplate.afterPropertiesSet()方法中，显示默认的序列化方式是JdkSerializationRedisSerializer。使用的是 JDK 序列化方式，数据以字节流的形式存储。这种方式会造成可读性很差。 12345678910111213141516171819202122232425if (defaultSerializer == null) &#123; defaultSerializer = new JdkSerializationRedisSerializer( classLoader != null ? classLoader : this.getClass().getClassLoader());&#125;if (enableDefaultSerializer) &#123; if (keySerializer == null) &#123; keySerializer = defaultSerializer; defaultUsed = true; &#125; if (valueSerializer == null) &#123; valueSerializer = defaultSerializer; defaultUsed = true; &#125; if (hashKeySerializer == null) &#123; hashKeySerializer = defaultSerializer; defaultUsed = true; &#125; if (hashValueSerializer == null) &#123; hashValueSerializer = defaultSerializer; defaultUsed = true; &#125;&#125; 如果项目中 key value 都只要使用字符串即可的话，StringRedisSerializer也是一种选项。这里我使用的是 Jackson 方式进行序列化操作。我事先使用的是Jackson2JsonRedisSerializer方式，该方式会将对象完全展为 JSON，但是在反序列的过程中报错：LinkedHashMap cannot be cast to ...，所以改成了GenericJackson2JsonRedisSerializer，该方案会在 JSON 中添加 @class类信息 field，这样在处理集合类泛型信息时，都能够正确处理。 使用 GenericJackson2JsonRedisSerializer 的时候，一开始是使用了自己定义的 ObjectMapper，结果发现无用，后来选择了无参构造器的实现才不出错。究其原因不难发现，该构造器中会对 objectMapper 设置 enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL)，正是该字段使 Jackson 生成了类信息字段，这才是允许反序列化的基础。而类的前面出现 @class 是因为 NullValueSerializer 里 设置了classIdentifier 为 @class（即 JsonTypeInfo.Id#CLASS）。 如果使用 Jackson2JsonRedisSerializer 时里面的 objectMapper 配置了 DefaultTyping.NON_FINAL，简单试验了一下发现序列化/反序列化操作会成功（没配 @class 前缀也是可以的）。 12345678910111213141516public GenericJackson2JsonRedisSerializer() &#123; this((String) null);&#125;public GenericJackson2JsonRedisSerializer(@Nullable String classPropertyTypeName) &#123; this(new ObjectMapper()); mapper.registerModule(new SimpleModule().addSerializer(new NullValueSerializer(classPropertyTypeName))); if (StringUtils.hasText(classPropertyTypeName)) &#123; mapper.enableDefaultTypingAsProperty(DefaultTyping.NON_FINAL, classPropertyTypeName); &#125; else &#123; mapper.enableDefaultTyping(DefaultTyping.NON_FINAL, As.PROPERTY); &#125;&#125; 感觉一个完整 JSON 工具包的实现还是很难的，有机会可以详细过一遍 Jackson… 官方 Reference","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"cache","slug":"cache","permalink":"https://weilans.github.io/tags/cache/"},{"name":"spring","slug":"spring","permalink":"https://weilans.github.io/tags/spring/"},{"name":"redis","slug":"redis","permalink":"https://weilans.github.io/tags/redis/"}]},{"title":"[Leetcode单排] 二叉树的序列化与反序列化 (N297)","slug":"Leetcode单排-二叉树的序列化与反序列化-N297","date":"2019-08-12T14:41:41.000Z","updated":"2019-08-12T16:30:01.341Z","comments":true,"path":"2019/08/12/Leetcode单排-二叉树的序列化与反序列化-N297/","link":"","permalink":"https://weilans.github.io/2019/08/12/Leetcode单排-二叉树的序列化与反序列化-N297/","excerpt":"","text":"297. Serialize and Deserialize Binary Treehttps://leetcode.com/problems/serialize-and-deserialize-binary-tree/ 先序遍历每个节点用逗号分隔，空节点使用#表示。序列化二叉树肯定会想到先序、中序、后序、层次遍历四种，中序和后序从下往上推不好实现，剩下的考虑先序和层次。而先序遍历之所以可以应用，是因为每个分支都有明确的结束标记。序列化的时候，先确定自己，再确定左右。反序列化的过程，先获取头部，再判断左子节点，左子节点有结束边界，之后右子节点也按照边界结束。 123456789101112131415161718192021222324252627282930313233public String serialize(TreeNode root) &#123; if (root == null) &#123; return \"#,\"; &#125; String curStr = root.val + \",\"; String leftStr = serialize(root.left); String rightStr = serialize(root.right); return curStr + leftStr + rightStr;&#125;public TreeNode deserialize(String data) &#123; if (data == null) &#123; return null; &#125; String[] strArr = data.split(\",\"); Queue&lt;String&gt; queue = new LinkedList&lt;&gt;(); for (String str : strArr) &#123; queue.offer(str); &#125; return deserialize(queue);&#125;private TreeNode deserialize(Queue&lt;String&gt; queue) &#123; String str = queue.poll(); if (str.equals(\"#\")) &#123; return null; &#125; TreeNode node = new TreeNode(Integer.parseInt(str)); node.left = deserialize(queue); node.right = deserialize(queue); return node;&#125; 层次遍历层次遍历写起来稍微有点复杂，但是更好理解。序列化的时候，先把顶部节点放至 queue 中，依据左右节点值放至 StringBuilder 中，再按照是否为空，将不为空的放入队列中进行下一层的遍历。反序列化同样是新建一个队列放入头结点，将左右节点非空的放入队列中，进行下一层的从左到右的解析。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public String serialize(TreeNode root) &#123; if (root == null) &#123; return null; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); // 注意 root.val 别放到构造函数里，因为: new StringBuilder(int capacity) StringBuilder sb = new StringBuilder().append(root.val).append(\",\"); queue.offer(root); while (!queue.isEmpty()) &#123; TreeNode node = queue.poll(); TreeNode left = node.left; TreeNode right = node.right; if (left != null) &#123; sb.append(left.val).append(\",\"); queue.offer(left); &#125; else &#123; sb.append(\"#,\"); &#125; if (right != null) &#123; sb.append(right.val).append(\",\"); queue.offer(right); &#125; else &#123; sb.append(\"#,\"); &#125; &#125; return sb.toString(); &#125; public TreeNode deserialize(String data) &#123; if (data == null || data == \"\") &#123; return null; &#125; String[] strArr = data.split(\",\"); int index = 0; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); TreeNode root = buildNode(strArr[0]); queue.offer(root); while (!queue.isEmpty()) &#123; TreeNode node = queue.poll(); TreeNode left = buildNode(strArr[++index]); TreeNode right = buildNode(strArr[++index]); node.left = left; node.right = right; if (left != null) &#123; queue.offer(left); &#125; if (right != null) &#123; queue.offer(right); &#125; &#125; return root; &#125; private TreeNode buildNode(String str) &#123; if (\"#\".equals(str)) &#123; return null; &#125; return new TreeNode(Integer.parseInt(str)); &#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"tree","slug":"tree","permalink":"https://weilans.github.io/tags/tree/"}]},{"title":"[Leetcode单排] 树类题目集合1 (N102 N107 N429 N872 N112 N113)","slug":"Leetcode单排- 树类题目集合1-N102-N107-N429-N872-N112-N113","date":"2019-08-10T02:10:54.000Z","updated":"2019-08-18T09:50:51.724Z","comments":true,"path":"2019/08/10/Leetcode单排- 树类题目集合1-N102-N107-N429-N872-N112-N113/","link":"","permalink":"https://weilans.github.io/2019/08/10/Leetcode单排- 树类题目集合1-N102-N107-N429-N872-N112-N113/","excerpt":"","text":"102. Binary Tree Level Order Traversalhttps://leetcode.com/problems/binary-tree-level-order-traversal/ 层次遍历，但是题目需要把每一层的放到一个 List 里面，这里用的是计数（需要注意先把左右节点放到队列中再进行数量判断）。当然也可以使用在 while 最开始获取 队列中的 size 作为这一层的大小，之后里面加一层 for 循环，详见此。 12345678910111213141516171819202122232425262728293031public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); if (root == null) &#123; return result; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); int count = 1, temp = 0, next = 0; List&lt;Integer&gt; layer = new ArrayList&lt;&gt;(); while (!queue.isEmpty()) &#123; TreeNode node = queue.poll(); int val = node.val; layer.add(val); if (node.left != null) &#123; queue.offer(node.left); next++; &#125; if (node.right != null) &#123; queue.offer(node.right); next++; &#125; if (++temp == count) &#123; result.add(new ArrayList&lt;&gt;(layer)); layer.clear(); count = next; next = 0; temp = 0; &#125; &#125; return result; &#125; 107. Binary Tree Level Order Traversal IIhttps://leetcode.com/problems/binary-tree-level-order-traversal-ii/ 这道题就很没意思了，每次只要加在 List 的最前面就可以了。 12345678910111213141516171819202122232425262728293031public List&lt;List&lt;Integer&gt;&gt; levelOrderBottom(TreeNode root) &#123; List&lt;List&lt;Integer&gt;&gt; result = new LinkedList&lt;&gt;(); if (root == null) &#123; return result; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); int count = 1, temp = 0, next = 0; List&lt;Integer&gt; layer = new ArrayList&lt;&gt;(); while (!queue.isEmpty()) &#123; TreeNode node = queue.poll(); int val = node.val; layer.add(val); if (node.left != null) &#123; queue.offer(node.left); next++; &#125; if (node.right != null) &#123; queue.offer(node.right); next++; &#125; if (++temp == count) &#123; result.add(0, new ArrayList&lt;&gt;(layer)); layer.clear(); count = next; next = 0; temp = 0; &#125; &#125; return result; &#125; 429. N-ary Tree Level Order Traversalhttps://leetcode.com/problems/n-ary-tree-level-order-traversal/ 依然是层次遍历，只不过二叉树换成 N 叉树。 1234567891011121314151617181920212223242526272829public List&lt;List&lt;Integer&gt;&gt; levelOrder(Node root) &#123; List&lt;List&lt;Integer&gt;&gt; result = new LinkedList&lt;&gt;(); if (root == null) &#123; return result; &#125; Queue&lt;Node&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); int count = 1, temp = 0, next = 0; List&lt;Integer&gt; layer = new ArrayList&lt;&gt;(); while (!queue.isEmpty()) &#123; Node node = queue.poll(); int val = node.val; layer.add(val); if (node.children != null &amp;&amp; node.children.size() !=0) &#123; for (Node n : node.children) &#123; queue.offer(n); next++; &#125; &#125; if (++temp == count) &#123; result.add(new ArrayList&lt;&gt;(layer)); layer.clear(); count = next; next = 0; temp = 0; &#125; &#125; return result;&#125; 872. Leaf-Similar Treeshttps://leetcode.com/problems/leaf-similar-trees/ 判断两颗二叉树的叶子节点（从左到右）是否相等。这里用的比较常规做法，使用中序遍历，把打印换成判断是否为叶子节点。 12345678910111213141516171819202122232425262728public boolean leafSimilar(TreeNode root1, TreeNode root2) &#123; if (root1 == null &amp;&amp; root2 == null) &#123; return true; &#125; if (root1 == null || root2 == null) &#123; return false; &#125; List&lt;Integer&gt; leaves1 = getLeaves(root1); List&lt;Integer&gt; leaves2 = getLeaves(root2); return leaves1.equals(leaves2); &#125; private List&lt;Integer&gt; getLeaves(TreeNode node) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); inorder(node, list); return list; &#125; private void inorder(TreeNode node, List&lt;Integer&gt; list) &#123; if (node == null) &#123; return; &#125; inorder(node.left, list); if (node.left == null &amp;&amp; node.right == null) &#123; list.add(node.val); &#125; inorder(node.right, list); &#125; 112. Path Sumhttps://leetcode.com/problems/path-sum/ 这里的递归没有去判断是否为 null ，因为为 null 的情形本身就被排除了。（另外，此类是否存在一个满足条件的问题，当有情况成功时，需要立刻返回。总是遗漏掉 if 为 true，立刻返回的情形。） 1234567891011121314151617181920212223public boolean hasPathSum(TreeNode root, int sum) &#123; if (root == null) &#123; return false; &#125; return dfs(root, 0, sum); &#125; private boolean dfs(TreeNode node, int curSum, int target) &#123; if (node.left == null &amp;&amp; node.right == null) &#123; return target == curSum + node.val; &#125; if (node.left != null) &#123; if (dfs(node.left, curSum + node.val, target)) &#123; return true; &#125; &#125; if (node.right != null) &#123; if (dfs(node.right, curSum + node.val, target)) &#123; return true; &#125; &#125; return false; &#125; 别人写的更精炼 1234567public boolean hasPathSum(TreeNode root, int sum) &#123; if(root == null) return false; if(root.left == null &amp;&amp; root.right == null &amp;&amp; sum - root.val == 0) return true; return hasPathSum(root.left, sum - root.val) || hasPathSum(root.right, sum - root.val);&#125; 113. Path SumIIhttps://leetcode.com/problems/path-sum-ii/ 第一次写成的版本比较糙。当前节点不满足进行下一轮左右节点递归时，都加上了add和remove方法，这是传统 回溯 做多了的惯性，但实际上这两种情形加上删除的值是相同的，所以可以进行精简。 123456789101112131415161718192021222324252627public List&lt;List&lt;Integer&gt;&gt; pathSum(TreeNode root, int sum) &#123; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); if (root == null) &#123; return result; &#125; dfs(root, sum, new ArrayList&lt;&gt;(), result); return result;&#125;private void dfs(TreeNode node, int curSum, List&lt;Integer&gt; curList, List&lt;List&lt;Integer&gt;&gt; result) &#123; if (node == null) &#123; return; &#125; if (curSum - node.val == 0 &amp;&amp; node.left == null &amp;&amp; node.right == null) &#123; curList.add(node.val); result.add(new ArrayList&lt;&gt;(curList)); curList.remove(curList.size() - 1); return; &#125; curList.add(node.val); dfs(node.left, curSum - node.val, curList, result); curList.remove(curList.size() - 1); curList.add(node.val); dfs(node.right, curSum - node.val, curList, result); curList.remove(curList.size() - 1);&#125; clean version: 123456789101112131415161718192021222324public List&lt;List&lt;Integer&gt;&gt; pathSum(TreeNode root, int sum) &#123; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); if (root == null) &#123; return result; &#125; dfs(root, sum, new ArrayList&lt;&gt;(), result); return result;&#125;private void dfs(TreeNode node, int curSum, List&lt;Integer&gt; curList, List&lt;List&lt;Integer&gt;&gt; result) &#123; if (node == null) &#123; return; &#125; curList.add(node.val); if (curSum - node.val == 0 &amp;&amp; node.left == null &amp;&amp; node.right == null) &#123; result.add(new ArrayList&lt;&gt;(curList)); curList.remove(curList.size() - 1); return; &#125; dfs(node.left, curSum - node.val, curList, result); dfs(node.right, curSum - node.val, curList, result); curList.remove(curList.size() - 1);&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"tree","slug":"tree","permalink":"https://weilans.github.io/tags/tree/"}]},{"title":"[Leetcode单排] 树相关Easy题 (N100 N101 N104 N110 N111 N572 N965)","slug":"Leetcode单排-树相关Easy题-N100-N101-N104-N110-N111-N572-N965","date":"2019-08-09T11:02:14.000Z","updated":"2019-08-18T09:51:32.775Z","comments":true,"path":"2019/08/09/Leetcode单排-树相关Easy题-N100-N101-N104-N110-N111-N572-N965/","link":"","permalink":"https://weilans.github.io/2019/08/09/Leetcode单排-树相关Easy题-N100-N101-N104-N110-N111-N572-N965/","excerpt":"","text":"100. Same Treehttps://leetcode.com/problems/same-tree/ 123456789101112public boolean isSameTree(TreeNode p, TreeNode q) &#123; if (p == null &amp;&amp; q == null) &#123; return true; &#125; if (p == null || q == null) &#123; return false; &#125; if (p.val != q.val) &#123; return false; &#125; return isSameTree(p.left, q.left) &amp;&amp; isSameTree(p.right, q.right);&#125; 101. Symmetric Treehttps://leetcode.com/problems/symmetric-tree/ 12345678910111213141516171819public boolean isSymmetric(TreeNode root) &#123; if (root == null) &#123; return true; &#125; return check(root.left, root.right); &#125; private boolean check(TreeNode p, TreeNode q) &#123; if (p == null &amp;&amp; q == null) &#123; return true; &#125; if (p == null || q == null) &#123; return false; &#125; if (p.val != q.val) &#123; return false; &#125; return check(p.left, q.right) &amp;&amp; check(p.right, q.left); &#125; 104. Maximum Depth of Binary Treehttps://leetcode.com/problems/maximum-depth-of-binary-tree/ 12345678public int maxDepth(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; int leftDepth = maxDepth(root.left); int rightDepth = maxDepth(root.right); return Math.max(leftDepth, rightDepth) + 1;&#125; 110. Balanced Binary Treehttps://leetcode.com/problems/balanced-binary-tree/ （第一回做的时候，犯了个小错误，求出leftDepth及rightDepth为 null 时，需要立即退出返回 null。） 123456789101112131415161718192021222324public boolean isBalanced(TreeNode root) &#123; if (root == null) &#123; return true; &#125; return depth(root) != null;&#125;private Integer depth(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; Integer leftDepth = depth(root.left); if (leftDepth == null) &#123; return null; &#125; Integer rightDepth = depth(root.right); if (rightDepth == null) &#123; return null; &#125; if (Math.abs(leftDepth - rightDepth) &gt; 1) &#123; return null; &#125; return Math.max(leftDepth, rightDepth) + 1;&#125; 111. Minimum Depth of Binary Treehttps://leetcode.com/problems/minimum-depth-of-binary-tree/ 与求最大高度相比，求最小高度特别之处在于：如果左右有一个高度为 0，则另一个的高度即为返回值。 1234567891011121314public int minDepth(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; int leftDepth = minDepth(root.left); int rightDepth = minDepth(root.right); if (leftDepth == 0) &#123; return rightDepth + 1; &#125; if (rightDepth == 0) &#123; return leftDepth + 1; &#125; return Math.min(leftDepth, rightDepth) + 1; &#125; 572. Subtree of Another Treehttps://leetcode.com/problems/subtree-of-another-tree/ 我这里是想先层次遍历找到值相同的点后，再检验两个树是否相等。当然也可以使用isSubtree(s.left, t) || isSubtree(s.right, t)的形式递归判断。 123456789101112131415161718192021222324252627282930public boolean isSubtree(TreeNode s, TreeNode t) &#123; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(s); while (!queue.isEmpty()) &#123; TreeNode node = queue.poll(); if (node != null &amp;&amp; t != null &amp;&amp; node.val == t.val &amp;&amp; check(node, t)) &#123; return true; &#125; if (node != null &amp;&amp; node.left != null) &#123; queue.offer(node.left); &#125; if (node != null &amp;&amp; node.right != null) &#123; queue.offer(node.right); &#125; &#125; return false;&#125;private boolean check(TreeNode n1, TreeNode n2) &#123; if (n1 == null &amp;&amp; n2 == null) &#123; return true; &#125; if (n1 == null || n2 == null) &#123; return false; &#125; if (n1.val != n2.val) &#123; return false; &#125; return check(n1.left, n2.left) &amp;&amp; check(n1.right, n2.right);&#125; 递归的做法如下（可以看作是先序递归遍历）： 12345public boolean isSubtree(TreeNode s, TreeNode t) &#123; if (s == null) return false; if (check(s, t)) return true; return isSubtree(s.left, t) || isSubtree(s.right, t); &#125; 965. Univalued Binary Treehttps://leetcode.com/problems/univalued-binary-tree/ 12345678910111213141516171819202122public boolean isUnivalTree(TreeNode root) &#123; if (root == null) &#123; return true; &#125; int temp = root.val; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); while (!queue.isEmpty()) &#123; TreeNode node = queue.poll(); if (node.val != temp) &#123; return false; &#125; if (node.left != null) &#123; queue.offer(node.left); &#125; if (node.right != null) &#123; queue.offer(node.right); &#125; &#125; return true; &#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"tree","slug":"tree","permalink":"https://weilans.github.io/tags/tree/"}]},{"title":"[Leetcode单排] 树的遍历 (N94 N589 N590)","slug":"Leetcode单排-树的遍历-N94-N589-N590","date":"2019-08-09T08:15:52.000Z","updated":"2019-08-09T10:25:02.526Z","comments":true,"path":"2019/08/09/Leetcode单排-树的遍历-N94-N589-N590/","link":"","permalink":"https://weilans.github.io/2019/08/09/Leetcode单排-树的遍历-N94-N589-N590/","excerpt":"","text":"94. Binary Tree Inorder Traversalhttps://leetcode.com/problems/binary-tree-inorder-traversal/ 先简单回顾下二叉树的遍历，分为先序、中序、后序三种方式，每一种有都有递归和非递归两种方式。先回顾递归的方式。 递归1234567891011121314151617181920212223242526272829303132333435/** * 先序遍历 递归 */public void preOrderRecur(Node head) &#123; if (head == null) &#123; return; &#125; System.out.print(head.value + \" \"); preOrderRecur(head.left); preOrderRecur(head.right);&#125;/** * 中序遍历 递归 */public void inOrderRecur(Node head) &#123; if (head == null) &#123; return; &#125; inOrderRecur(head.left); System.out.print(head.value + \" \"); inOrderRecur(head.right);&#125;/** * 后序遍历 递归 */public void posOrderRecur(Node head) &#123; if (head == null) &#123; return; &#125; posOrderRecur(head.left); posOrderRecur(head.right); System.out.print(head.value + \" \");&#125; 虽然递归方式的代码的样子很简单，但还是需要好好理解的。如果把节点的访问顺序一个个的记录下来，会发现每个节点会访问三次。如果把处理时机放在第一次来到这个节点的时候就是先续遍历，放在第二次就是中序遍历，放在第三次就是后续遍历。 非递归先序遍历：先将头结点放入栈中，之后在 while 中不断弹出。弹出节点有右节点即将其放入栈中，之后有左子树将其放放入栈中。不使用队列的原因是：先序遍历虽然只能往下走，但是遍历完左子树之后还是需要回去的，所以非递归中序遍历需要用栈结构。 12345678910111213141516171819 /** * 先序遍历 非递归 */public void preOrderUnRecur(Node head) &#123; if (head != null) &#123; Stack&lt;Node&gt; stack = new Stack&lt;&gt;(); stack.add(head); while (!stack.isEmpty()) &#123; head = stack.pop(); System.out.print(head.value + \" \"); if (head.right != null) &#123; stack.push(head.right); &#125; if (head.left != null) &#123; stack.push(head.left); &#125; &#125; &#125;&#125; 中序遍历：当前节点一定会把自己的左边界都压到栈里去，其实简略概括为：当前节点为空，从栈顶拿一个打印，当前节点往右边跑；当前节点不为空，当前节点压入栈，当前节点往左。 中序直接从头部节点开始，不需要事先压栈。 123456789101112131415161718/** * 中序遍历 非递归 */public void inOrderUnRecur(Node head) &#123; if (head != null) &#123; Stack&lt;Node&gt; stack = new Stack&lt;Node&gt;(); while (!stack.isEmpty() || head != null) &#123; if (head != null) &#123; stack.push(head); head = head.left; &#125; else &#123; head = stack.pop(); System.out.print(head.value + \" \"); head = head.right; &#125; &#125; &#125;&#125; 后序遍历：左右中是中右左的逆序，而中左右即为先序遍历，所以中右左是容易实现的。所以可以将中右左弹出的元素压入另一个栈中即可，这就是双栈的做法。单栈的做法不好理解，就不展开了。 1234567891011121314151617181920212223/** * 后序遍历 非递归（双栈） */public void posOrderUnRecur1(Node head) &#123; if (head != null) &#123; Stack&lt;Node&gt; s1 = new Stack&lt;Node&gt;(); Stack&lt;Node&gt; s2 = new Stack&lt;Node&gt;(); s1.push(head); while (!s1.isEmpty()) &#123; head = s1.pop(); s2.push(head); if (head.left != null) &#123; s1.push(head.left); &#125; if (head.right != null) &#123; s1.push(head.right); &#125; &#125; while (!s2.isEmpty()) &#123; System.out.print(s2.pop().value + \" \"); &#125; &#125;&#125; 所以 92 题非递归就是如下的写法： 1234567891011121314151617181920class Solution &#123; public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; if (root == null) &#123; return new ArrayList&lt;&gt;(); &#125; List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); while (!stack.isEmpty() || root != null) &#123; if (root != null) &#123; stack.push(root); root = root.left; &#125; else &#123; TreeNode p = stack.pop(); result.add(p.val); root = p.right; &#125; &#125; return result; &#125;&#125; 589. N-ary Tree Preorder Traversalhttps://leetcode.com/problems/n-ary-tree-preorder-traversal/ 递归1234567891011121314151617181920public List&lt;Integer&gt; preorder(Node root) &#123; List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); if (root == null) &#123; return result; &#125; preorder(result, root); return result;&#125;private void preorder(List&lt;Integer&gt; result, Node cur) &#123; if (cur == null) &#123; return; &#125; result.add(cur.val); if (cur.children != null &amp;&amp; cur.children.size() != 0) &#123; for (Node child : cur.children) &#123; preorder(result, child); &#125; &#125;&#125; 非递归12345678910111213141516171819202122public List&lt;Integer&gt; preorder(Node root) &#123; List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); if (root == null) &#123; return result; &#125; Stack&lt;Node&gt; stack = new Stack&lt;&gt;(); stack.push(root); while (!stack.isEmpty()) &#123; Node node = stack.pop(); result.add(node.val); if (node.children != null &amp;&amp; node.children.size() != 0) &#123; // 先右后左 for (int i = node.children.size() - 1; i &gt;= 0; i--) &#123; Node child = node.children.get(i); if (child != null) &#123; stack.push(child); &#125; &#125; &#125; &#125; return result; &#125; 590. N-ary Tree Postorder Traversalhttps://leetcode.com/problems/n-ary-tree-postorder-traversal/ 递归1234567891011121314151617181920public List&lt;Integer&gt; postorder(Node root) &#123; List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); if (root == null) &#123; return result; &#125; postorder(result, root); return result;&#125;private void postorder(List&lt;Integer&gt; result, Node cur) &#123; if (cur == null) &#123; return; &#125; if (cur.children != null &amp;&amp; cur.children.size() != 0) &#123; for (Node child : cur.children) &#123; postorder(result, child); &#125; &#125; result.add(cur.val);&#125; 非递归(双栈)12345678910111213141516171819202122232425public List&lt;Integer&gt; postorder(Node root) &#123; List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); if (root == null) &#123; return result; &#125; Stack&lt;Node&gt; stack1 = new Stack&lt;&gt;(); Stack&lt;Node&gt; stack2 = new Stack&lt;&gt;(); stack1.push(root); while (!stack1.isEmpty()) &#123; Node node = stack1.pop(); stack2.push(node); if (node.children != null &amp;&amp; node.children.size() != 0) &#123; // 先左后右 for (Node child : node.children) &#123; if (child != null) &#123; stack1.push(child); &#125; &#125; &#125; &#125; while (!stack2.isEmpty()) &#123; result.add(stack2.pop().val); &#125; return result;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"tree","slug":"tree","permalink":"https://weilans.github.io/tags/tree/"}]},{"title":"[Leetcode单排] 划分为k个相等的子集 (N698)","slug":"Leetcode单排-划分为k个相等的子集-N698","date":"2019-08-04T15:54:41.000Z","updated":"2019-08-04T17:09:06.503Z","comments":true,"path":"2019/08/04/Leetcode单排-划分为k个相等的子集-N698/","link":"","permalink":"https://weilans.github.io/2019/08/04/Leetcode单排-划分为k个相等的子集-N698/","excerpt":"","text":"698. Partition to K Equal Sum Subsetshttps://leetcode.com/problems/partition-to-k-equal-sum-subsets/ （最近做了挺多的DFS题目，这道题没做出来 o.O||，还是菜啊 ）做法来自 小f讲解。这道题目本以为会有其他的方法，最后也只能不断暴力递归求解。递归时先建立指定个数的桶，每个桶内数字总和是相等的。partation方法的含义是每个下标在这几个桶内都能够放下，只要满足这个条件即返回成功。只要找到一种可行方式即可。 求总和时用了Arrays.stream().sum()方法结果耗时 47ms，换手动计算变成 13ms。所以数据集有限的情况下，算法题还是谨慎用流。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public boolean canPartitionKSubsets(int[] nums, int k) &#123; if (nums == null || nums.length == 0 || k &lt;= 0) &#123; return false; &#125; int sum = sum(nums); // 校验1：除有余数，无法均分 if (sum % k != 0) &#123; return false; &#125; Arrays.sort(nums); int subSum = sum / k; int index = nums.length - 1; // 校验2：最大值比平均值大，及无法均分 if (nums[index] &gt; subSum) &#123; return false; &#125; int subNum = k; while (index &gt;= 0 &amp;&amp; nums[index] == subSum) &#123; index--; subNum--; &#125; return partition(nums, subSum, index, new int[subNum]);&#125;private boolean partition(int[] num, int target, int index, int[] subSet) &#123; if (index &lt; 0) &#123; return true; &#125; // 当前值在这几个桶内是否有地方可放置 for (int i = 0; i &lt; subSet.length; i++) &#123; if (subSet[i] + num[index] &lt;= target) &#123; subSet[i] += num[index]; if (partition(num, target, index - 1, subSet)) &#123; return true; &#125; subSet[i] -= num[index]; &#125; &#125; return false;&#125;private int sum(int[] array) &#123; int sum = 0; for (int i : array) &#123; sum += i; &#125; return sum;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"}]},{"title":"[Leetcode单排] 01矩阵 (N542)","slug":"Leetcode单排-01矩阵-N542","date":"2019-08-04T14:07:00.000Z","updated":"2019-08-04T14:37:49.321Z","comments":true,"path":"2019/08/04/Leetcode单排-01矩阵-N542/","link":"","permalink":"https://weilans.github.io/2019/08/04/Leetcode单排-01矩阵-N542/","excerpt":"","text":"542. 01 Matrixhttps://leetcode.com/problems/01-matrix/ BFS问题，第一感觉是使用队列来做。先对原数组进行处理，将 0 的下标入队列，非零下标记为最大Integer值。之后由每个0的四周逐渐散开，覆盖掉其四周的 Integer.MAX_VALUE。这样对于处理过的坐标，后续其他 0 散开达到时，其距离一定比当前值大，也就不用处理了。 12345678910111213141516171819202122232425262728293031public int[][] updateMatrix(int[][] matrix) &#123; if (matrix == null || matrix.length == 0) &#123; return null; &#125; int row = matrix.length; int col = matrix[0].length; Queue&lt;int[]&gt; queue = new LinkedList&lt;&gt;(); for (int i = 0; i &lt; row; i++) &#123; for (int j = 0; j &lt; col; j++) &#123; if (matrix[i][j] == 0) &#123; queue.offer(new int[]&#123;i, j&#125;); &#125; else &#123; matrix[i][j] = Integer.MAX_VALUE; &#125; &#125; &#125; int[][] neigh = new int[][]&#123;&#123;0, 1&#125;, &#123;0, -1&#125;, &#123;1, 0&#125;, &#123;-1, 0&#125;&#125;; while (!queue.isEmpty()) &#123; int[] idx = queue.poll(); for (int[] nei : neigh) &#123; int i = idx[0] + nei[0]; int j = idx[1] + nei[1]; if (i &gt;= 0 &amp;&amp; i &lt; row &amp;&amp; j &gt;= 0 &amp;&amp; j &lt; col &amp;&amp; matrix[i][j] &gt; matrix[idx[0]][idx[1]] + 1) &#123; matrix[i][j] = matrix[idx[0]][idx[1]] + 1; queue.offer(new int[]&#123;i, j&#125;); &#125; &#125; &#125; return matrix;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"},{"name":"bfs","slug":"bfs","permalink":"https://weilans.github.io/tags/bfs/"}]},{"title":"[Leetcode单排] 运算表达式设优先级求值 (N241)","slug":"Leetcode单排-运算表达式设优先级求值-N241","date":"2019-08-04T08:46:02.000Z","updated":"2019-08-04T12:30:44.119Z","comments":true,"path":"2019/08/04/Leetcode单排-运算表达式设优先级求值-N241/","link":"","permalink":"https://weilans.github.io/2019/08/04/Leetcode单排-运算表达式设优先级求值-N241/","excerpt":"","text":"241. Different Ways to Add Parentheseshttps://leetcode.com/problems/different-ways-to-add-parentheses/ 自己做的感觉不太好，听了花花酱的讲解后写了一版Java的，时间和内存可以达到都是 100%。 这道题目的关键在于： 递归的方式是按照操作符拆成左右两边表达式，左边的 List 和 右边的 List 进行笛卡尔积处理（以该操作符处理）。 递归的终止条件是字符串本身是个数值，没有操作符，那结果就将其放入到一个新 List 中返回。 重复计算：以用例2*3-4*5来说，计算方式可以有(2*(3-(4*5)))以及((2*3)-(4*5))，这里面的4*5会重复计算到，所有可以使用 map 记住字符串的计算结果。 试了下不带缓存的版本：Runtime: 2 ms, faster than 75.34%；Memory Usage: 38.6 MB, less than 65.42%，效果依然是不错的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public List&lt;Integer&gt; diffWaysToCompute(String input) &#123; if (input == null || input.length() == 0) &#123; return new ArrayList&lt;&gt;(); &#125; return handle(input, new HashMap&lt;&gt;());&#125;private List&lt;Integer&gt; handle(String str, Map&lt;String, List&lt;Integer&gt;&gt; cache) &#123; if (cache.containsKey(str)) &#123; return cache.get(str); &#125; List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; str.length(); i++) &#123; char ch = str.charAt(i); if (ch != '+' &amp;&amp; ch != '-' &amp;&amp; ch != '*') &#123; continue; &#125; String left = str.substring(0, i); String right = str.substring(i + 1); List&lt;Integer&gt; leftList = handle(left, cache); List&lt;Integer&gt; rightList = handle(right, cache); for (Integer l : leftList) &#123; for (Integer r : rightList) &#123; result.add(calculate(ch, l, r)); &#125; &#125; &#125; // str 为数字 if (result.size() == 0) &#123; result.add(Integer.parseInt(str)); &#125; cache.put(str, result); return result;&#125;private Integer calculate(char ch, Integer left, Integer right) &#123; if (ch == '+') &#123; return left + right; &#125; if (ch == '-') &#123; return left - right; &#125; if (ch == '*') &#123; return left * right; &#125; throw new IllegalArgumentException(\"incorrect char\");&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"},{"name":"partition","slug":"partition","permalink":"https://weilans.github.io/tags/partition/"}]},{"title":"[Leetcode单排] 分割回文串 (N131)","slug":"Leetcode单排-分割回文串-N131","date":"2019-08-04T07:13:47.000Z","updated":"2019-08-04T12:20:53.000Z","comments":true,"path":"2019/08/04/Leetcode单排-分割回文串-N131/","link":"","permalink":"https://weilans.github.io/2019/08/04/Leetcode单排-分割回文串-N131/","excerpt":"","text":"131. Palindrome Partitioninghttps://leetcode.com/problems/palindrome-partitioning/ DFS 回溯 典型问题。基本同 N93 复原IP地址问题。 需要注意的是 handle方法里面 for 的终止条件，一开始写的是i &lt; str.length()，发现最后一个字符总是漏掉，主要是 substring 的第二个参数在截取的时候 exclude，i 这个值本身可以等于 length。 12345678910111213141516171819202122232425262728293031323334353637public List&lt;List&lt;String&gt;&gt; partition(String s) &#123; List&lt;List&lt;String&gt;&gt; result = new ArrayList&lt;&gt;(); if (s == null || s.length() == 0) &#123; return result; &#125; handle(s, 0, new ArrayList&lt;&gt;(), result); return result;&#125;private void handle(String str, int index, List&lt;String&gt; curList, List&lt;List&lt;String&gt;&gt; result) &#123; if (index == str.length()) &#123; result.add(new ArrayList&lt;&gt;(curList)); return; &#125; for (int i = index + 1; i &lt;= str.length(); i++) &#123; if (isPalindrome(str.substring(index, i))) &#123; curList.add(str.substring(index, i)); handle(str, i, curList, result); curList.remove(curList.size() - 1); &#125; &#125;&#125;private boolean isPalindrome(String str) &#123; if (str == null || str.length() == 0) &#123; return false; &#125; if (str.length() == 1) &#123; return true; &#125; for (int i = 0; i &lt; str.length() / 2; i++) &#123; if (str.charAt(i) != str.charAt(str.length() - i - 1)) &#123; return false; &#125; &#125; return true;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"},{"name":"partition","slug":"partition","permalink":"https://weilans.github.io/tags/partition/"}]},{"title":"[Leetcode单排] 复原IP地址 (N93)","slug":"Leetcode单排-复原IP地址-N93","date":"2019-08-04T06:02:33.000Z","updated":"2019-08-04T12:19:18.984Z","comments":true,"path":"2019/08/04/Leetcode单排-复原IP地址-N93/","link":"","permalink":"https://weilans.github.io/2019/08/04/Leetcode单排-复原IP地址-N93/","excerpt":"","text":"93. Restore IP Addresseshttps://leetcode.com/problems/restore-ip-addresses/ DFS 回溯 典型问题，只要稍微留意一下为 0 的情况就可以了。 需要留意的是终止条件fields == 4 || index == chars.length。之前误写的是fields &gt; 4 || index == chars.length，导致内存 less than 5%。本以为是递归数据结构用的不好，结果发现只要内存用得多，那就应该想到是递归本身条件写的有问题。改回等号后 less than 100%。 123456789101112131415161718192021222324252627282930public List&lt;String&gt; restoreIpAddresses(String s) &#123; List&lt;String&gt; result = new ArrayList&lt;&gt;(); if (s == null || s.length() == 0) &#123; return result; &#125; search(s.toCharArray(), 0,0, \"\", result); return result; &#125; private void search(char[] chars, int index, int fields, String cur, List&lt;String&gt; result) &#123; if (fields == 4 &amp;&amp; index == chars.length) &#123; result.add(cur.substring(0, cur.length() - 1)); return; &#125; // 注意终止条件 if (fields == 4 || index == chars.length) &#123; return; &#125; if (chars[index] == '0') &#123; search(chars, index + 1, fields + 1, cur + new String(chars, index, 1) + \".\", result); &#125; else &#123; if (index + 2 &lt; chars.length &amp;&amp; Integer.parseInt(new String(chars, index, 3)) &lt;= 255) &#123; search(chars, index + 3, fields + 1, cur + new String(chars, index, 3) + \".\", result); &#125; if (index + 1 &lt; chars.length) &#123; search(chars, index + 2, fields + 1, cur + new String(chars, index, 2) + \".\", result); &#125; search(chars, index + 1, fields + 1, cur + new String(chars, index, 1) + \".\", result); &#125; &#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"},{"name":"partition","slug":"partition","permalink":"https://weilans.github.io/tags/partition/"}]},{"title":"[Leetcode单排] 单词接龙 (N127)","slug":"Leetcode单排-单词接龙-N127","date":"2019-08-01T13:46:54.000Z","updated":"2019-08-04T14:07:54.520Z","comments":true,"path":"2019/08/01/Leetcode单排-单词接龙-N127/","link":"","permalink":"https://weilans.github.io/2019/08/01/Leetcode单排-单词接龙-N127/","excerpt":"","text":"127. Word Ladderhttps://leetcode.com/problems/word-ladder/ 这道题目一眼看上去很像用 DFS 去操作，但是很快就会发现实在操作不下去。从单个单词跳往下一个单词时，还是得 26 个字符替换着来。这道题需要使用 BFS 完成，可以借助队列。从 beginWord 开始，对每个位置都尝试用26种字符替换，如果新字符串在单词集合中，则继续开始下一轮。需要注意的是，单词在集合中出现的话，需要将该单词删除，比如第 N + 2 轮出现的某个单词在第 N 轮也出现的话，那第 N 轮的分支得到的轮次数自然更少。 1234567891011121314151617181920212223242526272829303132333435public int ladderLength(String beginWord, String endWord, List&lt;String&gt; wordList) &#123; if (!wordList.contains(endWord)) &#123; return 0; &#125; Set&lt;String&gt; wordSet = new HashSet&lt;&gt;(wordList); Queue&lt;String&gt; queue = new LinkedList&lt;&gt;(); queue.offer(beginWord); int len = beginWord.length(); int step = 0; while (!queue.isEmpty()) &#123; ++step; // 对上一轮压进的所有值进行处理 for (int size = queue.size(); size &gt; 0; size--) &#123; String word = queue.poll(); // 针对String，获得其更改一位且在wordSet存在的值 for (int i = 0; i &lt; len; i++) &#123; for (char j = 'a'; j &lt; 'z'; j++) &#123; char[] arr = word.toCharArray(); arr[i] = j; String tempWord = new String(arr); if (endWord.equals(tempWord)) &#123; return step + 1; &#125; if (!wordSet.contains(tempWord)) &#123; continue; &#125; wordSet.remove(tempWord); queue.offer(tempWord); &#125; &#125; &#125; &#125; return 0;&#125; 广度优先搜索做出来已经比较不容易了，但是性能一般，还有另一种优化解法：双向广度优先搜索。单词数量较多时，效率相差非常明显。 Runtime: 14 ms, faster than 94.73%; Memory Usage: 38.1 MB, less than 99.36% 从一个队列换成两个 Set，一个从头到尾，一个从尾到头，每轮比较两个 Set 的大小，遍历小的一方的字符串进行处理，并将新单词 Set 赋给该 Set。后续继续比较两个 Set 的大小，以此类推。 12345678910111213141516171819202122232425262728293031323334353637383940414243public int ladderLength(String beginWord, String endWord, List&lt;String&gt; wordList) &#123; if (!wordList.contains(endWord)) &#123; return 0; &#125; Set&lt;String&gt; wordSet = new HashSet&lt;&gt;(wordList); Set&lt;String&gt; set1 = new HashSet&lt;&gt;(); set1.add(beginWord); Set&lt;String&gt; set2 = new HashSet&lt;&gt;(); set2.add(endWord); int len = beginWord.length(); int step = 0; while (!set1.isEmpty() &amp;&amp; !set2.isEmpty()) &#123; step++; Set&lt;String&gt; tempSet = new HashSet&lt;&gt;(); boolean set1Big = set1.size() &gt; set2.size(); Set&lt;String&gt; smallSet = !set1Big ? set1 : set2; Set&lt;String&gt; bigSet = set1Big ? set1 : set2; for (String str : smallSet) &#123; for (int i = 0; i &lt; len; i++) &#123; for (char j = 'a'; j &lt; 'z'; j++) &#123; char[] arr = str.toCharArray(); arr[i] = j; String tempWord = new String(arr); if (bigSet.contains(tempWord)) &#123; return step + 1; &#125; if (!wordSet.contains(tempWord)) &#123; continue; &#125; wordSet.remove(tempWord); tempSet.add(tempWord); &#125; &#125; &#125; if (set1Big) &#123; set2 = tempSet; &#125; else &#123; set1 = tempSet; &#125; &#125; return 0;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"},{"name":"bfs","slug":"bfs","permalink":"https://weilans.github.io/tags/bfs/"}]},{"title":"Clojure in Action: Clojure 构件","slug":"Clojure-in-Action-Clojure-构件","date":"2019-07-31T02:35:52.000Z","updated":"2019-08-12T02:36:37.813Z","comments":true,"path":"2019/07/31/Clojure-in-Action-Clojure-构件/","link":"","permalink":"https://weilans.github.io/2019/07/31/Clojure-in-Action-Clojure-构件/","excerpt":"","text":"元数据元数据提供了在必要时为值添加标识的 一种手段。 123456789101112131415161718192021222324252627282930(def untrusted (with-meta &#123;:command \"delete-table\" :subject \"users\"&#125; &#123;:safe false :io true&#125;)); 可以使用读取器宏^&#123;&#125;简化元数据定义(def untrusted ^&#123;:safe false :io true&#125; &#123;:command \"delete-table\" :subject \"users\"&#125;)untrusted;=&gt; &#123;:command \"delete-table\", :subject \"users\"&#125;;检查与值关联的元数据，可以使用meta函数(meta untrusted);=&gt; &#123;:safe false, :io true&#125;;元数据不影响值的相等性。(def trusted &#123;:command \"delete-table\" :subject \"users\"&#125;) (= trusted untrusted);=&gt; true;元数据在读取时可以加入，而不可以在求值时加入。下列程序将元数据与以hash-map开头的列表关联，而不是与函数调用产生的哈希映射关联，所以这个元数据在运行时不可见。(def untrusted2 ^&#123;:safe false :io true&#125; (hash-map :command \"delete-table\" :subject \"users\"))(meta untrusted2);=&gt; nil; 从有元数据的新值中创建新值时，元数据被复制到新数据里(def still-untrusted (assoc untrusted :complete? false))still-untrusted;=&gt; &#123;:complete? false, :command \"delete-table\", :subject \"users\"&#125;(meta still-untrusted);=&gt; &#123;:safe false, :io true&#125; 函数与宏也可以在定义中包含元数据。 1234567891011121314151617(defn ^&#123;:safe true :console true :doc \"testing metadata for functions\"&#125; testing-meta [] (println \"Hello from meta!\"))(meta testing-meta);=&gt; nil(meta (var testing-meta));=&gt; &#123;:ns #&lt;Namespace user&gt;,; :name testing-meta,; :file \"NO_SOURCE_FILE\",; :line 1, :arglists ([]),; :console true,; :safe true,; :doc \"testing metadata for functions\"&#125; Java 类型提示调用Java方法时，需要通过类找到方法的实现。但是，Clojure 是动态语言，变量类型只有在运行时才知道。可以使用读取器宏^symbol 123456789101112131415(set! *warn-on-reflection* true) ; Warn us when reflection is needed.(defn string-length [x] (.length x))(time (reduce + (map string-length (repeat 10000 \"12345\"))));Reflection warning;\"Elapsed time: 45.751 msecs\";=&gt; 50000(defn fast-string-length [^String x] (.length x)) ; No reflection warning.(time (reduce + (map fast-string-length (repeat 10000 \"12345\"))));\"Elapsed time: 5.788 msecs\";=&gt; 50000(meta (first (first (:arglists (meta #'fast-string-length)))))=&gt; &#123;:tag String&#125; Clojure 编译器在类型推导上相当智能，所有核心函数已经在必要时做了类型提示，所以不经常需要采用类型提示。 原始类型没有可读的类名可提供引用，Clojure 为所有原始类型和原始类型数组定义了别名：只需要使用^byte这样的类型提示表示原始类型，^bytes这样的复数形式表示原始类型数组。 Java 异常处理12345678910111213141516(defn average [numbers] (let [total (apply + numbers)] (/ total (count numbers))))(average []);ArithmeticException Divide by zero clojure.lang.Numbers.divide (Numbers.java:156)(defn safe-average [numbers] (let [total (apply + numbers)] (try (/ total (count numbers)) (catch ArithmeticException e (println \"Divided by zero!\") 0))))(safe-average []);Divided by zero!;=&gt; 0 如果有表达式产生异常，则 根据异常类型执行对应的 catch子句，返回该子句的值。可选的finally子句总会被执行，用于保证必须的副作用，但不返回任何数值。 1234567(try (print \"Attempting division... \") (/ 1 0) (finally (println \"done.\")))Attempting division... done.;=&gt;Execution error (ArithmeticException) at user/eval1516 (form-init4016394056826807004.clj:3).Divide by zero 需要注意catch子句的顺序。 12345678910(try (print \"Attempting division... \") (/ 1 0) (catch RuntimeException e \"Runtime exception!\") (catch ArithmeticException e \"DIVIDE BY ZERO!\") (catch Throwable e \"Unknown exception encountered!\") (finally (println \"done.\")));Attempting division... done.;=&gt; \"Runtime exception!\" 异常可以使用throw形式抛出，在希望抛出的场合可以使用: (throw (Exception. &quot;this is an error&quot;))。 函数先决和后置条件在执行函数主体之前运行的检查由:pre指定，称为先决条件。:post键指定的条件称为后置条件，条件中的%指的就是函数的返回值。 1234567891011121314151617181920(defn item-total [price quantity discount-percentage] &#123;:pre [(&gt; price 0) (&gt; quantity 0)] :post [(&gt; % 0)]&#125; (-&gt;&gt; (/ discount-percentage 100) (- 1) (* price quantity) float))(item-total 100 2 0);=&gt; 200.0(item-total 100 2 10);=&gt; 180.0(item-total 100 -2 10);Execution error (AssertionError) at user/item-total (form-init4016394056826807004.clj:1).;Assert failed: (&gt; quantity 0)(item-total 100 2 110);Execution error (AssertionError) at user/item-total (form-init4016394056826807004.clj:1).;Assert failed: (&gt; % 0) 重载（多种参数数量）12345(defn total-cost ([item-cost number-of-items] (* item-cost number-of-items)) ([item-cost] (total-cost item-cost 1))) 可以从某种参数数量的函数中调用其他参数数量的版本。 可变参数函数在 Clojure 中使用&amp;符号实现变长参数功能。 12(defn total-all-numbers [&amp; numbers] (apply + numbers)) 可变参数函数中有一些不可变的参数。可变参数中的必要参数数量至少要与最长的固定参数相同。 1234567891011121314151617(defn many-arities ([] 0) ([a] 1) ([a b c] 3) ([a b c &amp; more] \"variadic\"))(many-arities);=&gt; 0(many-arities \"one argument\");=&gt; 1(many-arities \"two\" \"arguments\");Execution error (ArityException) at user/eval1554 (form-init4016394056826807004.clj:11).;Wrong number of args (2) passed to: user/many-arities(many-arities \"three\" \"argu-\" \"ments\");=&gt; 3(many-arities \"many\" \"more\" \"argu-\" \"ments\");=&gt; \"variadic\" 高阶参数every?接受一个返回布尔值的函数（判定函数）和一个序列 12345(def bools [true true true false false])(every? true? bools) ;=&gt; false(every? even? '(2 4 6));=&gt; true some接受一个判定和一个序列，返回获得的第一个逻辑true值，如果调用都不返回逻辑 true，则返回 nil。 12(some (fn [p] (= \"rob\" p)) [\"kyle\" \"siva\" \"rob\" \"celeste\"]);=&gt; true constantly接受一个值 v，返回一个可变参数函数，这个函数不管输入的参数为何，总是返回相同的值 v。 12345678(def two (constantly 2)) ; same as ;(def two (fn [&amp; more] 2));(defn two [&amp; more] 2);=&gt; #'clj-in-act.ch3/two(two 1);=&gt; 2(two :a :b :c);=&gt; 2 complement接受一个函数作为参数，返回与原始函数参数数量相同、完成相同工作但返回逻辑相反值的函数。 123456789101112(defn greater? [x y] (&gt; x y))(greater? 10 5);=&gt; true(greater? 10 20);=&gt; false(def smaller? (complement greater?))(smaller? 10 5);=&gt; false(smaller? 10 20);=&gt; true comp接受多个函数并返回由哪些函数组合而成的新函数。计算从右到左进行，新函数将其参数应用于原始组成函数中最右侧的一个，然后将结果应用到它左边的函数，直到所有函数都被调用。 1234567(def opp-zero-str (comp str not zero?)); (defn opp-zero-str [x] (str (not (zero? x))))(opp-zero-str 0);=&gt; \"false\"(opp-zero-str 1);=&gt; \"true\" partial接受函数 f 以及 f 的几个参数，然后partial返回一个新函数，接受 f 的其余参数。当以余下的参数调用新函数时，它以全部参数调用原始函数 f。 1234567(defn above-threshold? [threshold number] (&gt; number threshold))(filter (fn [x] (above-threshold? 5 x)) [1 2 3 4 5 6 7 8 9]);=&gt; (6 7 8 9)(filter (partial above-threshold? 5) [1 2 3 4 5 6 7 8 9]);=&gt; (6 7 8 9) memoize内存化可以避免函数为已处理过的参数计算结果。 1234567891011121314(defn slow-calc [n m] (Thread/sleep 1000) (* n m))(time (slow-calc 5 7));\"Elapsed time: 1000.097 msecs\";=&gt; 35(def fast-calc (memoize slow-calc))(time (fast-calc 5 7));\"Elapsed time: 1002.446198 msecs\";=&gt; 35(time (fast-calc 5 7));\"Elapsed time: 0.089624 msecs\";=&gt; 35 注意：memoize缓存没有限定大小，因而会不停缓存输入和结果。因此该函数只应该用于少量可能输入的函数，否则最终会把内存耗尽。更高级的内存化功能，可以使用clojure.core.memoize库。 匿名函数匿名函数使用fn创建。 123(defn sorter-using [ordering-fn] (fn [collection] (sort-by ordering-fn collection))) 同时可以使用#()创建一个匿名函数。%表示一个参数，如果超过一个参数，则可以使用%1、%2…还可以使用%&amp;表示除明确引用的%&amp;参数之外的参数。 12345678(#(vector %&amp;) 1 2 3 4 5);=&gt; [(1 2 3 4 5)](#(vector % %&amp;) 1 2 3 4 5);=&gt; [1 (2 3 4 5)](#(vector %1 %2 %&amp;) 1 2 3 4 5);=&gt; [1 2 (3 4 5)](#(vector %1 %2 %&amp;) 1 2);=&gt; [1 2 nil]","categories":[{"name":"clojure","slug":"clojure","permalink":"https://weilans.github.io/categories/clojure/"}],"tags":[{"name":"clojure","slug":"clojure","permalink":"https://weilans.github.io/tags/clojure/"}]},{"title":"[Leetcode单排] 单词搜索 (N79 N212)","slug":"Leetcode单排-单词搜索 (N79 N211)","date":"2019-07-30T12:56:39.000Z","updated":"2019-07-31T15:37:04.885Z","comments":true,"path":"2019/07/30/Leetcode单排-单词搜索 (N79 N211)/","link":"","permalink":"https://weilans.github.io/2019/07/30/Leetcode单排-单词搜索 (N79 N211)/","excerpt":"","text":"79. Word Searchhttps://leetcode-cn.com/problems/word-search/ 在二维数组中搜索具体的单词是否存在。这个题目有几个值得借鉴吸收的地方： 1、 当要在二维数组的特定点四周继续寻找时，不需要写函数计算这个点周围有几个可用点，可以直接在递归中判断是否 out of range； 2、要注意递归函数的具体功能含义。初始尝试时，找到开始点和递归方法写成了两个函数，实际上可以融合； 3、下面的做法没有采用单独的列表存储走过的元素，而是采用将值记录为0，这样就可以在递归中碰到这个点时必然不相等，就相当于排除了这个点。 123456789101112131415161718192021222324252627282930public boolean exist(char[][] board, String word) &#123; for (int i = 0; i &lt; board[0].length; i++) &#123; for (int j = 0; j &lt; board.length; j++) &#123; if (dfs(i, j, 0, word, board)) &#123; return true; &#125; &#125; &#125; return false;&#125;private boolean dfs(int x, int y, int i, String word, char[][] board) &#123; if (x &lt; 0 || y &lt; 0 || x &gt;= board[0].length || y &gt;= board.length) &#123; return false; &#125; if (board[y][x] != word.charAt(i)) &#123; return false; &#125; if (i == word.length() - 1) &#123; return true; &#125; char temp = board[y][x]; board[y][x] = '0'; boolean res = dfs(x + 1, y, i + 1, word, board) || dfs(x - 1, y, i + 1, word, board) || dfs(x, y + 1, i + 1, word, board) || dfs(x, y - 1, i + 1, word, board); board[y][x] = temp; return res;&#125; 下面这个是使用了访问变量的版本： 123456789101112131415161718192021222324252627282930313233public boolean exist(char[][] board, String word) &#123; boolean[][] visit = new boolean[board.length][]; for (int i = 0; i &lt; board.length; i++) &#123; visit[i] = new boolean[board[0].length]; &#125; for (int i = 0; i &lt; board[0].length; i++) &#123; for (int j = 0; j &lt; board.length; j++) &#123; if (dfs(i, j, 0, word, board, visit)) &#123; return true; &#125; &#125; &#125; return false;&#125;private boolean dfs(int x, int y, int i, String word, char[][] board, boolean[][] visit) &#123; if (x &lt; 0 || y &lt; 0 || x &gt;= board[0].length || y &gt;= board.length) &#123; return false; &#125; if (board[y][x] != word.charAt(i) || visit[y][x]) &#123; return false; &#125; if (i == word.length() - 1) &#123; return true; &#125; visit[y][x] = true; boolean res = dfs(x + 1, y, i + 1, word, board, visit) || dfs(x - 1, y, i + 1, word, board, visit) || dfs(x, y + 1, i + 1, word, board, visit) || dfs(x, y - 1, i + 1, word, board, visit); visit[y][x] = false; return res;&#125; 212. Word Search IIhttps://leetcode.com/problems/word-search-ii/ 与上题不同的是，这次是给一个字符串数组，结果是所有满足条件的字符串的集合，其实就是把上题中的单字符串换成字符串数组。如果基于上文中的解法直接加一层for循环：Your runtime beats 13.43 %, memory usage beats 90.76 %。 正确做法是基于 Trie 树，其实从一串字符串中进行筛选就应该想到使用前缀树。答案借鉴的这位的做法，这代码风格和我上一题基本一模一样。实际上需要以二维数组的每个字符去匹配 Trie 树，从顶向下找，看能包含几个字符串。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// 构建Trie树节点(26叉树)class TrieNode &#123; public TrieNode[] children = new TrieNode[26]; public String word = null;&#125;// 构建Trie树class Trie &#123; public TrieNode root = new TrieNode(); // 只需要插入方法即可 public void insert(String word) &#123; TrieNode node = root; for (int i = 0; i &lt; word.length(); ++i) &#123; int charNo = word.charAt(i) - 'a'; if (node.children[charNo] == null) &#123; node.children[charNo] = new TrieNode(); &#125; node = node.children[charNo]; &#125; node.word = word; &#125;&#125;public class Solution &#123; public List&lt;String&gt; findWords(char[][] board, String[] words) &#123; // 事先构造 Trie trie = new Trie(); for (String word : words) &#123; trie.insert(word); &#125; boolean[][] visited = new boolean[board.length][board[0].length]; Set&lt;String&gt; resultSet = new HashSet&lt;&gt;(); for (int i = 0; i &lt; board.length; ++i) &#123; for (int j = 0; j &lt; board[0].length; ++j) &#123; search(board, visited, i, j, board.length, board[0].length, trie.root, resultSet); &#125; &#125; return new ArrayList&lt;&gt;(resultSet); &#125; private void search(char[][] board, boolean[][] visit, int i, int j, int x, int y, TrieNode node, Set&lt;String&gt; result) &#123; if (i &lt; 0 || j &lt; 0 || i &gt;= x || j &gt;= y || visit[i][j]) &#123; return; &#125; node = node.children[board[i][j] - 'a']; if (node == null) &#123; return; &#125; if (node.word != null) &#123; result.add(node.word); // 此处没有 return，后续可能还存在字符串 &#125; visit[i][j] = true; search(board, visit, i - 1, j, x, y, node, result); search(board, visit, i + 1, j, x, y, node, result); search(board, visit, i, j - 1, x, y, node, result); search(board, visit, i, j + 1, x, y, node, result); visit[i][j] = false; &#125;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"}]},{"title":"Clojure in Action: 程序结构、程序流程","slug":"Clojure-in-Action-程序结构、程序流程","date":"2019-07-30T05:58:29.000Z","updated":"2019-07-30T12:40:51.548Z","comments":true,"path":"2019/07/30/Clojure-in-Action-程序结构、程序流程/","link":"","permalink":"https://weilans.github.io/2019/07/30/Clojure-in-Action-程序结构、程序流程/","excerpt":"","text":"程序结构函数定义defn宏展开为def和fn调用的组合。fn宏接受方括号中的一系列参数然后是程序主体，fn形式可以用于定义匿名函数。 1234567(defn addition-function [x y] (+ x y));; Expanded form:(def addition-function (fn [x y] (+ x y))) let 形式let形式接受一个向量作为其第一个参数，该向量包含偶数个形式，然后是在 let 求值时进行求值的 0 个或者多个形式。let 形式可以在代码中将一个符号和某个值绑定，从而引入局部命名对象。let 返回的是最后一个表达式的值。 12345(let [x 1 y 2 z (+ x y)] z);=&gt; 3 以下函数可以使用 let 将其分成几个部分，使代码清晰。 123456789(defn average-pets [] (/ (apply + (map :number-pets (vals users))) (count users))) (defn average-pets [] (let [user-data (vals users) pet-counts (map :number-pets user-data) total (apply + pet-counts)] (/ total (count users)))) 在 let 中如果不需要关注值，可以使用下划线标识符，下划线标识符本身没有什么特别之处，只是 clojure 的一个惯例。在解构中，下划线标识符更加实用：(let [[_ _ z] [1 2 3]] z)。 123456(defn average-pets [] (let [user-data (vals users) pet-counts (map :number-pets user-data) _ (println \"total pets:\" pet-counts) total (apply + pet-counts)] (/ total (count users)))) do纯函数语言中，程序是没有副作用的，函数的唯一行为就是计算一个值并返回。但是现实世界中必然充满了状态，也必然有副作用，例如向控制台或者日志文件中打印某些内容、在数据库中保存内容就是改变世界状态的副作用。为了将多个表达式转为一个形式，clojure 提供了 do形式。 12345(if (is-something-true?) (do (log-message \"in true branch\") (store-something-in-db) (return-useful-value))) 1(for [i (range 1 3)] (do (println i) i)) 程序流程条件if(if test consequent alternative) if形式接受一个测试表达式，若为真则求后续表达式(consequent)，若为假则则使用替代形式(alternative)。形式可以结合do形式使其完成多项工作。 12(if (&gt; 5 2) \"yes\" \"no\");=&gt; \"yes\" if-not12(if-not (&gt; 5 2) \"yes\" \"no\");=&gt; \"no\" condcond可以将嵌套的if条件数扁平化，(cond &amp; clauses)。 123456(def x 1)(cond (&gt; x 0) \"greater!\" (= x 0) \"zero!\" :default \"lesser!\");=&gt; \"greater!\" 子句（clauses）是成对的表达式。当一个表达式返回 true，求值相关的后续表达式并返回。 如果所有表达式都没有返回真值，则可以传入取真值的表达式（比如关键词 :default），然后求值相关的后续表达式并返回。 whenwhen宏是将一个if和一个隐式的do。 123456789(when (&gt; 5 2) (println \"five\") (println \"is\") (println \"greater\") \"done\");five;is;greater;=&gt; \"done\" 此处就没有必要将do包装这三个函数了，when宏会负责这项工作。 when-not123456789(when-not (&lt; 5 2) (println \"two\") (println \"is\") (println \"smaller\") \"done\");two;is;smaller;=&gt; \"done\" 逻辑函数and接受 0 个或多个形式，按顺序求值每个形式，如果任何一个返回 nil 或者 false，则返回该值。如果所有形式都不返回 false 或 nil，则 and 返回最后一个形式的值。如果没有任何值，则返回 true。 12345678910(and);=&gt; true(and :a :b :c);=&gt; :c(and :a nil :c);=&gt; nil(and :a false :c);=&gt; false(and 0 \"\");=&gt; \"\" or接受 0 个或多个形式并逐一求值，如果任何形式返回逻辑真值，则将该值返回。如果所有形式都不返回逻辑真值，则返回最后一个值。 12345678910(or);=&gt; nil(or :a :b :c);=&gt; :a(or :a nil :c);=&gt; :a(or nil false);=&gt; false(or false nil);=&gt; nil not该函数始终返回true或者false。 123456(not true);=&gt; false(not 1);=&gt; false(not nil);=&gt; true 比较函数&lt;、&lt;=、&gt;、&gt;=、=有一个额外特性：可以取任意数量的参数。 12345; &lt; 可检测是否以升序排列(&lt; 2 4 6 8);=&gt; true(&lt; 2 4 3 8);=&gt; false = 与 ===函数等同于 Java 的 equals，但适用于范围更广的对象，包括 nil、数值、序列。Clojure 中的 ==函数只能用于比较数值。=可以比较任意两个值，但比较三种不同类型的数值时结果不理想。 12345678(= 1 1N 1/1);=&gt; true(= 0.5 1/2);=&gt; false(= 0.5M 0.5);=&gt; false(= 0.5M 1/2);=&gt; false 如果对比不同类型的数值，则可以用==代替，但是所有参数必须是数值。 12345678910111213(== 1 1N 1/1);=&gt; true(== 1/2 0.5M 0.5);=&gt; true1.9999999999999999;=&gt; 2.0(== 2.0M 1.9999999999999999) ; == 不是对抗浮点精度和舍入问题的银弹;=&gt; true_(== :a 1);ClassCastException clojure.lang.Keyword cannot be cast to java.lang.Number clojure.lang.Numbers.equiv (Numbers.java:206)_(== nil 1);NullPointerException clojure.lang.Numbers.ops (Numbers.java:961) 如果你预计所有要对比的数据都是数值，且预期有不同类型的数字，则使用==，否则使用=。 函数式循环大部分函数式语言都不支持传统的for循环结构，因为for的典型实现需要改变循环计数器的值。作为替代，它们使用递归和函数应用。 whilewhile宏与命令式语言类似。 12(while (request-on-queue?) (handle-request (pop-request-queue))) loop/recurClojure 没有传统的for循环，其循环流程控制是使用loop和recur。 12345(defn fact-loop [n] (loop [current n fact 1] (if (= current 1) fact (recur (dec current) (* fact current) )))) loop建立和let形式完全相同的绑定，recur也有两个绑定值(def current)和(* fact current)，他们在计算之后重新与current和fact绑定。 recur看起来像递归，实际上不适用栈。recur仅能作用于代码尾部，如果企图从任何其他位置使用它，编译器会报错。 doseq 和 dotimes123456(defn run-report [user] (println \"Running report for\" user))(defn dispatch-reporting-jobs [all-users] (doseq [user all-users] (run-report user))) 上面这个例子中doseq的第一个项是一个新符号，以后将绑定到第二个项（必须是一个序列）中的每一个元素。形式的主体将对序列中的每个元素执行，然后整个形式将返回 nil。 dotimes与之类似，接受一个向量（包含一个符号和一个数值），向量中符号被设置为 0 到 (n-1) 的值，并对每个数值求取主体的值。 12(dotimes [x 5] (println \"X is\" x)) 将打印数字 0~4，返回 nil。 map 、filter、remove、reduce、for在前篇文章中的数据结构 — 序列中的“序列转换”一节中已提及。这里做一些补充。 map 12345678910(map inc [0 1 2 3]);=&gt; (1 2 3 4);; map 接受一个函数，其可以有任意多个参数以及相同数量的序列。每个序列为函数提供一个参数。(map + [0 1 2 3] [0 1 2 3]);=&gt; (0 2 4 6);; 返回值的长度等于最短序列的长度(map + [0 1 2 3] [0 1 2]);=&gt; (0 2 4) filter 12345(defn non-zero-expenses [expenses] (let [non-zero? (fn [e] (not (zero? e)))] (filter non-zero? expenses)))(non-zero-expenses [-2 -1 0 1 2 3]);=&gt; (-2 -1 1 2 3) remove filter判定保留哪些元素，remove判定抛弃哪些元素。两者刚好相反。 1234(defn non-zero-expenses [expenses] (remove zero? expenses))(non-zero-expenses [-2 -1 0 1 2 3]);=&gt; (-2 -1 1 2 3) reduce &amp; reductions reduce接受一个函数（有两个参数）和一个数据元素序列。函数参数应用到序列的前两个元素，产生第一个结果，之后使用这个结果和序列的下一个元素再次调用同一个函数。重复此过程直到处理完最后一个元素。 12345(defn factorial [n] (let [numbers (range 1 (+ n 1))] (reduce * numbers)))(factorial 5);=&gt; 120 reduce只返回最终的规约值，而reductions返回每个中间值组成的序列。 12345(defn factorial-steps [n] (let [numbers (range 1 (+ n 1))] (reductions * numbers)))(factorial-steps 5);=&gt; (1 2 6 24 120) for 可以使用的限定词：:let，:when，:while 123456789101112(for [x [0 1 2 3 4 5] :let [y (* x 3)] :when (even? y)] y);=&gt; (0 6 12)(def chessboard-labels (for [alpha \"abcdefgh\" num (range 1 9)] (str alpha num)))chessboard-labels;=&gt; (\"a1\" \"a2\" \"a3\" \"a4\" \"a5\" … \"h6\" \"h7\" \"h8\") 123456789101112131415161718(defn prime? [x] (let [divisors (range 2 (inc (int (Math/sqrt x)))) remainders (map (fn [d] (rem x d)) divisors)] (not (some zero? remainders))))(defn primes-less-than [n] (for [x (range 2 (inc n)) :when (prime? x)] x))(primes-less-than 50);=&gt; (2 3 5 7 11 13 17 19 23 29 31 37 41 43 47)(defn pairs-for-primes [n] (let [z (range 2 (inc n))] (for [x z y z :when (prime? (+ x y))] (list x y))))(pairs-for-primes 5);=&gt; ((2 3) (2 5) (3 2) (3 4) (4 3) (5 2)) 串行宏thread-first12(defn final-amount [principle rate time-periods] (* (Math/pow (+ 1 (/ rate 100)) time-periods) principle)) 以上函数定义不易理解，需要从里往外读。使用thread-first宏-&gt;改写如下。该宏所做的是取第一个参数，将其放在下一个表达式的第二个位置。之所以成为thread-first，是因为它将代码移到下一个形式首个参数的位置。之后，它取得整个结果表达式，并将其移到再下一个表达式的第二个位置。 123456(defn final-amount-&gt; [principle rate time-periods] (-&gt; rate (/ 100) (+ 1) (Math/pow time-periods) (* principle))) thread-lastthread-last宏-&gt;&gt;在取得第一个表达式结果后，将其移入下一个表达式最后的位置。之后，对所有表达式重复该 过程。 12345678(defn factorial [n] (reduce * (range 1 (+ 1 n))))(defn factorial-&gt;&gt; [n] (-&gt;&gt; n (+ 1) (range 1) (reduce *))) thread-last宏更常见的用途是处理数据元素序列以及使用 map、reduce、filter 这样的高阶函数。这些函数都接受序列作为最后一个元素，所以thread-last宏更为合适。 some-&gt;和some-&gt;&gt;和上述两个宏基本相同，但是如果表达式的任意一步的结果是 nil，则计算结束。 thread-asthread-as宏as-&gt;相比上两者，更加灵活：你为它提供一个名称，它将把各个连续形式的结果绑定到这个名称，以便下一步使用。 1234(as-&gt; &#123;\"a\" [1 2 3 4]&#125; &lt;&gt; (&lt;&gt; \"a\") (conj &lt;&gt; 10) (map inc &lt;&gt;)) 该例子展开后如下： 12345(let [&lt;&gt; &#123;\"a\" [1 2 3 4]&#125; &lt;&gt; (&lt;&gt; \"a\") &lt;&gt; (conj &lt;&gt; 10) &lt;&gt; (map inc &lt;&gt;)] &lt;&gt;) 条件式串行宏cond-&gt;和cond-&gt;&gt;除了每个形式都包含一个条件之外，和-&gt;以及-&gt;&gt;基本相同，如果一个条件为false，则对应的形式将会跳过，但是对下一对形式继续串行求值（cond则是在发现为真的判定后将立刻停止后续成对形式的求值，而cond-&gt;会对每个条件求值）。 123456(let [x 1 y 2] (cond-&gt; [] (odd? x) (conj \"x is odd\") (zero? (rem y 3)) (conj \"y is divisible by 3\") (even? y) (conj \"y is even\")));=&gt; [\"x is odd\" \"y is even\"] 其等价描述为： 123456(let [x 1 y 2] (as-&gt; [] &lt;&gt; (if (odd? x) (conj &lt;&gt; \"x is odd\") &lt;&gt;) (if (zero? (rem y 3)) (conj &lt;&gt; \"y is divisible by 3\") &lt;&gt;) (if (even? y) (conj &lt;&gt; \"y is even\") &lt;&gt;)));=&gt; [\"x is odd\" \"y is even\"]","categories":[{"name":"clojure","slug":"clojure","permalink":"https://weilans.github.io/categories/clojure/"}],"tags":[{"name":"clojure","slug":"clojure","permalink":"https://weilans.github.io/tags/clojure/"}]},{"title":"Java进程CPU高负载排查","slug":"Java进程CPU高负载排查","date":"2019-07-30T03:39:55.000Z","updated":"2019-11-06T10:24:41.430Z","comments":true,"path":"2019/07/30/Java进程CPU高负载排查/","link":"","permalink":"https://weilans.github.io/2019/07/30/Java进程CPU高负载排查/","excerpt":"","text":"Arthas 排查怕麻烦的话，直接使用Arthas排查，具体的线程排查命令可以使用：thread -n 3，表示当前最忙的前N个线程并打印堆栈（详细命令）。 123wget https://alibaba.github.io/arthas/arthas-boot.jarjava -jar arthas-boot.jar &lt;pid&gt;thread -n 3 jstack 排查 使用top将系统资源实时显示，输入大写P对CPU消耗进行排序，第一个就是CPU消耗最高的程序，获取 pid （或者也可以使用jps找到特定程序 pid）。 利用top -Hp pid（-H表示开启线程查看），之后输入大写P，按照CPU使用率对线程排序。 找出线程ID后转为16进制:printf &quot;%x\\n&quot; tid。 通过jstack pid &gt; jstack.log生成进程日志文件，在文件中搜索16进制的线程ID，就可以看到这个线程在干啥了。","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://weilans.github.io/tags/jvm/"}]},{"title":"[Leetcode单排] 括号生成 (N22)","slug":"Leetcode单排-括号生成-N22","date":"2019-07-29T11:48:30.000Z","updated":"2019-07-29T12:16:18.215Z","comments":true,"path":"2019/07/29/Leetcode单排-括号生成-N22/","link":"","permalink":"https://weilans.github.io/2019/07/29/Leetcode单排-括号生成-N22/","excerpt":"","text":"22. Generate Parentheseshttps://leetcode.com/problems/generate-parentheses/ 给出一个整数 n，给出 n 对左右括号所有可能的排列结果。 设左右括号的个数分别为left和right，则需要满足以下规律：left &lt;= n &amp;&amp; right &lt;= right。所以在每一次递归中需要考虑两种变量的变化。以 left = 2, right = 0为例， 满足第一个条件，则求解handle(3,3,0,&quot;(((&quot;, result)分支下所有满足条件的情况，之后再考虑handle(3,2,1,&quot;(()&quot;, result)分支下所有满足条件结果。两个情况只要满足条件都要进行。 答案虽然比较短，但还是需要仔细咀嚼。 123456789101112131415161718192021public List&lt;String&gt; generateParenthesis(int n) &#123; List&lt;String&gt; result = new ArrayList&lt;&gt;(); if (n &lt;= 0) &#123; return result; &#125; handle(n, 0, 0, \"\", result); return result;&#125;private void handle(int n, int left, int right, String cur, List&lt;String&gt; result) &#123; if (left == n &amp;&amp; right == n) &#123; result.add(cur); return; &#125; if (left &lt; n) &#123; handle(n, left + 1, right, cur + \"(\", result); &#125; if (right &lt; left) &#123; handle(n, left, right + 1, cur + \")\", result); &#125;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"}]},{"title":"[Leetcode单排] 数独 (N37)","slug":"Leetcode单排-数独-N37","date":"2019-07-28T16:55:31.000Z","updated":"2019-07-28T17:50:08.405Z","comments":true,"path":"2019/07/29/Leetcode单排-数独-N37/","link":"","permalink":"https://weilans.github.io/2019/07/29/Leetcode单排-数独-N37/","excerpt":"","text":"37. Sudoku Solverhttps://leetcode.com/problems/sudoku-solver/ 这道题目你知道是回溯，知道是DFS，但是如果需要你完整的做出来，你会发现还是有各种各样的问题。下面这个做法来源于花花酱的讲解。 N皇后是每次递归是确定一行一列，但是这个题目你会发现连每个单元格都可能有N种可能，所以递归的时候不是定住行和列，而是以单元格进行递归。访问变量也从一维变成了两位。比如rows boolean[i][j]就是指第 i 行值为 j 的数是否已存在，而boxes[i][j]就是在第 i 个九宫格值为 j 的数是否已存在。 输入里面已经包含部分数值，所以开局先填充一波访问变量，之后正式开始递归。递归函数 fill的返回值是布尔类型，代表 x 和 y 确定时，board中的位置是否有满足条件的情况。在 for 循环里面只要有一个满足了条件则立刻结束。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849boolean[][] rows = new boolean[9][10];boolean[][] cols = new boolean[9][10];boolean[][] boxes = new boolean[9][10];public void solveSudoku(char[][] board) &#123; for (int i = 0; i &lt; 9; i++) &#123; for (int j = 0; j &lt; 9; j++) &#123; char c = board[i][j]; if (c != '.') &#123; int n = c - '0'; int bx = j / 3; int by = i / 3; rows[i][n] = true; cols[j][n] = true; boxes[by * 3 + bx][n] = true; &#125; &#125; &#125; fill(board, 0, 0);&#125;private boolean fill(char[][] board, int x, int y) &#123; if (y == 9) &#123; return true; &#125; int nextX = (x + 1) % 9; int nextY = (nextX == 0) ? y + 1 : y; if (board[y][x] != '.') &#123; return fill(board, nextX, nextY); &#125; // 每个单元格以 1-9 去试 for (int i = 1; i &lt;= 9; i++) &#123; int boxIndex = y / 3 * 3 + x /3; if (!rows[y][i] &amp;&amp; !cols[x][i] &amp;&amp; !boxes[boxIndex][i]) &#123; rows[y][i] = true; cols[x][i] = true; boxes[boxIndex][i] = true; board[y][x] = (char)(i + '0'); if (fill(board, nextX, nextY)) &#123; return true; &#125; board[y][x] = '.'; rows[y][i] = false; cols[x][i] = false; boxes[boxIndex][i] = false; &#125; &#125; return false;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"}]},{"title":"[Leetcode单排] N皇后 (N51 N52)","slug":"Leetcode单排-N皇后-N51-N52","date":"2019-07-28T12:58:36.000Z","updated":"2019-07-28T14:02:50.673Z","comments":true,"path":"2019/07/28/Leetcode单排-N皇后-N51-N52/","link":"","permalink":"https://weilans.github.io/2019/07/28/Leetcode单排-N皇后-N51-N52/","excerpt":"","text":"51. N-Queenshttps://leetcode.com/problems/n-queens/ N皇后问题，这里是将花花的讲解翻成 Java 版，花花的讲解已足够简明易懂。 每个棋子在每一行每一列必须是唯一的，这倒还好，关键在于每个棋子的所在斜线和反斜线都不包含棋子。难点就在于如何确认斜线处是否有棋子。而在标准做法中，斜线和反斜线各需要一个布尔数组就可以做到，只要找到 x 及 y 下标关系即可。 从第 0 行开始，确定第 0 行 Q 所在位置，之后递归行数加 1，以此类推。 因为担心递归函数中包含变量太多，故将三个布尔数组作为了全局变量。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758boolean[] cols;boolean[] diag1;boolean[] diag2;public List&lt;List&lt;String&gt;&gt; solveNQueens(int n) &#123; if (n &lt;= 0) &#123; return null; &#125; cols = new boolean[n]; // 左下-右上斜线 idx = x + y diag1 = new boolean[2 * n - 1]; // 左上-右下斜线 idx = x - y + (n -1) diag2 = new boolean[2 * n - 1]; List&lt;List&lt;String&gt;&gt; result = new ArrayList&lt;&gt;(); List&lt;String&gt; initial = buildInitialList(n); handle(n, 0, initial, result); return result;&#125;private void handle(int n, int row, List&lt;String&gt; cur, List&lt;List&lt;String&gt;&gt; result) &#123; if (row == n) &#123; result.add(new ArrayList&lt;&gt;(cur)); return; &#125; for (int j = 0; j &lt; n; j++) &#123; if (available(j, row, n)) &#123; update(j, row, n, true, cur); handle(n, row + 1, cur, result); update(j, row, n, false, cur); &#125; &#125;&#125;private boolean available(int x, int y, int n) &#123; return !(cols[x] || diag1[x + y] || diag2[x - y + (n - 1)]);&#125;private void update(int x, int y, int n, boolean state, List&lt;String&gt; cur) &#123; cols[x] = state; diag1[x + y] = state; diag2[x - y + (n - 1)] = state; char[] rowArray = cur.get(y).toCharArray(); rowArray[x] = state ? 'Q' : '.'; cur.set(y, new String(rowArray));&#125;private List&lt;String&gt; buildInitialList(int n) &#123; List&lt;String&gt; res = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; n; i++) &#123; StringBuilder sb = new StringBuilder(); for (int j = 0; j &lt; n; j++) &#123; sb.append('.'); &#125; res.add(sb.toString()); &#125; return res;&#125; 52. N-Queens IIhttps://leetcode.com/problems/n-queens-ii/ 52题和51题是一样的，只是这次是计算个数。这里是将 count 作为全局变量，其实可以将 handle 返回 count，亦或者 handle 在每次满足条件时返回 1，这几种做法皆可。（只要不是犯将 count 放到参数这种低级错误皆可）。 左程云的书 里面还有一种使用位运算做加速的超自然做法，暂且备注一下。 1234567891011121314151617181920212223242526272829303132int count = 0;public int totalNQueens(int n) &#123; if (n &lt;= 0) &#123; return 0; &#125; handle(0, n, new boolean[n], new boolean[2 * n - 1], new boolean[2 * n - 1]); return count;&#125;private void handle(int row, int n, boolean[] cols, boolean[] diag1, boolean[] diag2) &#123; if (row == n) &#123; ++count; &#125; for (int j = 0; j &lt; n; j++) &#123; if (available(j, row, n, cols, diag1, diag2)) &#123; modifyState(j, row, n, cols, diag1, diag2, true); handle(row + 1, n, cols, diag1, diag2); modifyState(j, row, n, cols, diag1, diag2, false); &#125; &#125;&#125;private boolean available(int x, int y, int n, boolean[] cols, boolean[] diag1, boolean[] diag2) &#123; return !(cols[x] || diag1[x + y] || diag2[x - y + (n - 1)]);&#125;private void modifyState(int x, int y, int n, boolean[] cols, boolean[] diag1, boolean[] diag2, boolean state) &#123; cols[x] = state; diag1[x + y] = state; diag2[x - y + (n - 1)] = state;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"}]},{"title":"[Leetcode单排] Subsets (N78 N90)","slug":"Leetcode单排-Subsets-N78-N90","date":"2019-07-27T15:10:06.000Z","updated":"2019-07-28T14:03:24.713Z","comments":true,"path":"2019/07/27/Leetcode单排-Subsets-N78-N90/","link":"","permalink":"https://weilans.github.io/2019/07/27/Leetcode单排-Subsets-N78-N90/","excerpt":"","text":"78. Subsetshttps://leetcode.com/problems/subsets/ 这两道取子集的题目基本上也没什么好讲的，基本的回溯方法即可，处理方式同排列和组合系列。 123456789101112131415161718public List&lt;List&lt;Integer&gt;&gt; subsets(int[] nums) &#123; if (nums == null || nums.length == 0) &#123; return new ArrayList&lt;&gt;(); &#125; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); handle(nums, 0, new ArrayList&lt;&gt;(), result); return result;&#125;private void handle(int[] nums, int start, List&lt;Integer&gt; cur, List&lt;List&lt;Integer&gt;&gt; result) &#123; result.add(new ArrayList&lt;&gt;(cur)); for (int i = start; i &lt; nums.length; i++) &#123; cur.add(nums[i]); // 注意别写成 start + 1 handle(nums, i + 1, cur, result); cur.remove(cur.size() - 1); &#125;&#125; 90. Subsets IIhttps://leetcode.com/problems/subsets-ii/ 12345678910111213141516171819202122public List&lt;List&lt;Integer&gt;&gt; subsetsWithDup(int[] nums) &#123; if (nums == null || nums.length == 0) &#123; return new ArrayList&lt;&gt;(); &#125; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); Arrays.sort(nums); handle(nums, 0, new ArrayList&lt;&gt;(), result); return result;&#125;private void handle(int[] nums, int start, List&lt;Integer&gt; cur, List&lt;List&lt;Integer&gt;&gt; result) &#123; result.add(new ArrayList&lt;&gt;(cur)); for (int i = start; i &lt; nums.length; i++) &#123; // 与 N40 中 for 循环里的 if 判断如出一辙 if (i &gt; start &amp;&amp; nums[i] == nums[i - 1]) &#123; continue; &#125; cur.add(nums[i]); handle(nums, i + 1, cur, result); cur.remove(cur.size() - 1); &#125;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"}]},{"title":"[Leetcode单排] Letter Combinations of a Phone Number(N17)","slug":"Leetcode单排-Letter-Combinations-of-a-Phone-Number (N17)","date":"2019-07-26T06:59:38.000Z","updated":"2019-07-28T14:04:00.360Z","comments":true,"path":"2019/07/26/Leetcode单排-Letter-Combinations-of-a-Phone-Number (N17)/","link":"","permalink":"https://weilans.github.io/2019/07/26/Leetcode单排-Letter-Combinations-of-a-Phone-Number (N17)/","excerpt":"","text":"17.Letter Combinations of a Phone Numberhttps://leetcode.com/problems/letter-combinations-of-a-phone-number/ 每个号码对应3或4个数字，输入一组号码，打印所有可能出现的排列。这道题很明显有BFS和DFS两类做法。 解法一当处理第n个数字时，实际上就是以n-1次的处理结果加上第n个数字对应的几个字符进行处理。 123456789101112131415161718192021/** * BFS 多层loop */public List&lt;String&gt; letterCombinations(String digits) &#123; if (digits == null || digits.length() == 0) &#123; return new ArrayList&lt;&gt;(); &#125; String digitArr[] = &#123;\"\", \"\", \"abc\", \"def\", \"ghi\", \"jkl\", \"mno\", \"pqrs\", \"tuv\", \"wxyz\"&#125;; List&lt;String&gt; result = new ArrayList&lt;&gt;(); result.add(\"\"); for (int i = 0; i &lt; digits.length(); i++) &#123; List&lt;String&gt; temp = new ArrayList&lt;&gt;(); for (String str : result) &#123; for (char c : digitArr[digits.charAt(i) - '0'].toCharArray()) &#123; temp.add(str + c); &#125; &#125; result = temp; &#125; return result;&#125; 在答案中看到另一种BFS的做法，他是以一个Queue作为载体。这种做法很巧妙，但是在写 while 和 for 中条件时还是比较容易出错的。 123456789101112131415161718/** * BFS 使用queue，易错点在于while条件以及for中数组的获取 */public List&lt;String&gt; letterCombinations2(String digits) &#123; if (digits == null || digits.length() == 0) &#123; return new ArrayList&lt;&gt;(); &#125; String digitArr[] = &#123;\"\", \"\", \"abc\", \"def\", \"ghi\", \"jkl\", \"mno\", \"pqrs\", \"tuv\", \"wxyz\"&#125;; LinkedList&lt;String&gt; result = new LinkedList&lt;&gt;(); result.add(\"\"); while (result.peek().length() != digits.length()) &#123; String peek = result.remove(); for (char c : digitArr[digits.charAt(peek.length()) - '0'].toCharArray()) &#123; result.add(peek + c); &#125; &#125; return result;&#125; 解法二在DFS中，表示当前结果的 String cur，在每次递归中都是一个新的String。一般在DFS的递归之后需要对表示当前结果的值进行回滚，而在这种场景下则不需要。 12345678910111213141516171819202122/** * DFS 递归 */public List&lt;String&gt; letterCombinations3(String digits) &#123; if (digits == null || digits.length() == 0) &#123; return new ArrayList&lt;&gt;(); &#125; String digitArr[] = &#123;\"\", \"\", \"abc\", \"def\", \"ghi\", \"jkl\", \"mno\", \"pqrs\", \"tuv\", \"wxyz\"&#125;; List&lt;String&gt; result = new ArrayList&lt;&gt;(); dfs(digits, digitArr, 0, \"\", result); return result;&#125;private void dfs(String digits, String[] digitArr, int i, String cur, List&lt;String&gt; result) &#123; if (i == digits.length()) &#123; result.add(cur); return; &#125; for (char c : digitArr[digits.charAt(i) - '0'].toCharArray()) &#123; dfs(digits, digitArr, i + 1, cur + c, result); &#125;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"},{"name":"bfs","slug":"bfs","permalink":"https://weilans.github.io/tags/bfs/"}]},{"title":"[Leetcode单排] 组合系列 (N39 N40 N77 N216)","slug":"Leetcode单排- 组合系列 (N39 N40 N77 N216)","date":"2019-07-25T14:18:06.000Z","updated":"2019-07-28T14:02:45.857Z","comments":true,"path":"2019/07/25/Leetcode单排- 组合系列 (N39 N40 N77 N216)/","link":"","permalink":"https://weilans.github.io/2019/07/25/Leetcode单排- 组合系列 (N39 N40 N77 N216)/","excerpt":"","text":"39. Combination Sumhttps://leetcode.com/problems/combination-sum/ 给定一个目标值，以及一个数组，若从数组中取出若干个值能组成目标值的话即满足条件。这个题目有个重要的前提：数组中的值以及目标值都是正数。同时，题目还要求结果集要去重。如果只进行简单回溯，答案是会出现重复的，比如7的组成就有[2,2,3],[2,3,2],[3,2,2]，而答案只需其中之一。 大部分答案的做法是将数组排序后，定一个start值，后续递归只从下标为start的开始。但是实际上，不对数组进行排序答案依然是对的，原因在于，答案中避免重复真正要防止的是情况是：在某一轮递归中放入该值后，想隔一轮后递归轮次中又出现该值。比如这一轮递归中元素选择2，下一轮为3，再下一轮再继续选择2那就会出现重复。相同元素出现的递归轮次必须是靠在一起的。而只要做到这一点，你排序也好，不排也好，实际上对于获取正确答案都没有影响，只要满足数组中元素按一定顺序参与递归即可。 123456789101112131415161718192021222324public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) &#123; if (candidates == null || candidates.length == 0) &#123; return null; &#125; Arrays.sort(candidates); // 排序可有可无? List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); handle(candidates, target, new ArrayList&lt;&gt;(), result, 0); return result;&#125;private void handle(int[] candidates, int curValue, List&lt;Integer&gt; curList, List&lt;List&lt;Integer&gt;&gt; result, int start) &#123; if (curValue == 0) &#123; result.add(new ArrayList&lt;&gt;(curList)); return; &#125; if (curValue &lt; 0) &#123; return; &#125; for (int i = start; i &lt; candidates.length; i++) &#123; curList.add(candidates[i]); handle(candidates, curValue - candidates[i], curList, result, i); curList.remove(curList.size() - 1); &#125;&#125; 那真的不用排序？当把不排序的代码丢进LeetCode判断时，答案虽是正确，但是时间排名较低。实际上，代码中一旦对数组进行排序，真正发挥排序作用是需要在for循环中加入这一段代码：if (candidates[i] &gt; curValue) { return; }，一旦判断当前下标值比目标curValue大，直接结束此轮判断，即进行一次剪枝，这次数据量非常大的时候能起到作用。按这种做法，时间空间排名都是top。 1234567891011121314151617181920212223242526272829public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) &#123; if (candidates == null || candidates.length == 0) &#123; return null; &#125; Arrays.sort(candidates); List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); handle(candidates, target, new ArrayList&lt;&gt;(), result, 0); return result;&#125;private void handle(int[] candidates, int curValue, List&lt;Integer&gt; curList, List&lt;List&lt;Integer&gt;&gt; result, int start) &#123; if (curValue == 0) &#123; result.add(new ArrayList&lt;&gt;(curList)); return; &#125; // for 循环中既有判断，此处可省 //if (curValue &lt; 0) &#123; // return; // &#125; for (int i = start; i &lt; candidates.length; i++) &#123; // 真正发挥排序作用的是这个判断 if (candidates[i] &gt; curValue) &#123; return; // break 或 return &#125; curList.add(candidates[i]); handle(candidates, curValue - candidates[i], curList, result, i); curList.remove(curList.size() - 1); &#125;&#125; 40. Combination Sum IIhttps://leetcode.com/problems/combination-sum-ii/submissions/ 与上题不同的是每个数字在每个组合中只能使用一次。整个流程大致上不变，只是有一些小变动，比如递归中每次下标为 i + 1，非 i。另外还有一个变动是剪枝去重的判断条件，即同一层中如果有相同元素则略过。 这个判断条件第一次写的时候，写成了 i &gt; 0而非 i &gt; s ，这样写会造成示例1的答案中少了[1,1,6]，这是因为 i = 1的时候，下标1和下标0的元素比较了。所以在每一次递归中，i 应该要比起始下标 s 大。 12345678910111213141516171819202122232425262728public List&lt;List&lt;Integer&gt;&gt; combinationSum2(int[] candidates, int target) &#123; if (candidates == null || candidates.length == 0) &#123; return null; &#125; Arrays.sort(candidates); List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); handle(candidates, target, 0, new ArrayList&lt;&gt;(), result); return result;&#125;private void handle(int[] candidates, int target, int s, List&lt;Integer&gt; cur, List&lt;List&lt;Integer&gt;&gt; result) &#123; if (target == 0) &#123; result.add(new ArrayList&lt;&gt;(cur)); return; &#125; for (int i = s; i &lt; candidates.length; i++) &#123; if (candidates[i] &gt; target) &#123; return; &#125; // 同一层中如果有相同元素则略过 if (i &gt; s &amp;&amp; candidates[i] == candidates[i - 1]) &#123; continue; &#125; cur.add(candidates[i]); handle(candidates, target - candidates[i], i + 1, cur, result); cur.remove(cur.size() - 1); &#125;&#125; 77. Combinationhttps://leetcode.com/problems/combinations/ 标准组合，从 n 里面取 k 个元素。要注意数组里没有相同数值，且数组间要避免重复，比如[1,4]和[4,1]就是重复的。所以只需将当前加入到 cur 中的值加1放入到下一层递归即可。 123456789101112131415161718192021public List&lt;List&lt;Integer&gt;&gt; combine(int n, int k) &#123; if (n &lt;= 0 || k &lt;= 0) &#123; return new ArrayList&lt;&gt;(); &#125; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); handle(n, k, 1, new ArrayList&lt;&gt;(), result); return result;&#125;private void handle(int n, int k, int start, List&lt;Integer&gt; cur, List&lt;List&lt;Integer&gt;&gt; result) &#123; if (cur.size() == k) &#123; result.add(new ArrayList&lt;&gt;(cur)); return; &#125; for (int i = start; i &lt;= n; i++) &#123; cur.add(i); // 注意 i + 1 别写成 start + 1 handle(n, k, i + 1, cur, result); cur.remove(cur.size() - 1); &#125;&#125; 216. Combination Sum IIIhttps://leetcode.com/problems/combination-sum-iii/submissions/ 同样没什么可讲的了，只是要注意可以进行适当的优化，比如if (k == curList.size())。 123456789101112131415161718192021222324public List&lt;List&lt;Integer&gt;&gt; combinationSum3(int k, int n) &#123; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); handle(k, n, 1, new ArrayList&lt;&gt;(), result); return result;&#125;private void handle(int k, int curTotal, int start, List&lt;Integer&gt; curList, List&lt;List&lt;Integer&gt;&gt; result) &#123; if (k == curList.size() &amp;&amp; curTotal == 0) &#123; result.add(new ArrayList&lt;&gt;(curList)); return; &#125; // optimize if (k == curList.size()) &#123; return; &#125; for (int i = start; i &lt;= 9; i++) &#123; if (curTotal &lt; i) &#123; return; &#125; curList.add(i); handle(k,curTotal - i, i + 1, curList, result); curList.remove(curList.size() - 1); &#125;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"},{"name":"combination","slug":"combination","permalink":"https://weilans.github.io/tags/combination/"}]},{"title":"[Leetcode单排] 排列系列（N46 N47 N784）","slug":"Leetcode单排- 排列系列 (N46 N47 N784)","date":"2019-07-25T12:28:24.000Z","updated":"2019-07-28T14:04:23.976Z","comments":true,"path":"2019/07/25/Leetcode单排- 排列系列 (N46 N47 N784)/","link":"","permalink":"https://weilans.github.io/2019/07/25/Leetcode单排- 排列系列 (N46 N47 N784)/","excerpt":"","text":"晚上注册了新LeetCode账号，正式开始了LeetCode的从零单排。 其实有这个念头是因为近期工作中感觉没有学到新东西而有一种不安感。而且作为程序员，长期学习回顾算法也本是该有的觉悟。初步预期是每月50题，希望有个好的开始吧。 后续可能不单是LeetCode，比如同事推荐的HackerRank也很棒，支持的语言非常多，恰好最近在学Clojure，感觉里面的题稍偏难一些。 LeetCode刷题顺序初步先按照花花酱的题目分类来，现在还不习惯直接在网页上写，暂时先用IDE。万事开头难，先把第一个50题做完吧。 46. Permutationshttps://leetcode.com/problems/permutations/ 全排列算是比较基础的题了，想到的第一个词就是回溯。可以选择对数组中的元素进行重排序，也可以选择从数组中每次取一个值放到自己的临时List中，这也就是下面这两种方法。回溯需要注意的是如果操作的对象是可变的，在递归后需要把它变回来。当然如果在递归中传递的是新对象，则没这个必要了。 解法一123456789101112131415161718192021222324252627282930313233/** * 解法一：以数组中元素排序为准 */public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) &#123; if (nums == null || nums.length == 0) &#123; return new ArrayList&lt;&gt;(); &#125; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); permute(nums, 0, result); return result;&#125;private void permute(int[] nums, int i, List&lt;List&lt;Integer&gt;&gt; result) &#123; if (nums.length == i) &#123; List&lt;Integer&gt; cur = new ArrayList&lt;&gt;(); for (Integer integer : nums) &#123; cur.add(integer); &#125; result.add(cur); return; &#125; for (int j = i; j &lt; nums.length; j++) &#123; swap(nums, i, j); permute(nums, i + 1, result); swap(nums, i, j); &#125;&#125;private void swap(int[] nums, int m, int n) &#123; int temp = nums[m]; nums[m] = nums[n]; nums[n] = temp;&#125; 解法二12345678910111213141516171819202122232425262728293031/** * 解法二：以自定义List存放当前变量 */public List&lt;List&lt;Integer&gt;&gt; permute2(int[] nums) &#123; if (nums == null || nums.length == 0) &#123; return new ArrayList&lt;&gt;(); &#125; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); permute2(nums, new ArrayList&lt;&gt;(), result); return result;&#125;/** * 查看是否包含某元素，除了直接使用contains判断外，很多人使用了boolean[] visited， * 递归前visited[i] = true，递归后还需visited[i] = false; * https://leetcode-cn.com/problems/permutations/solution/hui-su-suan-fa-python-dai-ma-java-dai-ma-by-liweiw/ */private void permute2(int[] nums, List&lt;Integer&gt; cur, List&lt;List&lt;Integer&gt;&gt; result) &#123; if (nums.length == cur.size()) &#123; result.add(new ArrayList&lt;&gt;(cur)); return; &#125; for (int i : nums) &#123; if (cur.contains(i)) &#123; continue; &#125; cur.add(i); permute2(nums, cur, result); cur.remove(cur.size() - 1); &#125;&#125; 47. Permutations IIhttps://leetcode.com/problems/permutations-ii/ 若数组中有重复元素，在全排列基础上要去除重复的结果。这个题目的解法不容易立即想到的，需要在全排列的树上完成剪枝的操作，而难点就在于判断树的哪颗节点该剪。 首先需要对整个数组进行排列，这是判断剪枝的前提。如果数组下标为i的元素的值与i-1元素的值相同，并且i-1元素并没有被访问过，那么下标为i的元素才可以被剪枝。其实难点在于理解前一个元素并没有被访问过，可以通过画图进行理解。 12345678910111213141516171819202122232425262728293031public List&lt;List&lt;Integer&gt;&gt; permuteUnique(int[] nums) &#123; if (nums == null || nums.length == 0) &#123; return new ArrayList&lt;&gt;(); &#125; // 排序 Arrays.sort(nums); List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); permute(nums, new ArrayList&lt;&gt;(), new boolean[nums.length], result); return result;&#125;/**注意剪枝规则*/private void permute(int[] nums, List&lt;Integer&gt; cur, boolean[] visit, List&lt;List&lt;Integer&gt;&gt; result) &#123; if (cur.size() == nums.length) &#123; result.add(new ArrayList&lt;&gt;(cur)); return; &#125; for (int i = 0; i &lt; nums.length; i++) &#123; if (visit[i]) &#123; continue; &#125; if (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; !visit[i - 1]) &#123; continue; &#125; visit[i] = true; cur.add(nums[i]); permute(nums, cur, visit, result); cur.remove(cur.size() - 1); visit[i] = false; &#125;&#125; 784. Letter Case Permutationhttps://leetcode.com/problems/letter-case-permutation/ 即输入一个String，里面的字符可以是数字、小写字母、大写字母。小写和大写可以相互转变，需要给出所有的 String 结果。答案也不难想，使用递归来做。 123456789101112131415161718192021222324public List&lt;String&gt; letterCasePermutation(String S) &#123; if (S == null || S.length() == 0) &#123; return null; &#125; List&lt;String&gt; result = new ArrayList&lt;&gt;(); handle(S.toCharArray(), 0, result); return result;&#125;private void handle(char[] chars, int i, List&lt;String&gt; result) &#123; if (i == chars.length) &#123; result.add(new String(chars)); return; &#125; if (Character.isDigit(chars[i])) &#123; handle(chars, i + 1, result); &#125; else &#123; chars[i] = Character.toLowerCase(chars[i]); handle(chars, i + 1, result); chars[i] = Character.toUpperCase(chars[i]); handle(chars, i + 1, result); &#125;&#125; 实际上第一遍做的时候，我是使用了一个 String 变量保存了当前结果，结果是对的，只是内存耗的稍多一点。当然这个变量是可以省的，只是需要更改字符数组。 1234567891011121314151617private void handle(char[] chars, int i, String cur, List&lt;String&gt; result) &#123; if (i == chars.length) &#123; result.add(cur); return; &#125; if (Character.isDigit(chars[i])) &#123; handle(chars, i + 1, cur + chars[i], result); &#125; if (Character.isLowerCase(chars[i])) &#123; handle(chars, i + 1, cur + chars[i], result); handle(chars, i + 1, cur + Character.toUpperCase(chars[i]), result); &#125; if (Character.isUpperCase(chars[i])) &#123; handle(chars, i + 1, cur + chars[i], result); handle(chars, i + 1, cur + Character.toLowerCase(chars[i]), result); &#125;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"permutations","slug":"permutations","permalink":"https://weilans.github.io/tags/permutations/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"}]},{"title":"Clojure in Action: 概述、数据结构","slug":"Clojure-in-Action-概述、数据结构","date":"2019-07-25T11:30:34.000Z","updated":"2019-08-01T09:43:36.826Z","comments":true,"path":"2019/07/25/Clojure-in-Action-概述、数据结构/","link":"","permalink":"https://weilans.github.io/2019/07/25/Clojure-in-Action-概述、数据结构/","excerpt":"","text":"Clojure 概述 关键词：JVM、Lisp、动态类型、函数式语言、不可变数据结构、Code as data 1. Clojure 是 Lisp 的一个变种Clojure 对所有函数甚至类似运算符的一切都使用前缀表示法。 2. Clojure 以JVM为宿主Clojure 代码直接编译为字节码供JVM运行； Clojure 默认加载 java.lang包下的所有类； Clojure 直接使用 Java 类型和标准程序库，如 Clojure 的集合实现接口与 Java 集合接口相同，重用 Java 类型和接口可以使 Java 代码无缝使用 Clojure 类型； 使用点运算符作为与Java 互操作的基础：(. Math abs -3)、(. &quot;foo&quot; toUpperCase)，静态成员可以重写为(Math/abs -3)，实例方法调用也可以使用(.toUpperCase &quot;foo&quot;)，创建类的实例可以使用(new Integer &quot;42&quot;)或(Integer. &quot;42&quot;)； Clojure 的不可变数据结构使共享可变状态的问题变得毫无意义。即使需要变更状态，Clojure 也提供了var（变量）、atom（原子）、ref（引用）、agent（代理）的并发数据结构。 3. Clojure 是一种函数式编程语言函数是第一等公民，函数可以作为参数传递给其他参数，也可以作为输出值返回。FP设计的函数式纯粹的，具备引用透明性，只要函数输入相同就始终返回相同输出； FP一般默认不可变数据结构，将不可变结构作为语言的默认状态保证了函数不会修改传递给他们的参数。Clojure的不可变数据结构避免了高代价复制。当对一个不可变数据结构进行更改，结果则为一个全新的结构。Clojrue隐式使用结构化共享和其他技术，确保执行复制的次数最少、不可变数据结构的操作便捷且节约内存。比如在一颗树上添加新值，会在通往根节点的路径上创建一组新的节点和引用； Clojure鼓励使用纯函数式编程：不可变数据结构、高阶函数和代替强制循环的递归，甚至可以选择集合的惰性求值和及早求值。当然，为了适应不同场景，Clojure也提供了对共享状态变更的方法。 Clojure 基础前期准备1. Clojure REPL（读取 - 求值 - 打印循环）1234567891011(+ 1 2) ;=&gt; 3(def my-addition (fn [operand1 operand2] (+ operand1 operand2)));=&gt; #'user/my-addition(my-addition 1 2);=&gt; 3(my-addition 100 30);=&gt; 130(+ 1 2) \"Two forms on one line!\";=&gt; 3;=&gt; \"Two forms on one line!\" 第二个表达式定义了一个命名空间限定的全局符号user/my-addition 。前缀#&#39;表明这是一个 Clojure 变量，变量是一个可变容器，其中包含唯一值，本例中为加法函数。 函数中没有显示的 return 语句。从函数中返回的值总是函数中最后一个求值的表达式。 最后三行是按照形式运行，Clojure 持续读取，直到发现一个完整的形式，然后求值并打印，此后如果缓冲区里仍有字符，它读取另一个形式、求值并打印。 2. 特殊 REPL 变量变量*1，*2，*3，*e保存最后一个、倒数第二个、倒数第三个成功读取的形式和最后一个错误。每当新形式求值成功，该值会保存在*1，旧*1被移动到*2，旧*2被移动到*3。 3. 文档查找 doc：返回具体的函数描述，该 宏需要你了解具体的实体名称。 find-doc：接受一个字符串（可以是正则），模糊查询复合条件的函数或宏文档。该函数在不确定名称时很实用。 apropos：工作方式与find-doc类似，只打印匹配搜索模式的函数名称。 4. 其他细节 前缀表示法。没有任何运算符，数学运算符就是 Clojure 函数。 空格。Clojure 不需要逗号来区分列表元素，当实用逗号时，Clojure 会把它们当成逗号忽略。当然，特定场景如哈希映射，使用逗号有助于程序员理解。 注释。单行注释使用分号表示。多行注释可以使用comment宏，该宏会忽略传入的形式，返回 nil。此外，宏#_会告诉reader忽略下一个Clojure形式。 12[1 2 3 #_ 4 5];=&gt; [1 2 3 5] Clojure 大小写敏感。 Clojure 数据结构1. nil / 真值 / 价值Clojure 的 nil等价于 Java 的 null ，在 nil 上调用一个函数可能报空指针异常。 除了 false 和 nil 之外，其他值都被视为真值。 2. 字符 / 字符串Clojure 字符是 Java 字符， 使用反斜杠宏表示字符: 12(type \\a);=&gt; java.lang.Character Clojure 字符串是 Java 字符串，使用双引号表示。（单引号则是另一个读取器宏，来表示 Symbol） 12(type \"hello\");=&gt; java.lang.String Java String API 在 Clojure 中依然很有用。 3. 数值Clojure 使用的整数是64位整数（Long），浮点数是64位浮点数（Double）。当需要更大的范围时，可以使用BigInteger,BigDecimal。此外，还有一个不常见的数值类型：比例（ratio），比例在两个整数相除时创建。 123456789101112(type 2);=&gt; java.lang.Long(type 3.14);=&gt; java.lang.Double(type 1/3);=&gt; clojure.lang.Ratio(type true);=&gt; java.lang.Boolean(type 123N);=&gt; clojure.lang.BigInt(type 0.5M);=&gt; java.math.BigDecimal 当不同数值类型在同一个算术运算中混合使用时，具有高传染性的数值类型将其类型传染给结果(long &lt; bigint &lt; ratio &lt; bigdec &lt; double) 12345678(+ 1 1N);=&gt; 2N(+ 1 1N 1/2);=&gt; 5/2(+ 1 1N 1/2 0.5M);=&gt; 3.0M(+ 1 1N 1/2 0.5M 0.5);=&gt; 3.5 溢出（overflow）：在 Clojure 中可能产生溢出的算术运算只有整数加法、减法和乘法（整数相除时，如果超过范围则生成一个比例）。 溢出发生时 Clojure 会抛出 ArtithmeticException异常。如果希望结果提升为大整数，则应该使用：+&#39;，-&#39;，*&#39;，inc&#39;，dec&#39;。 1234(inc 9223372036854775807);ArithmeticException integer overflow clojure.lang.Numbers.throwIntOverflow (Numbers.java:1424)(inc' 9223372036854775807);=&gt; 9223372036854775808N 4. 符号 / 关键字符号是 Clojure 中的标识符，代表值的名称。符号本身只包含可选命名空间的名称，但当一个表达式求值时，它们被所代表的值取代。 在一个程序中，符号通常被解析为不是符号的其他内容，但是可以通过一个前导的单引号引用符号，将其当成一个值而非标识符。 当为一个符号加上引号，就将这个引号当成数据而不是代码来处理，在实践中一般不会这么做，因为有另一种特殊类型：关键词，关键词从不引用其他值，求值的结果总是他们本身。关键词的典型用法是作为哈希映射中的键和枚举值。 5. 列表 主要函数：list，list?，conj，peek，pop，count Clojure 列表是单链表。只能从列表前端添加或删除元素，这意味着多个不同列表可以共享相同尾部，使列表成为最简单的不可变数据结构。 1234567891011121314151617181920212223242526(list 1 2 3 4 5);=&gt; (1 2 3 4 5)(list? *1);=&gt; true(conj (list 1 2 3 4 5) 6);=&gt; (6 1 2 3 4 5)(conj (list 1 2 3) 4 5 6);=&gt; (6 5 4 1 2 3)(conj (conj (conj (list 1 2 3) 4) 5) 6) ;=&gt; (6 5 4 1 2 3); 可以将列表当成一个栈来对待(peek (list 1 2 3));=&gt; 1(pop (list 1 2 3));=&gt; (2 3)(peek (list)) ;=&gt; nil(pop (list)) ;IllegalStateException Can't pop empty list clojure.lang.PersistentList$EmptyList.pop (PersistentList.java:183)(count (list));=&gt; 0(count (list 1 2 3 4));=&gt; 4 列表的特殊性：Clojure 会假定列表中出现的第一个符号表示函数（或者宏）名称。Clojure 视图以处理所有列表的相同方式来处理表(1,2,3) ，第一个元素被视为函数，而这里的整数 1 并不是函数。若希望将其作为数据而非代码，解决方式就是加上引号：&#39;(1,2,3)。 实践中一般不会在 Clojure 代码中使用列表作为数据，而是使用向量类型。 6. 向量 主要函数：vector，get，nth，assoc, conj,peek，pop，count，subvec，函数本身 向量可以使用vector函数创建，也可以使用方括号表示法创建，可以快速随机访问向量中的元素。获取其中元素中的方法有get和nth，差别在于没有找到相应值时，nth 会报出错误，get 返回 nil。 12345678910111213(vector 10 20 30 40 50);=&gt; [10 20 30 40 50](def the-vector [10 20 30 40 50]);=&gt; #'user/the-vector(get the-vector 2);=&gt; 30(nth the-vector 2);=&gt; 30(get the-vector 10);=&gt; nil(nth the-vector 10);IndexOutOfBoundsException clojure.lang.PersistentVector.arrayFor (PersistentVector.java:107) nth Get Vector as fn Vector is nil nil nil Throw exception Index out of range Throw exception Nil Throw exception Support ‘not found’ param yes Yes no 修改向量的方法中最常见的是 assoc。 1234567(assoc the-vector 2 25) ; 可以变更现有索引 ;=&gt; [10 20 25 40 50](assoc the-vector 5 60) ; 可以添加到尾部 ;=&gt; [10 20 30 40 50 60](assoc the-vector 6 70) ; 但是不能超过尾部 ;IndexOutOfBoundsException clojure.lang.PersistentVector.assocN (PersistentVector.java:137) conj函数同样适用于向量，但在向量中新元素将会被添加到最后，因为那是向量中最快速的插入位置。 12(conj [1 2 3 4 5] 6);=&gt; [1 2 3 4 5 6] peek和pop也适用于向量，方法会查看向量的尾部，而不是列表的表头。 12345678(peek [1 2]);=&gt; 2(pop [1 2]);=&gt; [1](peek []) ;=&gt; nil(pop []) ;IllegalStateException Can't pop empty vector clojure.lang.PersistentVector.pop (PersistentVector.java:381) 向量本身也是取单一参数的函数。(但向量函数不接受第二个参数) 12(the-vector 3);=&gt; 40 subvec会返回向量的一个子向量 (subvec avec start end?)。若未指定end，则默认为向量的末尾。 1234(subvec [1 2 3 4 5] 3);-&gt; [4 5](subvec [1 2 3 4 5] 1 3);-&gt; [2 3] 7. 映射 主要函数：hash-map，sorted-map，assoc，dissoc，select-keys，merge， merge-with，assoc-in，get-in，update-in，keys，vals，contains?，get，函数本身 一个映射就是一个键值对序列。映射可以使用hash-map函数构建。依据键获取对应的值时除了使用get函数外，映射本身也是一个函数。 123456789101112131415161718(def the-map &#123;:a 1 :b 2 :c 3&#125;);=&gt; #'user/the-map(hash-map :a 1 :b 2 :c 3);=&gt; &#123;:a 1, :c 3, :b 2&#125;(the-map :b);=&gt; 2(:b the-map);=&gt; 2(:z the-map 26) ; 若未找到关键字则返回一个默认值;=&gt; 26(get the-map :z 26) ;=&gt; 26(the-map :z 26) ;=&gt; 26(sorted-map :c 3 :b 2 :a 1);=&gt; &#123;:a 1, :b 2, :c 3&#125; 映射字面量和 hash-map 函数不完全等价，Clojure 实际上有哈希映射(hash-map)以及数组映射(array-map)。数组映射以有序方式保存键和值，以扫描的方式进行查找。如果使用 assoc 函数将太多键关联到一个数组映射，那将会得到一个哈希映射（而哈希映射变得太小不会反悔一个数组映射）。透明地替换数据结构的实现是 Clojure 提高性能的常用技巧。 此外，sorted-map不会按照存放的顺序返回，它会根据键来进行排序。 映射的修改方法有assoc和dissoc等。assoc 返回新增了一个键值对的映射表， dissoc 返回移除了某些键的映射表。 select-keys返回一个映射表，仅保留了参数传入的那些键。merge可以合并映射表。如果多个映射表包含了同一个键，那么最右边的获胜。merge-with与 merge 很类似，除了当两个或以上的映射表中有相同的键时，你能指定一个你自己的函数，来决定如何合并这个键对应的值。 1234567891011121314(def updated-map (assoc the-map :d 4));=&gt; #'user/updated-mapupdated-map;=&gt; &#123;:d 4, :a 1, :b 2, :c 3&#125;(dissoc updated-map :a);=&gt; &#123;:b 2, :c 3, :d 4&#125;(select-keys updated-map [:a :b]);=&gt; &#123;:a 1, :b 2&#125;(merge updated-map &#123;:m 666, :n 777&#125;);=&gt; &#123;:a 1, :b 2, :c 3, :d 4, :m 666, :n 777&#125;(merge &#123;:a 1 :b 2&#125; &#123;:a 3 :c 4&#125;);=&gt; &#123;:a 3, :b 2, :c 4&#125;(merge-with + &#123;:a 1 :b 2&#125; &#123;:a 3 :c 4&#125;);=&gt; &#123;:a 4, :b 2, :c 4&#125; 关于嵌套映射的使用。想要更改嵌套映射中的值需要先进入想要的位置，创建一个更改后的映射，并用 assoc 将更改的信息关联到这个中间映射，并一路返回到根。Clojure提供三个简化嵌套更新的函数。 1234567891011121314151617(def users &#123;:kyle &#123;:date-joined \"2009-01-01\" :summary &#123;:average &#123;:monthly 1000 :yearly 12000&#125;&#125;&#125;&#125;); assoc-in 可以设置新值，若不存在任何嵌套映射，在创建并正确关联。(assoc-in users [:kyle :summary :average :monthly] 3000);=&gt; &#123;:kyle &#123;:date-joined \"2009-01-01\", :summary &#123;:average &#123;:monthly 3000,; :yearly 12000&#125;&#125;&#125;&#125;; get-in 可以嵌套读取值(get-in users [:kyle :summary :average :monthly]);=&gt; 1000; update-in 可以更新嵌套映射中的值，其不提供新值，而是提供一个函数(update-in users [:kyle :summary :average :monthly] + 500);=&gt; &#123;:kyle &#123;:date-joined \"2009-01-01\", :summary &#123;:average &#123;:monthly 1500,; :yearly 12000&#125;&#125;&#125;&#125; keys将所有的键作为序列返回，vals则将所有的值作为序列返回。 1234(keys &#123;:sundance \"spaniel\", :darwin \"beagle\"&#125;);-&gt; (:sundance :darwin)(vals &#123;:sundance \"spaniel\", :darwin \"beagle\"&#125;);-&gt; (\"spaniel\" \"beagle\") 无法确认究竟是键对应的值为 nil，还是这个键在映射表中根本就不存在。contains?函数就可以解决这个问题。（(:z the-map 26) 这种形式也可以做到。） 123(def score &#123;:stu nil :joey 100&#125;)(contains? score :stu);-&gt; true 8. Set 主要函数：conj，disj，contains?，set， hash-set，sorted-set，union，intersection，difference，select Clojure set 工作方式和数学中的 set 是一样的，是一种集合，其中的元素无序且唯一。Clojure 支持两种不同的 set：排序的(sorted-set)和不排序的(hash-set)。sorted-set 会依据自然顺序对值进行排序。 123456789101112131415161718#&#123;:a :b :c&#125;;=&gt; #&#123;:c :b :a&#125;(conj #&#123;:a :b :c&#125; :d);=&gt; #&#123;:c :b :d :a&#125;(conj #&#123;:a :b :c&#125; :a);=&gt; #&#123;:c :b :a&#125;(disj #&#123;:a :b :c&#125; :a);=&gt; #&#123;:c :b&#125;(contains? #&#123;1 2 3&#125; 3);=&gt; true; set函数期望其第一个参数是个容器。而hash-set则接受可变的参数列表。(set [:a :b :c]);=&gt; #&#123;:c :b :a&#125;(hash-set 1 2 3);=&gt; #&#123;1 3 2&#125;(sorted-set 2 3 1);=&gt; #&#123;1 2 3&#125; clojure.set 集合函数需先调用(use &#39;clojure.set)。 union返回的集合，包含了所有输入集合中的元素。intersection返回的集合，其所有元素都曾同时出现于多个输入集合中。difference 返回的集合，其所有元素都出现于第一个输入集合，但却未出现于第二个中。select返回所有元素都能与给定谓词相匹配的一个集合。 123456789101112(def languages #&#123;\"java\" \"c\" \"d\" \"clojure\"&#125;)(def beverages #&#123;\"java\" \"chai\" \"pop\"&#125;)(use 'clojure.set)(union languages beverages);=&gt; #&#123;\"java\" \"c\" \"d\" \"clojure\" \"chai\" \"pop\"&#125;(difference languages beverages);=&gt; #&#123;\"c\" \"d\" \"clojure\"&#125;(intersection languages beverages);=&gt; #&#123;\"java\"&#125;(select #(= 1 (.length %)) languages);=&gt; #&#123;\"c\" \"d\"&#125; 差集和并集除了是集合论的一部分，也是关系代数的一部分，下面介绍了投影、笛卡尔积、连接、重命名等方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657; 音乐作品集内存数据库示例(def compositions #&#123;&#123;:name \"The Art of the Fugue\" :composer \"J. S. Bach\"&#125; &#123;:name \"Musical Offering\" :composer \"J. S. Bach\"&#125; &#123;:name \"Requiem\" :composer \"Giuseppe Verdi\"&#125; &#123;:name \"Requiem\" :composer \"W. A. Mozart\"&#125;&#125;)(def composers #&#123;&#123;:composer \"J. S. Bach\" :country \"Germany\"&#125; &#123;:composer \"W. A. Mozart\" :country \"Austria\"&#125; &#123;:composer \"Giuseppe Verdi\" :country \"Italy\"&#125;&#125;)(def nations #&#123;&#123;:nation \"Germany\" :language \"German\"&#125; &#123;:nation \"Austria\" :language \"German\"&#125; &#123;:nation \"Italy\" :language \"Italian\"&#125;&#125;)(select #(= (:name %) \"Requiem\") compositions);=&gt; #&#123;&#123;:name \"Requiem\", :composer \"W. A. Mozart\"&#125;; &#123;:name \"Requiem\", :composer \"Giuseppe Verdi\"&#125;&#125;; project函数返回的那些映射表中，仅包含与参数匹配的键。 (project relation keys)(project compositions [:name]);=&gt; #&#123;&#123;:name \"Musical Offering\"&#125;; &#123;:name \"Requiem\"&#125;; &#123;:name \"The Art of the Fugue\"&#125;&#125;; 笛卡尔积(for [m compositions c composers] (concat m c)); join 集合连接(join compositions composers);=&gt; #&#123;&#123;:composer \"W. A. Mozart\", :country \"Austria\", :name \"Requiem\"&#125;; &#123;:composer \"J. S. Bach\", :country \"Germany\", :name \"Musical Offering\"&#125;; &#123;:composer \"Giuseppe Verdi\", :country \"Italy\", :name \"Requiem\"&#125;; &#123;:composer \"J. S. Bach\", :country \"Germany\", :name \"The Art of the Fugue\"&#125;&#125;;如果两个关系中的键名不匹配，你可以传入一个keymap，将relation-1中的键名映射到relation-2中对应的键。;例如，你可以将使用:country的composers，与使用:nation的nations相连接。(join composers nations &#123;:country :nation&#125;);=&gt; #&#123;&#123;:composer \"W. A. Mozart\", :country \"Austria\", :nation \"Austria\", :language \"German\"&#125;; &#123;:composer \"J. S. Bach\", :country \"Germany\", :nation \"Germany\", :language \"German\"&#125;; &#123;:composer \"Giuseppe Verdi\", :country \"Italy\", :nation \"Italy\", :language \"Italian\"&#125;&#125;; 示例: 所有创作了安魂曲的作曲家们，家乡都在哪些国家(project (join (select #(= (:name %) \"Requiem\") compositions) composers) [:country]);=&gt; #&#123;&#123;:country \"Italy\"&#125; &#123;:country \"Austria\"&#125;&#125;; rename 可以给键(数据库的列)重命名(rename compositions &#123;:name :title&#125;);=&gt;#&#123;&#123;:composer \"Giuseppe Verdi\", :title \"Requiem\"&#125;; &#123;:composer \"W. A. Mozart\", :title \"Requiem\"&#125;; &#123;:composer \"J. S. Bach\", :title \"The Art of the Fugue\"&#125;; &#123;:composer \"J. S. Bach\", :title \"Musical Offering\"&#125;&#125; 9. 序列序列是一个接口(ISeq)，Clojure 数据结构、函数和宏都普遍实现这个接口，序列抽象使所有数据结构的外表和行为像列表一样。 first返回序列的第一个元素，rest返回排除第一个元素的序列，但是对所有集合类型采取相同的方式。 cons会在序列的开始位置(即使是向量也一样)添加一个元素。 序列抽象通常是惰性的，尽管 first、rest、cons的结果打印出来像一个列表，但它们并没有进行创建列表的额外工作。序列抽象使一切都像操纵真正的列表一样，但是避免真正地创建任何新数据结构或者进行任何不必要的工作。 12345678910111213141516171819202122(first (list 1 2 3));=&gt; 1(rest (list 1 2 3));=&gt; (2 3)(first [1 2 3]);=&gt; 1(rest [1 2 3]);=&gt; (2 3)(first &#123;:a 1 :b 2&#125;) ; 不保证项的顺序;=&gt; [:b 2](rest &#123;:a 1 :b 2&#125;);=&gt; ([:a 1])(first []) ; 空集合调用first返回nil;=&gt; nil(rest []) ; 空集合调用 rest 返回空序列;=&gt; ()(cons 1 [2 3 4 5]);=&gt; (1 2 3 4 5)(list? (cons 1 (list 2 3)));=&gt; false 一切皆序列 主要函数：first，rest，cons，seq， next 可被视为序列的容器，被称为可序化的，可序化的容器包括：所有的Clojure容器、所有的Java容器、Java数组和字符串、正则表达式的匹配结果、目录结构、输入/输出流、XML树。 除了序列三大核心first、rest、cons，还有seq，seq 函数会返回一个序列，该序列源自任何一个可序化的其他容器。next 函数也会返回一个序列，该序列由除第一个元素以外的其他所有元素组成。(next aseq)等价于 (seq (rest aseq))。 12345678910(seq nil);=&gt; nil(seq ());=&gt; nil(rest ());=&gt; ()(next ());=&gt; nil(seq (rest ()));=&gt; nil conj &amp; intoconj 会向容器添加一个或是多个元素，into 则会把容器中的所有元素添加至另一个容器。这两个方法的返回值类型不是序列，而是容器类型。添加数据时，conj和into都会根据底层数据结构的特点选取最高效的插入点。 1234567891011;对于列表而言，conj和into会在其前端进行添加。(conj '(1 2 3) :a);=&gt; (:a 1 2 3)(into '(1 2 3) '(:a :b :c));=&gt; (:c :b :a 1 2 3);而对于向量，conj和into则会把元素添加至末尾。(conj [1 2 3] :a);=&gt; [1 2 3 :a](into [1 2 3] [:a :b :c]);=&gt; [1 2 3 :a :b :c] 创建序列 主要函数：range，repeat，take，iterate， cycle，interleave，interpose 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950;ranage会生成一个从start开始到end结束的序列，每次的增量为step。 (range start? end step?)(range 10);=&gt; (0 1 2 3 4 5 6 7 8 9)(range 10 20);=&gt; (10 11 12 13 14 15 16 17 18 19)(range 1 25 2);=&gt; (1 3 5 7 9 11 13 15 17 19 21 23);repeat函数会重复n次元素x。 (repeat n x)(repeat 5 1);=&gt; (1 1 1 1 1)(repeat 10 \"x\");=&gt; (\"x\" \"x\" \"x\" \"x\" \"x\" \"x\" \"x\" \"x\" \"x\" \"x\");(iterate f x) iterate起始于值x，并持续地对每个值应用函数f，以计算下一个值，直至永远。;由于这是个无限序列，你需要另一个新函数 (take n sequence)。take会返回一个包含了容器中前n项元素的惰性序列。(take 10 (iterate inc 1));=&gt; (1 2 3 4 5 6 7 8 9 10);cycle函数接受一个容器，并无限的对其进行循环。 (cycle coll)(take 10 (cycle (range 3)));=&gt; (0 1 2 0 1 2 0 1 2 0);interleave函数接受多个容器作为参数，并产生一个新的容器，这个新容器会从每个参数容器中交错地提取元素，直至其中某个容器元素被耗尽。(defn whole-numbers [] (iterate inc 1))(interleave (whole-numbers) [\"A\" \"B\" \"C\" \"D\" \"E\"]);interpose函数，把输入序列中的每个元素用分隔符隔开，并作为新的序列返回。(interpose separator coll)(interpose \",\" [\"apples\" \"bananas\" \"grapes\"]);=&gt; (\"apples\" \",\" \"bananas\" \",\" \"grapes\");(apply f args* argseq)apply函数接受一个函数f、一些可选的args和一个序列argseq作为参数。之后会调用 f，并将args和argseq解开为一个参数列表传给f。(apply str (interpose \\, [\"apples\" \"bananas\" \"grapes\"]));=&gt; \"apples,bananas,grapes\";(join separator sequence)(use '[clojure.string :only (join)])(join \\, [\"apples\" \"bananas\" \"grapes\"]);=&gt; \"apples,bananas,grapes\";对应每种Clojure中的容器类型，都有一个可以接受任意数量参数的函数，用来创建该类型的容器。;hash-set与set与其工作方式稍有不同：set函数期望其第一个参数是个容器。而hash-set则接受可变的参数列表。(set [1 2 3]);=&gt; #&#123;1 3 2&#125;(hash-set 1 2 3);=&gt; #&#123;1 3 2&#125;;vector也有一个近亲vec，vec接受容器作为参数，而非可变的参数列表。(vec (range 3));=&gt; [0 1 2](vector 0 1 2);=&gt; [0 1 2] 过滤序列 主要函数：filter，take-while，drop-while，split-at， split-with 12345678910111213141516171819202122(defn whole-numbers [] (iterate inc 1));(filter pred coll) filter接受一个谓词和一个容器作为参数，并返回一个序列，这个序列的所有元素都经谓词判定为真。(take 10 (filter even? (whole-numbers)));=&gt; (2 4 6 8 10 12 14 16 18 20);使用take-while从序列中截取开头的一段，其每个元素都被谓词判定为真。 (take-while pred coll);字符串中逐个获取第一个元音字符之前的所有非元音字符(take-while (complement #&#123;\\a\\e\\i\\o\\u&#125;) \"the-quick-brown-fox\");=&gt; (\\t \\h);1、集合同时也可作为函数。所以你可以把#&#123;\\a\\e\\i\\o\\u&#125;读作“元音集”，或是“用于检测参数是否为元音的函数。”;2、complement 会反转另一个函数的行为。前例的那个反转函数用于检测参数是不是一个元音。;与take-while相对的是drop-while函数。drop-while 从序列的起始位置开始，逐个丢弃元素，直至谓词判定为真，然后返回序列剩余的部分。(drop-while (complement #&#123;\\a\\e\\i\\o\\u&#125;) \"the-quick-brown-fox\");=&gt; (\\e \\- \\q \\u \\i \\c \\k \\- \\b \\r \\o \\w \\n \\- \\f \\o \\x);split-at和split-with能把一个容器一分为二。(split-at index coll) (split-with pred coll);split-at接受一个索引作为参数，而split-with则接受一个谓词。(split-at 5 (range 10));=&gt;[(0 1 2 3 4) (5 6 7 8 9)](split-with #(&lt;= % 10) (range 0 20 2));=&gt;[(0 2 4 6 8 10) (12 14 16 18)] 序列谓词 主要函数：every?，some，not-every?，not-any? 1234567891011121314151617;every？要求其他谓词对序列中的每个元素都必须判定为真。(every? odd? [1 3 5]);=&gt; true(every? odd? [1 3 5 8]);=&gt; false;(some pred coll) 只要有一个元素被谓词判定为非假，some就会返回这个值，如果没有任何元素符合，则some返回nil。(some even? [1 2 3])-&gt; true(some even? [1 3 5])-&gt; nil;some 返回的是第一个符合项的值，而非 true。(some identity [nil false 1 nil 2]);=&gt; 1(not-every? even? (whole-numbers));=&gt; true(not-any? even? (whole-numbers));=&gt; false 序列转换 主要函数：map，reduce，sort，sort-by，for 123456789101112131415161718192021222324;映射函数map (map f coll) map接受一个源容器coll和一个函数f作为参数，并返回一个新的序列。(map #(format \"&lt;p&gt;%s&lt;/p&gt;\" %) [\"the\" \"quick\" \"brown\" \"fox\"]);=&gt; (\"&lt;p&gt;the&lt;/p&gt;\" \"&lt;p&gt;quick&lt;/p&gt;\" \"&lt;p&gt;brown&lt;/p&gt;\" \"&lt;p&gt;fox&lt;/p&gt;\");还可以传入多个容器给map。在这种情况下，f必须是一个多参函数。map会从每个容器分别取出一个值，作为参数来调用f，直到数量最少的那个容器被耗尽为止。(map #(format \"&lt;%s&gt;%s&lt;/%s&gt;\" %1 %2 %1) [\"h1\" \"h2\" \"h3\" \"h1\"] [\"the\" \"quick\" \"brown\" \"fox\"]);=&gt; (\"&lt;h1&gt;the&lt;/h1&gt;\" \"&lt;h2&gt;quick&lt;/h2&gt;\" \"&lt;h3&gt;brown&lt;/h3&gt;\" \"&lt;h1&gt;fox&lt;/h1&gt;\");归纳函数reduce (reduce f coll) reduce首先用coll的前两个元素作为参数来调用f，然后用得到的结果和第三个元素作为参数，继续调用f。(reduce + (range 1 11));=&gt; 55(reduce * (range 1 11));=&gt; 3628800;(sort comp? coll) (sort-by a-fn comp? coll) sort 会依据元素的自然顺序对容器进行排序，sort-by 则会对每个元素调用 a-fn，再依据得到的结果序列来进行排序。(sort [42 1 7 11]);=&gt; (1 7 11 42)(sort-by #(.toString %) [42 1 7 11]);=&gt;` (1 11 42 7);可以为sort或sort-by指定一个可选的比较函数comp。(sort &gt; [42 1 7 11]);=&gt; (42 11 7 1)(sort-by :grade &gt; [&#123;:grade 83&#125; &#123;:grade 90&#125; &#123;:grade 77&#125;]);=&gt; (&#123;:grade 90&#125; &#123;:grade 83&#125; &#123;:grade 77&#125;) Clojure把列表解析的概念泛化为了序列解析（sequence comprehension）。在Clojure中，是使用for宏来进行解析的。列表解析比诸如 map 和filter 这样的函数更加通用，而且，事实上它可以模拟之前的大多数过滤和转换函数。 1(for [binding-form coll-expr filter-expr? ...] expr) 123456789101112131415161718192021(defn whole-numbers [] (iterate inc 1))(for [word [\"the\" \"quick\" \"brown\" \"fox\"]] (format \"&lt;p&gt;%s&lt;/p&gt;\" word));=&gt; (\"&lt;p&gt;the&lt;/p&gt;\" \"&lt;p&gt;quick&lt;/p&gt;\" \"&lt;p&gt;brown&lt;/p&gt;\" \"&lt;p&gt;fox&lt;/p&gt;\");借助:when子句，解析也可以用来模拟filter函数。(take 10 (for [n (whole-numbers) :when (even? n)] n));=&gt; (2 4 6 8 10 12 14 16 18 20);只要:while字句的表达式保持为真，它就会继续进行求值。(for [n (whole-numbers) :while (even? n)] n);=&gt; ()(for [n (whole-numbers) :while (odd? n)] n);=&gt; (1)(for [n (whole-numbers) :while (&lt; n 5)] n);=&gt; (1 2 3 4);多个绑定表达式(for [file \"ABCDEFGH\" rank (range 1 9)] (format \"%c%d\" file rank));=&gt; (\"A1\" \"A2\" ...已省略... \"H7 \"\"H8\")(for [rank (range 1 9) file \"ABCDEFGH\"] (format \"%c%d\" file rank));=&gt; (\"A1\" \"B1\"... \"G8\" \"H8\") 序化正则表达式、文件系统、流 正则表达式： 12345678910(def matcher (re-matcher #\"\\d+\" \"abc12345def678\"));=&gt;#'user/matcher(re-find matcher);=&gt;\"12345\"(re-find matcher);=&gt; \"678\";; If you only want the first match, it is shorter to call re-find with the pattern and the string to search, rather than explicitly creating a matcher as above.(re-find #\"\\d+\" \"abc12345def\");=&gt;\"12345\" 使用正则更好的做法：(re-seq regexp string) re-seq 会把匹配结果暴露为一个不可变的序列。 12345678(re-seq #\"\\w+\" \"the quick brown fox\");=&gt; (\"the\" \"quick\" \"brown\" \"fox\")(sort (re-seq #\"\\w+\" \"the quick brown fox\"));=&gt; (\"brown\" \"fox\" \"quick\" \"the\")(drop 2 (re-seq #\"\\w+\" \"the quick brown fox\"));=&gt; (\"brown\" \"fox\")(map #(.toUpperCase %) (re-seq #\"\\w+\" \"the quick brown fox\"));=&gt; (\"THE\" \"QUICK\" \"BROWN\" \"FOX\") 文件系统： 12345678910(import '(java.io File)); 返回的是File数组，而非序列(.listFiles (File. \".\")); 返回序列(seq (.listFiles (File. \".\")) ); 想要获取name时可以使用map,一旦你决定使用诸如map这样的函数，再调用seq就会显得多余。序列库中的函数会替你调用seq。(map #(.getName %) (.listFiles (File. \".\")));遍历整个目录树。Clojure通过file-seq提供了一个深度优先的遍历方式(file-seq (File. \".\")) 流： 1234567(use '[clojure.java.io :only (reader)]); 统计文件多少行(with-open [rdr (reader \"src/examples/java.clj\")] (count (line-seq rdr))); 仅对非空行计数(with-open [rdr (reader \"src/examples/utils.clj\")] (count (filter #(re-find #\"\\S\" %) (line-seq rdr)))) 综合示例：获取clj代码行数 1234567891011(use '[clojure.java.io :only (reader)])(defn non-blank? [line] (if (re-find #\"\\S\" line) true false))(defn non-svn? [file] (not (.contains (.toString file) \".svn\")))(defn clojure-source? [file] (.endsWith (.toString file) \".clj\"))(defn clojure-loc [base-file] (reduce + (for [file (file-seq base-file) :when (and (clojure-source? file) (non-svn? file))] (with-open [rdr (reader file)] (count (filter non-blank? (line-seq rdr)))))))","categories":[{"name":"clojure","slug":"clojure","permalink":"https://weilans.github.io/categories/clojure/"}],"tags":[{"name":"clojure","slug":"clojure","permalink":"https://weilans.github.io/tags/clojure/"}]}]}