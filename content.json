{"meta":{"title":"HelloJohn","subtitle":"功不唐捐，殊途同归。","description":null,"author":"Hello John","url":"https://weilans.github.io","root":"/"},"pages":[{"title":"[404]","date":"2021-09-03T02:50:31.950Z","updated":"2019-07-21T14:54:11.000Z","comments":true,"path":"404.html","permalink":"https://weilans.github.io/404.html","excerpt":"","text":""},{"title":"about","date":"2021-09-03T02:50:31.950Z","updated":"2019-07-21T14:46:30.000Z","comments":true,"path":"about/index.html","permalink":"https://weilans.github.io/about/index.html","excerpt":"","text":"你要忍，忍到春暖花开； 你要走，走到灯火通明； 你要看过世界辽阔，再评判是好是坏； 你要卯足劲变好，再旗鼓相当站在不敢想象的人身边； 你要变成想象中的样子，这件事，一步都不能让。"}],"posts":[{"title":"基于Kubeadm离线安装Kubernetes","slug":"基于Kubeadm离线安装Kubernetes","date":"2021-09-23T11:38:31.000Z","updated":"2021-09-23T11:39:39.105Z","comments":true,"path":"2021/09/23/基于Kubeadm离线安装Kubernetes/","link":"","permalink":"https://weilans.github.io/2021/09/23/基于Kubeadm离线安装Kubernetes/","excerpt":"","text":"基于kubeadm离线安装K8sk8s版本：v1.22.2 安装前置条件 每台机器 RAM &gt;= 2GB 每台机器 CPU &gt;= 2核 集群中的所有机器的网络能互相连接（内网或公网皆可） 节点之中不可以有重复的主机名、MAC 地址、 product_uuid 1234# MAC addressip link# product_uuidsudo cat /sys/class/dmi/id/product_uuid 禁用交换分区（下文有关闭命令） 确认端口可用 控制平面节点端口 协议 方向 端口范围 作用 使用者 TCP 入站 6443 Kubernetes API 服务器 所有组件 TCP 入站 2379-2380 etcd 服务器客户端 API kube-apiserver, etcd TCP 入站 10250 Kubelet API kubelet 自身、控制平面组件 TCP 入站 10251 kube-scheduler kube-scheduler 自身 TCP 入站 10252 kube-controller-manager kube-controller-manager 自身 工作节点端口 协议 方向 端口范围 作用 使用者 TCP 入站 10250 Kubelet API kubelet 自身、控制平面组件 TCP 入站 30000-32767 NodePort 服务† 所有组件 环境配置关闭防火墙12systemctl stop firewalldsystemctl disable firewalld 关闭selinux12setenforce 0sed -i \"s/SELINUX=enforcing/SELINUX=disabled/g\" /etc/selinux/config 关闭swap1234#临时关闭swap分区, 重启失效;swapoff -a#永久关闭swap分区(在包含swap的行前加注释#)sed -ri 's/.*swap.*/#&amp;/' /etc/fstab 更改cgroup driver &amp; 安装Dockerhttps://kubernetes.io/docs/setup/production-environment/container-runtimes/#docker 1234567vim /etc/docker/daemon.json&#123; \"exec-opts\": [\"native.cgroupdriver=systemd\"]&#125;sudo systemctl enable dockersudo systemctl daemon-reloadsudo systemctl restart docker 更改网卡配置将桥接的IPv4流量传递到iptables的链 123456789cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOFnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOFsudo sysctl --systemvim /etc/sysctl.confnet.ipv4.ip_forward = 1sudo sysctl --system 安装 socat conntrack由于 Kubernetes Version ≥ 1.18 时，需要安装 socat 、conntrack 。 12yum install -y socatyum install -y conntrack-tools 安装 kubeadmA. 包管理器安装 kubelet kubeadm kubectl12345678910111213cat &lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\\$basearchenabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpgexclude=kubelet kubeadm kubectlEOFsudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetessudo systemctl enable --now kubelet B. 手动安装 kubelet kubeadm kubectl1. 安装CNI plugins官方文档的版本是v0.8.2，不过通过yum安装时确定的v0.8.7 123mkdir -p /opt/cni/binwget https://github.com/containernetworking/plugins/releases/download/v0.8.7/cni-plugins-linux-amd64-v0.8.7.tgztar zxvf cni-plugins-linux-amd64-v0.8.7.tgz -C /opt/cni/bin 2. 安装 crictlkubeadm/kubelet 容器运行时接口（CRI）所需。 官方文档的版本是v1.17.0，不过通过yum安装时确定的v1.13.0。 12wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.13.0/crictl-v1.13.0-linux-amd64.tar.gztar zxvf crictl-v1.13.0-linux-amd64.tar.gz -C /usr/local/bin 3. 安装 kubeadm、kubelet、kubectl 并添加 kubelet 系统服务：版本v1.22.2 存放在/usr/bin下，所以不用和官方文档一样用sed改存放位置 1234567curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/v1.22.2/bin/linux/amd64/&#123;kubeadm,kubelet,kubectl&#125;chmod +x &#123;kubeadm,kubelet,kubectl&#125;cp kube* /usr/bincurl -sSL \"https://raw.githubusercontent.com/kubernetes/release/v0.4.0/cmd/kubepkg/templates/latest/deb/kubelet/lib/systemd/system/kubelet.service\" | tee /etc/systemd/system/kubelet.servicemkdir -p /etc/systemd/system/kubelet.service.dcurl -sSL \"https://raw.githubusercontent.com/kubernetes/release/v0.4.0/cmd/kubepkg/templates/latest/deb/kubeadm/10-kubeadm.conf\" | tee /etc/systemd/system/kubelet.service.d/10-kubeadm.conf 启动并激活 kubelet 1systemctl enable --now kubelet 使用 kubeadm 进行安装kubeadm init1kubeadm init --apiserver-advertise-address=10.219.184.190 --kubernetes-version v1.22.2 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 –apiserver-advertise-address 为master 节点 IP –kubernetes-version：选择k8s版本 –pod-network-cidr：指明 pod 网络可以使用的 IP 地址段（该地址参考flannel插件） –service-cidr：为服务的虚拟 IP 地址另外指定 IP 地址段 init args：https://kubernetes.io/zh/docs/reference/setup-tools/kubeadm/kubeadm-init/ 初始化有问题时可以使用kubeadm reset还原。 执行日志123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172[root@ydqa5 kubelet.service.d]# kubeadm init --apiserver-advertise-address=10.219.184.190 --kubernetes-version v1.22.2 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12[init] Using Kubernetes version: v1.22.2[preflight] Running pre-flight checks[preflight] Pulling images required for setting up a Kubernetes cluster[preflight] This might take a minute or two, depending on the speed of your internet connection[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'[certs] Using certificateDir folder \"/etc/kubernetes/pki\"[certs] Generating \"ca\" certificate and key[certs] Generating \"apiserver\" certificate and key[certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local ydqa5] and IPs [10.96.0.1 10.219.184.190][certs] Generating \"apiserver-kubelet-client\" certificate and key[certs] Generating \"front-proxy-ca\" certificate and key[certs] Generating \"front-proxy-client\" certificate and key[certs] Generating \"etcd/ca\" certificate and key[certs] Generating \"etcd/server\" certificate and key[certs] etcd/server serving cert is signed for DNS names [localhost ydqa5] and IPs [10.219.184.190 127.0.0.1 ::1][certs] Generating \"etcd/peer\" certificate and key[certs] etcd/peer serving cert is signed for DNS names [localhost ydqa5] and IPs [10.219.184.190 127.0.0.1 ::1][certs] Generating \"etcd/healthcheck-client\" certificate and key[certs] Generating \"apiserver-etcd-client\" certificate and key[certs] Generating \"sa\" key and public key[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"[kubeconfig] Writing \"admin.conf\" kubeconfig file[kubeconfig] Writing \"kubelet.conf\" kubeconfig file[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file[kubeconfig] Writing \"scheduler.conf\" kubeconfig file[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"[kubelet-start] Starting the kubelet[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"[control-plane] Creating static Pod manifest for \"kube-apiserver\"[control-plane] Creating static Pod manifest for \"kube-controller-manager\"[control-plane] Creating static Pod manifest for \"kube-scheduler\"[etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\"[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s[apiclient] All control plane components are healthy after 17.505159 seconds[upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace[kubelet] Creating a ConfigMap \"kubelet-config-1.22\" in namespace kube-system with the configuration for the kubelets in the cluster[upload-certs] Skipping phase. Please see --upload-certs[mark-control-plane] Marking the node ydqa5 as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers][mark-control-plane] Marking the node ydqa5 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule][bootstrap-token] Using token: gghdcj.11vpqnv1oq8sbj52[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace[kubelet-finalize] Updating \"/etc/kubernetes/kubelet.conf\" to point to a rotatable kubelet client certificate and key[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxyYour Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configAlternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.confYou should now deploy a pod network to the cluster.Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 10.219.184.190:6443 --token gghdcj.11vpqnv1oq8sbj52 \\ --discovery-token-ca-cert-hash sha256:316e5253cf337e177afa65bf352922f03cc510e134ed786c80da2baf8a55239e 结果确认主节点安装完成后执行： 123mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config # 用于kubectlsudo chown $(id -u):$(id -g) $HOME/.kube/config # 用于修改上述配置所属用户为当前用户(非root时) 查看节点信息： 1kubectl get nodes -o wide 查看pods： 123456789[root@ydqa5 kubelet.service.d]# kubectl get pods --all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGEkube-system coredns-78fcd69978-6gvbv 0/1 Pending 0 15mkube-system coredns-78fcd69978-kvw8q 0/1 Pending 0 15mkube-system etcd-ydqa5 1/1 Running 0 15mkube-system kube-apiserver-ydqa5 1/1 Running 0 15mkube-system kube-controller-manager-ydqa5 1/1 Running 0 15mkube-system kube-proxy-8vbtm 1/1 Running 0 15mkube-system kube-scheduler-ydqa5 1/1 Running 0 15m codedns是pending状态，原因是没有配置网络插件。 安装网络插件1kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 12345678910[root@ydqa5 john]# kubectl get pods --all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGEkube-system coredns-78fcd69978-6gvbv 1/1 Running 0 24mkube-system coredns-78fcd69978-kvw8q 1/1 Running 0 24mkube-system etcd-ydqa5 1/1 Running 0 24mkube-system kube-apiserver-ydqa5 1/1 Running 0 24mkube-system kube-controller-manager-ydqa5 1/1 Running 0 24mkube-system kube-flannel-ds-cxf9k 1/1 Running 0 3m12skube-system kube-proxy-8vbtm 1/1 Running 0 24mkube-system kube-scheduler-ydqa5 1/1 Running 0 24m 查看 flannel 详情 1kubectl describe pods kube-flannel-ds-cxf9k -n kube-system kubeadm join在主节点使用以下命令获取join指令： 1kubeadm token create --print-join-command 在从节点执行后，kubectl get nodes -o wide 等待其他两个节点都是ready。 查看pods： 1234567891011121314[root@ydqa5 kubelet.service.d]# kubectl get pods --all-namespaces -o wideNAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESkube-system coredns-78fcd69978-6gvbv 1/1 Running 0 35m 10.244.0.3 ydqa5 &lt;none&gt; &lt;none&gt;kube-system coredns-78fcd69978-kvw8q 1/1 Running 0 35m 10.244.0.2 ydqa5 &lt;none&gt; &lt;none&gt;kube-system etcd-ydqa5 1/1 Running 0 35m 10.219.184.190 ydqa5 &lt;none&gt; &lt;none&gt;kube-system kube-apiserver-ydqa5 1/1 Running 0 35m 10.219.184.190 ydqa5 &lt;none&gt; &lt;none&gt;kube-system kube-controller-manager-ydqa5 1/1 Running 0 35m 10.219.184.190 ydqa5 &lt;none&gt; &lt;none&gt;kube-system kube-flannel-ds-599g4 1/1 Running 0 2m57s 10.219.188.160 ydqa8 &lt;none&gt; &lt;none&gt;kube-system kube-flannel-ds-cxf9k 1/1 Running 0 14m 10.219.184.190 ydqa5 &lt;none&gt; &lt;none&gt;kube-system kube-flannel-ds-jv82z 1/1 Running 0 3m 10.219.184.13 ydqa7 &lt;none&gt; &lt;none&gt;kube-system kube-proxy-8vbtm 1/1 Running 0 35m 10.219.184.190 ydqa5 &lt;none&gt; &lt;none&gt;kube-system kube-proxy-9c858 1/1 Running 0 2m57s 10.219.188.160 ydqa8 &lt;none&gt; &lt;none&gt;kube-system kube-proxy-gc4rb 1/1 Running 0 3m 10.219.184.13 ydqa7 &lt;none&gt; &lt;none&gt;kube-system kube-scheduler-ydqa5 1/1 Running 0 35m 10.219.184.190 ydqa5 &lt;none&gt; &lt;none&gt;","categories":[{"name":"k8s","slug":"k8s","permalink":"https://weilans.github.io/categories/k8s/"}],"tags":[]},{"title":"Kubernetes相关记录","slug":"Kubernetes相关记录","date":"2021-09-14T02:06:39.000Z","updated":"2021-09-23T11:39:46.755Z","comments":true,"path":"2021/09/14/Kubernetes相关记录/","link":"","permalink":"https://weilans.github.io/2021/09/14/Kubernetes相关记录/","excerpt":"","text":"pod是k8s调度最小单位，一个pod可以包含一或多个container，容器间共享一个Network namespace kubectl create -f pod_nginx.yml 123456789101112apiVersion: v1kind: Podmetadata: name: nginx labels: app: nginxspec: containers: - name: nginx image: nginx ports: - containerPort: 80 kubectl delete -f pod_nginx.yml kubectl get pods -o wide –all-namespaces kubectl exec -it nginx sh 如果多个容器的话需要-c指定 kubectl describe pods nginx kubectl port-forward nginx 8080:80 无法后台运行，不常用","categories":[{"name":"k8s","slug":"k8s","permalink":"https://weilans.github.io/categories/k8s/"}],"tags":[]},{"title":"容器实战 - 网络相关","slug":"Docker容器实战-网络相关","date":"2021-09-13T12:10:08.000Z","updated":"2021-09-13T12:49:36.045Z","comments":true,"path":"2021/09/13/Docker容器实战-网络相关/","link":"","permalink":"https://weilans.github.io/2021/09/13/Docker容器实战-网络相关/","excerpt":"","text":"Network Namespace隔离的网络资源包括： 网络设备，如eth0, lo 这种网络设备； ipv4和ipv6协议栈，IP层及上面的TCP/UDP协议栈也是每个Namespace独立工作的。 IP路由表，可通过ip route查看。 防火墙规则，每个Namespace可以独立配置iptables规则。 网络状态信息。可从 /proc/net 和 /sys/class/net 里得到。 lsns -t net这个命令来查看系统里已有的 Network Namespace。当然，lsns也可以用来查看其它 Namespace。 容器里 Network Namespace 的网络参数并不是完全从宿主机 Host Namespace 里继承的，也不是完全在新的 Network Namespace 建立的时候重新初始化的。容器中”/proc/sys/“是只读 mount 的，那么在容器里是不能修改”/proc/sys/net/“下面的任何参数了。 为什么“/proc/sys/” 在容器里是只读 mount 呢？ 这是因为 runC 当初出于安全的考虑，把容器中所有 /proc 和 /sys 相关的目录缺省都做了 read-only mount 的处理。 网络参数修改的“正确时机”：修改 Network Namespace 里的网络参数，要选择容器刚刚启动，而容器中的应用程序还没启动之前进行。 runC 也在对 /proc/sys 目录做 read-only mount 之前，预留出了修改接口，就是用来修改容器里 “/proc/sys”下参数的，同样也是 sysctl 的参数。Docker 的–sysctl或者 Kubernetes 里的allowed-unsafe-sysctls特性也都利用了 runC 的 sysctl 参数修改接口，允许容器在启动时修改容器 Namespace 里的参数。 1234# docker run -d --name net_para --sysctl net.ipv4.tcp_keepalive_time=600 centos:8.1.1911 sleep 36007efed88a44d64400ff5a6d38fdcc73f2a74a7bdc3dbc7161060f2f7d0be170d1# docker exec net_para cat /proc/sys/net/ipv4/tcp_keepalive_time600","categories":[],"tags":[]},{"title":"朝花夕拾 - Linux Shell 文本处理","slug":"朝花夕拾-Linux-Shell-文本处理","date":"2021-07-19T07:10:14.000Z","updated":"2021-07-19T14:56:29.700Z","comments":true,"path":"2021/07/19/朝花夕拾-Linux-Shell-文本处理/","link":"","permalink":"https://weilans.github.io/2021/07/19/朝花夕拾-Linux-Shell-文本处理/","excerpt":"","text":"朝花夕拾 - Linux Shell 文本处理A. grep文本搜索 123456789101112131415161718192021# 1. --color可以在输出行中着重标记出匹配到的模式grep --color=auto word filename# 2. 选项-E可以使grep使用扩展正则表达式。也可以使用默认启用扩展正则表达式的egrep命令grep -E \"[a-z]+\" filenameegrep \"[a-z]+\" filename# 3. 选项-o可以只输出匹配到的文本echo this is a line. | egrep -o \"[a-z]+\\.\" # line.# 4. 选项-v可以打印出不匹配match_pattern的所有行grep -v match_pattern file# 5. 选项-n可以打印出匹配字符串所在行的行号# 6. 选项-i可以在匹配模式时不考虑字符的大小写# 7. 匹配多个模式grep -e \"pattern1\" -e \"pattern2\"# 8. 在静默模式中，grep命令不会输出任何内容。它仅是运行命令，然后根据命令执行成功与否返回退出状态。0表示匹配成功，非0表示匹配失败。grep -q \"$match_text\" $filenameif [ $? -eq 0 ]; then echo \"The text exists in the file\"else echo \"Text does not exist in the file\"fi# 9. 匹配之前或之后的行. -A可以打印匹配结果之后的行, -B可以打印匹配结果之前的行, -C可以分别打印出匹配结果之前及之后的n行 B. cutcut命令可以按列来切分文件。 1234567891011121314151617181920212223# 制表符是字段默认的分隔符# FIELD_LIST是需要显示的列。它由列号组成，彼此之间用逗号分隔cut -f 2,3 filename# 选项-d能够设置分隔符cut -f 2 -d \":\"cut -f 2- -d @ # N- 从第N个字节、字符或字段开始到行尾# N-M 从第N个字节、字符或字段开始到第M个（包括第M个在内）字节、字符或字段# -M 从第1个字节、字符或字段开始到第M个（包括第M个在内）字节、字符或字段# -b 表示字节 -c 表示字符 -f 用于定义字段#cat range_fields.txt#abcdefghijklmnopqrstuvwxyz#abcdefghijklmnopqrstuvwxyzcut -c2-5 range_fields.txt#bcde#bcdecut -c -2 range_fields.txt#ab#ab# --output-delimiter可以指定输出分隔符cut range_fields.txt -c1-3,6-9 --output-delimiter \",\"#abc,fghi#abc,fghi C. sedsed是 stream editor(流编辑器) 的缩写。它最常见的用法是进行文本替换。 1234567891011121314151617181920212223242526sed 's/pattern/replace_string/' file# 选项-i会使得sed用修改后的数据替换原始文件sed -i 's/text/replace/' file#以上只替换了每行中模式首次匹配的内容。g标记可以使sed执行全局替换sed -i 's/pattern/replace_string/g' file#sed命令会将s之后的字符视为命令分隔符。这允许我们更改默认的分隔符sed 's:text:replace:g'sed 's|text|replace|g'# 删除行sed -i '/server/d' /etc/nginx/nginx.confsed -i '/^$/d' file # 移除空行, 空行可以用正则表达式 ^$ 进行匹配# &amp;可指代模式所匹配到的字符串，能够在替换字符串时使用已匹配的内容echo this is an example | sed 's/\\w\\+/[&amp;]/g' # 正则表达式\\w\\+匹配每一个单词# [this] [is] [an] [example]# 子串匹配标记（\\1）echo this is digit 7 in a number | sed 's/digit \\([0-9]\\)/\\1/' # \\(pattern\\)用于匹配子串. 对于匹配到的第n个子串，其对应的标记是\\n# this is 7 in a numberecho seven EIGHT | sed 's/\\([a-z]\\+\\) \\([A-Z]\\+\\)/\\2 \\1/'# EIGHT seven#利用管道组合多表达式. 以下三句含义相同:sed 'expression' | sed 'expression' sed 'expression; expression'sed -e 'expression' -e 'expression'echo abc | sed 's/a/A/' | sed 's/c/C/' # AbCecho abc | sed 's/a/A/;s/c/C/' # AbCecho abc | sed -e 's/a/A/' -e 's/c/C/' # AbC D. awkawk命令用于高级文本处理，可以处理数据流。它支持关联数组、递归函数、条件语句等功能。 awk脚本通常由3部分组成：BEGIN、END和带模式匹配选项的公共语句块。这3个部分都是可选的，可以不用出现在脚本中。 1awk 'BEGIN&#123; print \"start\" &#125; pattern &#123; commands &#125; END&#123; print \"end\" &#125;' file awk以逐行的形式处理文件。BEGIN之后的命令会先于公共语句块执行。对于匹配PATTERN的行，awk会对其执行PATTERN之后的命令。最后，在处理完整个文件之后，awk会执行END之后的命令。 和pattern关联的语句块是可选的。如不提供则默认执行{ print }，即打印所读取到的每一行。 12345echo -e \"line1\\nline2\" | awk 'BEGIN &#123; print \"Start\" &#125; &#123; print &#125; END &#123; print \"End\" &#125; '#Start#line1#line2#End print参数： 123# 数以逗号分隔，在打印参数时则以空格作为参数之间的分隔符echo | awk '&#123; var1=\"v1\"; var2=\"v2\"; var3=\"v3\"; print var1,var2,var3 ; &#125;' # v1 v2 v3echo | awk '&#123; var1=\"v1\"; var2=\"v2\"; var3=\"v3\"; print var1 \"-\" var2 \"-\" var3 ; &#125;' # v1-v2-v3 特殊变量： NR：表示记录编号，该变量相当于当前行号。 NF：表示字段数量，相当于字段数量，默认的字段分隔符是空格。 $0：该变量包含当前记录的文本内容。 $1：该变量包含第一个字段的文本内容。 $2：该变量包含第二个字段的文本内容。 1234# 打印出每一行的第二和第三个字段awk '&#123; print $3, $2 &#125;' file# 使用NR统计文件的行数awk 'END&#123; print NR &#125;' file 字符分隔符： 默认为空格，可以使用-F指定。 123awk -F: '&#123; print $NF &#125;' /etc/passwdawk -F ':' '&#123; print $NF &#125;' /etc/passwdawk 'BEGIN &#123; FS=\":\" &#125; &#123; print $NF &#125;' /etc/passwd 过滤模式进行行过滤: 1234awk 'NR &lt; 5' # 行号小于5的行awk 'NR==1,NR==4' # 行号在1到4之间的行awk '/linux/' # 包含模式为linux的行（可以用正则表达式来指定模式）awk '!/linux/' # 不包含模式为linux的行 getline: 得到的并不是当前行，而是当前行的下一行。getline之后，awk会改变对应的NF，NR，FNR和$0等内部变量 1234567891011121314151617181920212223seq 10 | awk '&#123;getline; print $0&#125;'#2#4#6#8#10seq 10 | awk '&#123;print $0; getline&#125;'#1#3#5#7#9seq 10 | awk '&#123;getline tmp; print tmp; print $0&#125;' # getline得到的下一行的内容放在了tmp这个变量里, NF NR FNR和$0等内部变量并不会被改变#2#1#4#3#6#5#8#7#10#9 从awk中读取命令输出： 把命令放入引号中，然后利用管道将命令输出传入getline：&quot;command&quot; | getline output ; 12echo | awk 'BEGIN &#123;FS=\":\"&#125; &#123; \"grep root /etc/passwd\" | getline; print $1,$6 &#125;'#root /root 关联数组和循环： 1awk 'BEGIN &#123;FS=\":\"&#125; &#123;nam[$1]=$5&#125; END &#123;for (i in nam) &#123;print i,nam[i]&#125;&#125;' /etc/passwd E. 日常demo1. 统计特定文件中的词频123456789101112if [ $# -ne 1 ];then echo \"Usage: $0 filename\"; exit -1fifilename=$1egrep -o \"\\b[[:alpha:]]+\\b\" $filename | \\ awk '&#123; count[$0]++ &#125; END&#123; printf(\"%-14s%s\\n\",\"Word\",\"Count\") ; for(ind in count) &#123; printf(\"%-14s%d\\n\",ind,count[ind]);&#125; &#125; 模式\\b[[:alpha:]]+\\b能够匹配每个单词并去除空白字符和标点符号。 2. 按列合并多个文件默认的分隔符是制表符，也可以用-d指定分隔符： 123456paste file1.txt file2.txt -d \",\"#1,slynux#2,gnu#3,bash#4,hack#5, 3. 打印行中第N个单词或列123awk '&#123; print $5 &#125;' filename# 可以打印多列数据并在各列间插入指定的字符串ls -l | awk '&#123; print $1 \" : \" $8 &#125;' 4. 打印指定行或模式之间的文本12345678910111213awk 'NR==M, NR==N' filenameseq 100 | awk 'NR==4,NR==6'# 打印位于模式start_pattern与end_pattern之间的文本awk '/start_pattern/, /end_pattern/' filename#cat section.txt#line with pattern1#line with pattern2#line with pattern3#line end with pattern4#line with pattern5awk '/pa.*3/, /end/' section.txt#line with pattern3#line end with pattern4 5. 逆序打印行tac命令默认使用\\n作为行分隔符。但我们也可以用选项-s指定其他分隔符 1234567#tac命令默认使用\\n作为行分隔符seq 5 | tac#5#4#3#2#1 或者通过awk: 1seq 9 | awk '&#123; lifo[NR]=$0 &#125; END &#123; for(lno=NR;lno&gt;-1;lno--)&#123; print lifo[lno]; &#125; &#125;' 6. 解析文本中的电子邮件地址和URL12egrep -o '[A-Za-z0-9._]+@[A-Za-z0-9.]+\\.[a-zA-Z]&#123;2,4&#125;' a.txtegrep -o \"http://[a-zA-Z0-9.]+\\.[a-zA-Z]&#123;2,3&#125;\" b.txt 7. 删除文件中包含特定单词的句子12# [^.]可以匹配除句点之外的任意字符sed 's/ [^.]*mobile phones[^.]*\\.//g' sentence.txt 8. 基础变量替换12345678910111213141516var=\"This is a line of text\"echo $&#123;var/line/REPLACED&#125;#This is a REPLACED of text# 字符串起始字符的索引从0开始string=abcdefghijklmnopqrstuvwxyzecho $&#123;string:4&#125;#efghijklmnopqrstuvwxyzecho $&#123;string:4:8&#125;#efghijklecho $&#123;string:(-1)&#125;#zecho $&#123;string:(-2):2&#125;#yz","categories":[{"name":"linux","slug":"linux","permalink":"https://weilans.github.io/categories/linux/"}],"tags":[]},{"title":"Clickhouse 概述","slug":"Clickhouse","date":"2021-07-15T07:30:54.000Z","updated":"2021-09-24T02:16:28.877Z","comments":true,"path":"2021/07/15/Clickhouse/","link":"","permalink":"https://weilans.github.io/2021/07/15/Clickhouse/","excerpt":"","text":"Clickhouse 概述使用场景因为ClickHouse在诞生之初是为了服务Yandex自家的Web流量分析产品Yandex.Metrica，所以在存储数据超过20万亿行的情况下，ClickHouse做到了90%的查询都能够在1秒内返回的惊人之举。它基本能够胜任各种数据分析类的场景，并且随着数据体量的增大，它的优势也会变得越为明显。ClickHouse非常适用于商业智能领域（也就是我们所说的BI领域），除此之外，它也能够被广泛应用于广告流量、Web、App流量、电信、金融、电子商务、信息安全、网络游戏、物联网等众多其他领域。不过ClickHouse不应该把它用于任何OLTP事务性操作的场景，因为它有以下几点不足：不支持事务；不擅长根据主键按行粒度进行查询（虽然支持），故不应该把ClickHouse当作Key-Value数据库使用；不擅长按行删除数据（虽然支持）。 特性介绍ClickHouse是一款MPP架构的列式存储数据库。特性如下： 完备的DBMS功能：DDL（数据定义语言）/ DML（数据操作语言）/ 权限控制 / 数据备份与恢复 / 分布式管理 列式存储与数据压缩：一个非常流行的观点认为，如果你想让查询变得更快，最简单且有效的方法是减少数据扫描范围和数据传输时的大小，而列式存储和数据压缩就可以帮助我们实现上述两点。列式存储和数据压缩通常是伴生的，因为一般来说列式存储是数据压缩的前提。数据按列进行组织，属于同一列的数据会被保存在一起，列与列之间也会由不同的文件分别保存（这里主要指MergeTree表引擎）。数据默认使用LZ4算法压缩。 向量化执行引擎：ClickHouse目前利用SSE4.2指令集实现向量化执行。 关系模型与SQL查询：ClickHouse使用关系模型描述数据并提供了传统数据库的概念（数据库、表、视图和函数等）。在SQL解析方面，ClickHouse是大小写敏感的。 多样化的表引擎：最初架构是基于MySQL实现的，所以在ClickHouse的设计中，能够察觉到一些MySQL的影子，表引擎的设计就是其中之一。每一种表引擎都有着各自的特点，用户可以根据实际业务场景的要求，选择合适的表引擎使用。 多线程与分布式：ClickHouse在数据存取方面，既支持分区（纵向扩展，利用多线程原理），也支持分片（横向扩展，利用分布式原理），可以说是将多线程和分布式的技术应用到了极致。 多主架构：HDFS、Spark、HBase和Elasticsearch这类分布式系统，都采用了Master-Slave主从架构，由一个管控节点作为Leader统筹全局。而ClickHouse则采用Multi-Master多主架构，集群中的每个节点角色对等，客户端访问任意一个节点都能得到相同的效果。这种多主的架构有许多优势，例如对等的角色使系统架构变得更加简单，不用再区分主控节点、数据节点和计算节点，集群中的所有节点功能相同。所以它天然规避了单点故障的问题，非常适合用于多数据中心、异地多活的场景。 数据分片与分布式查询：ClickHouse提供了本地表（Local Table）与分布式表（Distributed Table）的概念。一张本地表等同于一份数据的分片。而分布式表本身不存储任何数据，它是本地表的访问代理，其作用类似分库中间件。借助分布式表，能够代理访问多个数据分片，从而实现分布式查询。","categories":[{"name":"db","slug":"db","permalink":"https://weilans.github.io/categories/db/"}],"tags":[{"name":"clickhouse","slug":"clickhouse","permalink":"https://weilans.github.io/tags/clickhouse/"}]},{"title":"Linux宿主机及Docker监控","slug":"Linux宿主机及Docker监控","date":"2021-05-19T06:22:19.000Z","updated":"2021-06-05T09:35:55.560Z","comments":true,"path":"2021/05/19/Linux宿主机及Docker监控/","link":"","permalink":"https://weilans.github.io/2021/05/19/Linux宿主机及Docker监控/","excerpt":"","text":"宿主机监控Interpreting Prometheus metrics for Linux disk I/O utilizatio Node_exporter IO指标详解 Understanding Machine CPU usage Node_exporter CPU指标详解，教你看懂CPU适用率是怎么算出来的 Docker CPU Usage 介绍docker stats中的docker原生CPU信息收集的细节。 容器监控在调研方案中发现，基本都是采用cAdvisor，K8S内部也是采用cAdvisor。选取版本 v0.37.5。 cAdvisor CPU过高之前使用 cAdvisor 时发现CPU占用率太高，发现遇到此问题的人有很多，相关issue也有人提到，处理的方式是减少收集间隔期、减少收集的指标。 1234command: - '--docker_only' - '--housekeeping_interval=10s' - '--disable_metrics=disk,udp,referenced_memory,cpu_topology,resctrl,tcp,advtcp,sched,process,hugetlb' cAdvisor中有Housekeeping的概念，控制指标收集的周期行为。--housekeeping_interval默认情况值为1s，但是并不是每秒都进行采集。因为--allow_dynamic_housekeeping默认为true，动态的间隔时长依赖于容器的活动情况进行收集，此项设为 false 则会增加资源开销，因此不做变动。在动态收集的前提下，试验下来：设置为1s，1分钟收集12次左右；设置为5s后，1分钟采集大概7或8次；设置为10s，1分钟收集4次左右。 设置--docker_only：会只收集docker容器的状态，像id=&quot;/system.slice&quot;等指标都不会再收集。 设置disable_metrics：考虑到我们实际场景，在默认列表的基础上加上了disk。磁盘IO相关的指标还剩下container_fs_reads_bytes_total、container_fs_reads_total、container_fs_writes_bytes_total、container_fs_writes_total。 设置以上三个条件后，在我们的双机空置服务上跑监控大概会降低5%的CPU消耗。 设备映射官方示意的docker run 中加入了--device=/dev/kmsg设备映射，如果不包含此参数，则会在启动时报出警告： 11 manager.go:288] Could not configure a source for OOM detection, disabling OOM events: open /dev/kmsg: no such file or directory 由于Swarm下没有device的选项，可以考虑docker compose的方式启动服务堆栈。 Grafana图表看了一圈没啥品质高的图表，dockprom的 dashboards 可以参考下。 参考文档Monitoring cAdvisor with Prometheus[官方文档] Prometheus指标细节。吐槽下，文档感觉和实际有出入，在实验 disable_metrics 时（比如关闭disk，开启diskIO）关闭的指标和文中的不一样。 cAdvisor Runtime Options[官方文档] cadvisor启动参数，也可进容器里cadvisor --help，参数前缀试验下来--和-都是可以的。 cAdvisor内存使用率指标 cAdvisor中关于内存的监控项。 Memory_working_set vs Memory_rss in Kubernetes, which one you should monitor? cAdvisor中内存指标最关键的两项。 Docker monitoring - with Grafana, prometheus, cadvisor and exporter 一套标准的基于docker compose监控方案。 dockprom - A monitoring solution for Docker hosts and containers 一套标准的宿主机和docker通用监控方案，Prometheus, Grafana, cAdvisor, NodeExporter and alerting with AlertManager。Grafana图表可参考。","categories":[{"name":"linux, docker, monitor","slug":"linux-docker-monitor","permalink":"https://weilans.github.io/categories/linux-docker-monitor/"}],"tags":[{"name":"monitor","slug":"monitor","permalink":"https://weilans.github.io/tags/monitor/"}]},{"title":"Linux性能优化-内存篇","slug":"Linux性能优化-内存篇","date":"2021-05-16T09:14:33.000Z","updated":"2021-05-24T13:22:06.210Z","comments":true,"path":"2021/05/16/Linux性能优化-内存篇/","link":"","permalink":"https://weilans.github.io/2021/05/16/Linux性能优化-内存篇/","excerpt":"","text":"1. 内存映射虚拟内存： Linux 内核给每个进程都提供了一个独立的虚拟地址空间，并且这个地址空间是连续的。进程可以很方便地访问虚拟内存。 虚拟地址空间分为：内核空间和用户空间。不同字长处理器（32位/64位）地址空间范围也不同。进程在用户态时，只能访问用户空间内存；只有进入内核态后，才可以访问内核空间内存。 所有进程的虚拟内存加起来要比实际内存大得多，因此不是所有虚拟内存都分配内存，只有实际使用的虚拟内存才会分配物理内存，分配后的物理内存通过内存映射进行管理。内存映射，其实就是将虚拟内存地址映射到物理内存地址。为了完成内存映射，内核为每个进程都维护了一张页表，记录虚拟地址与物理地址的映射关系。当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。 内存映射的最小单位为页，通常是4KB大小。4G内存需4G/4K=100多万页表项才能完成整个地址空间映射。为解决页表项过多的问题，Linux提供两种机制：多级页表和大页 (HugePage)： 多级页表：映射关系改为区块索引和区块内的偏移。Linux采用的是四级页表管理内存页，前四个页表项用于选择页，最后一个索引表示页内偏移。 大页：更大的内存块，通常大小有2MB和1GB，通常应用在使用大量内存的Linux进程中。 2. 虚拟内存空间分布内核空间和用户空间，其中用户空间包括： 只读段，包括代码和常量等。 数据段，包括全局变量等。 堆，包括动态分配的内存，从低地址开始向上增长。 文件映射段，包括动态库、共享内存等，从高地址开始向下增长。 栈，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。 堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 malloc() 或者 mmap() ，就可以分别在堆和文件映射段动态分配内存。 3. 内存分配与回收malloc() 是 C 标准库提供的内存分配函数，当进程通过 malloc() 申请内存后，内存并不会立即分配，而是在首次访问时，才通过缺页异常陷入内核中分配内存。 malloc() 对应到系统调用有两种实现方式: brk() 和 mmap()。 小块内存（小于 128K），C 标准库使用 brk() 来分配，内存释放并不会立刻归还系统，而是被缓存起来重复使用。减少缺页异常的发生，提高内存访问效率，但频繁的内存分配和释放会造成内存碎片。 大块内存（大于 128K），使用mmap() 来分配，在文件映射段找一块空闲内存分配出去。频繁的内存分配会导致大量的缺页异常，使内核的管理负担增大 在应用程序用完内存后，还需要调用 free() 或 unmap() ，来释放这些不用的内存。 当有大量比页还小的的对象要分配时，为它们分配单独的页会浪费内存。因此，在用户空间，malloc() 通过 brk() 分配的内存，在释放时并不立即归还系统，而是缓存起来重复利用。在内核空间，Linux 则通过 slab 分配器来管理小内存，slab 主要作用就是分配并释放内核中的小对象。 4. 处理内存紧张 回收缓存，比如LRU回收最近使用最少的内存页面。 回收不常访问的内存，把不常用内存通过交换分区写入磁盘。 Swap 把系统的可用内存变大了。不过通常只在内存不足时才会发生 Swap 交换。由于磁盘读写的速度远比内存慢，Swap 会导致严重的内存性能问题。 杀死进程，系统通过OOM直接杀掉占用大量内存的进程。 OOM是内核的一种保护机制，监控进程的内存使用，使用 oom_score 为每个进程的内存使用情况进行评分：进程消耗内存越大，oom_score 就越大；进程运行占用 CPU 越多，oom_score 就越小。 oom_adj 的范围是 [-17, 15]，数值越大，表示进程越容易被 OOM 杀死；数值越小，表示进程越不容易被 OOM 杀死，其中 -17 表示禁止 OOM。 echo -16 &gt; /proc/$(pidof sshd)/oom_adj以这种方式可以调整某进程的oom_adj。 5. 内存使用查看查看系统内存使用使用free命令时的各列含义： total 总内存大小； used 已使用内存的大小，包含了共享内存； free 未使用内存的大小； shared 共享内存的大小； buff/cache 缓存和缓冲区的大小； available 新进程可用内存的大小。available 不仅包含未使用内存，还包括了可回收的缓存，所以一般会比未使用内存更大。 查看进程内存使用使用top时的内存相关列的含义： VIRT 进程虚拟内存的大小，只要是进程申请过的内存，即便还没有真正分配物理内存，也会计算在内。 RES 常驻内存的大小，也就是进程实际使用的物理内存大小。 SHR是共享内存的大小，比如与其他进程共同使用的共享内存、加载的动态链接库以及程序的代码段等。SHR 并不一定是共享的，比方说，程序的代码段、非共享的动态链接库，也都算在 SHR 里。当然，SHR 也包括了进程间真正共享的内存。 %MEM 是进程使用物理内存占系统总内存的百分比。 理解virt res shr之间的关系 - linux","categories":[{"name":"linux","slug":"linux","permalink":"https://weilans.github.io/categories/linux/"}],"tags":[{"name":"memory","slug":"memory","permalink":"https://weilans.github.io/tags/memory/"}]},{"title":"Redis-集群","slug":"Redis-集群","date":"2021-03-24T11:55:03.000Z","updated":"2021-05-06T06:40:02.400Z","comments":true,"path":"2021/03/24/Redis-集群/","link":"","permalink":"https://weilans.github.io/2021/03/24/Redis-集群/","excerpt":"","text":"Redis Cluster 是 Redis 的分布式解决方案，在3.0版本正式推出，有效地解决了Redis分布式方面的需求。当遇到单机内存、并发、流量等瓶颈时，可以采用 Cluster 架构方案达到负载均衡的目的。 1. 数据分布分布式数据库首先要解决把整个数据集按照分区规则映射到多个节点的问题，即把数据集划分到多个节点上，每个节点负责整体数据的一个子集，常规的有：哈希分区、顺序分区。主要的哈希分区规则有：节点取余分区、一致性哈希分区、虚拟槽分区。 节点取余分区hash(key) % N计算出哈希值，用来决定数据映射到哪一个节点上。 缺点：当节点数量变化时，如扩容或收缩节点，数据节点映射关系需要重新计算，会导致数据的重新迁移。 优点：简单性，常用于数据库的分库分表规则。 一般采用预分区的方式，提前根据数据量规划好分区数，比如划分为512或1024张表，保证可支撑未来一段时间的数据量，再根据负载情况将表迁移到其他数据库中。扩容时通常采用翻倍扩容，避免数据映射全部被打乱导致全量迁移的情况。 一致性哈希分区思路是为系统中每个节点分配一个token，范围一般在0~2^32，这些token构成一个哈希环。数据读写执行节点查找操作时，先根据key计算hash值，然后顺时针找到第一个大于等于该哈希值的token节点。 优点：加入和删除节点只影响哈希环中相邻的节点，对其他节点无影响。 缺点：增删节点需手动处理或忽略部分数据，因此一致性哈希多用于缓存场景；节点较少时，节点的变化将大范围影响数据映射；增减节点时为保证数据和负载的均衡需增加一倍或减去一半节点。 虚拟槽分区使用分散度良好的哈希函数把所有数据映射到一个固定范围的整数集合中，整数定义为槽（slot）。这个范围一般远远大于节点数，比如Redis Cluster槽范围是0~16383。 槽是集群内数据管理和迁移的基本单位。采用大范围槽的主要目的是为了方便数据拆分和集群扩展，每个节点会负责一定数量的槽。 Redis数据分布采用虚拟槽分区，所有的键根据哈希函数映射到 0~16383 整数槽内，计算公式：slot = CRC16(key) &amp; 16383。每一个节点负责维护一部分槽以及槽所映射的键值数据。 这种 Redis 虚拟槽分区的特点： 解耦数据和节点之间的关系，简化了节点扩容和收缩难度。 节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据。 支持节点、槽、键之间的映射查询，用于数据路由、在线伸缩等场景。 不过 Redis 集群存在功能限制： key 批量操作支持有限。如 mset、mget，目前只支持具有相同slot值的key执行批量操作。对于映射为不同slot值的key由于执行mget、mget等操作可能存在于多个节点上因此不被支持。 key事务操作支持有限。同理只支持多key在同一节点上的事务操作，当多个key分布在不同的节点上时无法使用事务功能。 key作为数据分区的最小粒度，因此不能将一个大的键值对象如hash、list等映射到不同的节点。 不支持多数据库空间。单机下的Redis可以支持16个数据库，集群模式下只能使用一个数据库空间，即db0。 复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构。 2. 搭建集群配置示例： 123456789#节点端口port 6379# 开启集群模式cluster-enabled yes# 节点超时时间, 单位毫秒cluster-node-timeout 15000# 集群内部配置文件cluster-config-file \"nodes-6379.conf\"daemonize yes 启动： 123456redis-server redis-6379.confredis-server redis-6380.confredis-server redis-6381.confredis-server redis-6382.confredis-server redis-6383.confredis-server redis-6384.conf 第一次启动时如果没有集群配置文件，它会自动创建一份，文件名称采用cluster-config-file参数项控制，建议采用node-{port}.conf格式定义。 当集群内节点信息发生变化，如添加节点、节点下线、故障转移等。节点会自动保存集群状态到配置文件中。需要注意的是，Redis自动维护集群配置文件，不要手动修改，防止节点重启时产生集群信息错乱。 文件内容记录了集群初始状态，这里最重要的是节点ID。节点ID不同于运行ID。节点ID在集群初始化时只创建一次，节点重启时会加载集群配置文件进行重用，而Redis的运行ID每次重启都会变化。 使用meet命令握手： 12345127.0.0.1:6379&gt;cluster meet 127.0.0.1 6380127.0.0.1:6379&gt;cluster meet 127.0.0.1 6381127.0.0.1:6379&gt;cluster meet 127.0.0.1 6382127.0.0.1:6379&gt;cluster meet 127.0.0.1 6383127.0.0.1:6379&gt;cluster meet 127.0.0.1 6384 查看集群节点：cluster nodes 查看集群状态： cluster info （此时发现 cluster_state:fail ，是因为未分配槽） 分配槽： 123redis-cli -h 127.0.0.1 -p 6379 cluster addslots &#123;0..5461&#125;redis-cli -h 127.0.0.1 -p 6380 cluster addslots &#123;5462..10922&#125;redis-cli -h 127.0.0.1 -p 6381 cluster addslots &#123;10923..16383&#125; 使用cluster replicate {nodeId}命令让一个节点成为从节点： 12345127.0.0.1:6382&gt;cluster replicate &lt;6379节点ID&gt;OK127.0.0.1:6383&gt;cluster replicate &lt;6380节点ID&gt;OK127.0.0.1:6384&gt;cluster replicate &lt;6381节点ID&gt; 3. 节点通信Redis Cluster 采用 P2P 的 Gossip（流言）协议来维护节点元数据信息，Gossip 协议工作原理就是节点彼此不断通信交换信息，一段时间后所有的节点都会知道集群完整的信息，这种方式类似流言传播。 集群中的每个节点都会单独开辟TCP通道，用于节点之间彼此通信，通信端口号在基础端口上加10000。 每个节点在固定周期内通过特定规则选择几个节点发送ping消息。 接收到ping消息的节点用pong消息作为响应 Gossip常用的 Gossip 消息可分为：ping 消息、pong 消息、meet 消息、fail 消息等。 meet 消息：用于通知新节点加入。消息发送者通知接收者加入到当前集群，meet 消息通信正常完成后，接收节点会加入到集群中并进行周期性的 ping、pong消息交换。 ping 消息：集群内交换最频繁的消息，集群内每个节点每秒向多个其他节点发送 ping 消息，用于检测节点是否在线和交换彼此状态信息。ping 消息发送封装了自身节点和部分其他节点的状态数据。 pong 消息：当接收到 ping、meet 消息时，作为响应消息回复给发送方确认消息正常通信。pong 消息内部封装了自身状态数据。节点也可以向集群内广播自身的 pong 消息来通知整个集群对自身状态进行更新。 fail 消息：当节点判定集群内另一个节点下线时，会向集群内广播一个fail消息，其他节点接收到fail消息之后把对应节点更新为下线状态。 节点选择集群内每个节点维护定时任务默认每秒执行10次，每秒会随机选取5个节点找出最久没有通信的节点发送ping消息。 如果发现节点最近一次接受pong消息的时间大于cluster_node_timeout/2，则立刻发送ping消息，防止该节点信息太长时间未更新。 4. 集群伸缩集群的水平伸缩的上层原理：集群伸缩=槽和数据在节点之间的移动 扩容集群A. 准备新节点B. 加入集群12345678# 准备节点redis-server conf/redis-6385.confredis-server conf/redis-6386.conf# 加入集群127.0.0.1:6379&gt; cluster meet 127.0.0.1 6385127.0.0.1:6379&gt; cluster meet 127.0.0.1 6386# 查看状态cluster nodes C. 迁移槽和数据迁移槽槽是Redis集群管理数据的基本单位，首先需要为新节点制定槽的迁移计划，确定原有节点的哪些槽需要迁移到新节点。 迁移计划需要确保每个节点负责相似数量的槽，从而保证各节点的数据均匀。例如，在集群中加入6385节点。加入6385节点后，原有节点负责的槽数量从6380变为4096个。 迁移数据 对目标节点发送cluster setslot {slot} importing {sourceNodeId}命令，让目标节点准备导入槽的数据。 对源节点发送cluster setslot {slot} migrating {targetNodeId}命令，让源节点准备迁出槽的数据。 源节点循环执行cluster getkeysinslot {slot} {count}命令，获取count个属于槽{slot}的键。 在源节点上执行migrate {targetIp} {targetPort} &quot;&quot; 0 {timeout} keys {keys...}命令，把获取的键通过流水线（pipeline）机制批量迁移到目标节点，批量迁移版本的migrate命令在Redis3.0.6以上版本提供，之前的migrate命令只能单个键迁移。对于大量key的场景，批量键迁移将极大降低节点之间网络IO次数。 重复执行步骤3和步骤4直到槽下所有的键值数据迁移到目标节点。 向集群内所有主节点发送cluster setslot {slot} node {targetNodeId}命令，通知槽分配给目标节点。为了保证槽节点映射变更及时传播，需要遍历发送给所有主节点更新被迁移的槽指向新节点。 伪代码： 123456789101112131415161718def move_slot(source,target,slot): # 目标节点准备导入槽 target.cluster(\"setslot\",slot,\"importing\",source.nodeId); # 源节点准备全出槽 source.cluster(\"setslot\",slot,\"migrating\",target.nodeId); while true : # 批量从源节点获取键 keys = source.cluster(\"getkeysinslot\",slot,pipeline_size); if keys.length == 0: # 键列表为空时, 退出循环 break; # 批量迁移键到目标节点 source.call(\"migrate\",target.host,target.port,\"\",0,timeout,\"keys\",keys); # 向集群所有主节点通知槽被分配给目标节点 for node in nodes: if node.flag == \"slave\": continue; node.cluster(\"setslot\",slot,\"node\",target.nodeId); 生成环境实际操作时涉及大量槽并且每个槽对应非常多的键使用，一般使用redis-trib.rb。 添加从节点6385、6386节点加入到集群，节点6385迁移了部分槽和数据作为主节点，需把6386作为6385的从节点。 在集群模式下 slaveof 添加从节点操作不再支持，需使用cluster replicate进行操作。 5. 请求路由客户端发送键命令至任意节点，会计算槽和对应节点，若发现指向自己则执行命令，若不是自己则回复MOVED。 12127.0.0.1:6379&gt; set key:test:2 value-2(error) MOVED 9252 127.0.0.1:6380 cluster keyslot key:test:1： 返回该key值对应的槽 cluster nodes：可以看到槽对应的节点 redis-cli使用-c参数时支持自动重定向，但实质是客户端接到MOVED信息后再次发送请求，并不是在redis节点中完成请求转发。 注意：如果键内容包含{和}大括号字符，则计算槽的有效部分是括号内的内容；否则采用键的全内容计算槽。这提供了不同的键具备相同slot的功能，常用于Redis IO优化，如使用mget等命令优化批量调用。 1234127.0.0.1:6379&gt; cluster keyslot key:&#123;hash_tag&#125;:111(integer) 2515127.0.0.1:6379&gt; cluster keyslot key:&#123;hash_tag&#125;:222(integer) 2515 Smart客户端Dummy（傀儡）客户端：根据MOVED重定向机制，客户端随机连接集群内任一Redis获取键所在节点。它优点是代码实现简单，对客户端协议影响较小。弊端很明显，每次执行键命令额外增加了IO开销，这不是Redis集群高效的使用方式。 Smart客户端：通过在内部维护slot→node的映射关系，本地就可实现键到节点的查找，从而保证IO效率的最大化，而MOVED重定向负责协助Smart客户端更新slot→node映射。 以Jedis为例： 初始化：JedisCluster 会选择一个运行节点，使用cluster slots初始化槽和节点映射关系，缓存结果，并为每个节点创建唯一的JedisPool连接池。 执行键命令：","categories":[{"name":"缓存","slug":"缓存","permalink":"https://weilans.github.io/categories/缓存/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://weilans.github.io/tags/redis/"}]},{"title":"Kubernetes 入门笔记","slug":"Kubernetes-入门","date":"2021-03-15T06:31:19.000Z","updated":"2021-03-15T12:37:09.230Z","comments":true,"path":"2021/03/15/Kubernetes-入门/","link":"","permalink":"https://weilans.github.io/2021/03/15/Kubernetes-入门/","excerpt":"","text":"Kubernetes 一个用于自动化部署、扩容和管理容器应用的开源系统；它将一个分布式软件的一组容器打包成一个个更容易管理和发现的逻辑单元。 它最开始由 Google 工程师创立，深受公司内部 Borg 和 Omega 项目的影响，目前是 CNCF 的项目。 主要功能： 自动装箱：基于容器对应用运行环境的资源配置要求自动部署应用容器 自我修复：当容器失败时，会对容器进行重启；当所部署的Node 节点有问题时，会对容器进行重新部署和重新调度；当容器未通过监控检查时，会关闭此容器直到容器正常运行时，才会对外提供服务 水平扩展：通过简单的命令、用户UI 界面或基于CPU 等资源使用情况，对应用容器进行规模扩大或规模剪裁 服务发现：用户不需使用额外的服务发现机制，就能够基于 Kubernetes 自身能力实现服务发现和负载均衡 滚动更新：可以根据应用的变化，对应用容器运行的应用，进行一次性或批量式更新 版本回退：可以根据应用部署情况，对应用容器运行的应用，进行历史版本即时回退 密钥和配置管理：在不需要重新构建镜像的情况下，可以部署和更新密钥和应用配置，类似热部署。 存储编排：自动实现存储系统挂载及应用，特别对有状态应用实现数据持久化非常重要存储系统可以来自于本地目录、网络存储(NFS、Gluster、Ceph 等)、公共云存储服务 批处理：提供一次性任务，定时任务；满足批量数据处理和分析的场景 Kubernetes 集群架构组件 客户端通过 RESTful 接口或者直接使用 kubectl 与 Kubernetes 集群进行通信，这两者在实际上并没有太多的区别，后者也只是对 Kubernetes 提供的 RESTful API 进行封装并提供出来。 每一个 Kubernetes 集群都由一组 Master 节点和一系列的 Worker (Node) 节点组成，其中 Master 节点主要负责存储集群的状态并为 Kubernetes 对象分配和调度资源。 Master API Server:负责处理来自用户的请求，其主要作用就是对外提供 RESTful 的接口，包括用于查看集群状态的读请求以及改变集群状态的写请求，也是唯一一个与 etcd 集群通信的组件。是 k8s 所有资源的增删改查的唯一入口。 Controller Manager一个资源对应一个控制器。运行了一系列的控制器进程，这些进程会按照用户的期望状态在后台不断地调节整个集群中的对象，当服务的状态发生了改变，控制器就会发现这个改变并且开始向目标状态迁移。可看作是k8s所有资源的自动化控制中心。 Scheduler节点调度，为 Kubernetes 中运行的 Pod 选择部署的 Worker 节点，它会根据用户的需要选择最能满足请求的节点来运行 Pod，它会在每次需要调度 Pod 时执行。 etcd保存 Kubernetes 所有集群数据的后台数据库，是兼具一致性和高可用性的键值数据库。 Worker (Node) kubelet是一个节点上的主要服务，它周期性地从 API Server 接受新的或者修改的 Pod 规范并且保证节点上的 Pod 和其中容器的正常运行，负责 Pod 对应的容器的创建、启停等任务，该节点会与 Master 节点密切协作，发送宿主机的健康状况。 kube-proxy负责宿主机的子网管理，同时也能将服务暴露给外部，实施负载均衡，其原理就是在多个隔离的网络中把请求转发给正确的 Pod 或者容器。 Kubernetes 核心概念Pod Pod 是 Kubernetes 中最基本的概念，它也是 Kubernetes 对象模型中可以创建或者部署的最小并且最简单的单元。 它将应用的容器、存储资源以及独立的网络 IP 地址等资源打包到了一起，表示一个最小的部署单元，但是每一个 Pod 中的运行的容器可能不止一个，这是因为 Pod 最开始设计时就能够在多个进程之间进行协调，构建一个高内聚的服务单元，这些容器能够共享存储和网络，非常方便地进行通信。 最小部署单元 一组容器的集合 共享网络 生命周期是短暂的 Controller用于创建和管理 Pod 的实例，能够在集群的层级提供复制、发布以及健康检查的功能，这些控制器其实都运行在 Kubernetes 集群的主节点上。 确保预期的Pod副本数量 实施无状态应用部署和有状态应用部署 Service定义一组pod的访问规则。可类比微服务架构中的一个微服务。 通过Service统一入口进行访问，由Controller创建Pod进行部署。","categories":[{"name":"k8s","slug":"k8s","permalink":"https://weilans.github.io/categories/k8s/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://weilans.github.io/tags/docker/"}]},{"title":"DDIA 读书整理- 1.可靠、可拓展与可维护的应用系统","slug":"DDIA-读书整理-1-可靠、可拓展与可维护的应用系统","date":"2021-01-24T05:18:07.000Z","updated":"2021-01-25T06:54:34.100Z","comments":true,"path":"2021/01/24/DDIA-读书整理-1-可靠、可拓展与可维护的应用系统/","link":"","permalink":"https://weilans.github.io/2021/01/24/DDIA-读书整理-1-可靠、可拓展与可维护的应用系统/","excerpt":"","text":"数据密集型数据密集型（Data-intensive）：对于一个应用系统，如果数据是其成败的决定性因素，包括：数据的规模、数据的复杂度、数据的产生与变化速率等，即可称为“数据密集型应用系统”。与之相对应的是“计算密集型系统”，CPU主频是其主要制约瓶颈。 数据密集型应用通常基于标准模块构造而成，每个模块负责单一功能，如：数据库、高速缓存、索引、流式处理、批处理等。单个组件无法满足所有数据处理与存储需求，因而需将任务分解，每个组件高效完成一部分，多组件依赖应用层代码有机衔接起来。 软件系统需主要关注三个问题： 可靠性（Reliability）：出现意外情况如硬件、软件故障、人为失误等，系统应可以继续正常运转；虽然性能可能有所降低，但确保功能正确。 可拓展性（Scalability）：随着规模的增长，例如数据量、流量或复杂性，系统应以合理的方式来匹配这种增长。 可维护性（Maintainability）：随着时间的推移，许多新的人员参与到系统开发和运维，以维护现有功能或适配新场景等，系统都应高效运转。 可靠性可简单认为是：即使发生了某些错误，系统仍可以继续工作。 故障（faults）和失效（failure）不完全一致，故障通常被定义为组件偏离常规规格，失效意味着系统作为一个整体停止，无法向客户提供所需服务。通常需要设计容错机制避免从故障引发系统失效。 一般可以通过故意引发故障的方式，来持续检验、测试系统的容错机制（Netflix - Chaos Monkey） 。 硬件故障硬盘崩溃、内存故障、电网停电、网络中断。 为硬件添加冗余来减少系统故障率：一个组价故障时，冗余组件快速接管，之后再更换失效组件。 软件错误软件BUG、某进程使用共享资源（内存、CPU等）时消耗过度、所依赖服务故障、级联故障 没有快速解决办法，需认真检查依赖条件和系统交互，进行全面测试，进程隔离，允许进程崩溃并自动重启，并监控评估行为。 人为失误 以最小出错方式设计系统。想办法分离最容易出错的地方。 充分的测试：单测、集成测试、手动测试。 快速回滚配置改动、滚动发布新代码、提供校验数据工具。 详细而清晰的监控子系统。 管理流程及培训。 可拓展性应对系统使用增长的措施、如何添加资源来处理额外的负载。 描述负载负载参数的选择取决于系统的体系结构。例如：Web 服务器每秒请求数，数据写入比例，聊天室同时在线人数，缓存命中率等。有时平均值很重要，有时系统瓶颈来自于少数峰值。 描述性能延迟（latency）和响应时间（response time）的区别在于：响应时间是客户端看到的，除了处理请求的时间外，还包括网络延迟和各种派对延迟。延迟则是请求花费在处理上的时间。很重要的一点是要在客户端来测试响应时间。 一般选择指标时，平均值并不合适，最好选择百分位数（percentiles），如将响应时间从快到慢排序，中位数（median）就是列表中间的响应时间。最常见的百分位数是95、99、99.9（即P95、P99、P999）。 还需要考虑长尾效应，如P99之外的请求恰恰可能是最重要的一个或多个，也是最有价值的一个。 实践中的百分位数：设置一个10min的滑动窗口，监控其中响应时间，滚动计算窗口中的中为数和各种百分位数然后绘制性能图表。 应对负载增加的办法特定级别负载不能应对超过目标10倍的实际负载。若目标服务处于快速增长阶段，则需认真考虑增加一个数量级的负载需如何设计。 扩展分为水平扩展（负载分布到多个更小机器）和垂直扩展（升级到更强大的机器），需在其中做出取舍。 将无状态服务扩展至多台机器相对比较容易，而有状态服务从单个节点扩展到分布式多机环境复杂度会增加。 扩展能力好的架构通常会做出某些假设，然后有针对性地优化设计，如哪些操作是最频繁的。 可维护性软件系统的三个设计原则： 可运维性：方便运营团队保持系统平稳运行 简单性：简化系统复杂性，使新人可以轻松理解系统。通过良好的抽象降低复杂度。 可演化性：后续工程师可以轻松地对系统进行改进，即易于改变","categories":[{"name":"分布式","slug":"分布式","permalink":"https://weilans.github.io/categories/分布式/"}],"tags":[{"name":"DDIA","slug":"DDIA","permalink":"https://weilans.github.io/tags/DDIA/"}]},{"title":"DDIA 读书整理- 1.可靠、可拓展与可维护的应用系统","slug":"DDIA-读书整理-3-数据存储与检索","date":"2021-01-24T05:18:07.000Z","updated":"2021-07-03T01:32:07.220Z","comments":true,"path":"2021/01/24/DDIA-读书整理-3-数据存储与检索/","link":"","permalink":"https://weilans.github.io/2021/01/24/DDIA-读书整理-3-数据存储与检索/","excerpt":"","text":"","categories":[{"name":"分布式","slug":"分布式","permalink":"https://weilans.github.io/categories/分布式/"}],"tags":[{"name":"DDIA, 数据库","slug":"DDIA-数据库","permalink":"https://weilans.github.io/tags/DDIA-数据库/"}]},{"title":"Docker 引擎结构与底层原理","slug":"Docker-引擎结构与底层原理","date":"2021-01-02T05:42:38.000Z","updated":"2021-09-24T02:18:00.177Z","comments":true,"path":"2021/01/02/Docker-引擎结构与底层原理/","link":"","permalink":"https://weilans.github.io/2021/01/02/Docker-引擎结构与底层原理/","excerpt":"","text":"Docker 引擎结构曾经的Docker曾经的Docker引擎主要包含两部分：LXC和Docker daemon： Docker daemon是单一的二进制文件，包含诸如Docker客户端、Docker API、容器运行时、镜像构建等。 LXC提供了对诸如命名空间（Namespace）和控制组（CGroup）等基础工具的操作能力，它们是基于Linux内核的容器虚拟化技术。 这两者皆有弊端： LXC 是基于Linux，无法做到跨平台。此外，过度依赖外部组件，影响发展。后开发 Libcontainer 取代LXC成为默认的执行驱动。 Docker daemon：难以变更，且运行较慢。后开展拆解和重构工作，所有容器执行和容器运行时的代码已经完全从daemon中移除，并重构为小而专的工具。 目前的DockerDocker Engine 目前主要由以下组件构成：Docker客户端（Docker Client）、Docker守护进程（Docker daemon）、containerd、runc。 启动容器示例 使用Docker命令行工具执行 docker run 命令时，Docker客户端会将其转换为合适的API格式，并发送到正确的API端点。 API是在daemon中实现的，一旦daemon接收到创建新容器的命令，它就会向containerd发出调用。daemon使用一种CRUD风格的API，通过gRPC与containerd进行通信。 虽然名叫containerd，但是它并不负责创建容器，而是指挥runc去做。containerd将Docker镜像转换为OCI bundle，并让runc基于此创建一个新的容器。 然后，runc与操作系统内核接口进行通信，基于所有必要的工具（Namespace、CGroup等）来创建容器。容器进程作为runc的子进程启动，启动完毕后，runc将会退出。 这种模型的优势在于：容器与Docker daemon是解耦的，对Docker daemon 的维护和升级不会影响到运行中的容器。 containerd所有的容器执行逻辑被重构到一个新的名为containerd（发音为container-dee）的工具中。它的主要任务是容器的生命周期管理——start | stop | pause | rm … 。 runcrunc是 OCI (开放容器计划) 容器运行时规范的参考实现。runc实质上是一个轻量级的、针对 Libcontainer 进行了包装的命令行交互工具。 runc生来只有创建容器这一个作用，它是一个CLI包装器，实质上就是一个独立的容器运行时工具。 shimcontainerd 指挥 runc 来创建新容器。事实上，每次创建容器时它都会fork一个新的runc实例。不过，一旦容器创建完毕，对应的runc进程就会退出。因此，即使运行上百个容器，也无须保持上百个运行中的runc实例。 一旦容器进程的父进程runc退出，相关联的containerd-shim进程就会成为容器的父进程。作为容器的父进程，shim的部分职责如下。 保持所有STDIN和STDOUT流是开启状态，从而当daemon重启的时候，容器不会因为管道的关闭而终止。 将容器的退出状态反馈给daemon。 Linux中的实现在 Linux 系统中，前面谈到的组件由单独的二进制来实现，具体包括： dockerd —- Docker daemon docker-containerd —- containerd docker-containerd-shim —- shim docker-runc —- runc daemon在经过剥离精简后的主要功能包括镜像管理、镜像构建、REST API、身份验证、安全、核心网络以及编排。 Docker 底层原理Namespace每个容器都有自己单独的命名空间，运行在其中的应用都像是在独立的操作系统中运行一样，命名空间保证了容器之间彼此互不影响。 namespace 是由 Linux 内核提供的，用于进程间资源隔离的一种技术，使得 a,b 进程可以看到 S 资源；而 c 进程看不到。 Linux 提供了多种 namespace，用于对多种不同资源进行隔离。容器的实质是进程，但与直接在宿主机执行的进程不同，容器进程运行在属于自己的独立的命名空间，因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。 当使用docker run –pid host --rm -it alpine sh在宿主机上运行一个简单的 alpine 容器，容器会与主机共用同一个 pid namespace。然后在容器内部执行指令 ps -a 会发现进程数量与宿主机的一样。 涉及到Namespace的操作接口包括clone()、setns()、unshare()以及还有/proc下的部分文件。在宿主机上执行ls -l /proc/self/ns 看到的就是当前系统所支持的 namespace。 123456lrwxrwxrwx 1 root root 0 Jan 2 15:05 ipc -&gt; ipc:[4026531839]lrwxrwxrwx 1 root root 0 Jan 2 15:05 mnt -&gt; mnt:[4026531840]lrwxrwxrwx 1 root root 0 Jan 2 15:05 net -&gt; net:[4026531962]lrwxrwxrwx 1 root root 0 Jan 2 15:05 pid -&gt; pid:[4026531836]lrwxrwxrwx 1 root root 0 Jan 2 15:05 user -&gt; user:[4026531837]lrwxrwxrwx 1 root root 0 Jan 2 15:05 uts -&gt; uts:[4026531838] pid 命名空间：不同用户的进程就是通过 pid 命名空间隔离开的，且不同命名空间中可以有相同 pid。 net 命名空间：进行网络隔离。 ipc 命名空间：ipc即为进程间通信 (Inter-process communication)， 包括信号量、消息队列和共享内存等。容器的进程间交互实际上还是 host 上具有相同 pid 命名空间中的进程间交互，因此需要在 IPC 资源申请时加入命名空间信息，每个 IPC 资源有一个唯一的 32 位 id。 mnt 命名空间：mnt 命名空间允许不同命名空间的进程看到的文件结构不同，这样每个命名空间 中的进程所看到的文件目录就被隔离开了。同 chroot 不同，每个命名空间中的容器在 /proc/mounts 的信息只包含所在命名空间的 mount point。 uts 命名空间：隔离主机名和域名信息 user 命名空间：每个容器可以有不同的用户和组 id， 也就是说可以在容器内用容器内部的用户执行程序而非主机上的用户。 cgroupscgroups （控制组）用来对共享资源进行隔离、限制、审计等。只有能控制分配到容器的资源，才能避免当多个容器同时运行时的对系统资源的竞争。例如可以设定一个 memory 使用上限，一旦进程组（容器）使用的内存达到限额再申请内存，就会出发 OOM（out of memory），这样就不会因为某个进程消耗的内存过大而影响到其他进程的运行。 联合文件系统UFS如果单单就隔离性来说，vagrant 也已经做到了。 docker 火爆的原因在于它允许用户将容器环境打包成为一个镜像进行分发，而且镜像是分层增量构建的，这可以大大降低用户使用的门槛。 容器可以近似理解为镜像的运行时实例，默认情况下也算是在镜像层的基础上增加了一个可写层。所以，一般情况下如果你在容器内做出的修改，均包含在这个可写层中。 UFS（Union File System ）将多个物理位置不同的文件目录联合起来，挂载到某一个目录下，形成一个抽象的文件系统。 从右侧以 UFS 的视角来看，lowerdir 和 upperdir 是两个不同的目录，UFS 将二者合并起来，得到 merged 层展示给调用方。从左侧的 docker 角度来理解，lowerdir 就是镜像，upperdir 就相当于是容器默认的可写层。在运行的容器中修改了文件，可以使用 docker commit 指令保存成为一个新镜像。 有了 UFS 的分层概念，我们易于理解 Dockerfile 中的FROM alpine这种描述。 12345docker info --format '&#123;&#123;.Driver&#125;&#125;' 获取使用的存储驱动（默认是 overlay2）docker info --format '&#123;&#123;.DockerRootDir&#125;&#125;' 镜像下载后的存储路径（默认存储在/var/lib/docker）。docker diff &lt;container&gt; 检查容器里文件结构的更改。 Reference 《深入浅出Docker》第5章节 https://mp.weixin.qq.com/s/0jFHlWAeH5avIO2NLpTmGA https://yeasy.gitbook.io/docker_practice/underly/arch","categories":[{"name":"docker","slug":"docker","permalink":"https://weilans.github.io/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://weilans.github.io/tags/docker/"}]},{"title":"Greenplum-Spark 数据传输工具: Greenplum-Spark Connector","slug":"Greenplum-Spark-数据传输工具-Greenplum-Spark-Connector","date":"2020-12-17T01:59:20.000Z","updated":"2020-12-17T08:32:31.580Z","comments":true,"path":"2020/12/17/Greenplum-Spark-数据传输工具-Greenplum-Spark-Connector/","link":"","permalink":"https://weilans.github.io/2020/12/17/Greenplum-Spark-数据传输工具-Greenplum-Spark-Connector/","excerpt":"","text":"Greenplum-Spark Connector 简称 GSC ，目前使用的版本为v1.6: https://greenplum-spark.docs.pivotal.io/1-6/index.html Greenplum-Spark Connector Version Greenplum Version Spark Version Scala Version 1.6.1, 1.6.2 4.3.x, 5.x, 6.x 2.3.1 and above 2.11 1.6.0 4.3.x, 5.x 2.1.2 and above 2.11 概述 Spark application 由 Driver 和 Executor 节点构成，当使用 GSC 加载GP数据至Spark时，Driver 会通过JDBC的方式请求 Greenplum 的 master 节点获取相关的元数据信息，这些信息帮助GSC获取到表数据存储在GP的位置，以及如何在可用的Spark工作节点切分数据或工作。 GSC 在加载Greenplum数据时，需要指定 GP 表的一个字段作为 Spark 的 partition 字段，Connector 会使用这个字段的值来计算，该 Greenplum 表的某个 segment 该被哪一个或多个Spark partition读取。 读取过程如下： Spark Driver通过Jdbc的方式连接Greenplum master，并读取指定表的相关元数据信息。然后根据指定的分区字段以及分区个数去决定segment怎么分配。 Spark Executor端会通过Jdbc的方式连接Greenplum master，创建Greenplum外部表。 然后Spark Executor通过Http方式连接Greenplum的数据节点，获取指定的segment的数据。该获取数据的操作在Spark Executor并行执行。 网络与端口需求GP Master 默认端口为 5432，Spark 的驱动和工作节点与该端口进行通信。 GSC 使用gpfdist来从 GP Segment 和 Spark 工作节点间传输数据。默认情况下，连接器使用Spark 工作节点的IP地址启动gpfdist服务进程，并暴露端口。gpfdist 的地址与端口可配。 基础使用读取123456789101112131415161718192021val spark = SparkSession.builder().master(\"local[*]\").appName(\"Spark GP Example\").getOrCreate()val gscReadOptionMap = Map( \"url\" -&gt; \"jdbc:postgresql://10.219.184.190:5432/youdata\", \"user\" -&gt; \"xxx\", \"password\" -&gt; \"xxx\", \"dbschema\" -&gt; \"test\", \"dbtable\" -&gt; \"hivespark1\", \"partitionColumn\" -&gt; \"x\")val gpdf = spark.read.format(\"greenplum\").options(gscReadOptionMap).load()gpdf.show()spark.close() 写入123456789101112131415161718192021222324val spark = SparkSession.builder().master(\"local[*]\").appName(\"Spark GP Write Example\").config(\"hive.metastore.uris\",\"thrift://xxx:9083\").enableHiveSupport().getOrCreate()val gscWriteOptionMap = Map( \"url\" -&gt; \"jdbc:postgresql://xxx:5432/xxx\", \"user\" -&gt; \"xxx\", \"password\" -&gt; \"xxx\", \"dbschema\" -&gt; \"test\", \"dbtable\" -&gt; \"hivespark_write\", \"partitionColumn\" -&gt; \"x\")spark.table(\"xx.xxx\").write.format(\"greenplum\").options(gscWriteOptionMap).mode(SaveMode.Overwrite)spark.close() 在将spark/conf/下的log4j配置加上log4j.logger.io.pivotal.greenplum.spark=DEBUG后启动： 1./spark-submit --master local[*] --class sparksql.GpWriteApp --jars ./temp/greenplum-spark_2.11-1.6.2.jar ./spark-learn-1.0-SNAPSHOT-jar-with-dependencies.jar 可以发现整个SQL执行过程： 12345678910111213CREATE TABLE \"test\".\"hivespark_write\" (\"a\" TEXT, \"b\" TEXT, \"c\" TEXT, \"d\" TEXT, \"e\" TEXT, \"f\" TEXT, \"n\" TEXT, \"na\" TEXT, \"nb\" TEXT, \"t\" TIMESTAMP, \"sa\" BIGINT, \"sb\" BIGINT, \"sc\" BIGINT, \"sd\" BIGINT, \"se\" BIGINT, \"sf\" BIGINT, \"x\" BIGINT, \"y\" BIGINT);CREATE READABLE EXTERNAL TABLE\"test\".\"spark_216956b47a67008c_3d9d854163f8f07a_driver_61\" (LIKE \"test\".\"hivespark_write\")LOCATION ('gpfdist://10.219.185.6:39825/spark_216956b47a67008c_3d9d854163f8f07a_driver_61')FORMAT 'CSV'(DELIMITER AS '|' NULL AS '')ENCODING 'UTF-8'INSERT INTO \"test\".\"hivespark_write\"SELECT * FROM \"test\".\"spark_216956b47a67008c_3d9d854163f8f07a_driver_61\"","categories":[{"name":"db","slug":"db","permalink":"https://weilans.github.io/categories/db/"}],"tags":[{"name":"greenplum","slug":"greenplum","permalink":"https://weilans.github.io/tags/greenplum/"},{"name":"spark","slug":"spark","permalink":"https://weilans.github.io/tags/spark/"}]},{"title":"Linux性能优化-网络性能篇","slug":"Linux性能优化-网络性能篇","date":"2020-12-16T03:16:03.000Z","updated":"2020-12-16T08:15:00.910Z","comments":true,"path":"2020/12/16/Linux性能优化-网络性能篇/","link":"","permalink":"https://weilans.github.io/2020/12/16/Linux性能优化-网络性能篇/","excerpt":"","text":"网络基础网络模型国际标准化组织制定的 OSI 网络模型： 应用层，负责为应用程序提供统一的接口。 表示层，负责把数据转换成兼容接收系统的格式。 会话层，负责维护计算机之间的通信连接。 传输层，负责为数据加上传输表头，形成数据包。 网络层，负责数据的路由和转发。 数据链路层，负责 MAC 寻址、错误侦测和改错。 物理层，负责在物理网络中传输数据帧。 OSI 模型过于复杂，没有提供一个可实现的方法。所以在 Linux 中实际上使用的是四层模型，即 TCP/IP 网络模型： 应用层，负责向用户提供一组应用程序，比如 HTTP、FTP、DNS 等。 传输层，负责端到端的通信，比如 TCP、UDP 等。 网络层，负责网络包的封装、寻址和路由，比如 IP、ICMP 等。 网络接口层，负责网络包在物理网络中的传输，比如 MAC 寻址、错误侦测以及通过网卡传输网络帧等。 Linux 网络栈及收发流程TCP/IP 模型后，在进行网络传输时，数据包就会按照协议栈，对上一层发来的数据进行逐层处理；然后封装上该层的协议头，再发送给下一层： 传输层在应用程序数据前面增加了 TCP 头； 网络层在 TCP 数据包前增加了 IP 头； 网络接口层，又在 IP 数据包前后分别增加了帧头和帧尾。 Linux 内核中的网络栈，其实也类似于 TCP/IP 的四层结构。 最上层的应用程序，需要通过系统调用，来跟套接字接口进行交互； 套接字的下面，就是我们前面提到的传输层、网络层和网络接口层； 最底层，则是网卡驱动程序以及物理网卡设备。 接收当一个网络帧到达网卡后，网卡会通过 DMA 方式，把这个网络包放到收包队列中；然后通过硬中断，告诉中断处理程序已经收到了网络包。 接着，网卡中断处理程序会为网络帧分配内核数据结构（sk_buff），并将其拷贝到 sk_buff 缓冲区中；然后再通过软中断，通知内核收到了新的网络帧。 内核协议栈从缓冲区中取出网络帧，并通过网络协议栈，从下到上逐层处理这个网络帧： 在链路层检查报文的合法性，找出上层协议的类型（比如 IPv4 还是 IPv6），再去掉帧头、帧尾，然后交给网络层。 网络层取出 IP 头，判断网络包下一步的走向，比如是交给上层处理还是转发。当网络层确认这个包是要发送到本机后，就会取出上层协议的类型（比如 TCP 还是 UDP），去掉 IP 头，再交给传输层处理。 传输层取出 TCP 头或者 UDP 头后，根据 &lt; 源 IP、源端口、目的 IP、目的端口 &gt; 四元组作为标识，找出对应的 Socket，并把数据拷贝到 Socket 的接收缓存中。 应用程序就可以使用 Socket 接口，读取到新接收到的数据了。 发送应用程序调用 Socket API（比如 sendmsg）发送网络包。这是一个系统调用，所以会陷入到内核态的套接字层中。套接字层会把数据包放到 Socket 发送缓冲区中。 网络协议栈从 Socket 发送缓冲区中，取出数据包；再按照 TCP/IP 栈，从上到下逐层处理。比如，传输层和网络层，分别为其增加 TCP 头和 IP 头，执行路由查找确认下一跳的 IP，并按照 MTU 大小进行分片。 分片后的网络包，再送到网络接口层，进行物理地址寻址，以找到下一跳的 MAC 地址。然后添加帧头和帧尾，放到发包队列中。这一切完成后，会有软中断通知驱动程序：发包队列中有新的网络帧需要发送。 最后，驱动程序通过 DMA ，从发包队列中读出网络帧，并通过物理网卡把它发送出去。 总结而言：应用程序通过套接字接口发送数据包时，先要在网络协议栈中从上到下逐层处理，然后才最终送到网卡发送出去；而接收数据包时，也要先经过网络栈从下到上的逐层处理，最后送到应用程序。 网络性能指标 带宽：链路的最大传输速率，单位通常为 b/s （比特 / 秒）。 吞吐量：单位时间内成功传输的数据量，单位通常为 b/s（比特 / 秒）或者 B/s（字节 / 秒）。吞吐量受带宽限制，而吞吐量 / 带宽，也就是该网络的使用率。 延时，表示从网络请求发出后，一直到收到远端响应，所需要的时间延迟。在不同场景中，这一指标可能会有不同含义。比如，它可以表示，建立连接需要的时间（比如 TCP 握手延时），或一个数据包往返所需的时间（比如 RTT）。 PPS，是 Packet Per Second（包 / 秒）的缩写，表示以网络包为单位的传输速率。PPS 通常用来评估网络的转发能力，比如硬件交换机，通常可以达到线性转发（即 PPS 可以达到或者接近理论最大值）。而基于 Linux 服务器的转发，则容易受网络包大小的影响。 查看网络接口配置ifconfig eth0 或 ip -s addr show dev eno1，其中的 -s 即 statistics，表示详细统计信息。 123456789102: eno1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 4c:cc:6a:70:20:04 brd ff:ff:ff:ff:ff:ff inet 10.219.185.6/21 brd 10.219.191.255 scope global noprefixroute dynamic eno1 valid_lft 663884sec preferred_lft 663884sec inet6 fe80::1cd9:3b98:24a8:a721/64 scope link noprefixroute valid_lft forever preferred_lft forever RX: bytes packets errors dropped overrun mcast 599375616704 1164569380 0 0 0 6200543 TX: bytes packets errors dropped carrier collsns 240792995036 650229007 0 94 0 0 第一，网络接口的状态标志。 ip 输出中的 LOWER_UP ，都表示物理网络是连通的 第二，MTU 的大小。MTU 默认大小是 1500，根据网络架构的不同，可能需要调大或者调小 MTU 的数值。 第三，网络接口的 IP 地址、子网以及 MAC 地址。 第四，网络收发的字节数、包数、错误数以及丢包情况，特别是 TX （发送）和 RX（接收） 部分的 errors、dropped、overruns、carrier 以及 collisions 等指标不为 0 时，通常表示出现了网络 I/O 问题。其中：errors 表示发生错误的数据包数，比如校验错误、帧同步错误等；dropped 表示丢弃的数据包数，即数据包已经收到了 Ring Buffer，但因为内存不足等原因丢包；overruns 表示超限数据包数，即网络 I/O 速度过快，导致 Ring Buffer 中的数据包来不及处理（队列满）而导致的丢包；carrier 表示发生 carrirer 错误的数据包数，比如双工模式不匹配、物理电缆出现问题等；collisions 表示碰撞数据包数。 查看套接字1234567# -l 表示只显示监听套接字# -t 表示只显示 TCP 套接字# -n 表示显示数字地址和端口(而不是名字)# -p 表示显示进程信息ss -ltnp | head -n 3netstat -nlp | head -n 3 查看网络吞吐量和PPS sar 增加 -n 参数就可以查看网络的统计信息，比如网络接口（DEV）、网络接口错误（EDEV）、TCP、UDP、ICMP 等等。 1234567# 数字1表示每隔1秒输出一组数据sar -n DEV 1 03:15:55 PM IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s03:15:56 PM veth06c3d3b 0.00 0.00 0.00 0.00 0.00 0.00 0.0003:15:56 PM eno1 121.00 38.00 17.09 3.92 0.00 0.00 0.00 rxpck/s 和 txpck/s 分别是接收和发送的 PPS，单位为包 / 秒。 rxkB/s 和 txkB/s 分别是接收和发送的吞吐量，单位是 KB/ 秒。 rxcmp/s 和 txcmp/s 分别是接收和发送的压缩数据包数，单位是包 / 秒。 查看带宽则是使用ethtool。 123ethtool eth0 | grep Speed# Speed: 1000Mb/s 即千兆网卡 连通性使用基于ICMP的ping 12# -c3表示发送三次ICMP包后停止ping -c3 114.114.114.114 补充： 使用 iperf 检查宿主机之间的带宽以 iperf2 为例，查找文档时不要混淆了 iperf2 和 iperf3。需要在服务端和客户端各起一个测试进程： 服务端：iperf -s -p 9999 客户端：iperf -c $SERVER_IP -p 9999 -i 1 注意：服务端标准输出显示的是服务端的入站带宽（download / ingress），客户端标准输出显示的是客户端的出站带宽（upload / egress），在使用工具（如 tc）修改网络设置后，明白这点很重要。 使用 qperf 检查宿主机之间的延迟同样需要在服务端和客户端各起一个测试进程： 服务端：qperf 客户端：qperf -vvs $SERVER_IP tcp_lat qperf 也可用于检查带宽，但是依然建议使用 iperf 检查，iperf 这个工具更加成熟。 Ref: How to use qperf to measure network bandwidth and latency performance?","categories":[{"name":"linux","slug":"linux","permalink":"https://weilans.github.io/categories/linux/"}],"tags":[{"name":"network","slug":"network","permalink":"https://weilans.github.io/tags/network/"}]},{"title":"Linux性能优化-CPU篇","slug":"Linux性能优化-CPU篇","date":"2020-12-13T01:55:07.000Z","updated":"2021-07-29T07:43:18.260Z","comments":true,"path":"2020/12/13/Linux性能优化-CPU篇/","link":"","permalink":"https://weilans.github.io/2020/12/13/Linux性能优化-CPU篇/","excerpt":"","text":"平均负载平均负载提供了一个快速查看系统整体性能的手段。平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数，它和 CPU 使用率并没有直接关系。 可运行状态进程，是指正在使用 CPU 或者正在等待 CPU 的进程（ ps 命令看到的处于 R 状态 Running 或 Runnable）的进程 不可中断状态进程：是正处于内核态关键流程中的进程，这些流程不可打断，如等待硬件设备的 I/O 响应（ ps 命令中看到的 D 状态 Uninterruptible Sleep，也称为 Disk Sleep）的进程 可以简单理解为，平均负载其实就是平均活跃进程数。平均活跃进程数，直观上的理解就是单位时间内的活跃进程数，实际上是活跃进程数的指数衰减平均值。 当平均负载为 2 时，意味着： 在只有 2 个 CPU 的系统上，意味着所有的 CPU 都刚好被完全占用 在 4 个 CPU 的系统上，意味着 CPU 有 50% 的空闲 在只有 1 个 CPU 的系统中，则意味着有一半的进程竞争不到 CPU 查看CPU个数1grep 'model name' /proc/cpuinfo | wc -l 负载是否合理比较 load1 / load5 / load15： 如果 1 分钟、5 分钟、15 分钟的三个值基本相同，或者相差不大，那就说明系统负载很平稳。 如果 1 分钟的值远小于 15 分钟的值，就说明系统最近 1 分钟的负载在减少，而过去 15 分钟内却有很大的负载。 如果 1 分钟的值远大于 15 分钟的值，就说明最近 1 分钟的负载在增加，这种增加有可能只是临时性的，也有可能还会持续增加下去，所以就需要持续观察。 一般生产环境下，当 ，就应该分析排查负载高的问题了。 平均负载与 CPU 使用率平均负载不仅包括了正在使用 CPU 的进程，还包括等待 CPU 和等待 I/O 的进程。 CPU 使用率，是单位时间内 CPU 繁忙情况的统计，跟平均负载并不一定完全对应： CPU 密集型进程，使用大量 CPU 会导致平均负载升高，此时这两者是一致的； I/O 密集型进程，等待 I/O 也会导致平均负载升高，但 CPU 使用率不一定很高； 大量等待 CPU 的进程调度也会导致平均负载升高，此时的 CPU 使用率也会比较高。 工具使用yum install -y sysstat mpstat：多核 CPU 性能分析工具，用来实时查看每个 CPU 的性能指标，以及所有 CPU 的平均指标。 pidstat：进程性能分析工具，用来实时查看进程的 CPU、内存、I/O 以及上下文切换等性能指标。 12345678910111213141516171819202122-u：默认的参数，显示各个进程的cpu使用统计-r：显示各个进程的内存使用统计-d：显示各个进程的IO使用情况-p：指定进程号-w：显示每个进程的上下文切换情况-t：显示选择任务的线程的统计信息外的额外信息# 所有进程的 CPU 使用情况pidstatpidstat -u -p ALL# 间隔5秒后输出一组数据pidstat -u 5 1# 内存使用，指定进程，每秒展示一次，展示四次pidstat -r -p 29468 1 4# 各进程的IO使用pidstat -d# 进程的上下文切换pidstat -w# 特定进程的线程统计信息pidstat -t -p 12920# 表示输出线程的上下文切换指标pidstat -wt 1 CPU 上下文切换任务运行前，CPU 都需要知道任务从哪里加载、又从哪里开始运行，即需要系统事先帮它设置好 CPU 寄存器和程序计数器。 CPU 上下文：CPU在运行前必须依赖的环境。一是CPU 寄存器，是 CPU 内置的容量小、但速度极快的内存。二是程序计数器，则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。 CPU上下文切换：先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。根据任务的不同，CPU 的上下文切换就可以分为几个不同的场景：进程上下文切换、线程上下文切换以及中断上下文切换。 过多的上下文切换，会把 CPU 时间消耗在寄存器、内核栈以及虚拟内存等数据的保存和恢复上。 进程上下文切换： 把进程的运行空间分为内核空间和用户空间。进程在用户空间运行时，被称为进程的用户态，而陷入内核空间的时候，被称为进程的内核态。从用户态到内核态的转变，需要通过系统调用来完成。 系统调用过程也会发生CPU上下文切换，一次系统调用的过程，其实是发生了两次 CPU 上下文切换。不过系统调用过程中，并不会涉及到用户态资源，也不会切换进程。这跟通常所说的进程上下文切换是不一样。系统调用过程通常称为特权模式切换，而不是上下文切换。 进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态。进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态。因此，进程的上下文切换就比系统调用时多了一步：在保存当前进程的内核状态和 CPU 寄存器之前，需要先把该进程的虚拟内存、栈等保存下来；而加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈。 保存上下文和恢复上下文的过程并不是“免费”的，需要内核在 CPU 上运行才能完成。每次上下文切换都需要几十纳秒到数微秒的 CPU 时间。在进程上下文切换次数较多的情况下，很容易导致 CPU 将大量时间耗费在寄存器、内核栈以及虚拟内存等资源的保存和恢复上，进而大大缩短了真正运行进程的时间。这也正是导致平均负载升高的一个重要因素。 线程上下文切换： 线程是调度的基本单位，而进程则是资源拥有的基本单位。所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。这些资源在上下文切换时是不需要修改的。另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。 线程的上下文切换其实就可以分为两种情况： 前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。 前后两个线程属于同一个进程。因为虚拟内存是共享的，所以在切换时虚拟内存这些资源就保持不动，只需切换线程的私有数据、寄存器等不共享数据。 同进程内的线程切换，要比多进程间的切换消耗更少的资源，而这，也正是多线程代替多进程的一个优势。 中断上下文切换： 为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。 中断上下文切换并不涉及到进程的用户态。 对同一个 CPU 来说，中断处理比进程拥有更高的优先级。 工具使用vmstat 主要用来分析系统的内存使用情况，也常用来分析 CPU 上下文切换和中断的次数。主要是给出系统总体的上下文切换情况： cs（context switch）是每秒上下文切换的次数。 in（interrupt）则是每秒中断的次数。 r（Running or Runnable）是就绪队列的长度，也就是正在运行和等待 CPU 的进程数。 b（Blocked）则是处于不可中断睡眠状态的进程数。 分析进程使用情况需使用pidstat -w: cswch ，表示每秒自愿上下文切换（voluntary context switches）的次数， nvcswch ，表示每秒非自愿上下文切换（non voluntary context switches）的次数。 所谓自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。而非自愿上下文切换，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。 自愿上下文切换变多了，说明进程都在等待资源，有可能发生了 I/O 等其他问题； 非自愿上下文切换变多了，说明进程都在被强制调度，也就是都在争抢 CPU，说明 CPU 的确成了瓶颈； 中断次数变多了，说明 CPU 被中断处理程序占用，还需要通过查看 /proc/interrupts 文件（watch -d cat /proc/interrupts）来分析具体的中断类型。 CPU 使用率/proc/stat 提供系统的 CPU 和任务统计信息； /proc/[pid]/stat展示进程的CPU和任务统计信息； 一般性能分析工具给出的都是间隔一段时间的平均 CPU 使用率，所以要注意间隔时间的设置； CPU 常见统计字段： user（通常缩写为 us），代表用户态 CPU 时间。注意，它不包括下面的 nice 时间，但包括了 guest 时间。 nice（通常缩写为 ni），代表低优先级用户态 CPU 时间，也就是进程的 nice 值被调整为 1-19 之间时的 CPU 时间。这里注意，nice 可取值范围是 -20 到 19，数值越大，优先级反而越低。 system（通常缩写为 sys），代表内核态 CPU 时间。 idle（通常缩写为 id），代表空闲时间。注意，它不包括等待 I/O 的时间（iowait）。 iowait（通常缩写为 wa），代表等待 I/O 的 CPU 时间。 irq（通常缩写为 hi），代表处理硬中断的 CPU 时间。 softirq（通常缩写为 si），代表处理软中断的 CPU 时间。 steal（通常缩写为 st），代表当系统运行在虚拟机中的时候，被其他虚拟机占用的 CPU 时间。 guest（通常缩写为 guest），代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的 CPU 时间。 guest_nice（通常缩写为 gnice），代表以低优先级运行虚拟机的时间。 要弄清楚用户（%user）、Nice（%nice）、系统（%system） 、等待 I/O（%iowait） 、中断（%irq）以及软中断（%softirq）这几种不同 CPU 的使用率： 用户 CPU 和 Nice CPU 高，说明用户态进程占用了较多的 CPU，所以应该着重排查进程的性能问题。 系统 CPU 高，说明内核态占用了较多的 CPU，所以应该着重排查内核线程或者系统调用的性能问题。 I/O 等待 CPU 高，说明等待 I/O 的时间比较长，所以应该着重排查系统存储是不是出现了 I/O 问题。 软中断和硬中断高，说明软中断或硬中断的处理程序占用了较多的 CPU，所以应该着重排查内核中的中断服务程序。 问题：系统CPU很高，但找不到对应的进程 首先要想到有可能是短时应用导致的问题，比如有可能是下面这两种情况： 第一，应用里直接调用了其他二进制程序，这些程序通常运行时间比较短，通过 top 等工具也不容易发现。 第二，应用本身在不停地崩溃重启，而启动过程的资源初始化，很可能会占用相当多的 CPU。这类进程可以用 pstree 或者 execsnoop 找到它们的父进程，再从父进程所在的应用入手，排查问题的根源。","categories":[{"name":"linux","slug":"linux","permalink":"https://weilans.github.io/categories/linux/"}],"tags":[{"name":"cpu","slug":"cpu","permalink":"https://weilans.github.io/tags/cpu/"}]},{"title":"","slug":"Spark","date":"2020-11-30T02:18:45.000Z","updated":"2020-12-02T09:24:57.790Z","comments":true,"path":"2020/11/30/Spark/","link":"","permalink":"https://weilans.github.io/2020/11/30/Spark/","excerpt":"","text":"Spark特点： Speed / Generality / Ease of use / Runs Everywhere 快的原因： 基于内存，而非基于磁盘。 基于DAG 有向无环图 的执行引擎 MR是进程级别运行，Spark是基于线程模型（线程池） local模式： ./spark-shell –master local[2] standalone模式 spark-env.sh 123SPARK_WORKER_CORES=2SPARK_WORKER_MEMORY=2gSPARK_WORKER_INSTANCES=1 slaves 文件slave启动在哪些机器上 ./sbin/start-all.sh SQL on Hadoop1）Hive sql ==&gt; mapreduce metastore ： 元数据 sql：database、table、view facebook 2）impala cloudera ： cdh、cm sql：自己的守护进程执行的，非mr 高内存要求 metastore 3）presto facebook 京东 sql 4）drill sql 可访问：hdfs、rdbms、json、hbase、mongodb、s3、hive 5）Spark SQL sql dataframe/dataset api metastore 访问：hdfs、rdbms、json、hbase、mongodb、s3、hive ==&gt; 外部数据源 hive –service metastore hive-site.xml 放到spark conf目录下 –jars 传递mysql驱动包 ./spark-shell –master local[2] –jars /root/hive-1.1.0/lib/mysql-connector-java-5.1.48.jar spark.sql(“select * from youdata.mock_table_1”).show 可直接输入sql ./spark-sql –master local[2] –jars /root/hive-1.1.0/lib/mysql-connector-java-5.1.48.jar select * from emp e join dept d on e.deptno=d.deptno; explain extented sql 输出执行计划 thriftserver ./start-thriftserver.sh –master local[2] –jars /root/hive-1.1.0/lib/mysql-connector-java-5.1.48.jar thriftserver和普通的spark-shell/spark-sql有什么区别？1）spark-shell、spark-sql都是一个spark application；2）thriftserver， 不管你启动多少个客户端(beeline/code)，永远都是一个spark application 解决了一个数据共享的问题，多个客户端可以共享数据； A Dataset is a distributed collection of data：分布式的数据集 A DataFrame is a Dataset organized into named columns.以列（列名、列的类型、列值）的形式构成的分布式数据集，按照列赋予不同的名称 DataFrame和RDD互操作的两种方式：1）反射：case class 前提：事先需要知道你的字段、字段类型 2）编程：Row 如果第一种情况不能满足你的要求（事先不知道列） 3) 选型：优先考虑第一种 DataFrame = Dataset[Row]Dataset：强类型 typed case classDataFrame：弱类型 Row","categories":[],"tags":[]},{"title":"JVM-内存区域与垃圾收集器","slug":"JVM-内存区域与垃圾收集器","date":"2020-08-30T11:44:58.000Z","updated":"2021-03-23T13:27:50.630Z","comments":true,"path":"2020/08/30/JVM-内存区域与垃圾收集器/","link":"","permalink":"https://weilans.github.io/2020/08/30/JVM-内存区域与垃圾收集器/","excerpt":"","text":"运行内存区域程序计数器当前线程所执行的字节码的行号指示器，字节码解释器就是通过改变该计数器来选取下一个要执行的字节码指令。 多线程的情况下线程切换后回到正确的执行位置需要该计数器。 线程私有。该区域不会存在OOM情况。 虚拟机栈线程私有。描述方法执行时线程的内存模型，每个方法被执行时，虚拟机会创建一个栈帧用于存放局部变量表、方法出口等信息。 方法被调用到执行完毕，对应一个栈帧在虚拟机栈中从入栈到出栈的过程。 常规的“栈”指的是虚拟机栈，更多指的是局部变量表，局部变量表存放编译器可知的基本数据类型、对象引用等。 如果线程请求的栈深度大于虚拟机允许的深度，会抛出StackOverflowError；如果线程申请栈空间申请失败时会报OOM。 本地方法栈本地方法栈为虚拟机使用到的本地方法（Native）服务（虚拟机栈为虚拟机执行Java方法，即执行字节码服务）。 本地方法栈也会在栈深度溢出或栈内存申请失败也会报StackOverflowError或OOM。 Java堆用于存放对象实例，虚拟机规范对堆的描述是：所有的对象实例以及数组都应在堆上分配。 但随着逃逸分析技术的发展，栈上分配、标量替换等优化手段使对象实例都分配在堆上已不绝对。 传统的经典分代：新生代（1Een+2Survivor）和老年代是Hotspot采用的方式。 Java7之后 字符串常量池在堆中，类的静态变量也转移到了堆中（本身在堆，但引用是元数据的一部分，在Metaspace）。 Java堆一旦没有内存完成实例分配，则会报OOM。 方法区各线程共享，主要存放被加载的类型信息等。 永久代只是 Hotspot 中的概念，且在 JDK8 之后也被废弃，现使用在本地内存中实现的元空间来代替，类型信息由元空间进行管理。 虚拟机规范规定，如果方法区无法满足新的内存分配需求，将抛出OOM。 运行时常量池是方法区的一部分，存放编译器生成的各种字面量和符号引用。 运行时常量池具备动态性，新常量也可以进入池中。 https://www.cnblogs.com/wangymd/p/13213265.html https://www.cnblogs.com/tiancai/p/12674192.html","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://weilans.github.io/tags/jvm/"}]},{"title":"Redis-持久化","slug":"Redis-持久化","date":"2020-08-29T04:31:07.000Z","updated":"2020-09-08T03:32:59.520Z","comments":true,"path":"2020/08/29/Redis-持久化/","link":"","permalink":"https://weilans.github.io/2020/08/29/Redis-持久化/","excerpt":"","text":"RDB1. 触发可以分为手动触发和自动触发： 手动触发 bgsave 命令，Redis 进程执行 fork 操作创建子进程，RDB过程由子进程负责，完成后自动结束。阻塞只发生在 fork 阶段，一般时间很短。 save 命令，已舍弃，会阻塞 Redis 直至 RDB 完成。 自动触发内部自动触发使用的都是 bgsave 的形式 配置文件中的 save 配置：save m n 表示m秒内数据集存在 n 次修改时，自动触发 bgsave。 从节点执行全量复制操作，主节点自动执行 bgsave 生成 RDB 文件并发送给从节点。 执行 shutdown 时，如果没有开启 aof，则会自动执行 bgsave。 执行 debug reload 时。 debug reload 用于更改配置后重新加载 Redis，RunID不变（RunID 如若改变，会使从节点重新做全量复制），从而避免不必要的全量复制。但 debug reload 会阻塞当前Redis节点主线程，阻塞期间会生成本地 RDB 快照并清空数据之后再加载 RDB 文件。 2. 执行流程123415718:M 29 Aug 12:24:08.523 * 1 changes in 900 seconds. Saving...15718:M 29 Aug 12:24:08.529 * Background saving started by pid 8845888458:C 29 Aug 12:24:08.535 * DB saved on disk15718:M 29 Aug 12:24:08.631 * Background saving terminated with success 当执行 bgsave 命令后： 父进程判断当前是否存在正在执行的子进程，如 RDB/AOF 子进程，如果存在 bgsave 命令直接返回； 父进程执行fork操作创建子进程，fork操作过程中父进程会阻塞； fork 完成后便返回 Background saving started信息，不再阻塞父进程； 子进程创建 RDB 文件（紧凑的二进制文件），根据父进程内存生成临时快照文件，完成后对原有文件进行原子替换； 子进程发送信号给父进程表示已完成，父进程更新统计信息。 文件位置和命名由配置文件中的dir和dbfilename所决定。手动 config set dir {newDir}和config set dbfilename {newFileName}运行期动态执行。 RDB 文件可以使用 redis-check-dump 工具进行校验，加载损坏的 RDB 文件时 Redis 会拒绝启动。 3. 优缺点优点非常适合于备份、全量复制等场景，也常用于灾难恢复。且其加载速度会远远快于 AOF。 缺点实时持久化/秒级持久化无法支持（bgsave的 fork 成本较高，属于重量级操作）。 老版本 Redis 可能无法支持新版本的 RDB 文件（RDB格式有多版）。 AOFAppend only file：独立日志的方式记录每次写命令，重启时再重新执行 AOF 文件中的命令达到恢复数据的目的。AOF 的主要作用是解决了数据持久化的实时性，是目前 Redis 持久化的主流方式。 AOF 默认不开启， 配置文件中需要设置 appendonly yes，AOF 文件名通过appendfilename配置，由dir指定路径。 0. 处理流程 所有的写入命令追加到 aof_buf（缓冲区）； AOF 缓冲区根据对应的策略（always、everysec、no）向硬盘做同步操作； 随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的； 当 Redis 服务器重启时，可以加载 AOF 文件进行数据恢复。 1. 命令写入写入的内容直接是文本协议格式（兼容性好、有可读性，便于直接修改处理）。 引入aof_buf：Redis 使用单线程响应命令，直接落盘性能完全由磁盘左右。同时，缓冲区同步磁盘的策略也可由用户作出平衡。 2. 文件同步 即 AOF 缓冲区同步到磁盘。appendfsync 配置的可选参数如下： 策略 说明 建议 always 命令写入buf后调用fsync同步到AOF文件，fsync完成后线程返回 性能较差，不建议配置 everysec 命令写入buf后调用write，write完成后返回。fsync同步文件操作由专门线程每秒执行1次 建议，且为默认，兼顾性能和数据安全性。系统突然宕机只丢失少量数据 no 命令写入buf后调用write，不做fsync同步。同步磁盘操作由操作系统完成，一般周期最长30s 操作系统每次同步AOF文件的周期不可控，而且会加大每次同步硬盘的数据量，虽然提升了性能，但数据安全性无法保证 write操作会触发延迟写（delayed write）机制。Linux在内核提供页缓冲区用来提高硬盘IO性能。write在写入系统缓冲区后直接返回。同步硬盘操作依赖于系统调度机制，例如：缓冲区页空间写满或达到特定时间周期。同步文件之前，如果此时系统故障宕机，缓冲区内数据将丢失。 fsync针对单个文件操作（比如AOF文件），做强制硬盘同步，fsync 将阻塞直到写入硬盘完成后返回，保证了数据持久化。 3. 重写机制Redis 使用 AOF 重写机制压缩文件体积，重写后的 AOF 文件不会包含超时的数据，重写直接使用进程内数据直接生成，不会包含无效的命令，多条写命令也可合并为一个。最终更小的 AOF 文件能被 Redis 更快的加载。 AOF 重写的触发： 手动 bgrewriteaof 自动：auto-aof-rewrite-min-size(AOF重写时文件最小体积，默认为64MB)和auto-aof-rewrite-percentage(当前AOF文件空间aof_current_size和上一次重写后AOF文件空间aof_base_size的比值)参数确定自动触发时机。 1aof_current_size &gt; auto-aof-rewrite-min-size &amp;&amp;（aof_current_size - aof_base_size）/ aof_base_size &gt;= auto-aof-rewrite-percentage 流程 如果当前进程正在执行AOF重写，请求不执行，如果当前进程正在执行bgsave操作，重写命令延迟到bgsave完成之后再执行； 父进程执行fork创建子进程； 主进程 fork 操作完成后响应其他命令。所有修改命令依然写入AOF 缓冲区并根据 appendfsync 策略同步到硬盘； 由于fork操作运用写时复制技术，子进程只能共享fork操作时的内存数据。由于父进程依然响应命令，Redis使用AOF重写缓冲区保存这部分新数据，防止新AOF文件生成期间丢失这部分数据； 子进程根据内存快照，按照命令合并规则写入到新的AOF文件。每次批量写入硬盘数据量由配置aof-rewrite-incremental-fsync控制，默认为32MB，防止单次刷盘数据过多造成硬盘阻塞； 新AOF文件写入完成后，子进程发送信号给父进程，父进程更新统计信息； 父进程把AOF重写缓冲区的数据写入到新的AOF文件； 使用新AOF文件替换老文件，完成AOF重写。 4. 重启加载AOF持久化开启且存在AOF文件时，优先加载AOF文件 AOF关闭或者AOF文件不存在时，加载RDB文件 加载AOF/RDB文件成功后，Redis启动成功 AOF/RDB文件存在错误时，Redis启动失败并打印错误信息。 对于错误格式的AOF文件，先进行备份，然后采用redis-check-aof --fix命令进行修复，修复后使用diff -u对比数据的差异，找出丢失的数据，有些可以人工修改补全。 AOF文件可能存在结尾不完整的情况（如机器突然掉电），Redis 为我们提供aof-load-truncated配置来兼容这种情况，默认开启。加载 AOF 时，当遇到此问题时会忽略并继续启动。 补充Fork fork 是个重量级操作，虽然 fork 创建的子进程不需要拷贝父进程的物理内存空间，但是会复制父进程的空间内存页表。例如对于 10GB 的 Redis 进程，需要复制大约 20MB 的内存页表，因此 fork 操作耗时跟进程总内存量息息相关。 正常情况下fork耗时应该是每GB消耗20毫秒左右。 改善 fork 操作的耗时：控制Redis实例最大可用内存，fork耗时跟内存量成正比，线上建议每个Redis实例内存控制在10GB以内。 子进程通过fork操作产生后，占用内存大小等同于父进程，理论上需要两倍的内存来完成持久化操作，但 Linux 有写时复制机制（copy-on-write）。父子进程会共享相同的物理内存页，当父进程处理写请求时会把要修改的页创建副本，而子进程在 fork 操作过程中共享整个父进程内存快照。 fork 出来的子进程把数据写到文件也属于CPU密集操作。 避免在大量写入时，做子进程重写操作，这样将导致父进程维护大量页副本，造成内存消耗。 如果重写过程中存在内存修改操作，父进程负责创建所修改内存页的副本，日志中看出这部分内存消耗了5MB，可以等价认为RDB重写消耗了5MB的内存。 1234* Background saving started by pid 7692* DB saved on disk* RDB: 5 MB of memory used by copy-on-write* Background saving terminated with success AOF 重写时需要重写缓冲区，因此根据日志可以预估内存消耗为：53MB + 1.49MB，就是AOF重写时子进程消耗的内存量。 123456789* Background append only file rewriting started by pid 8937* AOF rewrite child asks to stop sending diffs.* Parent agreed to stop sending diffs. Finalizing AOF...* Concatenating 0.00 MB of AOF diff received from parent.* SYNC append only file rewrite performed* AOF rewrite: 53 MB of memory used by copy-on-write* Background AOF rewrite terminated with success* Residual parent diff successfully flushed to the rewritten AOF (1.49 MB)* Background AOF rewrite finished successfully AOF重写时会消耗大量硬盘IO。 AOF追加阻塞同步硬盘的策略是everysec时，使用另一条线程每秒执行fsync同步硬盘。当系统硬盘资源繁忙时，会造成Redis主线程阻塞。 主线程负责写入AOF缓冲区。AOF线程负责每秒执行一次同步磁盘操作，并记录最近一次同步时间。主线程负责对比上次AOF同步时间： 如果距上次同步成功时间在2秒内，主线程直接返回。 如果距上次同步成功时间超过2秒，主线程将会阻塞，直到同步操作完成。 所以：配置 everysec 时，最多可能丢失 2 秒数据，不是 1 秒；如果系统 fsync 缓慢，将会导致 Redis 主线程阻塞影响效率。","categories":[{"name":"缓存","slug":"缓存","permalink":"https://weilans.github.io/categories/缓存/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://weilans.github.io/tags/redis/"}]},{"title":"Docker 网络综述","slug":"Docker-网络综述","date":"2020-03-29T03:02:01.000Z","updated":"2021-09-03T07:33:52.154Z","comments":true,"path":"2020/03/29/Docker-网络综述/","link":"","permalink":"https://weilans.github.io/2020/03/29/Docker-网络综述/","excerpt":"","text":"Docker 网络综述1. Docker 网络模型Docker的网络架构由三个主要部分构成：CNM（Container Networking Mode 容器网络模型）、Libnetwork、驱动。CNM 是设计标准，该方案是开源且支持插接式连接。而 Libnetwork 是 CNM 的具体实现，通过 Go 语言编写实现了 CNM 中列举的核心组件。驱动则以实现特定网络拓扑的形式达成模型扩展。 CNM CNM 中定义了几个基本元素： Sandbox 沙盒：Sandbox 作为一个独立的网络栈，管理着网络接口、DNS配置、路由表等。一个 Sandbox 可以包含来自多个网络的不同 Endpoint。Snadbox 的典型实现为 Linux Network Namespace。 Endpoint 终端：负责将 Sandbox 连接至网络。其意义就在于服务可使用不同类型的 Driver，不必关心与网络的连接方式。 Network 网络：CNM 并没有明确定义 Network 的形式，其典型实现可以是 Linux 网桥或者 VLAN。Network 就是需要进行交互的 Endpoint 的集合。 Libnetwork早期 Docker 的网络部分集中在 Daemon 上，后续 Docker 将网络部分从其中拆分并重构一个叫作 Libnetwork 的类库，实现了 CNM 中定义的全部三个组件，还实现了网络控制层和管理层的功能。 驱动驱动负责处理网络连通性和隔离性，Docker 内置的驱动包括：bridge、overlay、MACVLAN、host、none。 默认情况下，none 、host、bridge 会在每个 Docker host 中存在且无法被移除。当初始化 Swarm 时，两个额外的网络：名为docker_gwbridge的 bridge 网络和名为ingress的 overaly 会自动创建以进行集群通信。 123456NETWORK ID NAME DRIVER SCOPE1475f03fbecb bridge bridge locale2d8a4bd86cb docker_gwbridge bridge local407c477060e7 host host localf4zr3zrswlyg ingress overlay swarmc97909a4b198 none null local Docker 内置网络驱动借助于 Linux 网络模块，如Linux bridges, network namespaces, veth pairs, iptables 来实现复杂网络的转发规则、分隔、管理。 2. Docker 网络原理基础Docker 启动时会在宿主机建立一个名为docker0的虚拟网桥，当启动容器时会基于 docker0 网段划分私有IP，容器内部对应的接口是eth0。 创建容器时的网络处理如下： 创建一对veth pair放入宿主机和容器中 宿主机一端桥接到默认的docker0网桥，具有唯一名称 vethf49dd9f （veth*） 进入容器中的一端名称改为 eth0，该网络接口只在容器内可见。 从网桥的可用地址中获取一个空闲地址分配给容器中的eth0，并配置默认路由到桥接网卡 veth*。 当容器销毁时，容器内的eth0会随网络命名空间一起被清除，veth*接口也会从docker0中卸载。 1234567891011121314151617181920212223#宿主机$ ip a4: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default ··· inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 ···6: vethf49dd9f@if5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default ··· $ brctl showbridge name bridge id STP enabled interfacesdocker0 8000.0242dbecf190 no vethf49dd9f#容器$ docker exec -it b9 ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000 ··· inet 127.0.0.1/8 scope host lo ···5: eth0@if6: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UP ··· inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 ··· Linux Network Namespace可以手动实践 Linux Network Namespace，创建两个 Namespace 后创建一对veth pair进行连接测试。 12345678910111213141516171819# 创建两个 namespace$ ip netns add test1$ ip netns add test2# 查看 namespace$ ip netns ls# 创建一对 veth pair$ ip link add veth-test1 type veth peer name veth-test2# 分别置入两个namespace$ ip link set veth-test1 netns test1$ ip link set veth-test2 netns test2# 设置IP$ ip netns exec test1 ip addr add 192.168.1.1/24 dev veth-test1$ ip netns exec test2 ip addr add 192.168.1.2/24 dev veth-test2# 将link从DOWN置为UP$ ip netns exec test1 ip link set dev veth-test1 up$ ip netns exec test2 ip link set dev veth-test2 up# ping测试$ ip netns exec test1 ping 192.168.1.2$ ip netns exec test2 ping 192.168.1.1 2 个 namespace 之间可以借助 veth pair通信 ，多个 namespace 之间的通信则可以使用 bridge 来转接，不然每两个 namespace 都去配 veth pair 将会是一件麻烦的事。 3. 单机桥接网络Linux Docker 创建单机桥接网络采用内置桥接驱动（Windows Docker 采用内置的 NAT 驱动）。默认情况下用户若不指定--network，新建的容器都会连接至该网络。默认的 bridge网络被映射到docker0网桥上。 12docker network inspect bridge | grep com.docker.network.bridge.name\"com.docker.network.bridge.name\": \"docker0\", 可以自己创建一个桥接网络 localnet，Docker 桥接网络 localnet 就与 Linux 上的网桥 br-eef11882ad29 一一对应。新建的容器就可以指定--network localnet使用此网络。 12345$ docker network create -d bridge localnet$ brctl showbridge name bridge id STP enabled interfacesdocker0 8000.0242dbecf190 no br-eef11882ad29 8000.02421164377f no 使用新建的桥接网络和默认 Bridge 的区别在于：默认 Bridge 网络不支持通过 Docker DNS 服务进行域名解析的，但自定义桥接网络可以。因为 test2 运行了一个本地 DNS 解析器，该解析器将请求转发到了 Docker 内部DNS服务器当中。DNS服务器中记录了容器启动时通过--name或者--net-alias参数指定的名称与容器之间的映射关系。 12345$ docker run -d --name test1 --network localnet busybox /bin/sh -c \"while true;do sleep 3600; done\" # 5f37f36c$ docker run -d --name test2 --network localnet busybox /bin/sh -c \"while true;do sleep 3600; done\" # fff713dc$ docker exec -it 5f ping test2PING test2 (172.18.0.3): 56 data bytes64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.119 ms 桥接网络中的容器只能与位于相同网络中的容器进行通信。若想绕过此限制，可使用端口映射，不过这种方式会占用宿主机端口。 此外，容器内数据包是如何访问外网的呢？例如连接到 docker0 的容器想要访问外网，宿主机的 eth0 可以访问外网。在 docker0 和 eth0 有一层 NAT（网络地址转换），将经由 docker0 的地址转化为经由 eth0 的地址。NAT 是由 iptables实现的。 4. 多机覆盖网络5. DNS服务发现在 Swarm 中服务可以通过名称相互定位，其底层实现就是利用了 Docker 内置的 DNS 解析器，为每个容器提供 DNS 解析功能。以 c1 容器中 ping c2 为例： ping c2 会调用本地 DNS 解析器，每个 Docker 容器都有本地 DNS 解析器。 若本地解析器的本地缓存没有找到 c2 对应的 IP，本地解析器会向 Docker DNS 服务器发起递归查询，本地解析器会预先配置好 Docker DNS 服务器信息的。 Docker DNS 服务器记录全部容器名称与 IP 的映射关系，容器名称是在创建时通过--name或者--net-alias参数设置的。 Docker DNS 服务将 c2 IP 发送 c1 本地解析器。 发送 ping 命令至 c2。 服务发现受网络限制的，DNS 解析只对位于同一网络中的容器和服务生效。如果两个容器在不同的网络，那么就不能互相解析。 回顾：Docker 网络基础命令 2 docker network ls 列出运行在本地 Docker 上的全部网络 docker network create 创建新的Docker网络，可使用-d参数指定驱动 docker network inspect Docker 网络详细配置信息 docker network prune 删除 Docker 主机上全部未使用的网络 docker network rm 删除 Docker 主机上指定网络 Reference深入浅出 Docker 第11章、第12章 Docker Labs https://blog.waterstrong.me/docker-networking/ https://coding.imooc.com/class/chapter/189.html#Anchor https://www.cnblogs.com/bakari/p/10443484.html https://www.cnblogs.com/charlieroro/p/9897975.html","categories":[{"name":"docker","slug":"docker","permalink":"https://weilans.github.io/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://weilans.github.io/tags/docker/"}]},{"title":"Redis 复制","slug":"Redis-复制","date":"2020-03-14T13:08:05.000Z","updated":"2020-08-29T07:36:54.640Z","comments":true,"path":"2020/03/14/Redis-复制/","link":"","permalink":"https://weilans.github.io/2020/03/14/Redis-复制/","excerpt":"","text":"复制复制是高可用 Redis 的基础，哨兵和集群都是在复制的基础上实现高可用的。 Redis实例分为主节点和从节点，默认情况下都是主节点。每个从节点只有一个主节点，主节点可以同时具有多个从节点。复制的数据流是单向的，只能从主节点复制到从节点。 复制的相关配置 关键词：slaveof &lt;ip&gt; &lt;host&gt;; slaveof no one; info replication；masterauth；repl-disable-tcp-nodelay 建立复制一. 配置文件中加入 slaveof 配置： 1slaveof &lt;masterip&gt; &lt;masterport&gt; 二. redis-server 启动命令加入 –slaveof： 1./redis-server --port 7777 --slaveof 127.0.0.1 8888 三. 直接使用 slaveof 命令： 1127.0.0.1:6380&gt;slaveof 127.0.0.1 6379 slaveof本身是异步命令，执行slaveof命令时，节点只保存主节点信息后返回，后续复制流程在节点内部异步执行。主从节点复制成功建立后，可以使用info replication命令查看复制相关状态。 当主节点通过设置requirepass参数进行密码验证时，从节点需要配置masterauth参数与主节点密码保持一致。 传输延迟可以由repl-disable-tcp-nodelay决定，默认关闭，即主节点产生的任何命令数据都会及时发（适合同机房部署）；开启则表示会合并较小TCP数据包从而节省宽带，默认发送间隔取决于Linux内核，一般默认40ms（适合复杂网络环境）。 断开复制 从节点执行slaveof no one断开与主节点复制关系，在断开与主节点的复制关系后，从节点晋升为主节点。原有数据也不会抛弃。 slaveof 可以完成切主操作，即把当前从节点对主节点的复制切换为对另一个主节点。其流程是：切断与旧主节点的复制；建立与新主节点复制；删除从节点当前所有数据；对新主节点进行复制。【slaveof 命令务必小心执行。如果两个Redis实例数据本身不一样，但是B节点复制A节点时，B节点本身所有数据全部清空后再执行复制】 默认情况下，从节点使用slave-read-only=yes配置为只读模式，从节点的任何修改主节点都无法感知，建议线上不要修改从节点的只读模式。 当主节点自身shutdown了，从节点也不会升级为主节点，而是不断尝试。 12352049:S 14 Mar 22:45:07.409 * Connecting to MASTER 127.0.0.1:638052049:S 14 Mar 22:45:07.409 * MASTER &lt;-&gt; SLAVE sync started52049:S 14 Mar 22:45:07.409 # Error condition on socket for SYNC: Connection refused 拓扑一主一从 用于主节点宕机时从节点提供故障转移支持。 当应用写命令并发量较高且需持久化时，可以只在从节点上开启AOF，这样既保证数据安全性也避免了持久化对主节点的性能干扰。 当主节点关闭持久化功能时，如果主节点脱机要避免自动重启操作，从节点如果继续复制主节点会导致从节点数据也被清空。需在在从节点上执行 slaveof no one 断开与主节点的复制关系，再重启主节点。 一主多从 对于读占比较大的场景，可以把读命令发送到从节点来分担主节点压力。一些较耗时的读命令，如：keys、sort 等，可以在其中一台从节点上执行，防止慢查询对主节点造成阻塞从而影响线上服务的稳定性。 对于写并发量较高的场景，多个从节点会导致主节点写命令的多次发送从而过度消耗网络带宽，同时也加重了主节点的负载影响服务稳定性。 树状主从 该结构使从节点不但可以复制主节点数据，同时可以作为其他从节点的主节点继续向下层复制。 当主节点需要挂载多个从节点时为了避免对主节点的性能干扰，可以采用树状主从结构降低主节点负载和需要传送给从节点的数据量。 原理总复制原理从结点在执行完 slaveof 后正式开始复制过程： 保存主节点地址信息直接返回（ip host保存下来，但 master_link_status 状态为 down） 从节点内部的每秒运行的定时任务维护复制逻辑，定时任务发现新主节点后尝试建立网络连接，从节点会新建一个Socket套接字专门接收主节点复制命令。若无法建立连接，则无限重试至成功或执行 slaveof no one 连接建立成功后发送 PING，以检查套接字是否可用以及主节点是否可接受处理命令。若从节点无法接收PONG或超时，从节点会断开，等下次定时任务发起重连 权限校验，主节点若配置了 requirepass，需检查从节点的 masterauth。验证失败复制终止，从节点重新发起复制流程 同步数据集，首次会全量同步，后续会部分同步。 命令持续复制，主节点把当前数据同步给从节点后，后续会持续把写命令发送给从节点，保证主从一致性。 同步数据集复制偏移量： 参与复制的主从都会为之自身复制偏移量，主节点在处理写入后会把命令字节长度做累加记录（info 下 master_repl_offset）。从节点会上报自身偏移量给主节点，所以主节点会保存从节点复制偏移量。从节点自身也会逐步累加记录自身的偏移量（info 下 slave_repl_offset）。 复制解压缓冲区： 是保存在主节点的一个固定长度的队列，默认1M，主节点响应写命令时，不但会把命令发送给从节点，也会写入复制积压缓冲区。主要用于部分复制及复制异常时的数据补救，参数为 info 下的 repl_backlog_*，缓冲区可用偏移量为 [repl_backlog_first_byte_offset，repl_backlog_first_byte_offset + repl_backlog_histlen]。 主节点运行ID： 每个Redis节点都有动态分配的40位十六进制字符串作为运行ID。从节点会保存主节点运行ID，每次关闭重启Redis，运行ID都会改变，改变后从节点需要重新做全量复制。不使用IP + HOST 进行记录的原因是：主节点重启变更整体数据集，此时再基于偏移量复制不安全。参数为 info 下 run_id。若不想改变可以使用 debug reload 重新加载RDB：redis-cli debug reload。 psync命令： 从节点使用 psync 命令完成全量复制及部分复制，格式为：psync {runId} {offset}。主节点根据 psync 参数决定响应结果，回复+FULLRESYNC从节点触发全量复制；回复+CONTINUE，从节点将触发部分复制；回复+ERR，说明主节点版本低于Redis2.8，无法识别psync，从节点将发送sync命令触发全量复制。 全量复制第一次的全量复制成本较重，涉及到： 从节点发送 psync 命令，第一次的 offset 值为 1，主节点回复+FULLRESYNC。 从节点保存主节点运行ID和偏移量，而主节点会执行 bgsave 保存 RDB 文件。 主节点发送RDB文件给从节点，从节点把接收的RDB文件保存在本地并直接作为从节点的数据文件。 RDB创建到传输完毕若超过60s，则全量复制失败，从节点清理已下载的临时文件。时间可以通过repl-timeout配置。 Redis 2.8.18 后支持无盘复制，生成的RDB文件不保存到硬盘而是直接通过网络发送给从节点，通过repl-diskless-sync参数控制，默认关闭，适用于主节点所在机器磁盘性能较差但网络带宽较充裕的场景。 由于从节点接受 RDB 的时间段内，主节点依旧响应读写命令，等从节点加载完成后，主节点会把缓冲区内的数据发送给从节点，保证主从之间数据一致性。 期间若高流量写入造成主节点缓冲区溢出，也可造成全量复制失败。配置client-output-buffer-limit slave 256mb 64mb 60表示60秒内缓冲区消耗持续大于64MB或者直接超过256MB时则关闭复制连接。 从节点清空本身数据，开始加载RDB。 从节点若开启了AOF，立刻执行 bgwriteaof，保证全量复制后 AOF 持久化文件立刻可以。 对于线上读写分离场景，如果此时从节点正出于全量复制阶段或者复制中断，那从节点在响应读命令可能拿到过期或错误的数据。配置中 slave-serve-stale-data参数默认开启状态，表示依然响应所有命令。对于无法容忍不一致的应用场景可置为no ，除info和slaveof命令其他所有命令只返回SYNC with master in progress信息。 《Redis开发与运维》中的全量复制阶段示例图： 部分复制是避免全量复制开销过大的优化措施。从节点正在复制主节点时出现网络闪断或命令丢失情况（超过repl-timeout），等网络恢复后，由于从节点之前保存了自身已复制的偏移量和主节点的运行ID，从节点会向主节点要求补发丢失的命令（依然通过 psync ）。主节点核对完运行ID后，直接从复制积压缓冲区找到偏移量之后的数据并发送。如果请求的偏移量不在主节点的积压缓冲区内，则无法提供给从节点数据，则部分复制会退化为全量复制。 心跳复制连接建立后，主从都会有心跳检测： 主节点默认每隔10秒对从节点发送ping命令，判断从节点的存活性和连接状态（repl-ping-slave-period） 从节点在主线程中每隔1秒发送 replconf ack {offset} 命令，给主节点上报自身当前的复制偏移量 异步复制主节点把写命令同步给从节点是异步发送完成的。异步造成的延迟可在主节点执行 info replication 查看。读写分离时，可以编写外部监控程序监听主从节点的复制偏移量，当延迟较大时触发报警或者通知客户端避免读取延迟过高的从节点。 Reference 《Redis开发与运维》 Redis 深度历险：核心原理与应用实践","categories":[{"name":"缓存","slug":"缓存","permalink":"https://weilans.github.io/categories/缓存/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://weilans.github.io/tags/redis/"}]},{"title":"Greenplum 要点概述","slug":"Greenplum-要点概述","date":"2020-03-05T15:28:15.000Z","updated":"2020-03-07T04:49:22.000Z","comments":true,"path":"2020/03/05/Greenplum-要点概述/","link":"","permalink":"https://weilans.github.io/2020/03/05/Greenplum-要点概述/","excerpt":"","text":"BasicOLAP平时用的 OLTP 数据库（联机事务处理）较多，面向前台应用，注重高吞吐和高并发，对相应时间要求高。 而大数据集的统计分析需要 OLAP（联机分析处理），其本身不产生数据，基础数据主要来源于生产系统的操作数据，且经常使用多表关联、全表扫描等复杂查询，牵涉的数据量庞大，且响应时间与具体查询有很大关系。 PostgreSQL &amp; GreenplumPG 是成熟先进的关系型数据库，而 Greenplum 本质上将就是一个关系型数据库集群（PG集群），是由若干个独立数据库服务组合成的逻辑数据库，即为用户提供了一个逻辑上透明的数据库。Greenplum 采用 Shared-Nothing架构，整个集群由很多个数据节点（Segment Host）和控制节点（Master Host）组成，Shared-Nothing 是一个分布式的架构，每个节点上所有的资源（CPU，内存，磁盘）都是独立的，每个节点都只有全部数据的一部分。","categories":[{"name":"db","slug":"db","permalink":"https://weilans.github.io/categories/db/"}],"tags":[{"name":"greenplum","slug":"greenplum","permalink":"https://weilans.github.io/tags/greenplum/"}]},{"title":"曼昆经济学原理(7th) CH1 经济学十大原理","slug":"曼昆经济学原理-7th-Ch1-经济学十大原理","date":"2020-02-26T16:17:47.000Z","updated":"2020-03-01T13:19:40.000Z","comments":true,"path":"2020/02/27/曼昆经济学原理-7th-Ch1-经济学十大原理/","link":"","permalink":"https://weilans.github.io/2020/02/27/曼昆经济学原理-7th-Ch1-经济学十大原理/","excerpt":"","text":"人们如何做出决策1. People face tradeoffs人们面临权衡取舍。 稀缺资源投入抉择：大炮与黄油。 GPD与环境：有生产则有污染。 Efficiency 效率 v. Equity 公平： 效率：多劳多得，少劳少得； 公平：所有生成出来的东西公平分配； 效率提高可以把蛋糕越做越大，但贫富差距会拉大；注重公平会损失蛋糕本身。 2. The cost of something is what you give up to get it某东西的成本就是为得到它所放弃的东西。 机会成本：为了得到某种东西所必须放弃的东西。 3. Rational people think at the margin理性人考虑边际量。 Rational People 理性人：系统而有目的地尽最大努力实现其目标的人。（经济学中的”人”都是”理性人”） Marginal changes 边际变动：对行动计划的微小增量调整。 边际收益大于边际成本时就会采取行动。 4. People respond to incentives人们会对激励作出反应。 激励：引起一个让你做出某种行为的某种东西。 安全带：原先无安全带，司机会非常小心开车；出现安全带后，司机警惕性下降。结果交通事故增加，行人死亡人数增加。 人们如何相互影响5. Trade can make everyone better off贸易能使每个人状况变好。 贸易可双赢、多赢。原因：贸易可以使人们专业化生产。使各国可以专门从事自己最擅长的活动，并可以享有更多种类的物品与服务。 6. Markets are usually a good way to organize economic activity.市场通常是组织经济活动的一种好方法。 市场经济：当许多企业和家庭在物品与服务市场上相互交易时，通过他们的分散决策配置资源的经济。 市场经济中，中央计划者的决策被千万企业和家庭的决策所取代。 市场价格既反映了一种物品的社会价值，也反映了生产该物品的社会成本。 亚当斯密：“看不见的手”。人们在追求个体的利益的同时，往往可促进社会的利益。 7. Governments can sometimes improve market outcomes政府有时能改善市场结果。 需要政府的原因一：只有在政府实施规则并维持对市场经济至关重要的制度时，看不见的手才能施展其魔力。 保护产权，约束行为，规范秩序（防偷抢，消费得付费等） 产权：个人拥有并控制稀缺资源的能力。 需要政府的原因二：市场失灵下，需要政府干预经济以促进效率或促进平等。 market failure 市场失灵：市场本身不能有效配置资源的情况。 市场失灵的原因之一：外部性（一个人行为对旁观者福利的影响），如污染，市场本身无法将这种成本考虑在内； 市场失灵的原因之二：市场势力（某个经济活动者或某个经济活动小群体对市场价格有显著影响的能力）。 需要政府的原因三：公平。 社会的不平等性要求政府进行干预。 （大部分国家实际都是混合经济，主要看市场与计划的比重。） 整体经济如何运行8. The standard of living depends on a country’s production.一国的生活水平取决于它生产物品与劳务的能力。 各国及不同时期生活水平的巨大差异，归因于各国的生成率 productivity（每单位劳动投入所生产的商品与服务数量）。 一国生产率的增长也决定了平均收入的增长率。 决策者需要让工人受良好教育、拥有更多物品及服务所需工具、获取最好的技术来提高生产率。 9. Prices rise when the government prints too much money.当政府发行了过多货币时，物价上升。 通货膨胀 inflation：经济中物价总水平的上升。 10. Society faces a short-run tradeoff between inflation and unemployment.社会面临通货膨胀与失业之间的短期权衡取舍。 货币增加刺激社会整体支出水平 -&gt; 增加了物品和服务的需求 -&gt; 需求增加，物价在涨，但会鼓励企业雇佣大量员工 -&gt; 更多雇佣意味着更少的事业 任何一个复杂的经济学原理都可以由这十大经济学原理构成。","categories":[{"name":"经济学","slug":"经济学","permalink":"https://weilans.github.io/categories/经济学/"}],"tags":[]},{"title":"Apache Calcite (一) - Adapter","slug":"Apache-Calcite-Adapter-入门","date":"2020-02-20T09:03:34.000Z","updated":"2020-02-22T12:40:52.000Z","comments":true,"path":"2020/02/20/Apache-Calcite-Adapter-入门/","link":"","permalink":"https://weilans.github.io/2020/02/20/Apache-Calcite-Adapter-入门/","excerpt":"","text":"接触 Calcite 的时间不算长，感觉 Calcite 还是很难的，越往下看各个名次及查询优化部分就很难看的下去。不过工作方面暂时只用到了 Adapter 部分，而且由于通用性的考量，使用的 Table 暂时是ScannableTable。一下子接触太多东西也容易忘，所以还是从头开始记笔记，一边完成工作上的事一边继续学习，一蹴而不可取。 主要内容来自 Calcite 的英文官方指南，介绍如何使用 Calcite 对 CSV 进行 SQL 查询，主要参考一个基础的 Adapter 是如何实现的。 1234git clone https://github.com/apache/calcite.gitcd calcitemvn install -DskipTests -Dcheckstyle.skip=truecd example/csv 官方介绍的是使用 Sqlline 进行 shell 式查询，执行SELECT * FROM emps;可以看到存放在 CSV 中的emps表数据。 1234./sqllinesqlline&gt; !connect jdbc:calcite:model=src/test/resources/model.json admin adminsqlline&gt; !tablessqlline&gt; SELECT * FROM emps; model.json 文件中的内容是查询关键，可以看到factory中指定了CsvSchemaFactory，后续可以以该类为起点展开。 1234567891011121314&#123; \"version\": \"1.0\", \"defaultSchema\": \"SALES\", \"schemas\": [ &#123; \"name\": \"SALES\", \"type\": \"custom\", \"factory\": \"org.apache.calcite.adapter.csv.CsvSchemaFactory\", \"operand\": &#123; \"directory\": \"sales\" &#125; &#125; ]&#125; 由于使用 Sqlline 不方便 DEBUG，所以改写了CsvTest中的测试用例，把directory换成了绝对路径(实际用来使用的是new File(directory)，避免找不到文件)，model对应的JSON字符串开头多了inline。Calcite 对应的 Driver 是org.apache.calcite.jdbc.Driver，驱动的注册工作基于 SPI 自动完成，jdbcUrl为jdbc:calcite:即可。 123456789101112131415161718192021222324252627@Testpublic void common() throws SQLException &#123; Properties info = new Properties(); info.put(\"model\", \"inline:\" + \"&#123;\\n\" + \" \\\"version\\\": \\\"1.0\\\",\\n\" + \" \\\"defaultSchema\\\": \\\"SALES\\\",\\n\" + \" \\\"schemas\\\": [\\n\" + \" &#123;\\n\" + \" \\\"name\\\": \\\"SALES\\\",\\n\" + \" \\\"type\\\": \\\"custom\\\",\\n\" + \" \\\"factory\\\": \\\"org.apache.calcite.adapter.csv.CsvSchemaFactory\\\",\\n\" + \" \\\"operand\\\": &#123;\\n\" + \" \\\"directory\\\": \\\"/...绝对路径/src/test/resources/sales\\\"\\n\" + \" &#125;\\n\" + \" &#125;\\n\" + \" ]\\n\" + \"&#125;\"); try (Connection connection = DriverManager.getConnection(\"jdbc:calcite:\", info); Statement statement = connection.createStatement(); ResultSet resultSet = statement.executeQuery(\"select * from emps\")) &#123; while (resultSet.next()) &#123; // logic System.out.println(resultSet.getLong(1)); &#125; &#125;&#125; 一. SchemaFactory &amp; Schema First, we define a schema based on a schema factory class in a model file. Then the schema factory creates a schema, and the schema creates several tables, each of which knows how to get data by scanning a CSV file. Last, after Calcite has parsed the query and planned it to use those tables, Calcite invokes the tables to read the data as the query is being executed. 在 model 中指定了 factory 为 CsvSchemaFactory，其实现了 SchemaFactory 接口，主要完成生成Schema 的 create 方法实现。directory可作为 operand的参数获取到，根据directory生成directoryFile参数，及表示存放 csv/csv.gz 的文件目录。返回结果为 继承了AbstractSchema 的 CsvSchema。 12345678910111213141516171819public Schema create(SchemaPlus parentSchema, String name, Map&lt;String, Object&gt; operand) &#123; final String directory = (String) operand.get(\"directory\"); final File base = (File) operand.get(ModelHandler.ExtraOperand.BASE_DIRECTORY.camelName); File directoryFile = new File(directory); if (base != null &amp;&amp; !directoryFile.isAbsolute()) &#123; directoryFile = new File(base, directory); &#125; String flavorName = (String) operand.get(\"flavor\"); CsvTable.Flavor flavor; if (flavorName == null) &#123; flavor = CsvTable.Flavor.SCANNABLE; &#125; else &#123; flavor = CsvTable.Flavor.valueOf(flavorName.toUpperCase(Locale.ROOT)); &#125; return new CsvSchema(directoryFile, flavor); &#125;&#125; 在CsvSchema中需要实现的是getTableMap()方法，其返回结果为Map&lt;String, Table&gt;。在 sales 目录下的 DEPTS.csv、EMPS.csv.gz、SDEPTS.csv 都会解析为对应的表，返回一个不可变Map： 123&quot;DEPTS&quot; -&gt; &quot;CsvScannableTable&quot;&quot;EMPS&quot; -&gt; &quot;CsvScannableTable&quot;&quot;SDEPTS&quot; -&gt; &quot;CsvScannableTable&quot; 二. Table &amp; Enumerator有三种Table，其接口分别为ScannableTable、FilterableTable、TranslatableTable，在文中分别对应CsvScannableTable，CsvFilterableTable、CsvTranslatableTable，先使用ScannableTable完成入门流程。这三者的主要区别可简述为：ScannableTable 会把所有数据加载到内存中，在内存中进行条件过滤；FilterableTable 可以获得过滤条件，可以帮助在DB查询数据时先过滤一部分，从而减少内存开销；TranslatableTable 难度较大，需根据上下文自己定义表扫描的执行计划。 CsvScannableTable 继承自CsvTable，而CsvTable又继承在AbstractTable，在CsvTable中实现了getRowType方法，返回类型为RelDataType，表示所有列属性信息。文中的CSV示例是以DEPTNO:int,NAME:string特定格式表示数据类型的，getRowType返回的就是包含这些属性名称及类型对应关系的RelDataType。 在可获得类型信息后，CsvScannableTable需要关心的就是如何获取及扫描数据，这就需要实现ScannableTable定义的scan方法。 12345678910public Enumerable&lt;Object[]&gt; scan(DataContext root) &#123; final int[] fields = CsvEnumerator.identityList(fieldTypes.size()); final AtomicBoolean cancelFlag = DataContext.Variable.CANCEL_FLAG.get(root); return new AbstractEnumerable&lt;Object[]&gt;() &#123; public Enumerator&lt;Object[]&gt; enumerator() &#123; return new CsvEnumerator&lt;&gt;(source, cancelFlag, false, null, new CsvEnumerator.ArrayRowConverter(fieldTypes, fields)); &#125; &#125;;&#125; CsvEnumerator实现了Enumerator接口，内部调用 opencsv 的 CSVReader.readNext() 进行推进及获取数据。 123456public interface Enumerator&lt;T&gt; extends AutoCloseable &#123; T current(); boolean moveNext(); void reset(); void close();&#125; CSV Adapter 总体的依赖关系如下所示。 三: View在 JSON 中的 schemas 中可以添加 tables 来实现 View（type 指定为 view)。 123456789101112131415161718192021&#123; version: '1.0', defaultSchema: 'SALES', schemas: [ &#123; name: 'SALES', type: 'custom', factory: 'org.apache.calcite.adapter.csv.CsvSchemaFactory', operand: &#123; directory: 'sales' &#125;, tables: [ &#123; name: 'FEMALE_EMPS', type: 'view', sql: 'SELECT * FROM emps WHERE gender = \\'F\\'' &#125; ] &#125; ]&#125; 四: 自定义表1234567891011121314151617181920&#123; version: '1.0', defaultSchema: 'CUSTOM_TABLE', schemas: [ &#123; name: 'CUSTOM_TABLE', tables: [ &#123; name: 'EMPS', type: 'custom', factory: 'org.apache.calcite.adapter.csv.CsvTableFactory', operand: &#123; file: 'sales/EMPS.csv.gz', flavor: \"scannable\" &#125; &#125; ] &#125; ]&#125; 自定义表相对于自定义Schema有更高的自由度，每个表可以有单独的参数设置，使用的工厂类也变为了CsvTableFactory，其 create 方法也较为简单，返回结果一样是 CsvScannableTable。 12345678910public CsvTable create(SchemaPlus schema, String name, Map&lt;String, Object&gt; operand, RelDataType rowType) &#123; String fileName = (String) operand.get(\"file\"); final File base = (File) operand.get(ModelHandler.ExtraOperand.BASE_DIRECTORY.camelName); final Source source = Sources.file(base, fileName); final RelProtoDataType protoRowType = rowType != null ? RelDataTypeImpl.proto(rowType) : null; return new CsvScannableTable(source, protoRowType);&#125; 五: JDBC AdapterJDBC Adapter 可以将数据库中的一个 Schema 映射成 Calcite 中的一个 Schema，该 Adapter 内置在 Calcite 中。 1234567891011121314151617&#123; version: '1.0', defaultSchema: 'FOODMART', schemas: [ &#123; name: 'FOODMART', type: 'custom', factory: 'org.apache.calcite.adapter.jdbc.JdbcSchema$Factory', operand: &#123; jdbcDriver: 'com.mysql.jdbc.Driver', jdbcUrl: 'jdbc:mysql://localhost/foodmart', jdbcUser: 'foodmart', jdbcPassword: 'foodmart' &#125; &#125; ]&#125; 使用的时候需要注意SQL语句的双引号以及大小写，该 Adapter SQL 语法比较严格。目前该 Adapter有局限性，仅支持表扫描操作，其他处理(过滤、连接、聚集等)都发生在 Calcite 中。 可以通过下面的简单示例看一下 CSV 和 MYSQL 两处数据源的联合查询。 1234567891011121314151617181920212223242526272829303132333435363738394041@Testpublic void hybrid() throws SQLException &#123; Properties info = new Properties(); info.put(\"model\", \"inline:\" + \"&#123;\\n\" + \" \\\"version\\\": \\\"1.0\\\",\\n\" + \" \\\"defaultSchema\\\": \\\"TEST\\\",\\n\" + \" \\\"schemas\\\": [\\n\" + \" &#123;\\n\" + \" \\\"name\\\": \\\"TEST\\\",\\n\" + \" \\\"type\\\": \\\"custom\\\",\\n\" + \" \\\"factory\\\": \\\"org.apache.calcite.adapter.jdbc.JdbcSchema$Factory\\\",\\n\" + \" \\\"operand\\\": &#123;\\n\" + \" \\\"jdbcDriver\\\": \\\"com.mysql.jdbc.Driver\\\",\\n\" + \" \\\"jdbcUrl\\\": \\\"jdbc:mysql://127.0.0.1:3306/test\\\",\\n\" + \" \\\"jdbcUser\\\": \\\"...\\\",\\n\" + \" \\\"jdbcPassword\\\": \\\"...\\\"\\n\" + \" &#125;\\n\" + \" &#125;,\\n\" + \" &#123;\\n\" + \" \\\"name\\\": \\\"SALES\\\",\\n\" + \" \\\"type\\\": \\\"custom\\\",\\n\" + \" \\\"factory\\\": \\\"org.apache.calcite.adapter.csv.CsvSchemaFactory\\\",\\n\" + \" \\\"operand\\\": &#123;\\n\" + \" \\\"directory\\\": \\\"/.../sales\\\"\\n\" + \" &#125;\\n\" + \" &#125;\\n\" + \" ]\\n\" + \"&#125;\" ); try (Connection connection = DriverManager.getConnection(\"jdbc:calcite:\", info); Statement statement = connection.createStatement(); ResultSet resultSet = statement.executeQuery(\"SELECT * FROM \\\"TEST\\\".\\\"abc\\\",\\\"SALES\\\".\\\"EMPS\\\"\")) &#123; while (resultSet.next()) &#123; // logic System.out.println(resultSet.getString(1)); &#125; &#125;&#125; 另外，还有一种 Cloning JDBC adapter，数据同样来自数据库，但是在第一次读取时会将数据读取到内存表中，Calcite 根据内存表计算查询，实际上相当于数据库的缓存。 Referencehttps://matt33.com/2019/03/07/apache-calcite-process-flow/ https://zhuanlan.zhihu.com/p/53725382","categories":[],"tags":[]},{"title":"大数据入门草稿 - Hive","slug":"大数据入门草稿-Hive","date":"2020-01-06T02:00:21.000Z","updated":"2020-12-15T03:11:32.480Z","comments":true,"path":"2020/01/06/大数据入门草稿-Hive/","link":"","permalink":"https://weilans.github.io/2020/01/06/大数据入门草稿-Hive/","excerpt":"","text":"Hive简介Hive是Hadoop的数据仓库工具，可将结构化的数据文件映射为一张表，提供类SQL的查询功能。其本质是将HQL转化为MapReduce程序。 Hive处理的数据存储在HDFS中。 Hive分析数据的默认实现是MapReduce（可以改成Spark)。 Hive执行程序运行在Yarn上。 Hive 适用于数据分析场景以及对实时性要求不高的场合。其优势在于处理大数据，对于小数据处理没有优势，Hive的执行延迟较高（MapReduce 本身具有较高的延迟）。Hive还支持用户自定义函数。 Hive的缺点在于两点：HQL表达能力有限，迭代式算法无法表达（计算结果再次处理），故在数据挖掘方面并不擅长；执行效率较低，生成的MR任务通常不够智能，且调优困难。 Hive为数仓设计，数仓内容为读多写少，因此，Hive中不建议对数据的改写，所有的数据都是在加载的时候确定好的。当然增和删是可以做到的。 Hive 架构 command-line shell：通过 hive 命令行的的方式来操作数据； thrift／jdbc：通过 thrift 协议按照标准的 JDBC 的方式操作数据； Metastore: 元数据涉及到：表名、表所属的数据库（默认是default）、表的拥有者、列/分区字段、表的类型（是否是外部表）、表的数据所在目录等； Driver: 主要包括以下四个: SQL Parser 解析器：将SQL字符串转换成抽象语法树AST，这一步一般都用第三方工具库完成，比如antlr；对AST进行语法分析，比如表是否存在、字段是否存在、SQL语义是否有误。 Physical Plan 编译器：将AST编译生成逻辑执行计划。 Query Optimizer 优化器：对逻辑执行计划进行优化。 Execution 执行器：把逻辑执行计划转换成可以运行的物理计划。对于Hive来说，就是MR/Spark。 索引Hive没有对数据中的某些Key建立索引。Hive要访问数据中满足条件的特定值时，需要暴力扫描整个数据，因此访问延迟较高。由于 MapReduce 的引入， Hive 可以并行访问数据，因此即使没有索引，对于大数据量的访问，Hive 仍然可以体现出优势。 基础操作 启动hive: bin/hive 显示数据库: show databases; 使用default数据库: use default; 显示default数据库中的表: show tables; 删除已创建的student表: drop table student; 创建student表, 并声明文件分隔符’\\t’ create table student(id int, name string) ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘\\t’; 加载/opt/module/datas/student.txt 文件到student数据库表中。 load data local inpath ‘/opt/module/datas/student.txt’ into table student; 执行脚本中的sql (-f) bin/hive -f /opt/module/datas/hive.sql 不进入hive的交互窗口执行sql语句 (-e) bin/hive -e “select id from student;” Hive常见属性Hive数据仓库位置配置​ 1）Default数据仓库的最原始位置是在hdfs上的：/user/hive/warehouse路径下。 ​ 2）在仓库目录下，没有对默认的数据库default创建文件夹。如果某张表属于default数据库，直接在数据仓库目录下创建一个文件夹。 ​ 3）修改default数据仓库原始位置（将hive-default.xml.template如下配置信息拷贝到hive-site.xml文件中）。 12345&lt;property&gt; &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt; &lt;value&gt;/user/hive/warehouse&lt;/value&gt; &lt;description&gt;location of default database for the warehouse&lt;/description&gt;&lt;/property&gt; 配置同组用户有执行权限：bin/hdfs dfs -chmod g+w /user/hive/warehouse 查询后信息显示配置在hive-site.xml文件中添加如下配置信息，就可以实现显示当前数据库，以及查询表的头信息配置。 123456789&lt;property&gt; &lt;name&gt;hive.cli.print.header&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hive.cli.print.current.db&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; 参数配置方式1．查看当前所有的配置信息: set; 2．参数的配置三种方式 配置文件方式 默认配置文件：hive-default.xml 用户自定义配置文件：hive-site.xml 用户自定义配置会覆盖默认配置。另外，Hive也会读入Hadoop的配置，因为Hive是作为Hadoop的客户端启动的，Hive的配置会覆盖Hadoop的配置。配置文件的设定对本机启动的所有Hive进程都有效。 命令行参数方式 启动Hive时，可以在命令行添加-hiveconf param=value来设定参数: bin/hive -hiveconf mapred.reduce.tasks=10; 注意：仅对本次hive启动有效 参数声明方式 可以在HQL中使用SET关键字设定参数: hive (default)&gt; set mapred.reduce.tasks=100; 注意：仅对本次hive启动有效。 查看参数设置: hive (default)&gt; set mapred.reduce.tasks; 上述三种设定方式的优先级依次递增。即配置文件 &lt; 命令行参数 &lt; 参数声明。注意某些系统级的参数，例如log4j相关的设定，必须用前两种方式设定，因为那些参数的读取在会话建立以前已经完成了。 数据类型基本数据类型 Hive数据类型 Java数据类型 长度 例子 TINYINT byte 1byte有符号整数 20 SMALINT short 2byte有符号整数 20 INT int 4byte有符号整数 20 BIGINT long 8byte有符号整数 20 BOOLEAN boolean 布尔类型，true或者false TRUE FALSE FLOAT float 单精度浮点数 3.14159 DOUBLE double 双精度浮点数 3.14159 STRING string 字符系列。可以指定字符集。可以使用单引号或者双引号。 ‘now is the time’ “for all good men” TIMESTAMP 时间类型 BINARY 字节数组 复杂数据类型 数据类型 描述 语法示例 STRUCT 和c语言中的struct类似，都可以通过“点”符号访问元素内容。例如，如果某个列的数据类型是STRUCT{first STRING, last STRING},那么第1个元素可以通过字段.first来引用。 struct() MAP MAP是一组键-值对元组集合，使用数组表示法可以访问数据。例如，如果某个列的数据类型是MAP，其中键-&gt;值对是’first’-&gt;’John’和’last’-&gt;’Doe’，那么可以通过字段名[‘last’]获取最后一个元素 map() ARRAY 数组是一组具有相同类型和名称的变量的集合。这些变量称为数组的元素，每个数组元素都有一个编号，编号从零开始。例如，数组值为[‘John’, ‘Doe’]，那么第2个元素可以通过数组名[1]进行引用。 Array()","categories":[{"name":"BigData","slug":"BigData","permalink":"https://weilans.github.io/categories/BigData/"}],"tags":[]},{"title":"[HikariCP] HikariCP 配置项 ","slug":"HikariCP-2-HikariCP-配置项","date":"2019-12-18T01:42:48.000Z","updated":"2019-12-19T11:51:59.000Z","comments":true,"path":"2019/12/18/HikariCP-2-HikariCP-配置项/","link":"","permalink":"https://weilans.github.io/2019/12/18/HikariCP-2-HikariCP-配置项/","excerpt":"HikariCP 的全部配置介绍来自其首页，主要分为必填项和可选项，对于大部分配置项，HikariCP会有默认设置，官方建议在使用时无需过多的调整。 一些非必要属性的配置说明来自《HikariCP数据库连接池实战》。","text":"HikariCP 的全部配置介绍来自其首页，主要分为必填项和可选项，对于大部分配置项，HikariCP会有默认设置，官方建议在使用时无需过多的调整。 一些非必要属性的配置说明来自《HikariCP数据库连接池实战》。 相比其他数据库连接池，HikariCP会少一些配置项，作者的原话是： In keeping with the simple is better or less is more design philosophy, some configuration axis are intentionally left out. 必填配置需填写三项： dataSourceClassName、jdbcUrl 二选一 username password dataSourceClassName顾名思义，该属性就是 JDBC 驱动中DataSource的名称。dataSourceClassName和jdbcUrl都是可以的，但作者更推荐 dataSourceClassName（DataSource-based），不过对于使用 Spring Boot 自动装配的用户，还是需使用jdbcUrl 配置。此外，MySQL DataSource 并不支持网络超按时，建议使用 jdbcUrl 的方式。 jdbcUrl表明 HikariCP 使用的是传统的DriverManager-based配置。虽然作者认为基于 dataSourceClassName 的配置更加优越，但在实际部署上两种方式并没有差别。当使用某些老的驱动程序时，可能还需要设置 driverClassName 属性，但首先尝试不使用该属性。 username &amp; password从驱动中获取连接时使用到的身份认证用户名和密码。对于 DataSource，其使用 DataSouce.getConnection(String username, String password)，但对于 DriverManager，由于每个 Driver 特征不同，HikariCP 会将 username 和 password属性配置在 Properties 文件中，使用的是getConnection(String url, java.util.Properties info)方法。当然也可也以跳过此步，使用addDataSourceProperty(&quot;username&quot;, ...)及addDataSourceProperty(&quot;pass&quot;, ...)。 可选配置常用配置autoCommit控制从池中返回的连接的默认自动提交行为。Default: true connectionTimeout（重要）控制客户端等待池中连接的最长毫秒数，如果在没有连接可用的情况下超过此时间，则抛出SQLException，最低可接受的连接超时为250ms，Default: 30000 (30s)。 idleTimeout控制连接允许被闲置在池中的最大时间（此设置仅适用于minimumIdle定义为比maximumPoolSize小）。当整个连接池数量在 minimumIdle 时，空闲连接将不会退役。空闲连接在这个超时时间之前不可能退役。该值为 0 表示空闲连接永远不可能从连接池中移除。该值允许的最小值是：10000(10s)，Default: 600000(10min)。 原文中还有一句Whether a connection is retired as idle or not is subject to a maximum variation of +30 seconds, and average variation of +15 seconds.并不太好理解其含义。可能是指在达到 idleTimeout 后还需要的部分时间（比如检测任务的间隔时间）进行辨别。 maxLifeTime（重要）控制池中连接的最大生命周期，使用中的连接永远不会退役，只有当它在关闭后在会被移除。作者强烈建议用户设置此值，并且它应该比任何数据源的连接源的连接限制短几秒。值为0表示无限期生存，Default: 1800000(30min)。 有些使用MySQL的应用会报如下的错误： The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server. 这个问题分两种情况来看，是立即发生还是一段时间以后发生？如果是一段时间以后发生，在数据库的wait_timeout短于HikariCP的maxLifetime值的时候，发生的情况并不少见。一般来说，可以将maxLifetime设置缩短到900000毫秒（15分钟）然而更好的方法是，确定MySQL配置的wait_timeout值是什么，并将HikariCP设置为比maxLifetime短几分钟。 connectionTestQuery作者强烈建议，如果驱动支持 JDBC4，请不要使用这个属性。这适用于不支持 JDBC4 的 Connection.isValid() 的驱动。该属性是一个检测查询，在数据库连接池给出连接之前进行查询，以验证与数据库的连接是否仍然存在且有效。 如果追求极致性能，建议不设置此值，当不配置此值时会通过ping命令进行检测，性能会更好。 Default: none minimumIdle控制HikariCP尝试在池中维护的最小空闲连接数，若空闲连接数低于此值且池中的总连接数小于maximumPoolSize，则HikariCP将尽最大努力有效添加其他连接。 为了最大提高性能和对峰值需求的响应能力，作者不建议设置此值，而是让HikariCP充当一个固定大小连接池。若该参数未设置，则置为 maximumPoolSize，当连接关闭时，将会在池中被替换。如果设置了此值，那 HikariCP 就是一个大小可变的池，即使使用情况上下浮动，连接池也会保持 minimumIdle 连接可用。Default: same as maximumPoolSize maximumPoolSize控制连接池到达的最大大小，包括空闲的和正在使用的连接，由此值控制后端的实际连接的最大数量。当池到达此大小且没有空闲连接可使用时，对 getConnection 的调用将阻塞至超时前 connectionTimeout 毫秒。 metricRegistry允许用户指定池使用的 MetricRegistry 示例，记录各种指标度量值。 healthCheckRegistry允许用户指定池使用的 HealthCheckRegistry 示例，报告当前系统的健康信息。(Micrometer不支持) poolName标识连接池的用户定义名称，主要用于显示在日志记录和JMX管理控制台上。Default: auto-generated 非常用配置initializationFailTimeout如果池无法成功初始化连接，则此属性控制池是否“快速失败”。任何正数都被认为是尝试获取初始连接的毫秒数；在此期间，应用程序线程将被阻塞。如果在超时发生之前无法获取连接，则将引发异常。initializationFailTimeout超时发生在connectionTimeout阶段之后。如果值为0，HikariCP将尝试获取并验证连接。如果获得连接但验证失败，则抛出异常，而不会启动池。但是，如果无法获得连接，则池将启动，但稍后获取连接的尝试会失败。小于0的值将绕过任何初始连接尝试，并且池将在尝试在后台获取连接时立即启动。因此，以后获得连接的尝试可能会失败。默认值：1。 感觉官网说的还是比较晦涩，建议看HikariPool#checkFailFast源码。 isolateInternalQueries此属性决定HikariCP是否在自己的事务中隔离内部池查询，例如连接存活测试。由于这些通常是只读查询，因此很少有必要将它们封装在自己的事务中。此属性仅在autoCommit禁用时适用。默认值：false。 allowPoolSuspension 此属性控制池是否可以通过JMX挂起和恢复。这对某些故障转移自动化方案很有用。当池被挂起时，调用getConnection()将不会超时，并将一直保持到池恢复为止。默认值：false。 readOnly此属性控制默认情况下从池中获取的Connections是否处于只读模式。请注意，某些数据库不支持只读模式的概念，而其他数据库在Connection设置为只读时提供查询优化。是否需要此属性将在很大程度上取决于那的应用程序和数据库。默认值：false。 registerMbeans此属性控制是否注册JMX管理Bean（“MBean”）。默认值：false。 catalog此属性为支持catalog的数据库设置默认catalog。如果未指定此属性，则使用JDBC驱动程序定义的默认catalog。默认值：driver default。 connectionInitSql此属性设置一个SQL语句，该语句将在每次创建新连接之后执行，然后再将该连接添加到池中。如果此SQL无效或抛出异常，它将被视为连接失败，并将遵循标准重试逻辑。默认值：无。 driverClassNameHikariCP将尝试仅基于jdbcUrl通过DriverManager解析驱动程序，但对于某些较旧的驱动程序必须指定driverClassName。除非用户收到明显的错误消息，表明未找到驱动程序，否则可忽略此属性。默认值：无。 transactionIsolation此属性控制从池返回的连接的默认事务隔离级别。若未指定，则用JDBC驱动程序定义的默认事务隔离级别。仅当有针对所有查询的特定隔离需求时，才使用此属性。此属性的值是Connection类的常量名，如TRANSACTION_READ_COMMITTED、TRANSACTION_REPEATABLE_READ等。默认值：driver default。 validationTimeout此属性控制连接测试活性的最长时间。该值必须小于connectionTimeout。最低可接受的验证超时为250毫秒。默认值：5000。 leakDetectionThreshold此属性控制连接在记录一条指示可能连接泄漏的消息之前流出池的时间。值为0表示禁用泄漏检测。启用泄漏检测的最低可接受值是2000（2秒）。默认值：0。 schema该属性为支持schema概念数据库设置默认schema。如果未指定此属性，则使用JDBC驱动程序定义的默认模式。默认值：driver default。 threadFactory此属性仅可通过编程配置或IoC容器获得。此属性允许设置java.util.concurrent.ThreadFactory将用于创建池使用的所有线程的实例。在注入线程只能通过应用程序容器提供的ThreadFactory创建的某些受限执行环境中使用它。默认值：无。 scheduledExecutor仅可通过编程配置或IoC容器获得。允许设置java.util.concurrent.Scheduled-ExecutorService用于各种内部调度任务的实例。如果向HikariCP提供ScheduledThread-PoolExecutor实例，建议设置setRemoveOnCancelPolicy(true)。默认值：无。","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"connection-pool","slug":"connection-pool","permalink":"https://weilans.github.io/tags/connection-pool/"},{"name":"db","slug":"db","permalink":"https://weilans.github.io/tags/db/"}]},{"title":"大数据入门草稿 - Hadoop","slug":"大数据入门草稿-Hadoop","date":"2019-12-16T03:18:02.000Z","updated":"2020-12-10T07:13:30.290Z","comments":true,"path":"2019/12/16/大数据入门草稿-Hadoop/","link":"","permalink":"https://weilans.github.io/2019/12/16/大数据入门草稿-Hadoop/","excerpt":"HDFS、YARN、MapReduce","text":"HDFS、YARN、MapReduce 大数据基础概述4VVolume 海量的数据规模；Variety 多样的数据类型；Velocity 快速的数据流转；Value 发现数据加载。 大数据在技术架构上带来的挑战对现有数据库管理技术的挑战（TB以上结构化的存储）；经典数据库技术没有考虑数据的多类别；实时性的技术挑战；网络架构、数据中心、运维的挑战。 大数据带来的额外挑战：数据隐私。 Google大数据技术存储容量 GFS；读写速度 BigTable；计算效率 MapReduce Hadoop开源的分布式存储+分布式计算平台，可以对多机器的海量数据进行分布式处理的框架。其拥有成熟的生态圈，可存储在廉价的机器上。 Hadoop 主要包括四部分： Hadoop Common：Hadoop 共用包； Hadoop Distributed File System(HDFS)：可提供高吞吐量的分布式文件系统； Hadoop YARN：工作调度 &amp; 资源管理； Hadoop MapReduce：基于 YARN 可并行处理大数据集的框架 狭义的Hadoop即为这三者的总和，而广义的Hadoop是指Hadoop生态系统，生态系统中的每一个子系统只解决某一个特定问题域，是多个小而精的系统。 HDFS特点：扩展性 &amp; 容错性 &amp; 海量数据存储 将文件切分成指定大小（可配置，默认128M）的数据块并以多副本的形式存储在多个机器上。 数据切分、多副本、容错等操作对用户是透明的。 YARNYet Another Resource Negotiator，负责整个集群资源的管理和调度（作业占用CPU及内存）。 特点：扩展性 &amp; 容错性（Task异常进行一定次数的重试）&amp; 多框架资源统一调度（跑Spark等额外类型的作业，14年Spark逐渐代替MapReduce称为Hadoop缺省执行引擎。） MapReduceHadoop MapReduce 是 Google MapReduce 的克隆版 特点：扩展性 &amp; 容错性 &amp; 海量数据离线处理 HDFS如果要自行设计一个简易的分布式文件系统，可能会将大小不同的文件以多副本的方式存在在多台机器上，并且记录文件存在哪台机器上等元数据。这样的缺点是：不管文件多大都直接放在一个节点上会造成网络瓶颈且很难进行并行数据处理；存储负载较难均衡，部分节点的利用率较低。 而HDFS的做法是将每个文件先进行拆分，每块大小可设置（如128M ），每个Block多副本的方式进行存储。大小一致的Block会让机器的存储负载好很多，且便于并行处理。 HDFS架构 1个Master(NameNode/NN) &amp; N个Slaves(DataNode/DN) NameNode：负责客户端请求的响应；负责元数据（文件的名称、副本系数、Block存放的DataNode）的管理； DataNode：存储用户文件对应的数据块（Block）；定期向NN发送心跳信息，汇报本身及所有Block信息，健康状况； 实际生产部署时， 一个机器部署NameNode，其他每个机器部署一个DataNode。 Replication Factor：副本系数（副本因子）。每个文件可以单独配置副本因子和 Block Size。 HDFS的文件只能写一次（除非 appends truncates），且在任意时间内只能有一个 writer 进行写操作，不支持多并发写。 Hadoop伪分布式安装 JDK安装并添加至环境变量 安装ssh，并配置免密登录 123sudo yum install sshssh-keygen -t rsacp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys 下载并解压 hadoop，hadoop-2.6.0-cdh5.7.0.tar.gz 更改 hadoop 配置 (hadoop_home/etc/hadoop) ： hadoop-env.sh 更改 JAVA_HOME 1export JAVA_HOME=... core-site.xml 12345678&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://xxx:8020&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/xxx/tmp-hadoop&lt;/value&gt;&lt;/property&gt; hdfs-site.xml 1234&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt;&lt;/property&gt; slaves 文件添加 slave 信息，此处不做变动 启动HDFS：格式化文件系统，进入bin目录，ce，之后启动 hdfs，sbin/start-dfs.sh，使用jps查看 DataNode 以及 NameNode 是否启动成功，或者通过浏览器端口 50070。 停止HDFS：sbin/stop-dfs.sh HDFS Shellhdfs dfs和hadoop fs指令相同，直接输入后可以看见其他后续指令。 123456789101112hdfs dfs -ls /hdfs dfs -put test.log / 向HDFS存放文件hdfs dfs -text /test.log 查看hdfs dfs -cat /test.log 查看hdfs dfs -mkdir /tthdfs dfs -mkdir -p /tt/a/b 递归创建hdfs dfs -ls /tt/ahdfs dfs -ls /tt/a/bhdfs dfs -ls -R / 递归查看hdfs dfs -get /test.log 从HDFS中获取文件hdfs dfs -rm /test.log 删除文件hdfs dfs -rm -R /tt 删除目录 HDFS Java API123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131public static final String HDFS_PATH = \"hdfs://10.211.55.6:8020\"; FileSystem fileSystem = null; Configuration configuration = null; @Before public void setUp() throws Exception &#123; System.out.println(\"HDFSApp.setUp\"); configuration = new Configuration(); fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration, \"parallels\"); &#125; @After public void tearDown() throws Exception &#123; configuration = null; fileSystem = null; System.out.println(\"HDFSApp.tearDown\"); &#125; /** * 创建HDFS目录 */ @Test public void mkdir() throws Exception &#123; fileSystem.mkdirs(new Path(\"/hdfsapi/test2\")); &#125; /** * 创建文件 */ @Test public void create() throws Exception &#123; FSDataOutputStream output = fileSystem.create(new Path(\"/hdfsapi/test2/a.txt\")); output.write(\"hello hadoop\".getBytes()); output.flush(); output.close(); &#125; /** * 查看HDFS文件的内容 */ @Test public void cat() throws Exception &#123; FSDataInputStream in = fileSystem.open(new Path(\"/hdfsapi/test2/a.txt\")); IOUtils.copyBytes(in, System.out, 1024); in.close(); &#125; /** * 重命名 */ @Test public void rename() throws Exception &#123; Path oldPath = new Path(\"/hdfsapi/test/a.txt\"); Path newPath = new Path(\"/hdfsapi/test/b.txt\"); fileSystem.rename(oldPath, newPath); &#125; /** * 上传文件到HDFS */ @Test public void copyFromLocalFile() throws Exception &#123; Path localPath = new Path(\"/Users/Finch/Downloads/springboot2.1.7.pom\"); Path hdfsPath = new Path(\"/hdfsapi/test\"); fileSystem.copyFromLocalFile(localPath, hdfsPath); &#125; /** * 上传文件到HDFS */ @Test public void copyFromLocalFileWithProgress() throws Exception &#123; InputStream in = new BufferedInputStream( new FileInputStream( new File(\"/Users/rocky/source/spark-1.6.1/spark-1.6.1-bin-2.6.0-cdh5.5.0.tgz\"))); FSDataOutputStream output = fileSystem.create(new Path(\"/hdfsapi/test/spark-1.6.1.tgz\"), new Progressable() &#123; public void progress() &#123; System.out.print(\".\"); //带进度提醒信息 &#125; &#125;); IOUtils.copyBytes(in, output, 4096); &#125; /** * 下载HDFS文件 */ @Test public void copyToLocalFile() throws Exception &#123; Path localPath = new Path(\"/Users/rocky/tmp/h.txt\"); Path hdfsPath = new Path(\"/hdfsapi/test/hello.txt\"); fileSystem.copyToLocalFile(hdfsPath, localPath); &#125; /** * 查看某个目录下的所有文件 * * 问题：我们已经在hdfs-site.xml中设置了副本系数为1，为什么此时查询文件看到的3呢？ * 如果你是通过hdfs shell的方式put的上去的那么，才采用默认的副本系数1 * 如果我们是java api上传上去的，在本地我们并没有手工设置副本系数，所以否则采用的是hadoop自己的副本系数 * * 【设置副本系数：configuration.set(\"dfs.replication\", \"1\");】 */ @Test public void listFiles() throws Exception &#123; FileStatus[] fileStatuses = fileSystem.listStatus(new Path(\"/hdfsapi/test\")); for(FileStatus fileStatus : fileStatuses) &#123; String isDir = fileStatus.isDirectory() ? \"文件夹\" : \"文件\"; short replication = fileStatus.getReplication(); long len = fileStatus.getLen(); String path = fileStatus.getPath().toString(); System.out.println(isDir + \"\\t\" + replication + \"\\t\" + len + \"\\t\" + path); &#125; &#125; /** * 删除 */ @Test public void delete() throws Exception&#123; fileSystem.delete(new Path(\"/\"), true); &#125; HDFS读写原理通过漫画轻松掌握HDFS工作原理 HDFS优缺点优点：数据冗余、硬件容错；可构建在廉价机器上；适合存储大文件。 缺点：数据访问延迟（想要极快进行数据检索并不现实）；不适合小文件存储（小文件太多会导致NameNode占用内存信息越多，增加了NameNode压力）。 YARN资源调度框架YARN在1.x时代只支持MapReduce任务，而在2.x之后可以让更多的计算框架（如Spark、Storm）运行在集群里面，不同的计算框架可以共享同一个HDFS的数据，享受整体的资源调度。 YARN架构 ResourceManager: RM 整个集群同一时间提供服务的RM只有一个（可以使用主从解决单点问题），负责集群资源的统一管理和调度 处理客户端的请求： 提交一个作业、杀死一个作业 监控我们的NM，一旦某个NM挂了，那么该NM上运行的任务需要告诉我们的AM来如何进行处理 NodeManager: NM 整个集群中有多个，负责自己本身节点资源管理和使用 定时向RM汇报本节点的资源使用情况 接收并处理来自RM的各种命令：启动Container 处理来自AM的命令 单个节点的资源管理 ApplicationMaster: AM 每个应用程序对应一个：MR、Spark，负责应用程序的管理 为应用程序向RM申请资源（core、memory），分配给内部task 需要与NM通信：启动/停止task，task是运行在container里面，AM也是运行在container里面 Container 封装了CPU、Memory等资源的一个容器 是一个任务运行环境的抽象 Client 提交作业 查询作业的运行进度 杀死作业 运行流程https://github.com/heibaiying/BigData-Notes/blob/master/notes/Hadoop-YARN.md Client 提交作业到 YARN 上； Resource Manager 选择一个 Node Manager，启动一个 Container 并运行 Application Master 实例； Application Master 根据实际需要向 Resource Manager 请求更多的 Container 资源（如果作业很小, 应用管理器会选择在其自己的 JVM 中运行任务）； Application Master 通过获取到的 Container 资源执行分布式计算。 YARN伪分布式环境搭建1）mapred-site.xml [ mapred-site.xml.template 改名去后缀 ] 1234&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt; 2）yarn-site.xml 1234&lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt; 3) 启动YARN相关的进程 1sbin/start-yarn.sh 4）验证 jps：ResourceManager 、NodeManager 访问8088端口 5）停止YARN相关的进程 1sbin/stop-yarn.sh 提交mr作业到YARN上运行： 使用Jar包：hadoop-2.6.0-cdh5.7.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.7.0.jar 使用命令hadoop jar，比如 hadoop jar hadoop-mapreduce-examples-2.6.0-cdh5.7.0.jar pi 2 3 MapReduce优点：海量数据离线处理 缺点：实时流式计算 入门案例：wordcount: 统计文件中每个单词出现的次数，借用 MapReduce 可以实现分而治之。 MapReduce 框架专门用于键值对处理，它将作业的输入视为一组对，并生成一组对作为输出。输出和输出的 key 和 value 都必须实现Writable 接口。 key classes 还必须实现 WritableComparable 接口。 1(input) &lt;k1, v1&gt; -&gt; map -&gt; &lt;k2, v2&gt; -&gt; combine -&gt; &lt;k2, v2&gt; -&gt; reduce -&gt; &lt;k3, v3&gt; (output) 核心概念Split: 交由MapReduce作业来处理的数据块，是MapReduce中最小的计算单元。HDFS中 blocksize 是HDFS中最小的存储单元 128M。默认情况下：他们两是一一对应的，当然我们也可以手工设置他们之间的关系（不建议） InputFormat: 将我们的输入数据进行分片(split): InputSplit[] getSplits(JobConf job, int numSplits) throws IOException;TextInputFormat: 处理文本格式的数据 OutputFormat: 输出 Combiner Partitioner MapReduce 2.x 架构 Java 版 WordCount1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.Mapper;import org.apache.hadoop.mapreduce.Reducer;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;import java.io.IOException;/** * 使用MapReduce开发WordCount应用程序 **/public class WordCountApp &#123; /** * Map: 读取输入的文件内容 */ public static class MyMapper extends Mapper&lt;LongWritable, Text, Text, LongWritable&gt; &#123; LongWritable one = new LongWritable(1); protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; // 接收到的每一行数据 String line = value.toString(); // 按照指定的分割符进行拆分 String[] words = line.split(\" \"); for (String word : words) &#123; // 通过上下文把map的处理结果输出 context.write(new Text((word)), one); &#125; &#125; &#125; /** * Reduce: 归并操作 */ public static class MyReducer extends Reducer&lt;Text, LongWritable, Text, LongWritable&gt; &#123; protected void reduce(Text key, Iterable&lt;LongWritable&gt; values, Context context) throws IOException, InterruptedException &#123; long sum = 0; for (LongWritable value : values) &#123; // 求key出现的次数总和 sum += value.get(); &#125; // 将最终的统计结果输出 context.write(key, new LongWritable(sum)); &#125; &#125; /** * 定义Driver：封装了MapReduce作业的所有信息 */ public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123; Configuration configuration = new Configuration(); // 准备清理已存在的输出目录, 在MR中，输出文件是不能事先存在的 Path outputPath = new Path(args[1]); FileSystem fileSystem = FileSystem.get(configuration); if (fileSystem.exists(outputPath)) &#123; fileSystem.delete(outputPath,true); System.out.println(\"output file exists, but is has deleted\"); &#125; // 创建Job，通过参数设置Job的名称 Job job = Job.getInstance(configuration, \"wordcount\"); // 设置Job的处理类 job.setJarByClass(WordCountApp.class); // 设置作业处理的输入路径 FileInputFormat.setInputPaths(job, new Path(args[0])); // 设置map相关参数 job.setMapperClass(MyMapper.class); job.setMapOutputKeyClass(Text.class); job.setMapOutputValueClass(LongWritable.class); // 设置reduce相关参数 job.setReducerClass(MyReducer.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(LongWritable.class); // 通过Job对象来设置Combiner处理类，在逻辑上和reduce是一样的 job.setCombinerClass(MyReducer.class); // 设置作业处理完成后的输出路径 FileOutputFormat.setOutputPath(job, new Path(args[1])); System.exit(job.waitForCompletion(true) ? 0 : 1); &#125;&#125; 执行: 1hadoop jar /home/hadoop/lib/hadoop-train-1.0.jar com.hadoop.mapreduce.WordCountApp hdfs://10.211.55.6:8020/hello.txt hdfs://10.211.55.6:8020/output/wc Combiner 本地的Reduce； 减少Map Tasks输出的数据量及数据网络传输量； 但适用场景有限，比如求和计数等，不适合求平均数等类似场景。 PartitionerPartitioner决定Map Task输出的数据交由哪个Reduce Task处理。默认实现：分发的key的hash值对Reduce Task个数取模。 案例：手机销量手机按品牌分类收集至各个文件中 123456789101112131415161718192021222324252627282930313233343536373839public static class MyMapper extends Mapper&lt;LongWritable, Text, Text, LongWritable&gt; &#123; protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123; // 接收到的每一行数据 String line = value.toString(); // 按照指定的分割符进行拆分 String[] words = line.split(\" \"); // 通过上下文把map的处理结果输出 context.write(new Text((words[0])), new LongWritable(Long.parseLong(words[1]))); &#125; &#125; public static class MyPartitioner extends Partitioner&lt;Text, LongWritable&gt; &#123; public int getPartition(Text key, LongWritable value, int numPartitions) &#123; if(key.toString().equals(\"xiaomi\"))&#123; return 0; &#125; if(key.toString().equals(\"huawei\"))&#123; return 1; &#125; if(key.toString().equals(\"iphone7\")) &#123; return 2; &#125; return 3; &#125; &#125; public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123; ... // 设置Job的partition job.setPartitionerClass(MyPartitioner.class); // 设置4个reducer，每个分区一个 job.setNumReduceTasks(4); FileOutputFormat.setOutputPath(job, new Path(args[1])); System.exit(job.waitForCompletion(true) ? 0 : 1); &#125; JobHistoryJobHistory是一个Hadoop自带的历史服务器，它用于记录已运行完的MapReduce信息到指定的HDFS目录下。可以通过HTTP页面访问获得信息。 mapred-site.xml 添加： 12345678910111213141516171819202122&lt;!-- jobhistory的通信地址 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;192.168.77.130:10020&lt;/value&gt; &lt;description&gt;MapReduce JobHistory Server IPC host:port&lt;/description&gt;&lt;/property&gt;&lt;!-- jobhistory的web访问地址 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;192.168.77.130:19888&lt;/value&gt; &lt;description&gt;MapReduce JobHistory Server IPC host:port&lt;/description&gt;&lt;/property&gt;&lt;!-- 任务运行完成后，history信息所存放的目录 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.done-dir&lt;/name&gt; &lt;value&gt;/history/done&lt;/value&gt;&lt;/property&gt;&lt;!-- 任务运行中，history信息所存放的目录 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.intermediate-done-dir&lt;/name&gt; &lt;value&gt;/history/done_intermediate&lt;/value&gt;&lt;/property&gt; yarn-site.xml 添加： 12345&lt;!-- 开启聚合日志 --&gt;&lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; 之后需要重启YARN访问，stop-yarn.sh 以及 start-yarn.sh。 启动 sbin/mr-jobhistory-daemon.sh start historyserver，在19888端口处就可以看到接下来的执行信息了。 https://blog.51cto.com/zero01/2093445","categories":[{"name":"BigData","slug":"BigData","permalink":"https://weilans.github.io/categories/BigData/"}],"tags":[]},{"title":"[指标监控] 云原生监控系统 Prometheus","slug":"指标监控-2-云原生监控系统-Prometheus","date":"2019-12-07T18:44:30.000Z","updated":"2021-09-24T02:16:42.555Z","comments":true,"path":"2019/12/08/指标监控-2-云原生监控系统-Prometheus/","link":"","permalink":"https://weilans.github.io/2019/12/08/指标监控-2-云原生监控系统-Prometheus/","excerpt":"Prometheus 作为当前炙手可热的云原生监控系统，是继 Kubernetes 之后第二个加入云原生计算基金会的成员。其安装及使用也是相当便捷，有强大的扩展性和集成性，查询语言 PromQL 可以轻松完成指标数据的查询与聚和。","text":"Prometheus 作为当前炙手可热的云原生监控系统，是继 Kubernetes 之后第二个加入云原生计算基金会的成员。其安装及使用也是相当便捷，有强大的扩展性和集成性，查询语言 PromQL 可以轻松完成指标数据的查询与聚和。 监控的目标《SRE: Google运维解密》一书中指出，监控系统需要能够有效的支持白盒监控和黑盒监控：通过白盒能够了解其内部的实际运行状态，通过对监控指标的观察能够预判可能出现的问题，从而对潜在的不确定因素进行优化。而黑盒监控，常见的如HTTP探针，TCP探针等，可以在系统或者服务在发生故障时能够快速通知相关的人员进行处理。通过建立完善的监控体系，从而达到以下目的： 长期趋势分析：通过对监控样本数据的持续收集和统计，对监控指标进行长期趋势分析。例如，通过对磁盘空间增长率的判断，我们可以提前预测在未来什么时间节点上需要对资源进行扩容。 对照分析：两个版本的系统运行资源使用情况的差异如何？在不同容量情况下系统的并发和负载变化如何？通过监控能够方便的对系统进行跟踪和比较。 告警：当系统出现或者即将出现故障时，监控系统需要迅速反应并通知管理员，从而能够对问题进行快速的处理或者提前预防问题的发生，避免出现对业务的影响。 故障分析与定位：当问题发生后，需要对问题进行调查和处理。通过对不同监控监控以及历史数据的分析，能够找到并解决根源问题。 数据可视化：通过可视化仪表盘能够直接获取系统的运行状态、资源使用情况、以及服务运行状态等直观的信息。 为什么使用 Prometheus Prometheus核心部分只有一个单独的二进制文件，不存在任何的第三方依赖(数据库，缓存等等)。唯一需要的就是本地磁盘，因此不会有潜在级联故障的风险。(Prometheus 不仅仅是一个监控系统，同时也是一个时序数据库，Prometheus 不直接使用现有的时序数据库作为后端存储，就是希望监控系统有着时序数据库的特点，而且还需要部署和维护非常方便) Prometheus基于 Pull 模型的架构方式，可以在任何地方搭建我们的监控系统。对于一些复杂的情况，还可以使用Prometheus服务发现(Service Discovery)的能力动态管理监控目标。 拥有多维度数据模型：所有采集的监控数据均以指标(metric)的形式保存在内置的时间序列数据库当中(TSDB)。所有的样本除了基本的指标名称以外，还包含一组用于描述该样本特征的标签，一个时间序列由一个度量指标和多个标签值确定。 强大的查询语言 PromQL：Prometheus 内置了一个强大的数据查询语言 PromQL。 通过 PromQL 可以实现对监控数据的查询、聚合。同时 PromQL 也被应用于数据可视化(如Grafana)以及告警当中。通过PromQL可以轻松回答类似于以下问题： 在过去一段时间中95%应用延迟时间的分布范围？ 预测在4小时后，磁盘空间占用大致会是什么情况？ CPU占用率前5位的服务有哪些？(过滤) Prometheus可以高效地处理这些数据，对于单一 Prometheus Server 实例而言它可以处理：数以百万的监控指标；每秒处理数十万的数据点。 扩展性：每个数据中心、每个团队都可以运行独立的 Prometheus Sevrer。Prometheus 对于联邦集群的支持，可以让多个Prometheus实例产生一个逻辑集群，当单实例 Prometheus Server 处理的任务量过大时，通过使用 功能分区(sharding) + 联邦集群(federation) 可以对其进行扩展。 易于集成：支持多种语言客户端，基于这些SDK可以快速让应用程序纳入到Prometheus的监控当中，或者开发自己的监控数据收集程序。此外，还提供大量第三方提供的数据采集Exporters，比如：Oracle DB Exporter、PostgreSQL exporter、Redis exporter、NVIDIA GPU exporter、RabbitMQ exporter、Nginx metric library、JMX exporter等。 安装 Prometheus Serverdocker 安装 Prometheus Server： 1docker run -d -p 9090:9090 -v /etc/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus 打开 http://127.0.0.1:9090/ 就可以看到 Prometheus 主页了。 也可以直接下载安装包，解压后执行： 1./prometheus --config.file=prometheus.yml 在Prometheus的架构设计中，Prometheus Server 并不直接服务监控特定的目标，其主要任务负责数据的收集，存储并且对外提供数据查询支持。因此为了能够能够监控到某些东西，如主机的CPU使用率，我们需要使用到Exporter。为了能够采集到主机的运行指标如CPU, 内存，磁盘等信息，可以使用 Node Exporter。直接运行node_exporter，打开9100端口，在 http://localhost:9100/metrics 就可以看到相关信息。 想要主动拉取 Node 信息，需要配置 prometheus.yml，job_name 为 prometheus 为其自带的，暂且不管。metrics_path 默认为 /metrics，对于后续监控自己的系统，想要更改path，即添加或更改此属性。在下方新增 node job_name 启动后，就可以在 Prometheus 首页的 Expression 处搜索到 Node 信息了。 1234567scrape_configs: - job_name: 'prometheus' static_configs: - targets: ['localhost:9090'] - job_name: 'node' static_configs: - targets: ['localhost:9100'] Prometheus 架构 中间最核心的就是 Prometheus Server，最重要的功能就是数据的获取，主要是以 pull 的方式从 Jobs、Exporters 拉取，而寿命周期短的任务则可以存放数据至 Pushgateway 网关，再由 Prometheus Server 定期从网关中拉取。也可以通过 Service Discovery 发现需要主动监控的访问（当要监控特别多的节点，而这些节点也是动态变化的，可以采用这种方式） 。 Prometheus Server 会将数据存储存储在磁盘上，并对外暴露 HTTP 服务，供外部客户端进行 PromQL 查询。 此外，还可以配置一些报警条件，当条件满足时，报警信息会以 push 的方式推至 Alertmanager，由 Alertmanager 处理告警的通知（当然，实际的告警是 Prometheus 产生的），比如告警去重后以短信或者邮件的方式进行通知。 Prometheus 核心概念数据模型 Metric names and labels 指标名称及标签：每个时间序列由其指标名称和称为标签的可选键值对来进行唯一标识。 Sample 采样值：时序序列的数据即是样本，每个样本是一个float64数值，或者是一个精确到毫秒的时间戳。 Notation 标记/注解：实际上就是指标和标签组合的时间序列表示： 12&lt;metric name&gt;&#123;&lt;label name&gt;=&lt;label value&gt;, ...&#125;api_http_requests_total&#123;method=\"POST\", handler=\"/messages\"&#125; 度量指标 Counter 计数器 ： 是一个累计的指标，表示一个单调递增的计数器，比如用于任务请求数、成功或失败的任务数等。 Gauge 计量器：是一个数值可以上下移动的指标。 Histogram 直方图：主要用于采样分析，将范围分成一个个的桶，将数值放入桶中进行分布情况分析。 Summary 汇总：与 Histogram 类似，主要提供百分比分布情况。 任务和实例任务 Job、实例 Instance 一个任务可能有多个实例，比如要应用的某个指标，可以为这个应用建一个 Job，该应用可以有多台服务器，即有多个 Instance。当前在每一个Job中主要使用了静态配置(static_configs)的方式定义监控目标。除了静态配置每一个Job的采集Instance地址以外，Prometheus还支持与DNS、Consul、E2C、Kubernetes等进行集成实现自动发现Instance实例，并从这些Instance上获取监控数据。访问 /target 直接从Prometheus的UI中查看当前所有的任务以及每个任务对应的实例信息。 Prometheus 抓取采样值后，会自动给采样值添加一下标签和值：job 抓取所属任务、instance 抓取来源实例。 另外每次抓取时，Prometheus 还会自动在以下时序里插入采样值： up{job=&quot;&quot;, instance=&quot;&quot;}: 1 if the instance is healthy, i.e. reachable, or 0 if the scrape failed. scrape_duration_seconds{job=&quot;&quot;, instance=&quot;&quot;}: duration of the scrape. scrape_samples_post_metric_relabeling{job=&quot;&quot;, instance=&quot;&quot;}: the number of samples remaining after metric relabeling was applied. scrape_samples_scraped{job=&quot;&quot;, instance=&quot;&quot;}: the number of samples the target exposed. scrape_series_added{job=&quot;&quot;, instance=&quot;&quot;}: the approximate number of new series in this scrape. New in v2.10 Prometheus 配置完整配置文档 prometheus.yml 文件内容： 123456789101112131415161718192021222324global: # 全局配置，全局节点的配置对其他所有节点都有效，同时也是其他节点的默认值 scrape_interval: 15s # 抓取间隔 默认1min evaluation_interval: 15s # 规则评估间隔 默认1min # scrape_timeout # 抓取超时时间 默认10s alerting: # Alertmanager 的配置 alertmanagers: - static_configs: - targets: # - alertmanager:9093 rule_files: # 记录规则配置和告警规则配置 # - \"first_rules.yml\" # - \"second_rules.yml\" scrape_configs: # 抓取配置 - job_name: 'prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. static_configs: - targets: ['localhost:9090'] 抓取配置： 123456789101112131415161718192021222324252627282930313233# 任务名job_name: &lt;job_name&gt;# 抓取间隔，默认为全局配饰[ scrape_interval: &lt;duration&gt; | default = &lt;global_config.scrape_interval&gt; ]# 抓取超时时间，默认为全局配饰[ scrape_timeout: &lt;duration&gt; | default = &lt;global_config.scrape_timeout&gt; ]# 抓取地址的路径，默认为/metrics[ metrics_path: &lt;path&gt; | default = /metrics ]# 是否尊重抓取回来的标签[ honor_labels: &lt;boolean&gt; | default = false ]# 协议，默认http，可选https[ scheme: &lt;scheme&gt; | default = http ]# 抓取地址的参数params: [ &lt;string&gt;: [&lt;string&gt;, ...] ] # 目标配置 static_configs: [ - &lt;static_config&gt; ... ]# Sets the `Authorization` header on every scrape request with the# configured username and password.# password and password_file are mutually exclusive.basic_auth: [ username: &lt;string&gt; ] [ password: &lt;secret&gt; ] [ password_file: &lt;string&gt; ] ： 1234567# 目标地址列表targets: [ - '&lt;host&gt;' ]# 标签列表labels: [ &lt;labelname&gt;: &lt;labelvalue&gt; ... ] PromQLPromQL 语法数据类型 Instant vector 瞬时向量： 一组时序，每个时序只有一个采样值 Range vector 区间向量：一组时序，每个时序包含一段时间内的多个采样值 Scalar 标量：一个浮点数 String 字符串：一个字符串，暂时未用 时序选择器瞬时向量选择器选择一组时序在某个采用点的采样值。最简单的情况就是指定一个指标，选择出所有属于该度量指标的时序的当前采样值。 1http_requests_total 可以在后面添加用大括号包围起来的一组标签键值对来对时序进行过滤： 1http_requests_total&#123;job=\"prometheus\",group=\"canary\"&#125; 标签匹配时，可以使用值，也可以使用正则表达式，匹配操作符有如下四种： =: Select labels that are exactly equal to the provided string. !=: Select labels that are not equal to the provided string. =~: Select labels that regex-match the provided string. !~: Select labels that do not regex-match the provided string. 示例如下： 1http_requests_total&#123;environment=~\"staging|testing|development\",method!=\"GET\"&#125; 度量指标名称也可以使用使用内部标签__name__表示，表达式 http_requests_total 也可以写成 {__name__=&quot;http_requests_total&quot;}。表达式{__name__=~&quot;customized.*&quot;}匹配所有指标名称以customized打头的时序。 区间向量选择器与瞬时向量选择器不同的是，会在后面加上中括号包起来的指定区间长度： 1http_requests_total&#123;job=\"prometheus\"&#125;[5m] 时长单位为以下几种： s - seconds m - minutes h - hours d - days w - weeks y - years 偏移修饰器上两种选择器是是当前时间或从当前时间倒推的，若需要选择过去时间点或过去时间点倒推的，则使用偏移修饰器。 12345# 指标名称为 http_requests_total 的所有时序在5分钟前的采样值http_requests_total offset 5m# 指标名称为 http_requests_total 的在一周前的这个时间点过去5分钟的采样值http_requests_total[5m] offset 1w 二元操作符 + (addition) - (subtraction) * (multiplication) / (division) % (modulo) ^ (power/exponentiation) 传统二元运算符用在标量和标量之间，而这里可以用在向量和标量、向量和向量之间。二元操作符里的向量特指瞬时向量，不包含区间向量。 标量与标量：通常的算术运算。 向量与标量：把标量与向量里的每一个标量进行运算，结果组成一个新向量 向量与向量：左边向量里的每一个元素在右边向量里去找一个匹配元素（见向量匹配规则），然后两个匹配元素执行计算，计算结果组成一个新的向量。如果没有找到匹配元素，则该元素丢弃。 ![image-20191219181408718](/Users/john/Library/Application Support/typora-user-images/image-20191219181408718.png) 向量匹配规则有两种匹配规则：one-to-one，one-to-many/many-to-to： one-to-one：左边的向量的元素匹配到唯一一个右边元素。看标签键值对是否匹配（不看指标名称），ignoring忽略标签不参与匹配的标签，on指定参与匹配的标签。 123456789101112131415method_code:http_errors:rate5m&#123;method=\"get\", code=\"500\"&#125; 24method_code:http_errors:rate5m&#123;method=\"get\", code=\"404\"&#125; 30method_code:http_errors:rate5m&#123;method=\"put\", code=\"501\"&#125; 3method_code:http_errors:rate5m&#123;method=\"post\", code=\"500\"&#125; 6method_code:http_errors:rate5m&#123;method=\"post\", code=\"404\"&#125; 21method:http_requests:rate5m&#123;method=\"get\"&#125; 600method:http_requests:rate5m&#123;method=\"del\"&#125; 34method:http_requests:rate5m&#123;method=\"post\"&#125; 120查询：method_code:http_errors:rate5m&#123;code=\"500\"&#125; / ignoring(code) method:http_requests:rate5m执行结果：&#123;method=\"get\"&#125; 0.04 // 24 / 600&#123;method=\"post\"&#125; 0.05 // 6 / 120 one-to-many/many-to-one：某一边会有多个元素和另一边的元素匹配，需要使用group_left或group_right指明是左边还是右边元素较多： 1234567查询：method_code:http_errors:rate5m / ignoring(code) group_left method:http_requests:rate5m执行结果：&#123;method=\"get\", code=\"500\"&#125; 0.04 // 24 / 600&#123;method=\"get\", code=\"404\"&#125; 0.05 // 30 / 600&#123;method=\"post\", code=\"500\"&#125; 0.05 // 6 / 120&#123;method=\"post\", code=\"404\"&#125; 0.175 // 21 / 120 不过，这种方式过于复杂，要尽量避免使用，很多时候使用 ignoring 降为 one-to-one 的匹配。 聚和操作符用于聚和一个瞬时向量中的元素，将向量里的元素聚和的更少。 sum (calculate sum over dimensions) min (select minimum over dimensions) max (select maximum over dimensions) avg (calculate the average over dimensions) count (count number of elements in the vector) quantile (calculate φ-quantile (0 ≤ φ ≤ 1) over dimensions) stddev (calculate population standard deviation over dimensions) 标准差 stdvar (calculate population standard variance over dimensions) 方差 count_values (count number of elements with the same value) bottomk (smallest k elements by sample value) topk (largest k elements by sample value) without用来指定聚和时不需要保留的标签，by用来指定聚和时需要保留的标签（可以类比SQL中的 group by）。 http_requests_total有这三个标签 application, instance, and group ，以下两者相等： 12sum without (instance) (http_requests_total)sum by (application, group) (http_requests_total) 所有的进行求和： 1sum(http_requests_total) 函数完整见官方文档，常见的如下: abs 绝对值 sqrt 平方根 exp 指数计算 ln 自然对数 ceil 向上取整 floor 向下取整 round 四舍五入取整 delta 计算区间向量里每一个时序第一个和最后一个的差值 sort 排序 Referencehttps://songjiayang.gitbooks.io/prometheus/content/introduction/what.html https://www.bilibili.com/video/av22954995/ https://www.aneasystone.com/archives/2018/11/prometheus-in-action.html https://frezc.github.io/2019/08/03/prometheus-metrics/ https://yunlzheng.gitbook.io/prometheus-book/parti-prometheus-ji-chu/quickstart/why-monitor https://www.cnblogs.com/ryanyangcs/p/11309373.html","categories":[{"name":"monitor","slug":"monitor","permalink":"https://weilans.github.io/categories/monitor/"}],"tags":[{"name":"prometheus","slug":"prometheus","permalink":"https://weilans.github.io/tags/prometheus/"}]},{"title":"[指标监控] JVM 指标框架 Micrometer","slug":"指标监控-1-JVM-指标框架-Micrometer","date":"2019-11-29T01:38:56.000Z","updated":"2021-06-02T06:26:19.060Z","comments":true,"path":"2019/11/29/指标监控-1-JVM-指标框架-Micrometer/","link":"","permalink":"https://weilans.github.io/2019/11/29/指标监控-1-JVM-指标框架-Micrometer/","excerpt":"作为 Micrometer + Prometheus + Grafana 的开篇，介绍Micrometer的基础应用。当前项目与数据库集打交道，但目前因为没有相关指标监控，项目运行情况一直是个黑盒。对于接口调用情况、连接池配置情况、性能情况若都是手动分析日志，则必然是不可行的。所以想要基于这三者搭建一台指标监控体系。","text":"作为 Micrometer + Prometheus + Grafana 的开篇，介绍Micrometer的基础应用。当前项目与数据库集打交道，但目前因为没有相关指标监控，项目运行情况一直是个黑盒。对于接口调用情况、连接池配置情况、性能情况若都是手动分析日志，则必然是不可行的。所以想要基于这三者搭建一台指标监控体系。 接触到Micrometer还是因为Spring Boot Actuator，在 Spring Boot 2.0之后，Micrometer 已经是 Actuator 的默认实现。文中默认有 Actuator 以及 Prometheus 的依赖，Actuator 在 1.x 和 2.x 区别较大，本文使用的版本是 2.1.7，且默认management.endpoints.web.exposure.include中包含 prometheus。 123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;&lt;/dependency&gt; Metrics可以翻译成度量或者指标，这两者其实并无太大区别，只是各适用于特定场景而已，本文中统一叫作指标。 介绍Micrometer首页这么介绍自己： Micrometer provides a simple facade over the instrumentation clients for the most popular monitoring systems, allowing you to instrument your JVM-based application code without vendor lock-in. Think SLF4J, but for metrics. 不同的监控体系有不同的数据收集、命名规约、三方依赖，Micrometer 的定位就是监控系统的 Facade，类比于日志系统的 Slf4j，Micrometer 可以很好地完成针对不同监控系统的适配与切换，使指标数据可移植性最大化。在Maven仓库中，可以看到各类 Registry (mvn, github)。 RegistryMeter是 Micrometer 最基础的接口，使用 Micrometer 时最常用的 Timer、Counter、Guage、DistributionSummary就是继承自该接口，收集的系统数据就是用 Meter 来表示。Meter 在 Micrometer 中由 MeterRegistry创建并保存，每个支持的监控系统都有一个MeterRegistry实现（Prometheus的实现是PrometheusMeterRegistry）。如果事先没有指定监控系统，Micrometer 默认生成一个将 Meter 最新数据保留在内存的SimpleMeterRegistry。 在SimpleMetricsExportAutoConfiguration中就可以看到 SimpleMeterRegistry 的配置，该类包含: @ConditionalOnMissingBean(MeterRegistry.class)。 1234SimpleMeterRegistry simple = new SimpleMeterRegistry();Counter counter = simple.counter(\"counter\");counter.increment();System.out.println(counter.count()); // 1.0 除了作为基础实现的SimpleMeterRegistry外，Micrometer 提供CompositeMeterRegistry，可将多个 MeterRegistry 加入其中，使 Meter 数据同时发送到不同监控系统。 1234567891011121314CompositeMeterRegistry composite = new CompositeMeterRegistry();Counter compositeCounter = composite.counter(\"counter\");compositeCounter.increment(); // no opSystem.out.println(compositeCounter.count()); // 0.0SimpleMeterRegistry simple1 = new SimpleMeterRegistry();composite.add(simple1);SimpleMeterRegistry simple2 = new SimpleMeterRegistry();composite.add(simple2);compositeCounter.increment();System.out.println(simple1.counter(\"counter\").count()); // 1.0System.out.println(simple2.counter(\"counter\").count()); // 1.0 此外，Micrometer 还持有一个Global MeterRegistry：Metrics.globalRegistry，其也是一个 CompositeMeterRegistry。如果没有引入 Prometheus 的依赖，Metrics.globalRegistry 中包含的就是 SimpleMeterRegistry，MeterRegistryPostProcessor会将生成的系统初始生成的 SimpleMeterRegistry 注入进全局 Registry 中。如果引入了 Prometheus 的依赖，注入进全局 Registry 的就是 PrometheusMeterRegistry。 12345678public class Metrics &#123; public static final CompositeMeterRegistry globalRegistry = new CompositeMeterRegistry(); public static void addRegistry(MeterRegistry registry) &#123; globalRegistry.add(registry); &#125; //...&#125; 命名MeterMicrometer 中规定单词用.(dot)隔开，而不同监控系统的命名规范并不一致，例如在 Micrometer 中可以这样命名一个 Meter： 1registry.timer(\"http.server.requests\"); 在不同监控系统中则应该是： system name Prometheus http_server_requests_duration_seconds Atlas httpServerRequests Graphite http.server.requests InfluxDB http_server_requests 所以需要一种命名转换体系将 Micrometer 中的命名转为特定系统的规范命名，Micrometer 提供了 NamingConvention供各系统实现，开发者可以使用以下方式自定义命名规则： 1registry.config().namingConvention(myCustomNamingConvention); Tag既然有了指标，则必然包含维度的概念，只有使用不同的维度才能对指标进行更好的区分和收集。Micrometer 中 Tag 就扮演了这样的角色。 12registry.counter(\"database.calls\", \"db\", \"users\") // database.calls即为自行定义的指标, 而维度就是db, 含义即为db为users的数据库调用次数registry.counter(\"http.requests\", \"uri\", \"/api/users\") // uri为/api/users的http请求次数 Tag 参数必须以 TagKey=TagValue 的方式成对出现。当命名 Tag 时，也建议使用和 Meter 一样的 dot 命名方式。同时，Tag value 必须是非空。 此外，还有一种Common tags，对于每种 Meter，都会将 Tag 加入其中，一般用于指定 IP、实例、地区等信息，便于数据收集后进行区分。 1registry.config().commonTags(\"stack\", \"prod\", \"region\", \"us-east-1\"); Meter filtersMeterRegistry 提供 Meter Filter，可以控制 Meter 的注册以及忽略特定统计行为。官方示例如下： 123registry.config() .meterFilter(MeterFilter.ignoreTags(\"too.much.information\")) .meterFilter(MeterFilter.denyNameStartsWith(\"jvm\")); 针对Filter进行简单的试验： 1234567891011121314151617SimpleMeterRegistry simple1 = new SimpleMeterRegistry();simple1.config() .meterFilter(MeterFilter.ignoreTags(\"db2\", \"db3\")) .meterFilter(MeterFilter.denyNameStartsWith(\"jvm\"));Counter c1 = simple1.counter(\"database.calls\", \"db1\", \"users\");Counter c2 = simple1.counter(\"database.calls\", \"db2\", \"users\");Counter c3 = simple1.counter(\"database.calls\", \"db3\", \"users\");Counter c4 = simple1.counter(\"jvm.requests\", \"uri\", \"/api/users\");c1.increment();c2.increment();c3.increment();c4.increment();List&lt;Meter&gt; meters = simple1.getMeters();for (Meter meter : meters) &#123; System.out.println(meter.getId() + \" \" + meter.measure());&#125; 其输出结果为： 12MeterId&#123;name='database.calls', tags=[]&#125; [Measurement&#123;statistic='COUNT', value=2.0&#125;]MeterId&#123;name='database.calls', tags=[tag(db1=users)]&#125; [Measurement&#123;statistic='COUNT', value=1.0&#125;] 可以看见jvm.requests直接被过滤了，而 Tag db2和db3由于被忽略了，其值添加到了name=&#39;database.calls&#39;, tags=[]中，其 count值为 2.0。 Meter filters 有很多复杂的功能，此处就不展开了。 Meter类别CounterCounter 是最简单的 Meter，其含义即为单值递增计数器，值必须是正数。 对于每种 Meter 而言，各有一套 fluent api 创建实例，Counter 的示例如下： 1234567Counter counter = Counter .builder(\"counter\") .baseUnit(\"beans\") // optional .description(\"a description of what this counter does\") // optional .tags(\"region\", \"test\") // optional .register(registry);counter.increment(); FunctionCounter实际上和Counter本身差别不大，只是将计数的行为抽象成 ToDoubleFunction 接口。 比如上下文中有一个 AtomicInteger ，那么 FunctionCounter 可以直接使用这个原子类来完成相关计数操作。这样的好处是对程序上下文而言，不需要感知该 Meter 的存在。 12345678910111213141516MeterRegistry registry = new SimpleMeterRegistry();AtomicInteger ai = new AtomicInteger(0);FunctionCounter counter = FunctionCounter.builder(\"counter\", ai, AtomicInteger::get) .description(\"functionCounterTest\") .tag(\"region\", \"ABC\") .register(registry);ai.incrementAndGet();ai.incrementAndGet();ai.incrementAndGet();System.out.println(ai.get()); // 3System.out.println(counter.measure()); // [Measurement&#123;statistic='COUNT', value=3.0&#125;]ai.set(100);System.out.println(ai.get()); // 100System.out.println(counter.measure()); // [Measurement&#123;statistic='COUNT', value=100.0&#125;] Guage记录指标的当前值，其典型应用是集合或Map的大小、线程的数量、CPU或内存情况。Guages 主要适用于有上边界的指标，要将其和 Counter 区分开。其Fluent Api 接口同样是将计数逻辑交给 ToDoubleFunction 接口。 123456789List&lt;String&gt; list = new ArrayList&lt;&gt;();Gauge gauge = Gauge .builder(\"gauge\", list, List::size) .description(\"description\") // optional .tags(\"region\", \"test\") // optional .register(registry);System.out.println(gauge.measure()); // [Measurement&#123;statistic='VALUE', value=0.0&#125;]list.add(\"\");System.out.println(gauge.measure()); // [Measurement&#123;statistic='VALUE', value=1.0&#125;] 官方文档中还提供了用于观察数值、集合、Map的方法： 123456// &lt;T&gt; T gauge(String name, Iterable&lt;Tag&gt; tags, @Nullable T obj, ToDoubleFunction&lt;T&gt; valueFunction)List&lt;String&gt; list = registry.gauge(\"listGauge\", Collections.emptyList(), new ArrayList&lt;&gt;(), List::size); // &lt;T extends Collection&lt;?&gt;&gt; T gaugeCollectionSize(String name, Iterable&lt;Tag&gt; tags, T collection)List&lt;String&gt; list2 = registry.gaugeCollectionSize(\"listSize2\", Tags.empty(), new ArrayList&lt;&gt;()); // &lt;T extends Map&lt;?, ?&gt;&gt; T gaugeMapSize(String name, Iterable&lt;Tag&gt; tags, T map)Map&lt;String, Integer&gt; map = registry.gaugeMapSize(\"mapGauge\", Tags.empty(), new HashMap&lt;&gt;()); Micrometer 默认是不会创建对象的强引用（可以观察抽象类 MeterRegistry 的 newGauge 具体实现），如果 Guage 值无法观察到，那可能是对象已被执行垃圾回收。 TimerTimer 用于记录时间相对较短的事件延迟情况和事件发生的频率，Timer 的所有实现至少记录了事件总时间消耗以及次数。以记录请求延时情况为例，由于可能瞬时记录大量信息，所以Timer每秒将更新很多次。 123456789Timer timer = Timer .builder(\"my.timer\") .description(\"a description of what this timer does\") // optional .tags(\"region\", \"test\") // optional .register(registry);timer.record(12, TimeUnit.SECONDS);timer.record(2, TimeUnit.SECONDS);timer.record(23, TimeUnit.SECONDS);System.out.println(timer.measure()); // [Measurement&#123;statistic='COUNT', value=3.0&#125;, Measurement&#123;statistic='TOTAL_TIME', value=37.0&#125;, Measurement&#123;statistic='MAX', value=23.0&#125;] Timer 可以记录代码的执行耗时，其接收 Runnable 以及 Callable 参数。这个可以按照实际需要决定是否需要，个人不喜欢将执行代码的线程更换掉（还得考虑ThreadLocal及其他上下文情况），但不否认其拥有应用场景。 12345timer.record(() -&gt; dontCareAboutReturnValue());timer.recordCallable(() -&gt; returnValue());Runnable r = timer.wrap(() -&gt; dontCareAboutReturnValue());Callable c = timer.wrap(() -&gt; returnValue()); Timer 还有个内部类Timer.Sample，可以通过手动调用 start 和 stop 记录执行情况： 1234Timer.Sample sample = Timer.start(registry);// do stuffResponse response = ...sample.stop(registry.timer(\"my.timer\", \"response\", response.status())); Distribution summariesdistribution summary 用来追踪事件的分布情况，其结构和 Timer 类似，但是其值不是由时间单位表示，也可以认为 Timer 只是特例化的 distribution summary ，但是 Micrometer 会针对监控系统自动适配存放时间序列的基本单位，所以只要是关于时间的指标，官方建议都使用 Timer。 官方示例的 Fluent API 使用如下： 1234567DistributionSummary summary = DistributionSummary .builder(\"response.size\") .description(\"a description of what this summary does\") // optional .baseUnit(\"bytes\") // optional (1) .tags(\"region\", \"test\") // optional .scale(100) // optional (2) .register(registry); 添加 baseUnit 可以进一步提升整体的可移植性，因为 baseUnit 本身是监控系统命名转换的一部分，但如果省略它，也不会有负面影响。scale 作为比例因子，用来乘以所有的记录值。 Timers 和 distribution summaries 都支持收集数据后观察比例分布信息，有两种使用形式：一是直方图(histogram)，即分配一堆桶，观察数据在各个桶的分布情况；二是百分比(percentiles)，系统会为每一个 Meter 计算一个百分比近似值。以下面这个分布摘要在 Prometheus 中的展示为例： 1234567891011121314151617DistributionSummary summary = DistributionSummary.builder(\"ds.test\") .description(\"simple distribution summary\") .publishPercentiles(0.5, 0.6, 0.95) .publishPercentileHistogram() .minimumExpectedValue(1L) .maximumExpectedValue(30L) .register(meterRegistry);summary.record(2);summary.record(2);summary.record(2);summary.record(2);summary.record(2);summary.record(5);summary.record(5);summary.record(5);summary.record(5);summary.record(9); 除了 max / count / sum 这三种数据外，还会显示 quantile 信息以及直方图的桶信息。publishPercentiles即表示记录百分位数值，publishPercentileHistogram表示记录直方图信息，而桶的个数可以由minimumExpectedValue和maximumExpectedValue控制。 此外，还有一个sla方法，包含的桶信息会包含 sla 指定的数值。举例而言，下方的图中就包含了 18 和 19 两个桶。 12345678DistributionSummary summary = DistributionSummary.builder(\"ds.test\") .description(\"simple distribution summary\") .publishPercentiles(0.5, 0.6, 0.95) .publishPercentileHistogram() .minimumExpectedValue(1L) .maximumExpectedValue(30L) .sla(18, 19) .register(meterRegistry); Timer 的 Histogram 和 Percentiles 使用也完全类似： 1234567891011121314151617Timer timer = Timer.builder(\"my.timer\") .publishPercentiles(0.5, 0.95) .publishPercentileHistogram() .sla(Duration.ofMillis(200)) .minimumExpectedValue(Duration.ofMillis(1)) .maximumExpectedValue(Duration.ofSeconds(1)) .register(meterRegistry);timer.record(8, TimeUnit.MILLISECONDS);timer.record(9, TimeUnit.MILLISECONDS);timer.record(7, TimeUnit.MILLISECONDS);timer.record(8, TimeUnit.MILLISECONDS);timer.record(58, TimeUnit.MILLISECONDS);timer.record(56, TimeUnit.MILLISECONDS);timer.record(157, TimeUnit.MILLISECONDS);timer.record(299, TimeUnit.MILLISECONDS);timer.record(599, TimeUnit.MILLISECONDS);timer.record(1999, TimeUnit.MILLISECONDS); 其他简单吐槽一下，相同名称、不同 Tag 的数据不能聚和，其设计初衷可能就是让数据由上层应用处理。 Actuator 的 /metrics/logback.events 接口，对应的 Meter 是LogbackMetrics，可以看到内部 Meter 命名相同，但 Tag 不同。但是这个 uri 显示的 measurements 是聚和的，开始以为有没发现的 API 操作，查看MetricsEndpoint后发现，聚和操作也是由该类自己完成的。 Referencehttps://micrometer.io/docs/concepts https://www.throwable.club/2018/11/17/jvm-micrometer-prometheus/ http://yongyao.li/blog/article/使用micrometer进行业务指标上报","categories":[{"name":"java, monitor","slug":"java-monitor","permalink":"https://weilans.github.io/categories/java-monitor/"}],"tags":[{"name":"micrometer","slug":"micrometer","permalink":"https://weilans.github.io/tags/micrometer/"}]},{"title":"[回顾并发基础] 原子操作类","slug":"并发札记-8-原子操作类","date":"2019-10-08T10:49:34.000Z","updated":"2019-12-19T11:54:00.000Z","comments":true,"path":"2019/10/08/并发札记-8-原子操作类/","link":"","permalink":"https://weilans.github.io/2019/10/08/并发札记-8-原子操作类/","excerpt":"介绍了原子操作类，以AtomicLong介绍原子类的实现，并对原子类的分类和使用（基本数据类型、引用类型、对象属性更新器、数组、累加器）进行说明。","text":"介绍了原子操作类，以AtomicLong介绍原子类的实现，并对原子类的分类和使用（基本数据类型、引用类型、对象属性更新器、数组、累加器）进行说明。 简介JUC中对于简单的原子性问题提炼封装成一系列的原子类，这是一种无锁方案。相对于互斥锁而言，其最大的好处早会性能，互斥锁为了保证互斥性，需要执行加锁、解锁操作，而加锁、解锁操作本身就消耗性能；同时拿不到锁的线程还会进入阻塞状态，进而触发线程切换，线程切换对性能的消耗也很大。 相比之下，无锁方案则完全没有加锁、解锁的性能消耗，同时还能保证互斥性。 原子类使用到了硬件的支持，CPU为了解决并发问题，提供了CAS (Compare And Swap) 指令，CAS 指令包含三个参数：共享变量的内存地址 A、用于比较的值 B 和 共享变量的新值 C。只有内存地址中 A 处的值等于 B 时，才能将内存地址 A 处的值更新为新值 C。且作为一条 CPU 指令，CAS 本身能够保证原子性。 当然，CAS 不是完美无缺的。CAS 方案会有 ABA 问题，即值被更新后，后又被更新为原值。是否需要关系 ABA 问题也需要依照特定情况而言，可以使用版本号标识解决 ABA 问题，后续会进行介绍。 实现Atomic包里的类基本都是使用Unsafe实现的包装类。接下来以AtomicLong的方式先介绍典型实现。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class AtomicLong extends Number implements java.io.Serializable &#123; private static final long serialVersionUID = 1927816293512124184L; // 获取Unsafe示例 private static final Unsafe unsafe = Unsafe.getUnsafe(); // 存放变量value的偏移量 private static final long valueOffset; // 判断JVM是否支持Long类型无锁CAS static final boolean VM_SUPPORTS_LONG_CAS = VMSupportsCS8(); private static native boolean VMSupportsCS8(); static &#123; try &#123; // 获取value在AtomicLong中的偏移量 valueOffset = unsafe.objectFieldOffset(AtomicLong.class.getDeclaredField(\"value\")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; // 实际变量值value private volatile long value; public AtomicLong(long initialValue) &#123; value = initialValue; &#125; public AtomicLong() &#123;&#125; // 调用unsafe方法, 原子性设置value值为原始值＋1, 返回值为原始值。这里 this 和 valueOffset 两个参数可以唯一确定共享变量的内存地址。 public final long getAndIncrement() &#123; return unsafe.getAndAddLong(this, valueOffset, 1L); &#125; // 调用unsafe方法, 原子性设置value值为原始值＋1, 返回值为递增后的值 public final long incrementAndGet() &#123; return unsafe.getAndAddLong(this, valueOffset, 1L) + 1L; &#125; // 原子类的重要方法，更新成功返回true, 失败则返回false public final boolean compareAndSet(long expect, long update) &#123; return unsafe.compareAndSwapLong(this, valueOffset, expect, update); &#125; ...&#125;// Unsafe的getAndAddLong方法public final long getAndAddLong(Object var1, long var2, long var4) &#123; long var6; do &#123; var6 = this.getLongVolatile(var1, var2); &#125; while(!this.compareAndSwapLong(var1, var2, var6, var6 + var4)); return var6;&#125;// Unsafe的compareAndSwapLong方法public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6); 上述getAndAddLong方法就是 CAS 经典使用案例。可以看出，使用 CAS 来解决并发问题一般都会伴随着自旋。一般的无锁代码经常会采用如下的方式，使用的是compareAndSet方法。 123456do &#123; // 获取当前值 oldV = xxxx； // 根据当前值计算新值 newV = ...oldV...&#125; while (!compareAndSet(oldV, newV); 分类原子类可以按照以下的方式进行划分： 类型 具体类 基本数据类型 AtomicBoolean、AtomicInteger、AtomicLong 引用类型 AtomicReference、AtomicStampedReference、AtomicMarkableReference 对象属性更新器 AtomicIntegerFieldUpdater、AtomicLongFieldUpdater、AtomicReferenceFieldUpdater 数组 AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray 累加器 DoubleAccumulator、DoubleAdder、LongAccumulator、LongAdder AtomicIntegerArray将数组value传递给构造方法，然后会将当前数组复制一份，所以当AtomicIntegerArray对内部的数组元素进行修改时，不会影响传入的数组。 1234567public static void main(String[] args) &#123; int[] value = new int[]&#123;1, 2&#125;; AtomicIntegerArray ai = new AtomicIntegerArray(value); System.out.println(ai.getAndSet(0, 3)); // 1 System.out.println(ai.get(0)); // 3 System.out.println(value[0]); // 1&#125; 原子更新基本类型只能更新一个变量，如果要原子更新多个变量，就需要使用原子更新引用类型提供的类，以AtomicReference举例： 123456789101112131415161718192021222324252627public static void main(String[] args) &#123; AtomicReference&lt;User&gt; atomicUserRef = new AtomicReference&lt;&gt;(); User user = new User(\"user1\", 25); atomicUserRef.set(user); User updateUser = new User(\"user2\", 26); atomicUserRef.compareAndSet(user, updateUser); System.out.println(atomicUserRef.get().getName()); System.out.println(atomicUserRef.get().getAge());&#125;static class User &#123; private String name; private int age; public User(String name, int age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public int getAge() &#123; return age; &#125;&#125; 上文提到解决ABA问题可以使用版本号，只要保证版本号是递增的，那么即便 A 变成 B 之后再变回 A，版本号也不会变回来。AtomicStampedReference 实现的 CAS 方法就增加了版本号参数，方法签名如下： 12345boolean compareAndSet( V expectedReference, V newReference, int expectedStamp, int newStamp) 123456789public static void main(String[] args) &#123; // initialStamp 为 0 AtomicStampedReference&lt;String&gt; reference = new AtomicStampedReference&lt;&gt;(\"Atomic\", 0); int stamp = reference.getStamp(); String obj = reference.getReference(); System.out.println(reference.compareAndSet(obj, \"AtomicNew\", stamp, stamp + 1)); // true System.out.println(reference.getReference()); // AtomicNew System.out.println(reference.getStamp()); // 1&#125; AtomicMarkableReference 的实现机制则更简单，将版本号简化成了一个 Boolean 值，方法签名如下： 12345boolean compareAndSet( V expectedReference, V newReference, boolean expectedMark, boolean newMark) 如果需要原子地更新某个类里的某个字段时，可以使用原子更新字段类，以AtomicIntegerFieldUpdater举例： 1234567891011121314151617181920212223242526272829303132public static void main(String[] args) &#123; // 创建原子更新器, 并设置需要更新的对象类和对象的属性 AtomicIntegerFieldUpdater&lt;User&gt; updater = AtomicIntegerFieldUpdater .newUpdater(User.class, \"age\"); User conan = new User(\"user1\", 25); System.out.println(updater.getAndIncrement(conan)); System.out.println(updater.get(conan)); &#125; static class User &#123; private String name; /** * 更新类的属性必须使用 public volatile 修饰符 **/ public volatile int age; public User() &#123; &#125; public User(String name, int age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public int getAge() &#123; return age; &#125; &#125; DoubleAccumulator、DoubleAdder、LongAccumulator 和 LongAdder，这四个类仅仅用来执行累加操作，相比原子化的基本数据类型，速度更快，但是不支持 compareAndSet() 方法。如果你仅仅需要累加操作，使用原子化的累加器性能会更好。JDK8 之所以会新增这些类，是因为：原子类在高并发下大量线程会同时取竞争更新同一个原子变量，但由于只有一个线程 CAS 成功，就会造成大量线程竞争失败，会通过无限循环不断进行自旋尝试 CAS 操作，而这会浪费CPU资源。 以 LongAdder 为例，既然 AtomicLong 性能瓶颈在于多线程竞争一个变量的更新而产生的，那就把一个变量分解为多个变量，让多线程竞争多个资源。LongAdder 就是以这种方式进行设计的，其内部维护着一个延迟初始化的原子性更新数组（默认情况下Cell 数组是null）和一个基值变量base： 其内部维护多个 Cell 变量，每个 Cell 有一个初始值为 0 的 long 类型变量，同等并发量的情况下争夺单个变量的线程量会减少。 此外，多个线程争夺同一个 Cell 失败后并不会在当前在当前 Cell 变量上一直自旋 CAS 重试，而是尝试在其他 Cell 的变量上进行 CAS 尝试，以增加当前线程重试 CAS 成功的概率。 当最后获取累加值时就是将所有 Cell 变量的 value 值累加后加上 base 后返回的。 原子性数组元素的内存地址是连续的，所以数组内的多个元素能经常共享缓存行，因此使用＠sun.misc.Contended 注解对 Cell 类进行字节填充，以避免数组中多个元素共享缓存行（避免伪共享）。 关于伪共享 为了解决CPU和主内存间的速度差异，之间会添加一级或多级告诉缓冲存储器（Cache），而 Cache 内部是按行存储的，每行称为一个 Cache 行，Cache 行的大小一般为 2 的幂次数字节，这是 Cache 与主内存进行数据交换的单位。 当CPU访问变量不存在时，先去 Cache 中看存不存在，没有的话就去内存取，然后将该变量所在内存区域（大小相当于 Cache 行大小）复制到 Cache 中，注意不是复制单个变量而是复制内存块。当多个线程同时修改一个缓存行里面的多个变量时，由于每时刻只能有一个线程操作缓存行，所以相对于将每个变量放到单独缓存行中，性能会有所下降，这就是伪共享。 当两个不同线程同时进行操作时，线程1使用CPU1更新变量x，那么在缓存一致性协议下，CPU2中变量x对应的缓存行会失效，线程2想要对与x在同一缓存行中的y进行操作时，就只能去下一级缓存中寻找。 一般通过字节填充的方式解决伪共享，JDK8 中提供 @sun.misc.Contended注解就可解决伪共享，可用于修饰类，也可以修饰变量。此注解只能用于 rt 包下的核心类，用户类路径下想使用，需要添加 JVM 参数：-XX:-RestrictContended。填充的宽度默认为128 ，要自定义宽度则可以设置-XX:ContendedPaddingWidth 参数。 （from 《Java并发编程之美》） Referencehttps://time.geekbang.org/column/article/90515 《Java并发编程的艺术》 《Java并发编程之美》","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"https://weilans.github.io/tags/concurrent/"}]},{"title":"[回顾并发基础] JUC中的并发队列","slug":"并发札记-7-JUC中的并发队列","date":"2019-10-05T09:34:40.000Z","updated":"2019-12-19T11:53:54.000Z","comments":true,"path":"2019/10/05/并发札记-7-JUC中的并发队列/","link":"","permalink":"https://weilans.github.io/2019/10/05/并发札记-7-JUC中的并发队列/","excerpt":"SynchronousQueue: 一个不存储元素的阻塞队列；","text":"SynchronousQueue: 一个不存储元素的阻塞队列； JUC中的并发队列阻塞队列可以用于多线程间的数据共享，支持阻塞的插入（队列慢时，队列开始阻塞插入元素的线程，直到队列不满）以及阻塞的移除（队列为空时，获取元素线程会等待队列变为非空）。 方法/处理方式 抛出异常 返回特殊值 阻塞 超时退出 插入 add offer(e) put offer(e, time, unit) 移除 remove poll() take poll(time, unit) 查看 element peek \\ \\ 常见的阻塞队列包括： Class 描述 ArrayBlockingQueue 由数组结构组成的有界阻塞队列 LinkedBlockingQueue 由链表结构组成的有界阻塞队列 PriorityBlockingQueue 支持优先级排序的无界阻塞队列 DelayQueue 使用优先级队列实现的无界阻塞队列 SynchronousQueue 不存储元素的阻塞队列 LinkedTransferQueue 由链表结构组成的无界阻塞队列 LinkedBlockingDeque 由链表结构组成的双向阻塞队列 ArrayBlockingQueue数组实现，有界，阻塞由ReentrantLock实现，默认非公平。其代码是生产者消费者的典型实现。 其内部有一个数组 items 用来存放队列元素，putIndex 表示入队元素下标， takeIndex 表示出队下标， count 统计队列元素个数。且这些变量并没有使用 volatile 修饰，这也是因为访问这些变量都是在锁块内，加锁己经保证了锁块内变量的内存可见性了。另外， notEmpty 、notFull 条件变量用来进行出、入队的 Condition。 LinkedBlockingQueue链表实现，无界，默认及最大长度为Integer.MAX_VALUE，但用户可以指定容量，所以一定长度上来讲，LinkedBlockingQueue是有界阻塞的。 1234567891011121314151617/** The capacity bound, or Integer.MAX_VALUE if none */private final int capacity;/** Current number of elements */private final AtomicInteger count = new AtomicInteger();/** Head of linked list. Invariant: head.item == null */transient Node&lt;E&gt; head;/** Tail of linked list. Invariant: last.next == null */private transient Node&lt;E&gt; last;/** Lock held by take, poll, etc */private final ReentrantLock takeLock = new ReentrantLock();/** Wait queue for waiting takes */private final Condition notEmpty = takeLock.newCondition();/** Lock held by put, offer, etc */private final ReentrantLock putLock = new ReentrantLock();/** Wait queue for waiting puts */private final Condition notFull = putLock.newCondition(); LinkedBlockingQueue 使用单向链表实现，有分别代表队首和对尾的 Node，有一个记录队列元素个数的原子变量 count 和容量大小 capacity。此外，有两个 ReentrantLock，takeLock 用来控制只有一个线程可以从队列头部获取元素，putLock 用来控制同时只能有一个线程在队列尾部添加元素，故出队与入队可以同时进行。notEmpty 和 notFull 是对应两个锁的 Condition。 下面的代码看起来和 ArrayBlockingQueue 类似，实则思路完全不同。由于有两个锁，每个锁对应一个 Condition，需重点关注 Condition 的 await 和 signal 操作。 1234567891011121314151617181920212223242526272829303132333435363738public void put(E e) throws InterruptedException &#123; // null元素抛空指针错误 if (e == null) throw new NullPointerException(); int c = -1; // 构造节点，开始获取锁 Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try &#123; // 队满则等待 while (count.get() == capacity) &#123; notFull.await(); &#125; // 进队列 enqueue(node); // 递增计数 c = count.getAndIncrement(); // 若还可以继续放，则继续唤醒下一个 if (c + 1 &lt; capacity) notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125; // 队列里至少有一个元素了，通知非空 if (c == 0) signalNotEmpty();&#125;private void signalNotEmpty() &#123; final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try &#123; notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536public E take() throws InterruptedException &#123; E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; // 获取锁 takeLock.lockInterruptibly(); try &#123; // 无元素，挂起 while (count.get() == 0) &#123; notEmpty.await(); &#125; // 出队 计数减一 x = dequeue(); c = count.getAndDecrement(); // 若还可以继续拿的，则继续唤醒下一个 if (c &gt; 1) notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125; // 队列里至少有一个元素被拿掉，队列必不满，通知非满 if (c == capacity) signalNotFull(); return x;&#125;private void signalNotFull() &#123; final ReentrantLock putLock = this.putLock; putLock.lock(); try &#123; notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125;&#125; PriorityBlockingQueue带优先级的无界阻塞队列。 SynchronousQueue描述SynchronousQueue 是一个 不存储元素的阻塞队列，每一个 put 操作必须等待一个 take 操作，否则不能继续添加队列。其可以看作是一个传球手，负责把生产者线程处理的数据直接传递给消费者线程，队列本身不存储任何元素，非常适合传递性场景。SynchronousQueue 吞吐量高于 LinkedBlockingQueue 和 ArrayBlockingQueue。 由于没有容量，所以对应 peek、contains、clear、isEmpty 等方法其实是无效的：clear 是不执行任何操作的，contains始终返回false，peek始终返回null，peek方法直接返回null。 SynchronousQueue 直接使用 CAS 实现线程的安全访问，队列的实现策略分为公平模式和非公平模式，默认情况下线程采用非公平模式访问队列，是否公平可以在构造函数中指定。 方法 描述 void put(E o) 向队列提交一个元素,阻塞直到其他线程take或者poll此元素. boolean offer(E o) 向队列中提交一个元素,如果此时有其他线程正在被take阻塞(即其他线程已准备接收)或者”碰巧”有poll操作,那么将返回true,否则返回false E take() 获取并删除一个元素,阻塞直到有其他线程offer/put boolean poll() 获取并删除一个元素,如果此时有其他线程正在被put阻塞(即其他线程提交元素正等待被接收)或者”碰巧”有offer操作,那么将返回true,否则返回false E peek() 总会返回null,硬编码 比如，先offer一个值（其返回值是false），3s后进行 take 操作，则会一直阻塞。传统阻塞队列如 ArrayBlocking 则会在 offer 时返回 true，take 时成功拿到值并返回。 实现实现层面最关键的是E transfer(E e, boolean timed, long nanos)方法，put 和 take 方法都会使用该方法。当参数 e 为非空时，表示当前值传递给一个消费者，若为空则表示当前操作需要请求一个数据。timed 参数决定是否存在 timeout 时间， nanos 决定了 timeout 的时长。如果返回值非空，则表示数据已经接受或者正常提供，如果为空，则表示失败（超时或者中断）。 由于大量 CAS 代码，很难进行深层次细节理解，这里简单说明实现概述。主要使用LockSupport来控制线程，使用CAS来控制 head 元素。 公平模式： 内部实现为 TransferQueue，它有一个 head 和 tail 指针。生成新 TransferQueue 对象时时，head 和 tail 指向新生成的虚拟节点；线程 put1 执行 put()操作，由于当前没有配对的消费线程，创建节点，并阻塞进程（线程是 QNode 中的属性），tail 指向 put1；线程 put2 执行了 put() 操作，跟前面一样，执行阻塞操作，tail 指向 put2。当来了一个线程 take1，执行了 take 操作时，tail 指向的 put2 跟 take1 线程配对，但此时需要唤醒的是 put1线程（即队尾匹配队头出队）。 123456static final class QNode &#123; volatile QNode next; // next node in queue volatile Object item; // CAS'ed to or from null volatile Thread waiter; // to control park/unpark final boolean isData;&#125; 非公平模式： 内部实现为TransferStack，实现中用 head 指针指向栈顶。线程 put1 执行 put() 操作，由于当前没有配对的消费线程，所以 put1 线程会入栈，创建一个 node 为 DATA 的元素，并阻塞进程；线程 put2 再次执行 put() 操作，跟前面一样，put2 线程会建成节点并入栈；此时来了线程 take1，执行了 take 操作，这时候发现栈顶为 put2 线程，会创建 FULFILL 节点把 take1 线程入栈，并尝试设置 put2 为 take1 的匹配节点(tryMatch)，设置成功会激活等待线程，两个节点弹出。 123456789101112131415static final class SNode &#123; volatile SNode next; // next node in stack volatile SNode match; // the node matched to this volatile Thread waiter; // to control park/unpark Object item; // data; or null for REQUESTs int mode;&#125;/* Modes for SNodes, ORed together in node fields *//** Node represents an unfulfilled consumer */static final int REQUEST = 0;/** Node represents an unfulfilled producer */static final int DATA = 1;/** Node is fulfilling another unfulfilled DATA or REQUEST */static final int FULFILLING = 2; Referencehttps://www.iteye.com/blog/shift-alt-ctrl-1840385 https://zhuanlan.zhihu.com/p/29227508","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"https://weilans.github.io/tags/concurrent/"}]},{"title":"[HikariCP] HikariCP为什么快","slug":"HikariCP-1-高性能的秘密","date":"2019-10-04T10:12:07.000Z","updated":"2019-12-27T06:06:41.000Z","comments":true,"path":"2019/10/04/HikariCP-1-高性能的秘密/","link":"","permalink":"https://weilans.github.io/2019/10/04/HikariCP-1-高性能的秘密/","excerpt":"“Simplicity is prerequisite for reliability.”","text":"“Simplicity is prerequisite for reliability.” HikariCP 的诞生Hikari日语发音是Hi-ka-li，翻译成“光”，赋予两个含义：速度快，代码量少。作者 Brett Wooldridge 在工作时发现使用已有连接池时发现死锁问题，检查源码时发现存在大量的锁和嵌套。此外，Brett Wooldridge 研究的所有池都以多种方式违反了JDBC规约。当连接关闭或者返回，或者清除警告，或者回滚未提交的事务时，这些连接池并不会自动关闭语句Statements。并且它们不会重置用户更改的属性，如自动提交或事务隔离级别，以及更多的一些参数，从而导致下一个消费者获得将“脏”连接。“难道这就是 Java 20 年后生态系统中连接池的状态？”出于挫败感和必要性，Brett Wooldridge 创建了 HikariCP。目前，SpringBoot 2.x 已经官方宣布使用 HikariCP 作为 SpringBoot 默认的数据库连接池。 HikariCP 为什么快HikariCP是一款快到极致的数据库连接池。在 HikariCP Github Wiki 详细了介绍HikariCP所做的优化，总结如下： 优化并精简字节码、优化代码和拦截器。 使用 FastList 替代 ArrayList。 更好的并发集合类实现 ConcurrentBag。 其他针对BoneCP缺陷的优化，比如对于耗时超过一个CPU时间片的方法调用的研究。 FastList执行完数据库操作之后，往往需要依次关闭 ResultSet、Statement、Connection，而开发者经常只关闭了 Connection，而忘了关闭 ResultSet 和 Statement。为了解决这种问题，最好的办法是当关闭 Connection 时，能够自动关闭 Statement。为了达到这个目标，Connection 就需要跟踪创建的 Statement，因此可以将创建的 Statement 保存在 List 里，这样当关闭 Connection 的时候，就可以依次将 List 里所有 Statement 关闭。 HikariCP 觉得 ArrayList 存在不足，自己开发了一个 List 接口的精简实现 —— FastList： ArrayList 每次调用 get() 方法时都会进行rangeCheck，检查索引是否越界，FastList 的实现中去除了这一检查。 1234567891011121314// In ArrayListpublic E get(int index) &#123; rangeCheck(index); return elementData(index);&#125;private void rangeCheck(int index) &#123;//这里有rangeCheck if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;// In FastListpublic T get(int index) &#123;//这里的get方法取消了rangeCheck return elementData[index]; &#125; 当 Statement 关闭或 Connection 关闭时需要将对应的 Statement 从 List 中移除。通常情况下，JDBC 在同一个 Connection 创建了多个 Statement 时，后打开的 Statement 会先关闭，这种情况从尾部开始扫描将表现更好，FastList 从尾部到头部执行移除扫描。 1234567891011121314151617181920212223242526272829303132// In ArrayListpublic boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) // 从头到尾遍历 if (elementData[index] == null) &#123; fastRemove(index);// 从头到尾移除 return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false;&#125;// In FastListpublic boolean remove(Object element) &#123; for (int index = size - 1; index &gt;= 0; index--) &#123; // 从尾部遍历 if (element == elementData[index]) &#123; final int numMoved = size - index - 1; if (numMoved &gt; 0) &#123; System.arraycopy(elementData, index + 1, elementData, index, numMoved); &#125; elementData[--size] = null; return true; &#125; &#125; return false;&#125; 所以整体来看，FastList 的优化点还是很简单的。 ConcurrentBag","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"connection-pool","slug":"connection-pool","permalink":"https://weilans.github.io/tags/connection-pool/"},{"name":"db","slug":"db","permalink":"https://weilans.github.io/tags/db/"}]},{"title":"[HikariCP] DBPool & JDBC基础","slug":"HikariCP-0-DBPool & JDBC基础","date":"2019-10-03T10:01:06.000Z","updated":"2019-12-19T11:52:19.000Z","comments":true,"path":"2019/10/03/HikariCP-0-DBPool & JDBC基础/","link":"","permalink":"https://weilans.github.io/2019/10/03/HikariCP-0-DBPool & JDBC基础/","excerpt":"工作中负责了一个和数据源交互很重的模块，并独立开启重写任务。其中一个很重要的变化就是将 15 年源代码中所采用的一代 DBCP 换成 HikariCP。因为这个模块与池的交互实在太深了，所以我必须要比常人对 HikariCP 有更好的理解，所以想写一篇纪要进行总结，文章很多内容来自《HikariCP数据库连接池实战》。","text":"工作中负责了一个和数据源交互很重的模块，并独立开启重写任务。其中一个很重要的变化就是将 15 年源代码中所采用的一代 DBCP 换成 HikariCP。因为这个模块与池的交互实在太深了，所以我必须要比常人对 HikariCP 有更好的理解，所以想写一篇纪要进行总结，文章很多内容来自《HikariCP数据库连接池实战》。 DB Pool 基础为何需要连接池以访问MySQL为例，执行一个SQL语句的完整TCP流程共经历：TCP三次握手建立连接、MySQL三次握手认证、SQL语句执行、MySQL关闭、TCP四次挥手关闭连接5个步骤。 不用连接池的主要问题： 创建连接和关闭连接的过程比较耗时，并发时系统会变得很卡顿。 数据库同时支持的连接总数是有限的，如果并发量很大，那么数据库连接的总数就会被消耗光，增加数据库的负载，新的数据库连接请求就会失败。这样就会极大地浪费数据库的资源，极易造成数据库服务器内存溢出、宕机。 为了执行一条SQL，却产生了很多我们并不关心的网络IO。 应用如果频繁地创建连接和关闭连接，会导致JVM临时对象较多，GC频繁。 频繁关闭连接后，会出现大量TIME_WAIT的TCP状态（在2个MSL之后关闭），这点很棘手。 应用的响应时间及QPS较低。 因此，使用连接池的优点就是相对的：资源重用节省开销、系统能有更快的相应、可以进行统一的连接管理、更便于进行系统调优。 数据库连接池原理 在系统初始化的时候，在内存中开辟一片空间，将一定数量的数据库连接作为对象存储在对象池里，并对外提供数据库连接的获取和归还方法。 用户访问数据库时，并不是建立一个新的连接，而是从数据库连接池中取出一个已有的空闲连接对象；使用完毕归还后的连接也不会马上被关闭，而是由数据库连接池统一管理回收，为下一次借用做好准备。 如果由于高并发请求导致数据库连接池中的连接被借用完毕，其他线程就会等待，直到有连接被归还。 数据库连接池还可以通过设置其参数来控制连接池中的初始连接数、连接的上下限数，以及每个连接的最大使用次数、最大空闲时间等，也可以通过其自身的管理机制来监视数据库连接的数量、使用情况等。 连接的创建、获取和归涉及两项技术：一是连接使用List之类的集合进行初始化、装载和归还，二是使用动态代理来把资源归回给List集合。而HikariCP之所以这么快，也主要是将这两项技术做到了极致。 连接池的构成一款商用的数据库连接池除了连接池的建立和释放两大核心功能外，还支持： 并发（锁性能优化乃至无锁） 连接数控制（不同的系统对连接数有不同的需求） 监控（一些自身管理机制来监视连接的数量及使用情况等） 外部配置（各种主流数据库连接池官方文档最核心的部分） 资源重用（数据库连接池的核心思想） 检测及容灾（面对一些网络、时间等问题的自愈） 多库多服务（如不同的数据库、不同的用户名和密码、分库分表等情况） 事务处理（对数据库的操作符合ALL-ALL-NOTHING原则）、定时任务（如空闲检查、最小连接数控制） 缓存（如PSCache等避免对SQL重复解析） 异常处理（对JDBC访问的异常统一处理） 组件维护（如连接状态、JDBC封装的维护）等。 JDBC简述JDBC API是Java编程语言与各种数据库之间数据库无关连接的行业标准。JDBC API是一种执行SQL语句的API，JDBC驱动才是真正的接口实现，所有的网络逻辑和特定于数据库的通信协议都隐藏于、独立于供应商的JDBC API后面。Sun公司只是提供了JDBC API，每个数据库厂商都有自己的驱动来连接自己公司的数据库。 JDBC API采用了桥接的设计模式。JDBC接口相当于实现化角色接口，数据库厂商实现的驱动相当于具体实现化子类；应用程序相当于抽象化角色，内部持有一个实现化角色的对象。桥接模式将实现化和抽象化解耦，从而让两个部分可以沿着不同的方向拓展，只要遵循接口即可。 JDBC API主要位于JDK中的java.sql包中，扩展的内容位于javax.sql包中。了解JDBC，关注点更多的还是java.sql.*包，在这个包里，有4个核心接口（Driver、Connection、Statement和ResultSet）和两个核心类（DriverManager和SQLException）。 Statement关闭会导致ResultSet关闭，但是Connection关闭却不一定会导致Statement关闭。在数据库连接池里，Connection关闭并不是物理关闭，只是归还连接池，所以Statement和ResultSet有可能被持有，并且实际占用相关的数据库的游标资源。所以在关闭Connection前，需要关闭所有相关的Statement和ResultSet。这就是HikariCP作者所强调的JDBC的最基本的规范，也是他创造HikariCP的原因，数据库连接池一定不能违背这样的规则。最好方案就是顺序关闭ResultSet、Statement、Connection；在rs.close()和stmt.close()后面加上rs=null和stmt=null来防止内存泄漏。 Statement和PreparedStatementPreparedStatement在企业开发中被强烈推荐使用，原因主要有以下方面： Statement会频繁编译SQL。如果JDBC驱动支持的话（一般来说数据库系统库系统初次分析、编译时会对查询语句做最大的性能优化），PreparedStatement可对SQL进行预编译，提高效率，预编译的SQL存储在PreparedStatement对象中。从这个意义上来说，PreparedStatement比Statement更快，使用PreparedStatement也可以降低生产环境的数据库负载。 Statement对象编译SQL语句时，如果SQL语句有变量，就需要使用分隔符来隔开，如果变量非常多，就会使SQL变得非常复杂。PreparedStatement可以使用占位符，通过动态参数化的查询来简化SQL的编写。 PreparedStatement可防止SQL注入。 JDBC的最佳实践 使用PrearedStatement，通过预编译的方式避免在拼接SQL时造成SQL注入，使用“？”或其他占位符等变量绑定的形式可以使用不同的参数执行相同的查询也能防止SQL注入。 禁用自动提交，这样可以将数据库操作放在一个事务中，而不是每次执行SQL语句都在执行结束时提交自己独立的事务。 JDBC批处理可以降低数据库传输频率，进而提升性能。 使用列名而不是列序号获取ResultSet中的数据，避免invalidColumIndexError，从而提升程序的健壮性、可读性。 在Java 7中，可以通过Automatic Resource Management Block来自动关闭资源。要记得关闭所有的Connection、Statement等资源。 使用标准的SQL语句（如标准的ANSI SQL），避免数据库对SQL支持的差异。 JDBC与SPIJDBC 4.0以前，开发人员还需要基于Class.forName(“xxx”)的方式来装载驱动，而JDBC 4.0基于SPI机制来发现驱动提供商，可以通过META-INF/services/java.sql.Driver文件里指定实现类的方式来暴露驱动提供者。开发者只需要编写一行代码，使用不同厂商的jar包，就可以轻松创建连接了。 1Connection conn = DriverManager.getConnection(URL,USER,PASSWORD)； 关于SPI在Java中根据一个子类获取其父类或接口信息非常方便，但是根据一个接口获取该接口的所有实现类却没那么容易。有一种比较笨的办法就是扫描classpath下所有的class与jar包中的class，接着用ClassLoader加载进来，再判断是否是给定接口的子类。但是这种方法的代价太大，一般不会使用。根据这个问题，Java推出了ServiceLoader类来提供服务发现机制，动态地为某个接口寻找服务实现。当服务的提供者提供了服务接口的一种实现之后，必须根据SPI约定在META-INF/services/目录里创建一个以服务接口命名的文件，该文件里写的就是实现该服务接口的具体实现类。当程序调用ServiceLoader的load方法的时候，ServiceLoader能够通过约定的目录找到指定的文件，并装载实例化，完成服务的发现。 ServiceLoader是JDK6里面引进的一个特性，通过它可以具体实现代码的解耦，实现类似于IOC的效果。针对ServiceLoader还有一个特定的限制，就是具体实现类必须提供无参数的构造函数，否则ServiceLoader就会报错。 DriverManager的SPI实现DriverManager 中有一个静态代码块： 1234static &#123; loadInitialDrivers(); println(\"JDBC DriverManager initialized\");&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445private static void loadInitialDrivers() &#123; String drivers; try &#123; drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() &#123; public String run() &#123; // 1)处理系统属性jdbc.drivers配置的值 return System.getProperty(\"jdbc.drivers\"); &#125; &#125;); &#125; catch (Exception ex) &#123; drivers = null; &#125; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; // 2)处理通过ServiceLoader加载的Driver类 ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); // 加载配置在META-INF/services/java.sql.Driver文件里的Driver实现类 try&#123; while(driversIterator.hasNext()) &#123; driversIterator.next(); &#125; &#125; catch(Throwable t) &#123; // 什么都不做 &#125; return null; &#125; &#125;); println(\"DriverManager.initialize: jdbc.drivers = \" + drivers); if (drivers == null || drivers.equals(\"\")) &#123; return; &#125; String[] driversList = drivers.split(\":\"); println(\"number of Drivers:\" + driversList.length); for (String aDriver : driversList) &#123; try &#123; println(\"DriverManager.Initialize: loading \" + aDriver); // 3)加载Driver类 Class.forName(aDriver, true, ClassLoader.getSystemClassLoader()); &#125; catch (Exception ex) &#123; println(\"DriverManager.Initialize: load failed: \" + ex); &#125; &#125;&#125; MySQL的Driver实现在初始化的时候也是在 static 方法里就将自己的com.mysql.jdbc.Driver直接注册到了java.sql.DriverManager中。 12345678910public class Driver extends NonRegisteringDriver implements java.sql.Driver &#123; static &#123; try &#123;//强调!这个new Driver是com.mysql.jdbc.Driver!!! java.sql.DriverManager.registerDriver(new Driver()); &#125; catch (SQLException E) &#123; throw new RuntimeException(\"Can't register driver!\"); &#125; &#125; public Driver() throws SQLException &#123;&#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"connection-pool","slug":"connection-pool","permalink":"https://weilans.github.io/tags/connection-pool/"},{"name":"db","slug":"db","permalink":"https://weilans.github.io/tags/db/"}]},{"title":"[回顾并发基础] CopyOnWriteArrayList & ConcurrentHashMap","slug":"Java并发札记-6. CopyOnWriteArrayList & ConcurrentHashMap","date":"2019-09-21T17:41:36.000Z","updated":"2019-12-19T11:54:42.000Z","comments":true,"path":"2019/09/22/Java并发札记-6. CopyOnWriteArrayList & ConcurrentHashMap/","link":"","permalink":"https://weilans.github.io/2019/09/22/Java并发札记-6. CopyOnWriteArrayList & ConcurrentHashMap/","excerpt":"CopyOnWriteArrayList： 基于写时复制策略的线程安全的 List； ConcurrentHashMap：由分段锁(jdk7)实现发展为 CAS+synchronized+红黑树(jdk8) 的线程安全的 Map；","text":"CopyOnWriteArrayList： 基于写时复制策略的线程安全的 List； ConcurrentHashMap：由分段锁(jdk7)实现发展为 CAS+synchronized+红黑树(jdk8) 的线程安全的 Map； 并发List —— CopyOnWriteArrayList描述在很多应用场景中，读操作可能会远远大于写操作。 由于读操作根本不会修改原有的数据，因此对于每次读取都进行加锁其实是一种资源浪费。为了将读取的性能发挥到极致，JDK中提供了CopyOnWriteArrayList类。读取是完全不用加锁的，并且写入也不会阻塞读取操作，只有写入和写入之间需要进行同步等待，这样便可以使读操作的性能就会大幅度提升。 并发包中的并发List 只有 CopyOnWriteArrayList。CopyOnWri teArray List 是一个线程安全的 ArrayList ，对其进行的修改操作都是在底层的一个复制的数组（快照）上进行的，也就是使用了写时复制策略。 实现CopyOnWriteArrayList 有两个成员变量，lock 是用在写时锁的实现，数据则存储在 array 数组中。 12345/** The lock protecting all mutators */final transient ReentrantLock lock = new ReentrantLock();/** The array, accessed only via getArray/setArray. */private transient volatile Object[] array; 1. 初始化1234567891011121314151617181920public CopyOnWriteArrayList() &#123; setArray(new Object[0]);&#125;public CopyOnWriteArrayList(Collection&lt;? extends E&gt; c) &#123; Object[] elements; if (c.getClass() == CopyOnWriteArrayList.class) elements = ((CopyOnWriteArrayList&lt;?&gt;)c).getArray(); else &#123; elements = c.toArray(); // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elements.getClass() != Object[].class) elements = Arrays.copyOf(elements, elements.length, Object[].class); &#125; setArray(elements);&#125;public CopyOnWriteArrayList(E[] toCopyIn) &#123; setArray(Arrays.copyOf(toCopyIn, toCopyIn.length, Object[].class));&#125; 无参构造器创建了一个大小为 0 的Object数组作为 array 初始值。而有参构造器则是将数组或集合的副本作为 array 初始值。 2. 添加元素1234567891011121314151617181920212223public boolean add(E e) &#123; final ReentrantLock lock = this.lock; // 1. 获取独占锁 lock.lock(); try &#123; // 2. 获取 array Object[] elements = getArray(); // 3. 复制 array 到新数组, 添加元素到新数组 int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; // 4. 使用新数组替换添加前的数组 setArray(newElements); return true; &#125; finally &#123; // 5. 释放独占锁 lock.unlock(); &#125;&#125;final Object[] getArray() &#123; return array;&#125; 删除及修改同添加操作一样，首先获取独占锁以保证其他线程不能对 array 进行修改，之后再释放锁。 3. 获取指定位置元素1234567private E get(Object[] a, int index) &#123; return (E) a[index];&#125;public E get(int index) &#123; return get(getArray(), index);&#125; 当用户调用get(x)时，有两步操作：1. 获取数组；2.依照数组下标获取值。如果在两部之间，另一个线程对数组有增/删/改操作，那么对get(x)不会有影响，因为步骤2操作的数组依然是之前的数组。这就是写时复制策略产生的弱一致性。 4. 迭代器CopyOnWriteArrayList 的迭代器是弱一致性的，即返回迭代器后，其他线程对 list 的增删该操作对迭代器是不可见的。 1234567891011121314151617181920212223242526272829public Iterator&lt;E&gt; iterator() &#123; return new COWIterator&lt;E&gt;(getArray(), 0);&#125;static final class COWIterator&lt;E&gt; implements ListIterator&lt;E&gt; &#123; // Snapshot of the array private final Object[] snapshot; // 数组下标 private int cursor; // 构造函数 private COWIterator(Object[] elements, int initialCursor) &#123; cursor = initialCursor; snapshot = elements; &#125; // 是否遍历结束 public boolean hasNext() &#123; return cursor &lt; snapshot.length; &#125; // 获取 next public E next() &#123; if (! hasNext()) throw new NoSuchElementException(); return (E) snapshot[cursor++]; &#125; ...&#125; COWIterator 对象的 snapshot 变量保存了当前 list 的内容， cursor 是遍历 list 时数据的下标。如果在遍历期间其他线程对该 list 进行修改，那么 snapshot 即表示为快照，因为增删改后数组被新数组替换了，而老数组被 snapshot 引用。 5. 应用场景 CopyOnWriteArrayList 仅适用于写操作非常少的场景，而且能够容忍读写的短暂不一致，即写入的新元素并不能立刻被遍历到。 此外，CopyOnWriteArrayList 迭代器是只读的，不支持增删改，迭代器遍历的仅仅是一个快照。 6. 重看COWCOW 适用于数据库连接池这种读操作远远多于修改操作的场景，它反映出3个很重要的分布式理念：读写分离；最终一致；使用额外空间解决办法冲突。 当然 COW 的弱点是很明显的：随着 CopyOnWriteArrayList 中元素的增加，其修改代价将越来越昂贵，在高性能的互联网应用中，这种操作很容易引起故障。设置合理的初始化值、减少扩容开销、使用批量添加减少容器复制次数都是值得考虑的性能优化点。 Linux中也存在CopyOnWrite技术，除了有名的文件系统Brtfs外，基本的fork命令也使用了这项技术。fork()之后，kernel把父进程中所有的内存页的权限都设为read-only，然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，于是触发页异常中断（page-fault），陷入kernel的一个中断例程。中断例程中，kernel就会把触发的异常的页复制一份，于是父子进程各自持有独立的一份。这项技术可以减少分配和复制大量资源时带来的瞬间延时，也可以减少不必要的资源分配。 ConcurrentHashMap在 JDK7 和 JDK8 中的实现有些许变化，不过很多材料谈的都是 JDK7 。ConcurrentHashMap本身实现也是十分复杂，包含注释大约 6000+ 行，相比之前的笔记，不会贴代码，主要关注它实现思路，细节层面不会非常细。 HashMap回顾 ConcurrentHashMap 之前，国际惯例回顾下HashMap吧。JDK7中 HashMap 采用的是数组位桶+链表的方式，每个键值对封装在 Entry (static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt;) 里面，而 HashMap 维持着 Entry 数组，这就是数组位桶；而 Entry 本身也有 next 属性指向下一个 Entry，这可以看作是单向链表。 get()方法通过hash()函数得到对应 bucket 的下标hash(k)&amp;(table.length-1)，然后依次遍历冲突链表，通过key.equals(k)方法来判断是否是要找的那个 Entry。 put()方法先检查是否包含这个key，不包含则采用头插法(JDK8是尾插)，在链表头部插入新的 Entry。当然新增Entry可能导致HashMap的实际容量超过阈值，需要扩容。当Entry 的数量超过 capacity(当前容量)* load_factor 时，容器将自动扩容并重新哈希，哈希表将具有大约两倍的桶数。 HashMap 的扩容时机选在了插入之后判断阈值是否扩容，若后续无插入则浪费了。而 ConcurrentHashMap 的实现是在插入元素前就判断是否超过阈值。 而 JDK8 的实现最大改进就是链表元素数量超过一定值后，将其转为红黑树，避免大量节点存在链表上时的O(n)查找时间。所以说 JDK8 使用的是 数组位桶+链表/红黑树的形式。JDK8使用Node代替 Entry，Node 可以被扩展成TreeNode，如果 node 的数目多于 8 个，那么链表就会被转换成红黑树；如果 node 的数目小于 6个，那么红黑树就会被转换成链表。 HashMap 不支持并发，主要场景是多线程同时put时，如果同时触发了rehash操作，会导致 HashMap 中的链表中出现循环节点(一个线程 rehash 完毕，另一个线程还没开始)，进而使得后面 get 的时候出现死循环，CPU达到100%。 并发Map —— ConcurrentHashMapJDK7ConcurrentHashMap 使用分段锁技术，将数据分成一段一段的存储（分成一个个Segment，每个 Segment 包含HashEntry数组，Segment extends ReentrantLock本质上是一个可重入的互斥锁），当一个线程对 HashEntry 数组的数据进行修改时，必须获得与之对应的 Segment 锁，其他段的数据也能被其他线程访问。 get(): 对 key.hashCode 进行再散列，通过这个散列值取高位定位到正确的 Segment，再使用再散列值与数组长度减一相与定位 HashEntry。接着遍历该 HashEntry 链表。get 过程不需要加锁，get 方法里使用到的共享变量都定义成了volatile类型（如当前 Segment 的大小字段 count 以及存储值的 HashEntry 中的 value），Happens-before规定了对 volatile 字段的写入先于读操作，所以 get 操作总能拿到最新值。 put(): 首先定位到 Segment 获取锁，之后定位到 HashEntry 索引位置进行遍历，有重复 key 则替换，若没有则插入头部。需要注意的是，插入操作需先判断 HashEntry 数组是否超过容量需扩容，扩容时只会针对这个 Segment 进行，数组容量是原先两倍。 size(): 先尝试2次不加锁的统计各个 Segment 大小，如果统计过程中 count 变化（modCount，在 put / remove / clean 时加 1），采用加锁的方式统计所有Segment的大小。 JDK8 Referencehttps://read.douban.com/reader/ebook/122245168/ 《Java并发编程之美》","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"https://weilans.github.io/tags/concurrent/"}]},{"title":"[回顾并发基础] 常用并发工具类","slug":"Java并发札记-5-常用并发工具类","date":"2019-09-21T17:30:47.000Z","updated":"2019-12-31T11:13:55.000Z","comments":true,"path":"2019/09/22/Java并发札记-5-常用并发工具类/","link":"","permalink":"https://weilans.github.io/2019/09/22/Java并发札记-5-常用并发工具类/","excerpt":"","text":"SemaphoreSemaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源。 Semaphore 有 Lock 不易实现的功能：Semaphore 可以允许多个线程访问一个临界区。 123456789101112public Semaphore(int permits);public Semaphore(int permits, boolean fair);public void acquire() throws InterruptedException;public void acquireUninterruptibly();public void acquire(int permits) throws InterruptedException;public void acquireUninterruptibly(int permits);public boolean tryAcquire();public boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException;public boolean tryAcquire(int permits);public boolean tryAcquire(int permits, long timeout, TimeUnit unit) throws InterruptedException;public void release()；public void release(int permits); 其他方法： 12345public int availablePermits(); // 返回此信号量中当前可用的许可证public final int getQueueLength(); // 返回正在等待获取许可证的线程数public final boolean hasQueuedThreads(); // 是否有线程正在等待获取许可证protected void reducePermits(int reduction); // 减少reduction个许可证protected Collection&lt;Thread&gt; getQueuedThreads(); // 返回所有等待获取许可证的线程集合 应用示例示例一：共10个线程，每次只有两个线程可以获取到资源。 1234567891011121314151617181920public class SemaphoreTest &#123; private static final int THREAD_COUNT = 10; private static ExecutorService threadPool = Executors.newFixedThreadPool(THREAD_COUNT); private static Semaphore s = new Semaphore(2); public static void main(String[] args) &#123; for (int i = 0; i &lt; THREAD_COUNT; i++) &#123; threadPool.execute(() -&gt; &#123; try &#123; s.acquire(); TimeUnit.SECONDS.sleep(2); System.out.println(\"save data\"); s.release(); &#125; catch (InterruptedException e) &#123; &#125; &#125;); &#125; threadPool.shutdown(); &#125;&#125; 示例二：Semaphore的许可量为0，后两个线程分别release，使得acquire(2)的线程可以继续下去。 1234567891011121314151617181920212223public class SemaphoreTest &#123; private static Semaphore semaphore = new Semaphore(0); public static void main(String[] args) throws InterruptedException &#123; ExecutorService executorService = Executors.newFixedThreadPool(2); executorService.submit(() -&gt; &#123; try &#123; System.out.println(Thread.currentThread() + \" over \"); semaphore.release(); &#125; catch (Exception e) &#123; &#125; &#125;); executorService.submit(() -&gt; &#123; try &#123; System.out.println(Thread.currentThread() + \" over \"); semaphore.release(); &#125; catch (Exception e) &#123; &#125; &#125;); semaphore.acquire(2); System.out.println(\"all child thread over \"); executorService.shutdown(); &#125;&#125; 示例三：官方示例 Semaphores are often used to restrict the number of threads than can access some (physical or logical) resource. For example, here is a class that uses a semaphore to control access to a pool of items: 123456789101112131415161718192021222324252627282930313233343536373839404142class Pool &#123; private static final int MAX_AVAILABLE = 100; private final Semaphore available = new Semaphore(MAX_AVAILABLE, true); public Object getItem() throws InterruptedException &#123; available.acquire(); return getNextAvailableItem(); &#125; public void putItem(Object x) &#123; if (markAsUnused(x)) available.release(); &#125; // Not a particularly efficient data structure; just for demo protected Object[] items = ... whatever kinds of items being managed protected boolean[] used = new boolean[MAX_AVAILABLE]; protected synchronized Object getNextAvailableItem() &#123; for (int i = 0; i &lt; MAX_AVAILABLE; ++i) &#123; if (!used[i]) &#123; used[i] = true; return items[i]; &#125; &#125; return null; // not reached &#125; protected synchronized boolean markAsUnused(Object item) &#123; for (int i = 0; i &lt; MAX_AVAILABLE; ++i) &#123; if (item == items[i]) &#123; if (used[i]) &#123; used[i] = false; return true; &#125; else return false; &#125; &#125; return false; &#125;&#125; 实现Semaphore 还是使用 AQS 实现的。Sync 只是对 AQS 的一个修饰，并且 Sync 有两个实现类(NonfairSync,FairSync)，用来指定获取信号量时是否采用公平策略，默认采用非公平策略。相对而言，比较简单，这里不赘述。把源码的文档注释删掉，其实也就是一百多行。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176public class Semaphore implements java.io.Serializable &#123; private static final long serialVersionUID = -3222578661600680210L; private final Sync sync; abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 1192457210091910933L; Sync(int permits) &#123; setState(permits); &#125; final int getPermits() &#123; return getState(); &#125; final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125; protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; int current = getState(); int next = current + releases; if (next &lt; current) // overflow throw new Error(\"Maximum permit count exceeded\"); if (compareAndSetState(current, next)) return true; &#125; &#125; final void reducePermits(int reductions) &#123; for (;;) &#123; int current = getState(); int next = current - reductions; if (next &gt; current) // underflow throw new Error(\"Permit count underflow\"); if (compareAndSetState(current, next)) return; &#125; &#125; final int drainPermits() &#123; for (;;) &#123; int current = getState(); if (current == 0 || compareAndSetState(current, 0)) return current; &#125; &#125; &#125; static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = -2694183684443567898L; NonfairSync(int permits) &#123; super(permits); &#125; protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires); &#125; &#125; static final class FairSync extends Sync &#123; private static final long serialVersionUID = 2014338818796000944L; FairSync(int permits) &#123; super(permits); &#125; protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; if (hasQueuedPredecessors()) return -1; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125; &#125; public Semaphore(int permits) &#123; sync = new NonfairSync(permits); &#125; public Semaphore(int permits, boolean fair) &#123; sync = fair ? new FairSync(permits) : new NonfairSync(permits); &#125; public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; public void acquireUninterruptibly() &#123; sync.acquireShared(1); &#125; public boolean tryAcquire() &#123; return sync.nonfairTryAcquireShared(1) &gt;= 0; &#125; public boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout)); &#125; public void release() &#123; sync.releaseShared(1); &#125; public void acquire(int permits) throws InterruptedException &#123; if (permits &lt; 0) throw new IllegalArgumentException(); sync.acquireSharedInterruptibly(permits); &#125; public void acquireUninterruptibly(int permits) &#123; if (permits &lt; 0) throw new IllegalArgumentException(); sync.acquireShared(permits); &#125; public boolean tryAcquire(int permits) &#123; if (permits &lt; 0) throw new IllegalArgumentException(); return sync.nonfairTryAcquireShared(permits) &gt;= 0; &#125; public boolean tryAcquire(int permits, long timeout, TimeUnit unit) throws InterruptedException &#123; if (permits &lt; 0) throw new IllegalArgumentException(); return sync.tryAcquireSharedNanos(permits, unit.toNanos(timeout)); &#125; public void release(int permits) &#123; if (permits &lt; 0) throw new IllegalArgumentException(); sync.releaseShared(permits); &#125; public int availablePermits() &#123; return sync.getPermits(); &#125; public int drainPermits() &#123; return sync.drainPermits(); &#125; protected void reducePermits(int reduction) &#123; if (reduction &lt; 0) throw new IllegalArgumentException(); sync.reducePermits(reduction); &#125; public boolean isFair() &#123; return sync instanceof FairSync; &#125; public final boolean hasQueuedThreads() &#123; return sync.hasQueuedThreads(); &#125; public final int getQueueLength() &#123; return sync.getQueueLength(); &#125; protected Collection&lt;Thread&gt; getQueuedThreads() &#123; return sync.getQueuedThreads(); &#125; public String toString() &#123; return super.toString() + \"[Permits = \" + sync.getPermits() + \"]\"; &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"https://weilans.github.io/tags/concurrent/"}]},{"title":"[回顾并发基础] ReentrantLock & ReentrantReadWriteLock & StampedLock","slug":"Java并发札记-4-常用Lock实现类","date":"2019-09-21T17:12:31.000Z","updated":"2019-12-19T11:54:29.000Z","comments":true,"path":"2019/09/22/Java并发札记-4-常用Lock实现类/","link":"","permalink":"https://weilans.github.io/2019/09/22/Java并发札记-4-常用Lock实现类/","excerpt":"","text":"ReentrantLock描述ReentrantLock，支持重进入的锁，表示该锁能够支持一个线程对资源的重复加锁。该锁还支持公平和非公平选择。如果是公平锁，唤醒阻塞队列中节点的策略就是谁等待的时间长就唤醒谁；如果是非公平锁，则不提供这个公平保证，默认是非公平的。（synchronized关键字隐式的支持重进入，且是非公平的。） AQS 的 state 状态值表示线程获取该锁的可重入次数， 在默认情况下， state的值为 0 表示当前锁没有被任何线程持有。当一个线程第一次获取该锁时会尝试使用CAS设置state 的值为 1 ，如果 CAS 成功则记录该锁的持有者为当前线程。在该线程没有释放锁的情况下第二次获取该锁后，状态值被设置为2 ， 这就是可重入次数。在该线程释放该锁时，会尝试使用CAS 让状态值减1， 如果减1 后状态值为0，则当前线程释放该锁。 Lock的可见性保证可以使用ReentrantLock来举例。ReentrantLock 内部持有一个 volatile 的成员变量 state，获取锁的时候，会读写 state 的值；解锁的时候，也会读写 state 的值。可以通过 volatile 变量规则、顺序性规则以及传递性规则推导出 前一个线程在加锁时对变量的修改 Happens-Before 于另一个线程的加锁操作。 实现（1）获取锁ReentrantLock 的 lock() 方法直接调用 sync.lock() 方法。ReentrantLock 中有继承 AQS 的抽象类Sync，内部有NonfairSync，FairSync分别代表非公平实现和公平实现。在AQS中，我们知道tryAcquire方法是要自己实现的。 先以非公平锁开始，调用 Lock 的线程通过 CAS 设置状态值为1成功后，则表示当前线程获取到了锁， 然后 setExclusiveOwnerThread 设置该锁持有者是当前线程。后续线程会调用 acquire方法，其内部既先调用tryAcquire，从而调用nonfairTryAcquire，这个方法就是获取锁的关键： 当 state 为 0 时，代表锁空闲，尝试 CAS 获取后再设置持有者线程为当前线程，便成功返回。 当 state 非 0 时，即锁已被占用，若持有线程不是当前线程便直接返回失败，后放入 AQS 阻塞队列；若是当前线程，则状态值加一。需要注意的是，nextc &lt; 0 是指可重入次数溢出了。 这里的非公平性体现在何处呢？若线程A持有锁后，线程B持有失败，进入阻塞队列。此时线程A释放锁的同时，线程C到来，其尝试 CAS 成功后，便获取到了锁。或者刚释放锁的线程A想要再次获取锁时，其成功几率也会非常大。 公平锁的tryAcquire和nonfairTryAcquire几乎一致，只是多了一个 !hasQueuedPredecessors() ，该方法判断当前线程节点是否有前驱节点。使用公平锁时，任何线程一进来不会让你 CAS 成功就获取到锁，而是进入 tryAcquire中进行判断队列中是否有线程在等待，若没有等待的线程且CAS成功，则代表获取到锁，设置持有者线程后便返回 true。公平锁保证了锁的获取按照FIFO原则，而代价是进行大量的线程切换。非公平性锁虽然可能造成线程“饥饿”，但极少的线程切换，保证了其更大的吞吐量。 123456789101112131415161718192021222324252627282930313233343536// NonfairSync 实现static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else // AQS 中的 acquire 方法 acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; // 代码实现在 Sync 抽象类中，具体实现见下 return nonfairTryAcquire(acquires); &#125;&#125;final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false;&#125; 12345678910111213141516171819202122232425262728293031323334353637// FairSync 实现static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; // AQS 中的 acquire 方法 acquire(1); &#125; // 与 nonfairTryAcquire 的唯一区别在于多了 !hasQueuedPredecessors() 判断 protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; &#125;&#125; public final boolean hasQueuedPredecessors() &#123; Node t = tail; Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread()); &#125; （2）释放锁ReentrantLock.unlock() 调用的是：sync.release(1)，方法内会调用tryRelease方法（实现是在Sync中，即公平和非公平都是同一种实现）。该方法中，当前线程非持有者线程立即报错。当检查 state 若减去 release 值为 0 后，则清空持有者线程， 正式设置 state 为 0。 123456789101112131415161718192021222324// in AQS public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125;// in ReentrantLockprotected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; ReentrantReadWriteLock读写锁维护了一对锁，一个读锁和一个写锁，通过分离读锁和写锁，使得并发性相比一般的排他锁有了很大提升，能够简化读写交互场景的编程方式。 ReentrantReadWriteLock支持公平性/非公平性选择、重进入、锁降级。样例如下： 12345678910111213141516171819202122232425262728293031323334public class ReadWriteLockTest &#123; static Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); static ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); static Lock r = rwl.readLock(); static Lock w = rwl.writeLock(); // 获取一个key对应的value public static final Object get(String key) &#123; r.lock(); try &#123; return map.get(key); &#125; finally &#123; r.unlock(); &#125; &#125; // 设置key对应的value，并返回旧的value public static final Object put(String key, Object value) &#123; w.lock(); try &#123; return map.put(key, value); &#125; finally &#123; w.unlock(); &#125; &#125; // 清空所有的内容 public static final void clear() &#123; w.lock(); try &#123; map.clear(); &#125; finally &#123; w.unlock(); &#125; &#125;&#125; 关于读写状态读写锁同样依赖自定义同步器来实现同步功能，而读写状态就是其同步器的同步状态。读写锁的自定义同步器需要在同步状态（一个整型变量）上维护多个读线程和一个写线程的状态。如果在一个整型变量上维护多种状态，就一定需要“按位切割使用”这个变量，读写锁将变量切分成了两个部分，高16位表示读，低16位表示写 写锁的获取与释放写锁是一个支持重进入的排它锁。如果当前线程已经获取了写锁，则增加写状态。如果当前线程在获取写锁时，读锁已经被获取（读状态不为0）或者该线程不是已经获取写锁的线程，则当前线程进入等待状态。如果存在读锁，则写锁不能被获取，原因在于：读写锁要确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。写锁的释放与ReentrantLock的释放过程基本类似，等待的读写线程能够继续访问读写锁，同时前次写线程的修改对后续读写线程可见。 读锁的获取与释放读锁是一个支持重进入的共享锁，它能够被多个线程同时获取。读锁总会被成功地获取，而所做的也只是（线程安全的）增加读状态。如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。读锁的每次释放（线程安全，可能有多个读线程同时释放读锁）均减少读状态，减少的值是（1&lt;&lt;16）。 锁降级锁降级是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程。 锁降级示例：因为数据不常变化，所以多个线程可以并发地进行数据处理，当数据变更后，如果当前线程感知到数据变化，则进行数据的准备工作，同时其他处理线程被阻塞，直到当前线程完成数据的准备工作。 123456789101112131415161718192021222324public void processData() &#123; readLock.lock(); if (!update) &#123; // 必须先释放读锁 readLock.unlock(); // 锁降级从写锁获取到开始 writeLock.lock(); try &#123; if (!update) &#123; // 准备数据的流程（略） update = true; &#125; readLock.lock(); &#125; finally &#123; writeLock.unlock(); &#125; // 锁降级完成，写锁降级为读锁 &#125; try &#123; // 使用数据的流程（略） &#125; finally &#123; readLock.unlock(); &#125; &#125; 当数据发生变更后，update变量（布尔类型且volatile修饰）被设置为false，此时所有访问processData()方法的线程都能够感知到变化，但只有一个线程能够获取到写锁，其他线程会被阻塞在读锁和写锁的lock()方法上。当前线程获取写锁完成数据准备之后，再获取读锁，随后释放写锁，完成锁降级。 锁降级中读锁的获取是否必要呢？答案是必要的。主要是为了保证数据的可见性，如果当前线程不获取读锁而是直接释放写锁，假设此刻另一个线程（记作线程T）获取了写锁并修改了数据，那么当前线程无法感知线程T的数据更新。如果当前线程获取读锁，即遵循锁降级的步骤，则线程T将会被阻塞，直到当前线程使用数据并释放读锁之后，线程T才能获取写锁进行数据更新。 RentrantReadWriteLock不支持锁升级（把持读锁、获取写锁，最后释放读锁的过程）。目的也是保证数据可见性，如果读锁已被多个线程获取，其中任意线程成功获取了写锁并更新了数据，则其更新对其他获取到读锁的线程是不可见的。 示例18个读线程 + 2个写线程，读写操作都是耗时1s，最终耗时3s。换成 ReentrantLock 则为 20s。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class ReadWriteLockDemo &#123; private static Lock lock = new ReentrantLock(); private static ReentrantReadWriteLock readWriteLock = new ReentrantReadWriteLock(); private static Lock readLock = readWriteLock.readLock(); private static Lock writeLock = readWriteLock.writeLock(); /** 用于计时 */ private static CountDownLatch latch = new CountDownLatch(20); public Object handleRead(Lock lock) throws InterruptedException &#123; try &#123; lock.lock(); System.out.println(\"start read\"); Thread.sleep(1000); return null; &#125; finally &#123; latch.countDown(); lock.unlock(); &#125; &#125; public void handleWrite(Lock lock) throws InterruptedException &#123; try &#123; lock.lock(); System.out.println(\"start write\"); Thread.sleep(1000); &#125; finally &#123; latch.countDown(); lock.unlock(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; final ReadWriteLockDemo demo = new ReadWriteLockDemo(); Runnable readRunnale = () -&gt; &#123; try &#123; demo.handleRead(readLock); // demo.handleRead(lock); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;; Runnable writeRunnale = () -&gt; &#123; try &#123; demo.handleWrite(writeLock); // demo.handleWrite(lock); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;; Instant i1 = Instant.now(); for (int i = 0; i &lt; 18; i++) &#123; new Thread(readRunnale).start(); &#125; for (int i = 18; i &lt; 20; i++) &#123; new Thread(writeRunnale).start(); &#125; latch.await(); Instant i2 = Instant.now(); System.out.println(Duration.between(i1, i2).toMillis()); &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"https://weilans.github.io/tags/concurrent/"}]},{"title":"[回顾并发基础] Lock & AQS","slug":"Java并发札记-3-Lock & AQS","date":"2019-09-20T17:13:48.000Z","updated":"2019-12-19T11:54:23.000Z","comments":true,"path":"2019/09/21/Java并发札记-3-Lock & AQS/","link":"","permalink":"https://weilans.github.io/2019/09/21/Java并发札记-3-Lock & AQS/","excerpt":"回顾 Java Lock 基础，详细介绍了 AbstractQueuedSynchronizer的实现；并说明了Condition的原理以及LockSupport的底层作用。","text":"回顾 Java Lock 基础，详细介绍了 AbstractQueuedSynchronizer的实现；并说明了Condition的原理以及LockSupport的底层作用。 1. LockLock接口123456789101112// 获取锁，当锁获得后，从该方法处返回void lock(); // 获取锁的过程能够响应中断 void lockInterruptibly() throws InterruptedException；// 非阻塞式获取锁，获取锁放回true反之返回fasle boolean tryLock();// 超时获取锁，在超时内或者未中断的情况下能够获取锁boolean tryLock(long time, TimeUnit unit) throws InterruptedException; // 释放锁void unlock(); // 获取与lock绑定的等待通知组件，当前线程必须获得了锁才能进行等待，进行等待时会先释放锁，当再次获取锁时才能从等待中返回Condition newCondition(); Lock与synchronized相比拥有的优势 可响应中断。synchronized 会在线程持有锁 A 后，如果尝试获取锁 B 失败，那么线程就进入阻塞状态，而且一旦发生死锁，就没有任何机会来唤醒阻塞的线程。lockInterruptibly()可响应中断信号，可以在锁的获取过程中中断当前线程，调用thread.interrupt()方法能够中断线程的等待过程。 支持超时。tryLock(long time, TimeUnit unit)方法在拿不到锁时会等待一定的时间，在时间期限之内如果还拿不到锁，就返回 false。如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回 true。 非阻塞获取锁。 tryLock()方法会尝试获取锁，如果获取成功则返回true，如果获取失败则返回 false，也就说这个方法无论如何都会立即返回。 除此之外，synchronized 会隐式获取锁，且会自动释放锁，而 Lock 是显式的获取锁，手工释放（synchronized 固化了锁的获取和释放，而 Lock相对的提供了更好的拓展性）；Lock可以绑定多个条件：Condition，await，signal。synchronized的wait，notify只可以实现一种条件。 2. AbstractQueuedSynchronizer队列同步器AbstractQueuedSynchronizer是用来构建锁或者其他同步组件的基础框架,它使用了一个int成员变量表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作。同步器面向的是锁的实现者，它简化了锁的实现方式，屏蔽了同步状态管理、线程排队、等待与唤醒等底层操作细节。同步器的主要使用方式是继承，子类被推荐为自定义同步组件的静态内部类。 a. 基础描述双向队列AQS 内部通过 head 和 tail记录队首和队尾元素，队列元素的类型是 Node。在 Node 类型中：prev和next分别记录当前节点的前驱和后置节点；thread变量用来存放进入AQS队列里的线程；waitStatus记录当前线程的等待状态：CANCELLED 线程被取消、SIGNAL 线程需要被唤醒、CONDITION 线程在条件队列里面等待、PROPAGATE 释放共享资源时需要通知其他节点。 状态信息在AQS 中维持了一个单一的状态信息state，可以通过getState 、setState 、compareAndSetState 函数修改其值。 根据state 是否属于一个线程，操作state 的方式分为独占方式和共享方式。在独占方式下获取和释放资源使用的方法为 acquire / acquirelnterruptibly / release 。在共享方式下获取和释放资源的方法为： acquireShared / acquireSharedInterruptibly / releaseShared。 对于ReentrantLock 的实现来说， state 可以用来表示当前线程获取锁的可重入次数；对于读写锁ReentrantReadWriteLock 来说， state 的高16位表示读状态，也就是获取该读锁的次数，低16 位表示获取到写锁的线程的可重入次数；对于semaphore 来说， state 用来表示当前可用信号的个数：对于CountDownlatch 来说，state 用来表示计数器当前的值。 ConditionAQS 有个内部类ConditionObject ， 用来结合锁实现线程同步。ConditionObject 可以直接访问 AQS 对象内部的变量，比如 state 状态值和 AQS 队列。ConditionObject 是条件变量， 每个条件变量对应一个条件队列（单向链表队列），其用来存放调用条件变量的 await 方法后被阻塞的线程，这个条件队列的头、尾元素分别为自 firstWaiter 和 lastWaiter 。 b. AQS可重写的方法 方法名称 描述 tryAcquire(int arg) 独占获取同步状态，实现该方法需要查询当前状态，并判断同步状态是否符合预期状态，然后再进行CAS设置同步状态。 tryRelease(int arg) 独占式释放同步状态，等待获取同步状态的线程将有机会获取同步状态 tryAcquireShared(int arg) 共享式获取同步状态，返回大于等于0的值，表示获取成功，反之失败 tryReleaseShared(int arg) 共享式释放同步状态 isHeldExclusively() 当前同步器是否在独占模式下被线程占用，一般该方法表示是否被当前线程所独占 AQS提供的模板方法： c. AQS使用示例示例来自AQS官方文档（ non-reentrant mutual exclusion lock）。 12345678910111213141516171819202122232425262728293031323334353637383940class Mutex implements Lock &#123; // 静态内部类，自定义同步器 private static class Sync extends AbstractQueuedSynchronizer &#123; // 是否处于占用状态 protected boolean isHeldExclusively() &#123; return getState() == 1; &#125; // 当状态为0的时候获取锁 public boolean tryAcquire(int acquires) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; // 释放锁，将状态设置为0 protected boolean tryRelease(int releases) &#123; if (getState() == 0) throw new IllegalMonitorStateException(); setExclusiveOwnerThread(null); setState(0); return true; &#125; // 返回一个Condition，每个condition都包含了一个condition队列 Condition newCondition() &#123; return new ConditionObject(); &#125; &#125; // 仅需要将操作代理到Sync上即可 private final Sync sync = new Sync(); public void lock() &#123; sync.acquire(1); &#125; public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; public void unlock() &#123; sync.release(1); &#125; public Condition newCondition() &#123; return sync.newCondition(); &#125; public boolean isLocked() &#123; return sync.isHeldExclusively(); &#125; public boolean hasQueuedThreads() &#123; return sync.hasQueuedThreads(); &#125; public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125; d. 独占式与共享式如果论述AQS完整实现比较麻烦的话，单独描述下独占式和共享式资源获取与释放，也是可以看清楚AQS的核心的。 独占式：如果一个线程获取到了资源，会标记是这个线程获取到了，其他线程再尝试操作 state 获取资源时会发现当前该资源不是自己持有的，就会在获取失败后被阻塞。比如独占锁ReentrantLock， 当一个线程获取了ReerrantLock 的锁后，AQS 内部会首先使用CAS 操作把 state 状态值从0变为1 ，然后设置当前锁的持有者为当前线程，当该线程再次获取锁时发现它就是锁的持有者，会把状态值从1变为2 ，也就是设置可重入次数，而当另外一个线程获取锁时发现自己并不是该锁的持有者就会被放入AQS 阻塞队列后挂起。 共享式：当多个线程去请求资源时通过 CAS 方式竞争获取资源，当一个线程获取到了资源后，另外一个线程再次去获取时如果当前资源还能满足它的需要，则当前线程只需要使用 CAS 方式进行获取即可。比如Semaphore 信号量， 当一个线程通过acquire方法获取信号量时，会首先看当前信号量个数是否满足需要， 不满足则把当前线程放入阻塞队列，如果满足则通过 CAS 获取信号量。 e. AQS实现独占式资源获取与释放（1）获取12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 上述代码主要完成了同步状态获取、节点构造、加入同步队列以及在同步队列中自旋等待的相关工作，其主要逻辑是： tryAcquire(int arg)，该方法保证线程安全的获取同步状态，具体就是设置状态变量 state 的值，成功则直接返回； 如果同步状态获取失败，则构造同步节点（独占式Node.EXCLUSIVE）并通过addWaiter(Node node)方法将该节点加入到AQS阻塞队列的尾部； 最后调用acquireQueued方法，使用 LockSupport.park(this) 挂起自己，使得该节点以“死循环”的方式获取同步状态。 123456789101112131415private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // 快速尝试在尾部添加 Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 同步器通过死循环来保证节点的正确添加 enq(node); return node;&#125; 设置尾节点：加入队列的过程必须要保证线程安全，因此同步器提供了一个基于CAS的设置尾节点的方法：compareAndSetTail(Node expect,Node update)，它需要传递当前线程“认为”的尾节点和当前节点，只有设置成功后，当前节点才正式与之前的尾节点建立关联。 第一个线程想要获取锁时，直接返回，不会进入阻塞队列的逻辑。第二个线程获取锁时，在addWaiter中的enq方法中，会在阻塞队列头部塞入一个新的空Node（也可以成为“哨兵Node”），第二个线程封装为Node后，放在该空Node后面；之后第二个线程在acquireQueued方法中的shouldParkAfterFailedAcquire中返回false，但waitStatus置为了SIGNAL，再次循环进入shouldParkAfterFailedAcquire方法，由于waitStatus等于SIGNAL，返回true，故使用LockSupport阻塞第二个线程。 当第一个线程返回时，调用release方法，此时head还是之前的空Node，unparkSuccessor(head)会唤醒head的后继者，即第二个线程。第二个线程在acquireQueued方法中的tryAcquire方法中成功返回，会将head设为自己。 若在第二个线程之后，还有n个线程在队列中，在第二个线程release时，会唤醒head的后继者，即队列后续线程，以此类推。 （2）释放同步器的release(int arg)方法可以释放同步状态）。 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 设置首节点：首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，将会唤醒后继节点，而后继节点将会在获取同步状态成功时将自己设置为首节点。设置首节点是通过获取同步状态成功的线程来完成的，由于只有一个线程能够成功获取到同步状态，因此设置头节点的方法并不需要使用CAS来保证。 在unparkSuccessor的方法中，会对节点的后续节点线程调用LockSupport.unpark方法以激活后续线程。被激活的线程则使用tryAcquire 尝试，看当前状态变量state的值是否能满足自己的需要，满足则该线程被激活，然后继续向下运行，否则还是会被放入 AQS 队列并被挂起。 共享式资源获取与释放（1）获取当线程调用acquireShared获取共享资源时，会首先使用tryAcquireShared尝试获取资源， 具体是设置状态变量 state 的值，成功则直接返回（成功获取到同步状态并退出自旋的条件就是 tryAcquireShared 方法返回值大于等于0），失败则将当前线程封装为类型为 Node.SHARED 的 Node 节点后插入到 AQS 阻塞队列的尾部，并使用LockSupport.park(this） 方法挂起自己。 1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; （2）释放线程调用releaseShared时会尝试使用tryReleaseShared操作释放资源，这里是设置状态变量 state 的值，然后在unparkSuccessor中使用LockSupport.unpark激活后续线程 。被激活的线程则使用tryAcquireShared查看当前状态变量 state 的值是否能满足自己的需要，满足则继续向下运行，否则还是会被放入AQS 队列并被挂起。 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; 共享式前N个可以获取资源的线程直接返回， 不会进入阻塞队列的逻辑。后续线程无法获取到资源时，在doAcquireShared的第一行就是addWaiter方法，后续大体逻辑和独占式类似。 自定义同步组件 TwinsLockTwinsLock: 只允许至多两个线程访问，超过两个线程的访问将被阻塞 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class TwinsLock implements Lock &#123; /** * 自定义的同步器，能够有两个线程同时获取资源 */ private final Sync sync = new Sync(2); private static final class Sync extends AbstractQueuedSynchronizer &#123; Sync(int count) &#123; if (count &lt;= 0) &#123; throw new IllegalArgumentException(\"count must large than zero.\"); &#125; setState(count); &#125; @Override public int tryAcquireShared(int reduceCount) &#123; for (; ; ) &#123; int current = getState(); int newCount = current - reduceCount; if (newCount &lt; 0 || compareAndSetState(current, newCount)) &#123; return newCount; &#125; &#125; &#125; @Override public boolean tryReleaseShared(int returnCount) &#123; for (; ; ) &#123; int current = getState(); int newCount = current + returnCount; if (compareAndSetState(current, newCount)) &#123; // 将释放的资源返回 return true; &#125; &#125; &#125; Condition newCondtion() &#123; return new ConditionObject(); &#125; &#125; @Override public void lock() &#123; sync.acquireShared(1); &#125; @Override public void lockInterruptibly() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; @Override public boolean tryLock() &#123; return sync.tryAcquireShared(1) &gt;= 0; &#125; @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(time)); &#125; @Override public void unlock() &#123; sync.releaseShared(1); &#125; @Override public Condition newCondition() &#123; return sync.newCondtion(); &#125;&#125; 3. ConditionAPI1234567void await() throws InterruptedException;void awaitUninterruptibly();long awaitNanos(long nanosTimeout) throws InterruptedException;boolean await(long time, TimeUnit unit) throws InterruptedException;boolean awaitUntil(Date deadline) throws InterruptedException;void signal();void signalAll(); await() 方法会使当前线程等待，同时释放当前锁，当其他线程中使用signal()或者signalAll()方法时，线程会重新获得锁并继续执行。或者当线程被中断时，也能跳出等待。这和Object.wait()方法很相似； awaitUninterruptibly() 方法与 await() 方法基本相同，但是它并不会在等待过程中响应中断； singal() 用于唤醒一个在等待中的线程； singalAll() 方法会唤醒所有在等待中的线程，和Obejct.notify()方法很类似； 使用范式123456789101112131415161718Lock lock = new ReentrantLock();Condition condition = lock.newCondition();public void conditionWait() throws InterruptedException &#123; lock.lock(); try &#123; condition.await(); &#125; finally &#123; lock.unlock(); &#125;&#125; public void conditionSignal() throws InterruptedException &#123; lock.lock(); try &#123; condition.signal(); &#125; finally &#123; lock.unlock(); &#125;&#125; 官方示例范式中 lock() 并没有放在 try {} 中，应该是因为不排除获取锁(比如自定义锁)的过程中产生异常后，却调用了unlock() 方法。 和Object.wait()和notify()方法一样，当线程使用Condition.await()时，要求线程持有相关的重入锁，在Condition.await()调用后，这个线程会释放这把锁。 在Condition.signal()方法调用时，也要求线程先获得相关的锁。在signal()方法调用后，系统会从当前Condition对象的等待队列中，唤醒一个线程。一旦线程被唤醒，它会重新尝试获得与之绑定的重入锁，一旦成功获取，就可以继续执行了。因此，在signal()方法调用之后，一般需要释放相关的锁，谦让给被唤醒的线程，让它可以继续执行。 ArrayBlockingQueue 中 Lock 及 Condition 的使用1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889final Object[] items;int takeIndex;int putIndex;int count;final ReentrantLock lock;private final Condition notEmpty;private final Condition notFull;this.items = new Object[capacity];lock = new ReentrantLock(fair);notEmpty = lock.newCondition();notFull = lock.newCondition();public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == 0) notEmpty.await(); return dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125;private E dequeue() &#123; final Object[] items = this.items; E x = (E) items[takeIndex]; items[takeIndex] = null; if (++takeIndex == items.length) takeIndex = 0; count--; // 如果迭代器itrs不为null，则需要维护下该迭代器。可忽略 if (itrs != null) itrs.elementDequeued(); notFull.signal(); return x;&#125;public void put(E e) throws InterruptedException &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; // while loop防止意外的通知，只有条件符合才能退出循环 while (count == items.length) notFull.await(); enqueue(e); &#125; finally &#123; lock.unlock(); &#125;&#125;private void enqueue(E x) &#123; final Object[] items = this.items; items[putIndex] = x; if (++putIndex == items.length) putIndex = 0; count++; notEmpty.signal();&#125;// 补充public E poll() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; return (count == 0) ? null : dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125;// 补充public boolean offer(E e) &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lock(); try &#123; if (count == items.length) return false; else &#123; enqueue(e); return true; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125; Condition实现lock.newCondition() 的作用其实是 new 了一个在AQS 内部声明的 ConditionObject 对象， ConditionObject 是AQS 的内部类，可以访问 AQS 内部的变量和方法。每个Condition对象都包含着一个队列（等待队列），用来存放调用条件变量的 await() 方法时被阻塞的线程。这个条件队列和 AQS 的同步队列不是一回事，该队列是Condition对象实现等待/通知功能的关键。 等待队列 一个 Condition 包含一个等待队列，Condition拥有首节点（firstWaiter）和尾节点（lastWaiter）。当前线程调用Condition.await()方法，将会以当前线程构造节点，将原有的尾节点 nextWaiter 指向它，并且更新尾节点即可。引用更新的过程并没有使用CAS保证，原因在于调用await()方法的线程必定是获取了锁的线程，也就是说该过程是由锁来保证线程安全的。 在Object的监视器模型上，一个对象拥有一个同步队列和等待队列，而并发包中的Lock（更确切地说是同步器）拥有一个同步队列和多个等待队列。 await() 调用Condition的await()方法（或者以await开头的方法），会构造一个类型为Node.CONDITION 的node 节点，然后将该节点插入条件队列末尾并释放锁，同时当前线程也会被阻塞挂起。之后唤醒同步队列中的后继节点，然后当前线程会进入等待状态。 123456789101112131415161718192021public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 创建新 node 节点，插入到条件队列末尾 Node node = addConditionWaiter(); // 释放当前线程获得到的锁 int savedState = fullyRelease(node); int interruptMode = 0; // 调用 park 方法阻塞当前线程 while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); &#125; signal()signal() 方法会进行isHeldExclusively()检查，确认当前线程是获取锁的线程。接着会把条件队列里头节点从条件队列里面移除并放入 AQS 的同步队列里面，然后使用 LockSupport 唤醒节点中的线程。 l o ck（） 方法获取锁） ， 在内部会把条件队列里面队头的一个线程节点从条件队列里面移除并 被唤醒后的线程，将从 await() 方法中的while循环中退出（isOnSyncQueue方法返回true，节点已经在同步队列中），进而调用同步器的 acquireQueued() 方法加入到获取同步状态的竞争中。 123456789public final void signal() &#123; // 确认当前线程是获取锁的线程 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) // 将条件队列头元素移动到AQS队列 doSignal(first);&#125; Condition的signalAll()方法，相当于对等待队列中的每个节点均执行一次signal()方法，效果就是将等待队列中所有节点全部移动到同步队列中，并唤醒每个节点的线程。 4. LockSupport线程阻塞类工具，可以在线程内任何位置让线程阻塞。1. 和Thread.suspend()相比，它弥补了由于resume()在前发生，导致线程无法继续执行的情况。2. 和Object.wait()相比，它不需要先获得某个对象的锁。3. 也不会抛出InterruptedException异常。 LockSupport的静态方法park()可以阻塞当前线程，类似的还有parkNanos()、parkUntil()等方法，它们实现了一个限时的等待。 unpark(Thread thread)方法原来唤醒一个被阻塞的线程。 1234567891011121314151617181920212223242526272829public class LockSupportDemo &#123; public static Object u = new Object(); static ChangeObjectThread t1 = new ChangeObjectThread(\"t1\"); static ChangeObjectThread t2 = new ChangeObjectThread(\"t2\"); public static class ChangeObjectThread extends Thread &#123; public ChangeObjectThread(String name) &#123; super.setName(name); &#125; @Override public void run() &#123; synchronized (u) &#123; System.out.println(\"in \" + getName()); LockSupport.park(); &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; t1.start(); Thread.sleep(100); t2.start(); LockSupport.unpark(t1); LockSupport.unpark(t2); t1.join(); t2.join(); &#125;&#125; 虽然无法保证unpark()方法发生在park()方法之后。但以上代码自始至终都可以正常的结束，不会因为park()方法而导致线程永久性的挂起。这是因为LockSupport类使用类似信号量的机制。它为每一个线程准备了一个许可，如果许可可用，那么park()函数会立即返回，并且消费这个许可（也就是将许可变为不可用），如果许可不可用，就会阻塞。而unpark()则使得一个许可变为可用（但是和信号量不同的是，许可不能累加，你不可能拥有超过一个许可，它永远只有一个）。这个特点使得：即使unpark()操作发生在park()之前，它也可以使下一次的park()操作立即返回。 如果使用park(Object)函数，还可以为当前线程设置一个阻塞对象。这个阻塞对象会出现在线程Dump中。这样在分析问题时，就更加方便了。 LockSupport.park()还能支持中断响应，如果其他线程调用了阻塞线程的interrupt()方法，设置了中断标志，则阻塞线程会返回。和其他接收中断的函数很不一样，LockSupport.park()不会抛出InterruptedException异常。它只是会默默的返回，我们可以从Thread.interrupted()等方法获得中断标记。 5. 使用锁的最佳实践并发大师 Doug Lea《Java 并发编程：设计原则与模式》一书中，推荐的三个用锁的最佳实践： 永远只在更新对象的成员变量时加锁 永远只在访问可变的成员变量时加锁 永远不在调用其他对象的方法时加锁 关于最后一条同样是尽量要去遵守：调用其他对象的方法，实在是太不安全了，也许其他方法里面有线程 sleep() 的调用，也可能会有奇慢无比的 I/O 操作，这些都会严重影响性能。更可怕的是，其他类的方法可能也会加锁，然后双重加锁就可能导致死锁。 6. CaseQ：下面的代码是否存在死锁？ A：不出现死锁，但会出现活锁（主动将资源释放给他人使用，那么就会出现资源不断在两个线程中跳动，而没有一个线程可以同时拿到所有资源而正常执行）。 1234567891011121314151617181920212223class Account &#123; private int balance; private final Lock lock = new ReentrantLock(); // 转账 void transfer(Account tar, int amt)&#123; while (true) &#123; if(this.lock.tryLock()) &#123; try &#123; if (tar.lock.tryLock()) &#123; try &#123; this.balance -= amt; tar.balance += amt; &#125; finally &#123; tar.lock.unlock(); &#125; &#125;//if &#125; finally &#123; this.lock.unlock(); &#125; &#125;//if &#125;//while &#125;//transfer&#125; Reference 《Java并发编程的艺术》 《Java并发编程之美》 https://time.geekbang.org/column/article/87779","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"https://weilans.github.io/tags/concurrent/"}]},{"title":"使用自定义ClassLoader加载SpringBoot打包文件中嵌套jar驱动","slug":"使用ClassLoader在SpringBoot打包文件中获取嵌套jar","date":"2019-09-11T06:25:51.000Z","updated":"2019-10-06T12:51:04.000Z","comments":true,"path":"2019/09/11/使用ClassLoader在SpringBoot打包文件中获取嵌套jar/","link":"","permalink":"https://weilans.github.io/2019/09/11/使用ClassLoader在SpringBoot打包文件中获取嵌套jar/","excerpt":"需求：针对某些DB不同版本的冲突问题，采用自定义类加载器的方式自行加载 Driver，驱动包放至 jdbc module 下，而 web module 在使用 Spring Boot 打成 jar 包后，需要获取到内部 jdbc module 中的驱动包。Spring Boot jar 包启动时，自定义类加载需要能够读到驱动包资源。","text":"需求：针对某些DB不同版本的冲突问题，采用自定义类加载器的方式自行加载 Driver，驱动包放至 jdbc module 下，而 web module 在使用 Spring Boot 打成 jar 包后，需要获取到内部 jdbc module 中的驱动包。Spring Boot jar 包启动时，自定义类加载需要能够读到驱动包资源。 曾几何时，我以为所谓的Spring Boot 启动原理这些知识点最多就是面试时候可能问到的东西，后来在工作时还真用到了。 前期尝试这种需求，本以为并不难做，毕竟针对 jar 包内部的 jar，Java URL 协议中本身就有jar:file:前缀提供支持。使用PathMatchingResourcePatternResolver获取到 URL 后，直接赋给 URLClassLoader 应该是可行的。这种方式在 IDE 中运行时没有问题的，urls 中的 URL 都是以file:为前缀，运行正常；而打成 jar 包运行时，URL的格式变为jar:file:/...web.jar!/BOOT-INF/lib/...jdbc.jar!/.../hive/2.1.1/hive-common-2.1.1.jar，运行时出现了java.lang.ClassNotFoundException。 12345678String location = \"classpath:drivers/hive/2.1.1/*.jar\"; PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver();Resource[] resources = resolver.getResources(locationPattern);URL[] urls = new URL[resources.length];for (int i = 0; i &lt; resources.length; i++) &#123; urls[i] = resources[i].getURL();&#125;return new URLClassLoader(urls, getClassLoader()); 重新调试我选择在一个单独的调试项目下对刚才生成的jar包进行调试。第一直觉是 URLClassloader 是不是不支持这种 jar:file前缀 URL，不过并没有找到相关描述信息，不过倒是发现刚才的jar:file的URL中没有加上!/后缀（这表示在 jar 包内部就行查找）。实际上，对于原始的JarFile URL，只支持一个!/。那 Spring Boot 是怎么做到的呢，他是怎么做到能够读取到 jar in jar 呢，原来 Spring Boot 扩展了协议，使其能够支持读取嵌套 jar。于是在调试项目下，我引入了spring-boot-loader的依赖进行试验。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-loader&lt;/artifactId&gt;&lt;/dependency&gt; 由于一般 Spring Boot 打成的 jar 包中的META-INF/MANIFEST.MF文件中会包含Main-Class: org.springframework.boot.loader.JarLauncher。即指定了 Main Class 为 JarLauncher。在其 launch 方法中发现，Spring Boot 就是在 JarFile.registerUrlProtocolHandler()注册了URLStreamHandler的实现：org.springframework.boot.loader.jar.Handler。 123456789101112131415// in Launcherprotected void launch(String[] args) throws Exception &#123; JarFile.registerUrlProtocolHandler(); ClassLoader classLoader = createClassLoader(getClassPathArchives()); launch(args, getMainClass(), classLoader);&#125;// in JarFileprivate static final String PROTOCOL_HANDLER = \"java.protocol.handler.pkgs\";public static void registerUrlProtocolHandler() &#123; String handlers = System.getProperty(PROTOCOL_HANDLER, \"\"); System.setProperty(PROTOCOL_HANDLER, (\"\".equals(handlers) ? HANDLERS_PACKAGE : handlers + \"|\" + HANDLERS_PACKAGE)); resetCachedUrlHandlers();&#125; 在测试项目下，由于是 IDE 运行，我先在 main 方法中加入了JarFile.registerUrlProtocolHandler()。在Handle的openConnection方法中调用了JarURLConnection的get(URL url, JarFile jarFile)方法，真正报错的地方在于内部的jarFile.getNestedJarFile(jarEntry)，这个信息在java.lang.ClassNotFoundException的堆栈中是没有显示的： 1java.lang.IllegalStateException: Unable to open nested entry '....jar'. It has been compressed and nested jar files must be stored without compression. Please check the mechanism used to create your executable jar file 显示是 Jar 包压缩的问题？于是我在 jdbc module 的 pom 文件中加了这么一段，compress 置为了false，结果发现终于成功了。 12345678910111213&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;compress&gt;false&lt;/compress&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 最终实现到最后发现实际上改的地方不多，但是如果自己不去调试 Spring Boot 的启动包，也发现不了真正的原因。 改动1就是 jdbc module 加入了maven-jar-plugin插件且compress置为 false。 改动2是在一开始实现的 for 循环中，对于jar:file开头的URL加了!/后缀。 123456789for (int i = 0; i &lt; resources.length; i++) &#123; String urlStr = resources[i].getURL().toString(); if (StringUtils.isNotBlank(urlStr) &amp;&amp; urlStr.startsWith(\"jar:file\")) &#123; urlStr = urlStr + \"!/\"; &#125; URL url = ResourceUtils.getURL(urlStr); urls[i] = url; log.info(url.toString());&#125; 实际上代码中不需要加JarFile.registerUrlProtocolHandler()注册协议，由于刚才的调试项目的main方法运行的，所以才加上。而在正式项目代码处，若打包运行的话，jar 包启动时本身就执行了注册协议；若在 IDE 里运行，file:前缀则不需要走此协议。当然如果不是加上这句话进行调试，也发现不了问题。 Reference https://benjaminwhx.com/2018/07/14/说说Spring中的资源文件的读取/ https://segmentfault.com/a/1190000013532009 https://blog.iooo.tech/2018/06/19/SpringBoot可执行文件解析/","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://weilans.github.io/tags/jvm/"},{"name":"spring","slug":"spring","permalink":"https://weilans.github.io/tags/spring/"}]},{"title":"JVM 类加载机制解析","slug":"JVM-类加载机制","date":"2019-09-07T05:40:20.000Z","updated":"2021-03-02T08:07:48.450Z","comments":true,"path":"2019/09/07/JVM-类加载机制/","link":"","permalink":"https://weilans.github.io/2019/09/07/JVM-类加载机制/","excerpt":"“与那些在编译时需要进行连接工作的语言不同，在Java语言里面，类型的加载、连接和初始化过程都是在程序运行期间完成的，这种策略虽然会令类加载时稍微增加一些性能开销，但是会为Java应用程序提供高度的灵活性，Java里天生可以动态扩展的语言特性就是依赖运行期动态加载和动态连接这个特点实现的。”","text":"“与那些在编译时需要进行连接工作的语言不同，在Java语言里面，类型的加载、连接和初始化过程都是在程序运行期间完成的，这种策略虽然会令类加载时稍微增加一些性能开销，但是会为Java应用程序提供高度的灵活性，Java里天生可以动态扩展的语言特性就是依赖运行期动态加载和动态连接这个特点实现的。” 类加载机制类加载时机以前初学的时候，以为在Web程序启动时，静态代码块中的内容就会执行。其实这是没有理解类是何时进行初始化的。 加载、验证、准备、初始化和卸载这5个阶段的顺序是确定的，类的加载过程必须按照这种顺序按部就班地开始，而解析阶段则不一定：它在某些情况下可以在初始化阶段之后再开始，这是为了支持Java语言的动态绑定。Java虚拟机规范中没有强制规定类何时初始化，但是对于初始化阶段，则严格规定以下情况必须立即对类进行“初始化”（加载、验证、准备自然需要在此之前开始）： 遇到new、getstatic、putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令的最常见的Java代码场景是：使用new关键字实例化对象的时候、读取或设置一个类的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。（而一个接口在初始化时，并不要求其父接口全部都完成了初始化，只有在真正使用到父接口的时候（如引用接口中定义的常量）才会初始化。） 当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。 当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。” 这五种场景称为“主动引用”，而引用类的方法不会触发初始化的则称为“被动引用”。被动引用具体有以下三种例子： 通过子类引用父类的静态字段，不会导致子类初始化。（对于静态字段，只有直接定义这个字段的类才会初始化，因此只会触发父类的初始化。） 通过数组定义来引用类，不会触发此类的初始化。 常量在编译阶段会存入调用类的常量池中，本质上没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。 类加载过程类装载主要涉及三个步骤：加载、连接（验证、准备、解析）、初始化 加载 (Class-Loading) 通过类的全限定名取得类的二进制流 将字节流所代表的静态存储结构转为方法区数据结构 在Java堆中生成对应的java.lang.Class对象 连接 - 验证其目标是保证Class文件字节流的格式是正确的，符合虚拟机的要求，主要涉及： 文件格式的验证 是否以0xCAFEBABE开头 版本号是否合理 元数据验证：对字节码描述的信息进行语义分析，以保证符合 Java 语言规范的要求 该类是否有父类（除了 Object，所有类都应当有父类） 该类是否继承了不允许被继承的类（被 final 修饰的类） 非抽象类是否实现了所有该实现的抽象方法 字节码验证 (很复杂)：对类的方法体进行校验分析，以保证方法执行时不会危害虚拟机安全 运行检查 栈数据类型和操作码数据参数吻合 保证跳转指令不会跳转到方法体以外的字节码指令上 保证方法体中的类型转换是有效的 符号引用验证：发生在将符号引用转化为直接引用的时候，动作发生在连接第三阶段 - 解析的过程中。像java.lang.NoSuchFieldError，java.lang.NoSuchMethodError都是发生在此阶段。 符号引用中通过字符串描述的全限定名是否能找到对应的类 在指定类中是否存在符合方法的字段描述符以及简单名称所描述的方法和字段 访问的方法或字段是否存在且有足够的权限 连接 - 准备分配内存，并为类变量设置初始值，变量所使用的内存都在方法区中进行分配。 内存分配仅为类变量 (static 修饰)，而不包括实例变量，实例变量将会在对象示例化时随着对象一起分配在 Java 堆中。如public static int v=1;在准备阶段中，v会被设置为0。在初始化的&lt;clinit&gt;中才会被设置为1。 对于static final类型，在准备阶段就会被赋上正确的值public static final int v=1; 连接 - 解析将符号引用转为直接引用的过程。 符号引用：符号可以是任何形式的字面量，引用的目标不一定已经加载到内存中。 直接引用：直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。 初始化到了初始化阶段，才真正开始执行类中定义的 Java 程序代码。 执行类构造器&lt;clinit&gt; static变量 赋值语句 static{} 语句 子类的&lt;clinit&gt;调用前保证父类的&lt;clinit&gt;被调用 &lt;clinit&gt;是线程安全的。虚拟机会保证一个类的＜clinit＞方法在多线程环境中被正确地加锁、同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的＜clinit＞方法，其他线程都需要阻塞等待，直到活动线程执行＜clinit＞()方法完毕。 类加载器对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机中的唯一性。否则，即使这两个类来源于同一个Class文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。“相等”包括代表类的Class对象的equals()方法、isAssignableFrom()方法、isInstance()方法的返回结果，也包括使用instanceof关键字做对象所属关系判定等情况。 什么是类装载器ClassLoader ClassLoader是一个抽象类； ClassLoader的实例将读入Java字节码将类装载到JVM中； ClassLoader可以定制，满足不同的字节码流获取方式； ClassLoader负责类装载过程中的加载阶段。 ClassLoader的重要方法12345678// 载入并返回一个Classpublic Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException// 定义一个类，不公开调用protected final Class&lt;?&gt; defineClass(byte[] b, int off, int len)// loadClass回调该方法，自定义ClassLoader的推荐做法 protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException// 寻找已经加载的类protected final Class&lt;?&gt; findLoadedClass(String name) ClassLoader分类 BootStrap ClassLoader （启动ClassLoader） 负责将存放在＜JAVA_HOME＞\\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的类库加载到虚拟机内存中。 Extension ClassLoader （扩展ClassLoader） 负责加载＜JAVA_HOME＞\\lib\\ext目录中的，或者被java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。 App ClassLoader （应用ClassLoader/系统ClassLoader） 负责加载用户类路径ClassPath上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 Custom ClassLoader(自定义ClassLoader) Custom ClassLoader的简单示例从特定路径找到特定类的class文件，获取其字节数组后调用defineClass方法来定义类。 123456789101112131415public class CustomClassLoader extends ClassLoader &#123; private String path; public CustomClassLoader(String path) &#123; this.path = path; &#125; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; // 自己实现的方法：由 path + name + \".class\" 获取class文件字节数组 byte[] classBytes = loadClassData(name); return defineClass(name, classBytes, 0, classBytes.length); &#125;&#125; 双亲委派模型 上图中的类加载器之间的层次关系即为类加载器的双亲委派模型：自底向上检查类是否被加载，自顶向下尝试加载类。 类加载器不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。 好处是：Java类随着它的类加载器一起具备了一种带有优先级的层次关系。Object无论哪一个类加载器要加载这个类，最终都是委派给启动类加载器进行加载，各种类加载器环境中都是同一个类。若没有使用双亲委派模型，用户自己编写了一个Object类，并放在程序的ClassPath中，那系统中将会出现多个不同的Object类，Java类型体系中最基础的行为也就无法保证，应用程序也将会变得一片混乱。 以下代码就是 ClassLoader.loadClass方法，可以看到双亲委派的具体实现。 123456789101112131415161718192021222324252627282930313233343536373839protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; // 可能涉及到多个线程调用同一个classLoader来加载同一个类 synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; // 由 Bootstrap ClassLoader 找是否加载个这个类 c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 破坏双亲委派模型First该模型虽然解决了各个类加载器基础类的统一问题，但如果基础类要调用用户的代码则无法实现。如SPI的定义在rt.jar(即BootStrap ClassLoader)中，而实现类在AppClassLoader中。 解决方式为线程上下文类加载器(Thread Context ClassLoader)，基本思想是，在顶层ClassLoader中，传入底层ClassLoader的实例。这个类加载器可以通过java.lang.Thread类的setContextClassLoaser()方法进行设置，如果创建线程时还未设置，它将会从父线程中继承一个，如果在应用程序的全局范围内都没有设置过的话，那这个类加载器默认就是应用程序类加载器。读取即为Thread.currentThread().getContextClassLoader()。 Second双亲委派模式是默认的模式，但不是必须这么做，破坏双亲委派模型也可以自定义实现ClassLoader： Tomcat 的 WebappClassLoader 就会先加载自己的Class，找不到再委托parent； OSGi 的 ClassLoader形成网状结构，根据需要自由加载Class。 loadClass和forName之间的区别ClassLoader.loadClass(name)调用重载方法loadClass(name, false)，第二个参数为 resolve，其含义就是是否进行解析(连接的解析阶段)，若是 true，会调用 resolveClass，开始连接指定的类。所以 loadClass 不会连接类。 而Class.forName内部调用 forname0 方法，其第二个布尔值参数代表是否初始化这个类， 而调用时使用的是 true，即会初始化这个类。 所以结论是，Class.forName 得到的是 class 是已经初始化的；而 ClassLoader.loadClass 得到的 Class 是还没有进行连接的。可以自定义一个类，类中加一个静态代码块进行确认是否进行了初始化。 loadClass 可以在 Spring IOC 中看到身影，这么做的原因是和 Spring 的 lazy loading 有关。为了加快类加载速度，大量使用延时加载技术，loadClass不需要执行类中的初始化代码且不需要连接，类的初始化工作留到实际使用到这个类的时候才去进行。 Tomcat 类加载器结构主流Java服务器都实现了自定义的类加载器，因为一个健全的Web服务器需要解决以下几个问题： 部署在同一个服务器上的两个Web应用程序所使用的Java类库可以实现相互隔离。 部署在同一个服务器上的两个Web应用程序所使用的Java类库可以互相共享。如果类库不能共享，虚拟机的方法区就会很容易出现过度膨胀的风险。 服务器需要尽可能地保证自身的安全不受部署的Web应用程序影响。一般来说，基于安全考虑，服务器所使用的类库应该与应用程序的类库互相独立。 支持JSP应用的Web服务器，大多数都需要支持HotSwap功能。 因为上述问题的存在，所以Web服务器一般都会划分出好几个类路径。以Tomcat为例： /common目录：类库可被Tomcat和所有的Web应用程序共同使用。 /server目录：类库可被Tomcat使用，对所有的Web应用程序都不可见。 /shared目录：类库可被所有的Web应用程序共同使用，但对Tomcat自己不可见。 /WebApp/WEB-INF目录：类库仅仅可以被此Web应用程序使用，对Tomcat和其他Web应用程序都不可见。 为了支持这套目录结构，并对目录里面的类库进行加载和隔离，Tomcat自定义了多个类加载器。CommonClassLoader、CatalinaClassLoader、SharedClassLoader和WebappClassLoader则是Tomcat自己定义的类加载器，它们分别加载/common/*、/server/*、/shared/*和/WebApp/WEB-INF/*中的Java类库。其中WebApp类加载器和Jsp类加载器通常会存在多个实例，每一个Web应用程序对应一个WebApp类加载器，每一个JSP文件对应一个Jsp类加载器。 思维导图 Reference周志明. 深入理解Java虚拟机：JVM高级特性与最佳实践","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://weilans.github.io/tags/jvm/"}]},{"title":"[回顾并发基础] Java内存模型","slug":"Java并发札记-1-Java内存模型","date":"2019-08-24T16:01:46.000Z","updated":"2019-12-19T11:54:13.000Z","comments":true,"path":"2019/08/25/Java并发札记-1-Java内存模型/","link":"","permalink":"https://weilans.github.io/2019/08/25/Java并发札记-1-Java内存模型/","excerpt":"","text":"Java内存模型JMM控制线程间的通信，定义了工作内存和主内存的抽象关系，每个线程有私有工作内存，保留该线程使用的变量的主内存副本拷贝，读写都在工作内存中进行。若要通信的话需把本地内存刷新到主内存中，另一个线程从主内存中读取。 模型三种特征JMM的关键点都是围绕着多线程的原子性、可见性和有序性来建立的。（即为JMM如何解决前篇文中提到的并发问题） 原子性基本数据类型的访问读写是具备原子性的（例外32位系统中long和double的读写是非原子性）。若应用场景需要更大规模的原子性保证，JVM提供了两个高级的字节码指令monitorenter和monitorexit。这两个字节码指令反映到Java代码中就是同步块——synchronized关键字，因此在synchronized块之间的操作也具备原子性。 可见性指当一个线程修改了共享变量的值，其他线程能够立即得知这个修改。volatile可以保证可见性。普通变量与volatile变量的区别是，volatile的特殊规则保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。因此，可以说volatile保证了多线程操作时变量的可见性，而普通变量则不能保证这一点。Java中的synchronized和final两个关键字也可以实现可见性。 synchronized规定，线程在加锁时，先清空工作内存→在主内存中拷贝最新变量的副本到工作内存→执行完代码→将更改后的共享变量的值刷新到主内存中→释放互斥锁。 synchronized 的可见性也可以通过 Happens-Before 推断：“对一个锁解锁 Happens-Before 后续对这个锁的加锁”，指的是前一个线程的解锁操作对后一个线程的加锁操作可见，综合 Happens-Before 的传递性原则，我们能得出前一个线程在临界区修改的共享变量（该操作在解锁之前），对后续进入临界区（该操作在加锁之后）的线程是可见的。 final关键字的可见性是指：被final修饰的字段在构造器中一旦初始化完成，并且构造器没有把”this”的引用传递出去（this引用逃逸是一件很危险的事情，其他线程有可能通过这个引用访问到“初始化了一半”的对象），那在其他线程中就能看见final字段的值。 有序性程序在执行时，可能会进行指令重排序，重排后的指令与原指令的顺序未必一致。 重排序在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型： 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术（ ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 如果在单线程内观察，所有的操作都是有序的，这就是“线程内表现为串行的语义”（Within-Thread As-If-Serial Semantics）。而重排序对多线程则会有影响，重排序只保证单线程串行语义一直，没有义务保证多线程的语义也一致。 在Java中，可以使用volatile和synchronized来保证多线程之间操作的有序性。实现方式有所区别：volatile关键字会禁止指令重排。synchronized关键字保证同一时刻只允许一条线程操作。 as-if-serial语义不管怎么重排序（编译器和处理器为了提高并行度），单线程程序的执行结果不能被改变。编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被编译器和处理器重排序。as-if-serial语义把单线程程序保护了起来。 指令重排也是有原则的，并非所有指令都可以随意重排，Happens-before 可以指定两个操作之间的顺序。Happens-Before 并不是说前面一个操作发生在后续操作的前面，它真正要表达的是：前面一个操作的结果对后续操作是可见的。 Happens-Before 原则下面的这些原则是指令重排不可违背的： 程序顺序原则：在一个线程中，前面的操作 Happens-Before 于后面任何操作。 管程锁定规则：对一个锁的解锁 Happens-Before于后续对这个锁的加锁。 传递性：如果 A happens- before B，且 B happens- before C，那么 A happens- before C。 volatile变量规则：对一个volatile变量的写操作 Happens-Before 于后面对这个变量的读操作。 线程启动规则：Thread对象的start()方法 Happens-Before 于此线程的每一个动作。 线程终止规则：线程中所有操作都 Happens-Before 于此线程的终结。 对象终结规则：对象的构造函数执行结束 Happens-Before 于finalize方法。 这些先行发生关系无须使用任何同步手段就能成立，可以在编码中直接使用，这是Java内存模型对程序员的保证。如果两个操作之间的关系不在此列，并且无法从下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们随意地进行重排序。 123456789101112131415161718192021222324//////////程序启动规则示例/////////Thread B = new Thread(()-&gt;&#123; // 主线程调用 B.start() 之前 // 所有对共享变量的修改，此处皆可见 // 此例中，var==77&#125;);// 此处对共享变量 var 修改var = 77;// 主线程启动子线程B.start();//////////线程终止规则示例/////////Thread B = new Thread(()-&gt;&#123; // 此处对共享变量 var 修改 var = 66;&#125;);// 例如此处对共享变量修改，// 则这个修改结果对线程 B 可见// 主线程启动子线程B.start();B.join()// 子线程所有对共享变量的修改// 在主线程调用 B.join() 之后皆可见// 此例中，var==66 volatile使用volatile关键字修饰的变量，保证了其在多线程之间的可见 性，即当一个线程修改了这个变量的值，新值对于其他线程来说是可以立即得到的： 当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存（写语义）； 当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效，线程接下来将从主内存中读取共享变量（读语义）。 使用volatile的主要原因是其另一个特性：禁止指令重排序优化。比如说执行完某个操作时将布尔值设定为true，若没有volatile则会存在重排序的可能，设为true的操作会提前执行。编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。 “基于volatile变量的运算在并发下是安全的”不准确。20个线程，对volatile修饰的变量进行10000次自增，结果会小于200000。自增操作在加一时，变量值可能已经过期了。Volatile++ 此种复合操作无法保证原子性。 CaseQ: java 单例模式中双重检查锁定 volatile 的作用 1234567891011121314public class Singleton &#123; private Singleton() &#123;&#125; private volatile static Singleton instance; public Singleton getInstance() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if(instance == null)&#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; instance = new Singleton(); 包含了三个操作：1.分配对象的内存空间；2.初始化对象；3.设置instance指向刚分配的内存地址。但由于存在重排序的问题，2和3可能进行重排序。用volatile修饰的话就可以禁止2和3操作重排序，从而避免这种情况。 那volatile是否起到了可见性的作用？否，第二次非null判断是在加锁以后，可见性已经由synchronized来保证了。 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。 Referencehttps://time.geekbang.org/column/article/84017 《Java并发编程的艺术》 《深入理解Java虚拟机》","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"https://weilans.github.io/tags/concurrent/"}]},{"title":"[回顾并发基础] Java并发编程基础","slug":"Java并发札记-2-Java并发编程基础","date":"2019-08-24T16:01:46.000Z","updated":"2019-12-27T09:15:20.000Z","comments":true,"path":"2019/08/25/Java并发札记-2-Java并发编程基础/","link":"","permalink":"https://weilans.github.io/2019/08/25/Java并发札记-2-Java并发编程基础/","excerpt":"","text":"并发概念同步（Synchronous） 异步（Asynchronous） 同步和异步通常用来形容一次方法调用。同步方法调用一旦开始，调用者必须等到方法调用返回后，才能继续后续的行为。异步方法调用更像一个消息传递，一旦开始，方法调用就会立即返回，调用者就可以继续后续的操作。而异步方法通常会在另外一个线程中“真实”地执行。整个过程，不会阻碍调用者的工作。如果异步调用需要返回结果，那么当这个异步调用真实完成时，则会通知调用者。 阻塞（Blocking） 非阻塞（NonBlocking） 阻塞和非阻塞通常用来形容多线程间的相互影响。比如一个线程占用了临界区资源，那么其他所有需要这个资源的线程就必须在这个临界区中进行等待。等待会导致线程挂起，这种情况就是阻塞。如果占用资源的线程一直不愿意释放资源，那么其他所有阻塞在这个临界区上的线程都不能工作。非阻塞的意思与之相反，它强调没有一个线程可以妨碍其他线程执行。所有的线程都会尝试不断前向执行。 死锁（Deadlock）、饥饿（Starvation）和活锁（Livelock） 死锁、饥饿和活锁都属于多线程的活跃性问题。 饥饿：指某一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行。比如它的线程优先级可能太低，而高优先级的线程不断抢占它需要的资源。或者某一个线程一直占着关键资源不放，导致其他需要这个资源的线程无法正常执行。 活锁：主动将资源释放给他人使用，那么就会出现资源不断在两个线程中跳动，而没有一个线程可以同时拿到所有资源而正常执行。 死锁：资源竞争而产生的相互等待的情况。主要原因是资源有限以及竞争不当。四个必要条件：互斥、占有且等待、不可抢占、循环等待（存在一个进程链，使得每个进程都占有下一个进程所需的至少一种资源）。避免死锁可以使用银行家算法。 并发（Concurrency）和并行（Parallelism） 严格意义上来说，并行的多个任务是真实的同时执行，而对于并发来说，这个过程只是交替的，一会儿运行任务A一会儿执行任务B，系统会不停地在两者间切换。但对于外部观察者来说，即使多个任务之间是串行并发的，也会造成多任务间是并行执行的错觉。 Java 并发编程基础线程线程是比进程更轻量级的调度执行单位，线程的引入，可以把一个进程的资源分配和执行调度分开，各个线程既可以共享进程资源（内存地址、文件I/O等），又可以独立调度（线程是CPU调度的基本单位）。 线程的状态见于 Thread.State 枚举类： 初始(NEW) - 新创建了一个线程对象，但还没有调用start()方法。 运行(RUNNABLE) - Java线程中将就绪(ready)和运行中(running)两种状态笼统的成为“运行中”。（等待被线程调度选中获取cpu的使用权，处于就绪状态(ready)；就绪的线程在获得cpu 时间片后变为运行中状态(running)）。 阻塞(BLOCKED) - 表示线程阻塞于锁。 等待(WAITING) - 进入该状态的线程需要等待其他线程做出一些特定动作（通知或中断）。 超时等待(TIME_WAITING) - 该状态不同于WAITING，它可以在指定的时间内自行返回。 终止(TERMINATED) - 表示该线程已经执行完毕。 构造线程新构造的线程对象是由其parent线程来进行空间分配的，而child线程继承了parent是否为Daemon、优先级和加载资源的 ContextClassLoader 以及可继承的ThreadLocal，同时还会分配一个唯一的ID来标识这个child线程。至此，一个能够运行的线程对象就初始化好了，在堆内存中等待着运行。 虽然可以使用匿名内部类重载run()方法来新建一个线程。但考虑到Java是单继承的，也就是说继承本身也是一种很宝贵的资源，因此，主要使用Runnable接口来实现同样的操作。 终止线程stop()方法太过于暴力，强行把执行到一半的线程终止，并不会保证线程资源的正常释放，通常没有给予线程完成资源释放工作的机会，可能会引起一些数据不一致的问题，导致程序可能工作在不确定状态下。 suspend(), resume(), stop()都标注为过期方法，暂停以及恢复操作可以使用等待/通知机制代替。suspend()方法在导致线程暂停的同时，并不会去释放任何锁资源，任何线程想要访问锁都会被牵连，导致无法正常继续运行。 中断线程中断可以理解为是线程的一个标志位属性。线程中断并不会使线程立即退出，而是给线程发送一个通知，告知目标线程，有人希望你退出。至于目标线程接到通知后如何处理，则完全由目标线程自行决定。 123456// 中断线程public void Thread.interrupt() // 判断是否被中断public boolean Thread.isInterrupted() // 判断是否被中断，并清除当前中断状态public static boolean Thread.interrupted() 许多声名抛出InterruptedException的方法在抛出InterruptedException之前，Java虚拟机会先将该线程的中断标识位清除，然后抛出InterruptedException，此时调用isInterrupted()方法将会返回false。 123456789101112131415161718192021222324public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread() &#123; @Override public void run() &#123; while (true) &#123; if (Thread.currentThread().isInterrupted()) &#123; System.out.println(\"Interruted!\"); break; &#125; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; System.out.println(\"Interruted When Sleep\"); //设置中断状态 Thread.currentThread().interrupt(); &#125; Thread.yield(); &#125; &#125; &#125;; t1.start(); Thread.sleep(2000); t1.interrupt();&#125; 如果线程被中断程序会抛出异常，进入catch子句，为了后续逻辑处理，执行了Thread.interrupt()方法再次中断自己，置上中断标记位。只有这么做，在中断检查中，才能发现当前线程已经被中断了。 安全地终止线程：中断操作是一种简单的线程间交互方式，此种交互方式最适合用来取消或停止任务。除了中断之外，还可以利用一个boolean变量控制是否需要停止任务并终止该线程。示例代码中可以通过标识位或者中断的方式使线程在终止时有机会去清理资源。 123456789101112131415161718192021222324252627282930313233public class Shutdown &#123; public static void main(String[] args) throws Exception &#123; Runner one = new Runner(); Thread countThread = new Thread(one, \"CountThread\"); countThread.start(); // 睡眠1秒，main线程对CountThread进行中断，使CountThread能够感知中断而结束 TimeUnit.SECONDS.sleep(1); countThread.interrupt(); Runner two = new Runner(); countThread = new Thread(two, \"CountThread\"); countThread.start(); // 睡眠1秒，main线程对Runner two进行取消，使CountThread能够感知on为false而结束 TimeUnit.SECONDS.sleep(1); two.cancel(); &#125; private static class Runner implements Runnable &#123; private long i; private volatile boolean on = true; @Override public void run() &#123; while (on &amp;&amp; !Thread.currentThread().isInterrupted()) &#123; i++; &#125; System.out.println(\"Count i = \" + i); &#125; public void cancel() &#123; on = false; &#125; &#125;&#125; 线程组ThreadGroup不属于Java并发包中的内容，它是java.lang中的内容。主要用于对线程方便进行统一管理，线程组可以进行复制，快速定位到一个线程，统一进行异常设置等。 activeCount()可以获得活动线程的总数，但由于线程是动态的，因此这个值只是一个估计值，无法确定精确，list()方法可以打印这个线程组中所有的线程信息，对调试有一定帮助。 ThreadGroup中有一个uncaughtException()方法。当线程组中某个线程发生Unchecked exception异常时，由执行环境调用此方法进行相关处理，如果有必要，可以重新定义此方法。 123456789101112131415161718192021public static void main(String[] args) &#123; ThreadGroup threadGroup1 = // 匿名类写法 new ThreadGroup(\"group1\") &#123; // 继承ThreadGroup并重新定义以下方法 // 在线程成员抛出unchecked exception 会执行此方法 public void uncaughtException(Thread t, Throwable e) &#123; System.out.println(t.getName() + \": \" + e.getMessage()); &#125; &#125;; // 匿名类写法 Thread thread1 = // 这个线程是threadGroup1的一员 new Thread(threadGroup1, new Runnable() &#123; public void run() &#123; // 抛出unchecked异常 throw new RuntimeException(\"测试异常\"); &#125; &#125;); thread1.start();&#125; 守护线程Daemon线程：是一种支持型线程，主要用作程序后台调度以及支持性工作。当一个Java虚拟机中不存在非Daemon线程的守护，Java虚拟机会退出。可以通过在启动之前设置Thread.setDaemon(true)来设置。 构建Daemon线程时，不能依靠构建finally块中的内容来确保执行关闭或清理资源的逻辑。 12345678910111213141516171819202122public class DaemonDemo &#123; public static class DaemonT extends Thread &#123; @Override public void run() &#123; while (true) &#123; System.out.println(\"I am alive\"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Thread t = new DaemonT(); t.setDaemon(true); t.start(); Thread.sleep(3000); // 在main线程休眠3秒后退出时，整个程序会随之结束 &#125;&#125; 线程优先级123public final static int MIN_PRIORITY = 1;public final static int NORM_PRIORITY = 5;public final static int MAX_PRIORITY = 10; 优先级的范围是1~10，默认优先级是5。 线程的优先级调度和底层操作系统有密切的关系，在各个平台上表现不一，并且这种优先级产生的后果也可能不容易预测，无法精准控制，操作系统可能完全不会理会Java线程对优先级的设定。 synchronized原理同步代码块的实现会使用 monitorenter 和 monitorexit 指令，同步方法则依靠方法修饰符上的 ACC_SYNCHRONIZED 来完成的。无论是何种方式，本质上是对一个对象的监视器 (moitor) 进行获取，任何对象都有一个monitor与之关联，这个过程是排他的，每个对象都拥有自己的监视器，同一时刻只能一个线程获得对象监视器。 monitorenter 指令是在编译后插入到同步代码块的开始位置，monitorexit 是插入到方法结束处和异常处（JVM保证了每个monitorenter 有对应的 monitorexit 与之配对）。当执行 monitorenter 指令时，执行线程必须先获取到该对象的监视器才能进入，没有获取到监视器的线程会阻塞在同步块或同步方法的入口处没进入 BLOCKED 状态。 执行 monitorenter 时获取对象的锁，会把锁的计数器+1（可重入），在执行 monitorexit 时锁计数器会－1，当计数器为0会释放锁。 synchronized 用的锁是存在Java对象头里的，加锁本质就是在锁对象的对象头中写入当前线程id。 案例 当修饰静态方法的时候，锁定的是当前类的 Class 对象； 当修饰非静态方法的时候，锁定的是当前实例对象 this。 case1123456789class SafeCalc &#123; long value = 0L; long get() &#123; return value; &#125; synchronized void addOne() &#123; value += 1; &#125;&#125; 执行 addOne()方法后，value值对于get()方法是没有可见性保证的，需要在 get 方法上也加上 synchronized。 case2123456789class SafeCalc &#123; static long value = 0L; synchronized long get() &#123; return value; &#125; synchronized static void addOne() &#123; value += 1; &#125;&#125; 上面的代码是用两个锁保护一个资源。这个受保护的资源就是静态变量 value，两个锁分别是 this 和 SafeCalc.class。由于临界区 get() 和 addOne() 是用两个锁保护的，因此这两个临界区没有互斥关系，临界区 addOne() 对 value 的修改对临界区 get() 也没有可见性保证，这就导致并发问题了。 case3123456pulbic class Something &#123; public synchronized void isSyncA()&#123;&#125; public synchronized void isSyncB()&#123;&#125; public static synchronized void cSyncA()&#123;&#125; public static synchronized void cSyncB()&#123;&#125;&#125; x.isSyncA()与x.isSyncB() 不能被同时访问。因为isSyncA()和isSyncB()都是访问同一个对象(对象x)的同步锁； x.isSyncA()与y.isSyncA() 可以同时被访问。因为访问的不是同一个对象的同步锁，x.isSyncA()访问的是x的同步锁，而y.isSyncA()访问的是y的同步锁； x.cSyncA()与y.cSyncB() 不能被同时访问。因为cSyncA()和cSyncB()都是static类型，x.cSyncA()相当于Something.isSyncA()，y.cSyncB()相当于Something.isSyncB()，因此它们共用一个同步锁，不能被同时反问； x.isSyncA()与Something.cSyncA()可以被同时访问。因为isSyncA()是实例方法，x.isSyncA()使用的是对象x的锁；而cSyncA()是静态方法，Something.cSyncA()可以理解对使用的是“类的锁”。因此，它们是可以被同时访问的。 死锁转账案例12345678910class Account &#123; private int balance; // 转账 synchronized void transfer(Account target, int amt)&#123; if (this.balance &gt; amt) &#123; this.balance -= amt; target.balance += amt; &#125; &#125; &#125; 上述代码用于多Account转账是不正确的，因为 synchronized 使用的是 this 这把锁可以保护自己的余额 this.balance，但是保护不了别人的余额 target.balance。 所以可以使用 Account.class作为共享的锁。但会将所有Account的操作串行，性能会很差。 123456789101112class Account &#123; private int balance; // 转账 void transfer(Account target, int amt)&#123; synchronized(Account.class) &#123; if (this.balance &gt; amt) &#123; this.balance -= amt; target.balance += amt; &#125; &#125; &#125; &#125; 于是可以采用如下方式，使用两把锁： 12345678910111213141516class Account &#123; private int balance; // 转账 void transfer(Account target, int amt)&#123; // 锁定转出账户 synchronized(this) &#123; // 锁定转入账户 synchronized(target) &#123; if (this.balance &gt; amt) &#123; this.balance -= amt; target.balance += amt; &#125; &#125; &#125; &#125; &#125; 但这样就会造成死锁，A要向B转账，B也要向A转账，同时拿到第一个锁，但无法等到第二个锁。 死锁发生条件 互斥，共享资源 X 和 Y 只能被一个线程占用； 占有且等待，线程 T1 已经取得共享资源 X，在等待共享资源 Y 的时候，不释放共享资源 X； 不可抢占，其他线程不能强行抢占线程 T1 占有的资源； 循环等待，线程 T1 等待线程 T2 占有的资源，线程 T2 等待线程 T1 占有的资源，就是循环等待。 避免死锁只要破坏上述其中一个条件，死锁就不会发生。互斥条件无法破坏，其他三种有方法破坏： 对于“占用且等待”这个条件，我们可以一次性申请所有的资源，这样就不存在等待了。 对于“不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可抢占这个条件就破坏掉了。 对于“循环等待”这个条件，可以靠按序申请资源来预防。所谓按序申请，是指资源是有线性顺序的，申请的时候可以先申请资源序号小的，再申请资源序号大的，这样线性化后自然就不存在循环了。 关于1，可以添加一个账本管理员，必须通过账本管理员拿到所有资源才会提供给相关方，通过这种方案保证一次申请所有资源。 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Allocator &#123; private List&lt;Object&gt; als = new ArrayList&lt;&gt;(); // 一次性申请所有资源 synchronized boolean apply(Object from, Object to)&#123; if (als.contains(from) || als.contains(to))&#123; return false; &#125; else &#123; als.add(from); als.add(to); &#125; return true; &#125; // 归还资源 synchronized void free(Object from, Object to)&#123; als.remove(from); als.remove(to); &#125;&#125;class Account &#123; // actr 应该为单例 private Allocator actr; private int balance; // 转账 void transfer(Account target, int amt)&#123; // 一次性申请转出账户和转入账户，直到成功 while(!actr.apply(this, target)) ； try&#123; // 锁定转出账户 synchronized(this)&#123; // 锁定转入账户 synchronized(target)&#123; if (this.balance &gt; amt)&#123; this.balance -= amt; target.balance += amt; &#125; &#125; &#125; &#125; finally &#123; actr.free(this, target) &#125; &#125; &#125; 关于2，可以使用Lock。 关于3，可以对每个账号ID进行排序，按照从小到大的顺序锁账号，这样便不会出现循环等待的情况了。破坏循环等待条件的成本在这种场景下是最低的。 1234567891011121314151617181920212223class Account &#123; private int id; private int balance; // 转账 void transfer(Account target, int amt)&#123; Account left = this; Account right = target; if (this.id &gt; target.id) &#123; left = target; right = this; &#125; // 锁定序号小的账户 synchronized(left)&#123; // 锁定序号大的账户 synchronized(right)&#123; if (this.balance &gt; amt)&#123; this.balance -= amt; target.balance += amt; &#125; &#125; &#125; &#125; &#125; 如果Account对象中只有转账业务的话，while(actr.apply(this, target) 和 synchronized(Account.class)的性能优势几乎看不出来，synchronized(Account.class)方案由于 synchronized 三次，性能可能更差；但是如果Account对象中如果还有其它业务，比如查看余额等功能也加了synchronized(Account.class)修饰，那还是while的方式效率更高。此外，如果转账操作非常慢，也是while更有优势。 等待 / 通知 机制线程A调用对象O的wait方法进入等待状态，线程B调用对象O的notify或notifyAll方法后，线程A收到通知后从对象O的wait方法返回，进而执行后续操作。 典型范式等待方（加锁，循环，处理逻辑）1）获取对象的锁。2）如果条件不满足，那么调用对象的wait()方法，被通知后仍要检查条件。3）条件满足则执行对应的逻辑。 123456 synchronized(对象) &#123; while(条件不满足时) &#123; 对象.wait() &#125; 对应的逻辑&#125; 之所以使用while loop，因为可能有其他线程执行对象的notify()或notify()方法，但是条件不满足。即“条件曾经满足过”。当 wait() 返回时，有可能条件已经发生变化了，曾经条件满足，但是现在已经不满足了，所以要重新检验条件是否满足。范式，意味着是经典做法，所以没有特殊理由不要尝试换个写法。 通知方1）获得对象的锁。2）改变条件。3）通知所有等待在对象上的线程。 1234synchronized(对象) &#123; 改变条件 对象.notifyAll()&#125; 如何工作 调用wait()方法后，线程状态由RUNNING变为WAITING，并将当前线程放置到对象的等待队列。 notify()方法将等待队列中的一个等待线程从等待队列中移到同步队列中，而notifyAll()方法则是将等待队列中所有的线程全部移到同步队列，被移动的线程状态由WAITING变为BLOCKED。 注意点： 使用wait()、notify()和notifyAll()时需要先对调用对象加锁。 notify()或notifyAll()方法调用后，等待线程依旧不会从wait()返回，要调用notify()或notifAll()的线程释放锁之后，等待线程才有机会从wait()返回。 wait()、notify()、notifyAll() 方法操作的等待队列是互斥锁的等待队列，所以如果 synchronized 锁定的是 this，那么对应的一定是 this.wait()、this.notify()、this.notifyAll()；如果 synchronized 锁定的是 其他target，那么对应的一定是 target.wait()、target.notify()、target.notifyAll() 。而且 wait()、notify()、notifyAll() 这三个方法能够被调用的前提是已经获取了相应的互斥锁，所以我们会发现 wait()、notify()、notifyAll() 都是在 synchronized{}内部被调用的。如果在 synchronized{}外部调用，或者锁定的 this，而用 target.wait() 调用的话，JVM 会抛出一个运行时异常：java.lang.IllegalMonitorStateException。 典型描述： WaitThread首先获取了对象的锁，然后调用对象的wait()方法，从而放弃了锁并进入了对象的等待队列WaitQueue中，进入等待状态。由于WaitThread释放了对象的锁，NotifyThread随后获取了对象的锁，并调用对象的notify()方法，将WaitThread从WaitQueue移到SynchronizedQueue中，此时WaitThread的状态变为阻塞状态。NotifyThread释放了锁之后，WaitThread再次获取到锁并从wait()方法返回继续执行。 案例改写将前文中提到的转账例子可以改写为： 123456789101112131415161718192021class Allocator &#123; private List&lt;Object&gt; als; // 一次性申请所有资源 synchronized void apply(Object from, Object to)&#123; // 经典写法 while(als.contains(from) || als.contains(to))&#123; try&#123; wait(); &#125;catch(Exception e)&#123; &#125; &#125; als.add(from); als.add(to); &#125; // 归还资源 synchronized void free(Object from, Object to)&#123; als.remove(from); als.remove(to); notifyAll(); &#125;&#125; 同时需尽量使用notifyAll()方法，notify()会随机通知一个等待队列中的一个线程，notifyAll()会通知等待队列中的所有线程。 依然基于上面的例子，假设线程 1 申请到了 AB，线程 2 申请到了 CD，此时线程 3 申请 AB，会进入等待队列，线程 4 申请 CD 也会进入等待队列。假设之后线程 1 归还了资源 AB，如果使用 notify() 来通知等待队列中的线程，有可能被通知的是线程 4，但线程 4 申请的是 CD，所以此时线程 4 还是会继续等待，而真正该唤醒的线程 3 就再也没有机会被唤醒了。 join一个线程A执行了thread.join()时代表当前线程A等待线程终止后才从thread.join()返回。 12public final void join() throws InterruptedExceptionpublic final synchronized void join(long millis) throws InterruptedException 第一个join()方法表示无限等待，它会一直阻塞当前线程，直到目标线程执行完毕。第二个方法给出了一个最大等待时间，如果超过给定时间目标线程还在执行，当前线程也会因为“等不及了”，而继续往下执行。 其方法内部使用等待/通知机制，不停检查join线程是否存活，如果join线程存活则让当前线程永远等待。当join线程终止时，会调用线程自身的notifyAll()方法，通知所有等待在该线程上的线程。 1234567public final synchronized void join(long millis) throws InterruptedException &#123; // 条件不满足，继续等待 while (isAlive()) &#123; wait(0); &#125; // 条件满足，方法返回&#125; 上述代码和等待 / 通知经典范式一致，即加锁、循环、处理逻辑三个步骤。 值得注意的一点是：不要在应用程序中，在Thread对象实例上使用类似wait()或者notify()等方法，因为这很有可能会影响系统API的工作，或者被系统API所影响。 yield1public static native void yield(); Thread.yield() 是一个静态方法，一旦执行，它会使当前线程让出CPU。但要注意，让出 CPU 并不表示当前线程不执行了。当前线程在让出CPU后，还会进行CPU资源的争夺，但是是否能够再次被分配到，就不一定了。因此，对Thread.yield()的调用就好像是在说：我已经完成一些最重要的工作了，我应该是可以休息一下了，可以给其他线程一些工作机会。 如果一个线程不那么重要，或者优先级非常低，而且又害怕它会占用太多的CPU资源，那么可以在适当的时候调用Thread.yield()，给予其他重要线程更多的工作机会。 Case下面代码会得到小20000000很多的数值，原因是Integer属于不变对象。也就是对象一旦被创建，就不可能被修改。 i++ 在真实执行时变成了 i=Integer.valueOf(i.intValue()+1); i++ 的本质是，创建一个新的Integer对象，并将它的引用赋值给i。锁加到不同的对象实例上了。 123456789101112131415161718192021public class BadLockOnInteger implements Runnable &#123; public static Integer i = 0; static BadLockOnInteger instance = new BadLockOnInteger(); @Override public void run() &#123; for (int j = 0; j &lt; 10000000; j++) &#123; synchronized (i) &#123; i++; &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(instance); Thread t2 = new Thread(instance); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(i); &#125;&#125; Reference《实战Java高并发程序设计》 《Java并发编程的艺术》 https://time.geekbang.org/column/article/84601","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"https://weilans.github.io/tags/concurrent/"}]},{"title":"[回顾并发基础] 并发问题的根源","slug":"Java并发札记-0-并发问题的根源","date":"2019-08-24T08:46:48.000Z","updated":"2019-12-19T11:54:08.000Z","comments":true,"path":"2019/08/24/Java并发札记-0-并发问题的根源/","link":"","permalink":"https://weilans.github.io/2019/08/24/Java并发札记-0-并发问题的根源/","excerpt":"","text":"正式开启并发的回顾整理，札记主要记录知识点、典型Case、自己的想法、思维导图以及好的文章，侧重于知识的理解与整理，毕竟要在并发上有自己独到的理解还是欠火候的。以后回顾或学习到新内容，会不断对文章进行更新，以作长期知识储备。 并发编程问题的根源1. CPU缓存导致“可见性”问题单核时代，所有线程操作同一个CPU的缓存，CPU缓存和内存间不会存在数据不一致问题。 一个线程对共享变量的修改，另一个线程能立刻看到，即为“可见性”。 多核时代，每个CPU都有自己的缓存，这就容易造成数据一致性问题。例如对应特定变量V，线程A操作CPU1上V的缓存，线程B操作CPU2上V的缓存，前者对V的操作于后者而言不具备可见性。这就是缓存一致性问题。 缓存一致性(Cache Coherence)计算机的CPU与内存间有一层高速缓存作为缓冲，用于解决处理器与内存之间的速度矛盾。在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存。如果某一处理器将数据写会内存，其他处理器上的值是旧的，执行计算操作会有问题。为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期。 样例：多线程并发执行count += 1，结果往往可能和想象结果不一样。两个相同的线程同时执行，第一次都会将 count = 0 读入自己的CPU缓存，执行完之后各自的CPU缓存中的值都是1，同时写入内存后，内存中的值为1。 2. 线程切换带来的“原子性”问题现代操作系统的CPU调度都是使用时间片算法，经过特定时间片之后便会进行任务切换。曾经的操作系统基于进程调度CPU，不同进程不共享内存空间，进程切换要切换内存映射地址。而进程内的所有线程共享同一个内存区间，使用线程进行任务切换成本较低，所以现代操作系统更多基于轻量的线程进行调度，常说的CPU任务切换特指线程切换。 高级语言中的一条语句往往需要多个CPU指令完成。如 count += 1，需要三条指令： 将 count 值从内存中加载到CPU的寄存器中； 在CPU寄存器中执行 +1 操作； 将结果写会内存（也可能写回 CPU 高速缓存）。 而操作系统的任务切换是可以发生在任何一条CPU指令执行完，而非高级语言的一条语句。如果两个线程执行 count 操作，线程A执行指令1后，CPU切换到线程B，线程执行完 +1 操作后，将1写回内存，后又切换至线程A，线程A执行 +1 命令的结果是1，后又将count=1的结果写入内存。 一个或者多个操作在 CPU 执行的过程中不被中断的特性称为“原子性”。CPU 能保证的原子操作是 CPU 指令级别的，而不是高级语言的操作符。 3. 编译优化带来的“有序性”问题编译器有时为了优化性能，有时会更改代码中的先后执行顺序。 示例：双重检查锁（无volatile） 123456789101112public class Singleton &#123; static Singleton instance; static Singleton getInstance()&#123; if (instance == null) &#123; synchronized(Singleton.class) &#123; if (instance == null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 执行new操作实际上执行的是： 分配一块内存M； 在内存M上初始化对象； 将 M 的地址赋值给示例对象。 但优化后的执行路径可能将2与3互换，当一个线程执行到内存地址赋值，切换到另一个线程，它会在第一个为空判断时直接返回 instance 对象，但 instance 对象没有初始化过，这时使用 instance 可能发生空指针异常。 CaseQ: 32位机器对 long 类型变量进行加减操作存在并发隐患的原因。 A: 因为64位的 long 类型在32位的机器上的操作必然是由多条CPU指令组合而成，是无法保证原子性的。 Referencehttps://time.geekbang.org/column/article/83682","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"https://weilans.github.io/tags/concurrent/"}]},{"title":"Spring Data Redis 实践 (v2.1.7)","slug":"Spring-Data-Redis-实践-v2-1-7","date":"2019-08-15T12:59:09.000Z","updated":"2019-08-15T15:38:23.000Z","comments":true,"path":"2019/08/15/Spring-Data-Redis-实践-v2-1-7/","link":"","permalink":"https://weilans.github.io/2019/08/15/Spring-Data-Redis-实践-v2-1-7/","excerpt":"","text":"最近重写一个项目，在 SpringBoot 用的是最新的 GA 版本 2.1.7，缓存层使用了 Spring Data Redis。其实使用它是因为上一个项目也是用的这个框架，了解的程度还行，但不算细致。此外，因为以前直接使用 Redisson 的时候出现了内存泄漏（实际上也不是人家的锅，算是依赖的 Netty 版本的 bug），对 Redisson 总会心有余悸。但我真的得承认，Redisson 非常好用，如果项目中需要使用一些分布式的 API，比如分布式锁、优先级阻塞队列等，Redisson 是不二之选。其实与Redisson 做横向对比的应该是 Jedis，Spring Data Redis 是在 Jedis 上架了一层（boot 1.x）。但是这个项目对 Redis 的API 操作比较简单，所以就当仔细学习一下 Spring Data Redis了。 POM因为 Boot 版本升了 2.X，Spring Data Redis 的默认框架从 Jedis 换成了 Lettuce，后者主要突出基于 Netty 的事件驱动，容易发挥异步优势。但是由于真不了解以及学习成本的考量，还是使用了 Jedis。 POM文件中需移除 lettuce 的依赖，引入 Jedis。具体版本在 2.1.7.RELEASE 的 spring-boot-dependencies 文件中（lettuce 版本 5.1.8.RELEASE，jedis 版本 2.9.3）。 1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;io.lettuce&lt;/groupId&gt; &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt;&lt;/dependency&gt; ConfigRedisConnectionFactory12345678910111213141516@Beanpublic RedisConnectionFactory redisConnectionFactory() &#123; redisConf = ...; RedisStandaloneConfiguration standaloneConf = new RedisStandaloneConfiguration( redisConf.getHost(), redisConf.getPort()); if (!Strings.isNullOrEmpty(redisConf.getPassword())) &#123; standaloneConf.setPassword(redisConf.getPassword()); &#125; JedisConnectionFactory jedisConnectionFactory = new JedisConnectionFactory(standaloneConf); GenericObjectPoolConfig poolConfig = jedisConnectionFactory.getPoolConfig(); poolConfig.setMaxTotal(30); poolConfig.setMinIdle(0); poolConfig.setMaxIdle(10); poolConfig.setMaxWaitMillis(3000); return jedisConnectionFactory;&#125; 2.x 的配置也和之前有所区别，JedisConnectionFactory的setXxx方法大多已是 Deprecated，如：setHostName、setPort、setPassword等。文档的提示内容是： since 2.0, configure the password using {@link RedisStandaloneConfiguration}, {@link RedisSentinelConfiguration} or {@link RedisClusterConfiguration}. 所以，在 JedisConnectionFactory 构造参数中设置RedisStandaloneConfiguration。而 pool 信息可以从 factory 中获取，从而进行设置。从 JedisConnectionFactory 构造函数中，我们发现它构造了MutableJedisClientConfiguration对象。该对象的 poolConfig 在 变量声名中就 new 出了JedisPoolConfig，我们可以对这个对象进行连接池设置。 123public JedisConnectionFactory(RedisStandaloneConfiguration standaloneConfig) &#123; this(standaloneConfig, new MutableJedisClientConfiguration());&#125; 当然设置 pool 信息不单只有这一种，MutableJedisClientConfiguration是JedisClientConfiguration接口的实现类，该接口下面还有接口JedisPoolingClientConfigurationBuilder，也可以使用它的实现类DefaultJedisClientConfigurationBuilder，JedisClientConfiguration.builder()返回的就是这个类实例。 感觉到了 2.x，手动建 Factory 配置有点麻烦啊… RedisTemplateRedisTemplate 的 配置比较简单，注入 RedisConnectionFactory Bean 对象即可，但是要注意的序列化方案。 12345678@Beanpublic RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) &#123; RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(factory); setSerializer(redisTemplate); redisTemplate.afterPropertiesSet(); return redisTemplate;&#125; 序列化12345678private void setSerializer(RedisTemplate&lt;String, Object&gt; template) &#123; GenericJackson2JsonRedisSerializer genericJackson2JsonRedisSerializer = new GenericJackson2JsonRedisSerializer(); template.setKeySerializer(new StringRedisSerializer()); template.setValueSerializer(genericJackson2JsonRedisSerializer); template.setHashKeySerializer(new StringRedisSerializer()); template.setHashValueSerializer(genericJackson2JsonRedisSerializer);&#125; 在 redisTemplate.afterPropertiesSet()方法中，显示默认的序列化方式是JdkSerializationRedisSerializer。使用的是 JDK 序列化方式，数据以字节流的形式存储。这种方式会造成可读性很差。 12345678910111213141516171819202122232425if (defaultSerializer == null) &#123; defaultSerializer = new JdkSerializationRedisSerializer( classLoader != null ? classLoader : this.getClass().getClassLoader());&#125;if (enableDefaultSerializer) &#123; if (keySerializer == null) &#123; keySerializer = defaultSerializer; defaultUsed = true; &#125; if (valueSerializer == null) &#123; valueSerializer = defaultSerializer; defaultUsed = true; &#125; if (hashKeySerializer == null) &#123; hashKeySerializer = defaultSerializer; defaultUsed = true; &#125; if (hashValueSerializer == null) &#123; hashValueSerializer = defaultSerializer; defaultUsed = true; &#125;&#125; 如果项目中 key value 都只要使用字符串即可的话，StringRedisSerializer也是一种选项。这里我使用的是 Jackson 方式进行序列化操作。我事先使用的是Jackson2JsonRedisSerializer方式，该方式会将对象完全展为 JSON，但是在反序列的过程中报错：LinkedHashMap cannot be cast to ...，所以改成了GenericJackson2JsonRedisSerializer，该方案会在 JSON 中添加 @class类信息 field，这样在处理集合类泛型信息时，都能够正确处理。 使用 GenericJackson2JsonRedisSerializer 的时候，一开始是使用了自己定义的 ObjectMapper，结果发现无用，后来选择了无参构造器的实现才不出错。究其原因不难发现，该构造器中会对 objectMapper 设置 enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL)，正是该字段使 Jackson 生成了类信息字段，这才是允许反序列化的基础。而类的前面出现 @class 是因为 NullValueSerializer 里 设置了classIdentifier 为 @class（即 JsonTypeInfo.Id#CLASS）。 如果使用 Jackson2JsonRedisSerializer 时里面的 objectMapper 配置了 DefaultTyping.NON_FINAL，简单试验了一下发现序列化/反序列化操作会成功（没配 @class 前缀也是可以的）。 12345678910111213141516public GenericJackson2JsonRedisSerializer() &#123; this((String) null);&#125;public GenericJackson2JsonRedisSerializer(@Nullable String classPropertyTypeName) &#123; this(new ObjectMapper()); mapper.registerModule(new SimpleModule().addSerializer(new NullValueSerializer(classPropertyTypeName))); if (StringUtils.hasText(classPropertyTypeName)) &#123; mapper.enableDefaultTypingAsProperty(DefaultTyping.NON_FINAL, classPropertyTypeName); &#125; else &#123; mapper.enableDefaultTyping(DefaultTyping.NON_FINAL, As.PROPERTY); &#125;&#125; 感觉一个完整 JSON 工具包的实现还是很难的，有机会可以详细过一遍 Jackson… 官方 Reference","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://weilans.github.io/tags/redis/"},{"name":"cache","slug":"cache","permalink":"https://weilans.github.io/tags/cache/"},{"name":"spring","slug":"spring","permalink":"https://weilans.github.io/tags/spring/"}]},{"title":"[Leetcode单排] 二叉树的序列化与反序列化 (N297)","slug":"Leetcode单排-二叉树的序列化与反序列化-N297","date":"2019-08-12T14:41:41.000Z","updated":"2019-08-12T16:30:01.000Z","comments":true,"path":"2019/08/12/Leetcode单排-二叉树的序列化与反序列化-N297/","link":"","permalink":"https://weilans.github.io/2019/08/12/Leetcode单排-二叉树的序列化与反序列化-N297/","excerpt":"","text":"297. Serialize and Deserialize Binary Treehttps://leetcode.com/problems/serialize-and-deserialize-binary-tree/ 先序遍历每个节点用逗号分隔，空节点使用#表示。序列化二叉树肯定会想到先序、中序、后序、层次遍历四种，中序和后序从下往上推不好实现，剩下的考虑先序和层次。而先序遍历之所以可以应用，是因为每个分支都有明确的结束标记。序列化的时候，先确定自己，再确定左右。反序列化的过程，先获取头部，再判断左子节点，左子节点有结束边界，之后右子节点也按照边界结束。 123456789101112131415161718192021222324252627282930313233public String serialize(TreeNode root) &#123; if (root == null) &#123; return \"#,\"; &#125; String curStr = root.val + \",\"; String leftStr = serialize(root.left); String rightStr = serialize(root.right); return curStr + leftStr + rightStr;&#125;public TreeNode deserialize(String data) &#123; if (data == null) &#123; return null; &#125; String[] strArr = data.split(\",\"); Queue&lt;String&gt; queue = new LinkedList&lt;&gt;(); for (String str : strArr) &#123; queue.offer(str); &#125; return deserialize(queue);&#125;private TreeNode deserialize(Queue&lt;String&gt; queue) &#123; String str = queue.poll(); if (str.equals(\"#\")) &#123; return null; &#125; TreeNode node = new TreeNode(Integer.parseInt(str)); node.left = deserialize(queue); node.right = deserialize(queue); return node;&#125; 层次遍历层次遍历写起来稍微有点复杂，但是更好理解。序列化的时候，先把顶部节点放至 queue 中，依据左右节点值放至 StringBuilder 中，再按照是否为空，将不为空的放入队列中进行下一层的遍历。反序列化同样是新建一个队列放入头结点，将左右节点非空的放入队列中，进行下一层的从左到右的解析。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public String serialize(TreeNode root) &#123; if (root == null) &#123; return null; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); // 注意 root.val 别放到构造函数里，因为: new StringBuilder(int capacity) StringBuilder sb = new StringBuilder().append(root.val).append(\",\"); queue.offer(root); while (!queue.isEmpty()) &#123; TreeNode node = queue.poll(); TreeNode left = node.left; TreeNode right = node.right; if (left != null) &#123; sb.append(left.val).append(\",\"); queue.offer(left); &#125; else &#123; sb.append(\"#,\"); &#125; if (right != null) &#123; sb.append(right.val).append(\",\"); queue.offer(right); &#125; else &#123; sb.append(\"#,\"); &#125; &#125; return sb.toString(); &#125; public TreeNode deserialize(String data) &#123; if (data == null || data == \"\") &#123; return null; &#125; String[] strArr = data.split(\",\"); int index = 0; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); TreeNode root = buildNode(strArr[0]); queue.offer(root); while (!queue.isEmpty()) &#123; TreeNode node = queue.poll(); TreeNode left = buildNode(strArr[++index]); TreeNode right = buildNode(strArr[++index]); node.left = left; node.right = right; if (left != null) &#123; queue.offer(left); &#125; if (right != null) &#123; queue.offer(right); &#125; &#125; return root; &#125; private TreeNode buildNode(String str) &#123; if (\"#\".equals(str)) &#123; return null; &#125; return new TreeNode(Integer.parseInt(str)); &#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"tree","slug":"tree","permalink":"https://weilans.github.io/tags/tree/"}]},{"title":"[Leetcode单排] 树类题目集合1 (N102 N107 N429 N872 N112 N113)","slug":"Leetcode单排- 树类题目集合1-N102-N107-N429-N872-N112-N113","date":"2019-08-10T02:10:54.000Z","updated":"2019-08-18T09:50:51.000Z","comments":true,"path":"2019/08/10/Leetcode单排- 树类题目集合1-N102-N107-N429-N872-N112-N113/","link":"","permalink":"https://weilans.github.io/2019/08/10/Leetcode单排- 树类题目集合1-N102-N107-N429-N872-N112-N113/","excerpt":"","text":"102. Binary Tree Level Order Traversalhttps://leetcode.com/problems/binary-tree-level-order-traversal/ 层次遍历，但是题目需要把每一层的放到一个 List 里面，这里用的是计数（需要注意先把左右节点放到队列中再进行数量判断）。当然也可以使用在 while 最开始获取 队列中的 size 作为这一层的大小，之后里面加一层 for 循环，详见此。 12345678910111213141516171819202122232425262728293031public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); if (root == null) &#123; return result; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); int count = 1, temp = 0, next = 0; List&lt;Integer&gt; layer = new ArrayList&lt;&gt;(); while (!queue.isEmpty()) &#123; TreeNode node = queue.poll(); int val = node.val; layer.add(val); if (node.left != null) &#123; queue.offer(node.left); next++; &#125; if (node.right != null) &#123; queue.offer(node.right); next++; &#125; if (++temp == count) &#123; result.add(new ArrayList&lt;&gt;(layer)); layer.clear(); count = next; next = 0; temp = 0; &#125; &#125; return result; &#125; 107. Binary Tree Level Order Traversal IIhttps://leetcode.com/problems/binary-tree-level-order-traversal-ii/ 这道题就很没意思了，每次只要加在 List 的最前面就可以了。 12345678910111213141516171819202122232425262728293031public List&lt;List&lt;Integer&gt;&gt; levelOrderBottom(TreeNode root) &#123; List&lt;List&lt;Integer&gt;&gt; result = new LinkedList&lt;&gt;(); if (root == null) &#123; return result; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); int count = 1, temp = 0, next = 0; List&lt;Integer&gt; layer = new ArrayList&lt;&gt;(); while (!queue.isEmpty()) &#123; TreeNode node = queue.poll(); int val = node.val; layer.add(val); if (node.left != null) &#123; queue.offer(node.left); next++; &#125; if (node.right != null) &#123; queue.offer(node.right); next++; &#125; if (++temp == count) &#123; result.add(0, new ArrayList&lt;&gt;(layer)); layer.clear(); count = next; next = 0; temp = 0; &#125; &#125; return result; &#125; 429. N-ary Tree Level Order Traversalhttps://leetcode.com/problems/n-ary-tree-level-order-traversal/ 依然是层次遍历，只不过二叉树换成 N 叉树。 1234567891011121314151617181920212223242526272829public List&lt;List&lt;Integer&gt;&gt; levelOrder(Node root) &#123; List&lt;List&lt;Integer&gt;&gt; result = new LinkedList&lt;&gt;(); if (root == null) &#123; return result; &#125; Queue&lt;Node&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); int count = 1, temp = 0, next = 0; List&lt;Integer&gt; layer = new ArrayList&lt;&gt;(); while (!queue.isEmpty()) &#123; Node node = queue.poll(); int val = node.val; layer.add(val); if (node.children != null &amp;&amp; node.children.size() !=0) &#123; for (Node n : node.children) &#123; queue.offer(n); next++; &#125; &#125; if (++temp == count) &#123; result.add(new ArrayList&lt;&gt;(layer)); layer.clear(); count = next; next = 0; temp = 0; &#125; &#125; return result;&#125; 872. Leaf-Similar Treeshttps://leetcode.com/problems/leaf-similar-trees/ 判断两颗二叉树的叶子节点（从左到右）是否相等。这里用的比较常规做法，使用中序遍历，把打印换成判断是否为叶子节点。 12345678910111213141516171819202122232425262728public boolean leafSimilar(TreeNode root1, TreeNode root2) &#123; if (root1 == null &amp;&amp; root2 == null) &#123; return true; &#125; if (root1 == null || root2 == null) &#123; return false; &#125; List&lt;Integer&gt; leaves1 = getLeaves(root1); List&lt;Integer&gt; leaves2 = getLeaves(root2); return leaves1.equals(leaves2); &#125; private List&lt;Integer&gt; getLeaves(TreeNode node) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); inorder(node, list); return list; &#125; private void inorder(TreeNode node, List&lt;Integer&gt; list) &#123; if (node == null) &#123; return; &#125; inorder(node.left, list); if (node.left == null &amp;&amp; node.right == null) &#123; list.add(node.val); &#125; inorder(node.right, list); &#125; 112. Path Sumhttps://leetcode.com/problems/path-sum/ 这里的递归没有去判断是否为 null ，因为为 null 的情形本身就被排除了。（另外，此类是否存在一个满足条件的问题，当有情况成功时，需要立刻返回。总是遗漏掉 if 为 true，立刻返回的情形。） 1234567891011121314151617181920212223public boolean hasPathSum(TreeNode root, int sum) &#123; if (root == null) &#123; return false; &#125; return dfs(root, 0, sum); &#125; private boolean dfs(TreeNode node, int curSum, int target) &#123; if (node.left == null &amp;&amp; node.right == null) &#123; return target == curSum + node.val; &#125; if (node.left != null) &#123; if (dfs(node.left, curSum + node.val, target)) &#123; return true; &#125; &#125; if (node.right != null) &#123; if (dfs(node.right, curSum + node.val, target)) &#123; return true; &#125; &#125; return false; &#125; 别人写的更精炼 1234567public boolean hasPathSum(TreeNode root, int sum) &#123; if(root == null) return false; if(root.left == null &amp;&amp; root.right == null &amp;&amp; sum - root.val == 0) return true; return hasPathSum(root.left, sum - root.val) || hasPathSum(root.right, sum - root.val);&#125; 113. Path SumIIhttps://leetcode.com/problems/path-sum-ii/ 第一次写成的版本比较糙。当前节点不满足进行下一轮左右节点递归时，都加上了add和remove方法，这是传统 回溯 做多了的惯性，但实际上这两种情形加上删除的值是相同的，所以可以进行精简。 123456789101112131415161718192021222324252627public List&lt;List&lt;Integer&gt;&gt; pathSum(TreeNode root, int sum) &#123; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); if (root == null) &#123; return result; &#125; dfs(root, sum, new ArrayList&lt;&gt;(), result); return result;&#125;private void dfs(TreeNode node, int curSum, List&lt;Integer&gt; curList, List&lt;List&lt;Integer&gt;&gt; result) &#123; if (node == null) &#123; return; &#125; if (curSum - node.val == 0 &amp;&amp; node.left == null &amp;&amp; node.right == null) &#123; curList.add(node.val); result.add(new ArrayList&lt;&gt;(curList)); curList.remove(curList.size() - 1); return; &#125; curList.add(node.val); dfs(node.left, curSum - node.val, curList, result); curList.remove(curList.size() - 1); curList.add(node.val); dfs(node.right, curSum - node.val, curList, result); curList.remove(curList.size() - 1);&#125; clean version: 123456789101112131415161718192021222324public List&lt;List&lt;Integer&gt;&gt; pathSum(TreeNode root, int sum) &#123; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); if (root == null) &#123; return result; &#125; dfs(root, sum, new ArrayList&lt;&gt;(), result); return result;&#125;private void dfs(TreeNode node, int curSum, List&lt;Integer&gt; curList, List&lt;List&lt;Integer&gt;&gt; result) &#123; if (node == null) &#123; return; &#125; curList.add(node.val); if (curSum - node.val == 0 &amp;&amp; node.left == null &amp;&amp; node.right == null) &#123; result.add(new ArrayList&lt;&gt;(curList)); curList.remove(curList.size() - 1); return; &#125; dfs(node.left, curSum - node.val, curList, result); dfs(node.right, curSum - node.val, curList, result); curList.remove(curList.size() - 1);&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"tree","slug":"tree","permalink":"https://weilans.github.io/tags/tree/"}]},{"title":"[Leetcode单排] 树相关Easy题 (N100 N101 N104 N110 N111 N572 N965)","slug":"Leetcode单排-树相关Easy题-N100-N101-N104-N110-N111-N572-N965","date":"2019-08-09T11:02:14.000Z","updated":"2019-08-18T09:51:32.000Z","comments":true,"path":"2019/08/09/Leetcode单排-树相关Easy题-N100-N101-N104-N110-N111-N572-N965/","link":"","permalink":"https://weilans.github.io/2019/08/09/Leetcode单排-树相关Easy题-N100-N101-N104-N110-N111-N572-N965/","excerpt":"","text":"100. Same Treehttps://leetcode.com/problems/same-tree/ 123456789101112public boolean isSameTree(TreeNode p, TreeNode q) &#123; if (p == null &amp;&amp; q == null) &#123; return true; &#125; if (p == null || q == null) &#123; return false; &#125; if (p.val != q.val) &#123; return false; &#125; return isSameTree(p.left, q.left) &amp;&amp; isSameTree(p.right, q.right);&#125; 101. Symmetric Treehttps://leetcode.com/problems/symmetric-tree/ 12345678910111213141516171819public boolean isSymmetric(TreeNode root) &#123; if (root == null) &#123; return true; &#125; return check(root.left, root.right); &#125; private boolean check(TreeNode p, TreeNode q) &#123; if (p == null &amp;&amp; q == null) &#123; return true; &#125; if (p == null || q == null) &#123; return false; &#125; if (p.val != q.val) &#123; return false; &#125; return check(p.left, q.right) &amp;&amp; check(p.right, q.left); &#125; 104. Maximum Depth of Binary Treehttps://leetcode.com/problems/maximum-depth-of-binary-tree/ 12345678public int maxDepth(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; int leftDepth = maxDepth(root.left); int rightDepth = maxDepth(root.right); return Math.max(leftDepth, rightDepth) + 1;&#125; 110. Balanced Binary Treehttps://leetcode.com/problems/balanced-binary-tree/ （第一回做的时候，犯了个小错误，求出leftDepth及rightDepth为 null 时，需要立即退出返回 null。） 123456789101112131415161718192021222324public boolean isBalanced(TreeNode root) &#123; if (root == null) &#123; return true; &#125; return depth(root) != null;&#125;private Integer depth(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; Integer leftDepth = depth(root.left); if (leftDepth == null) &#123; return null; &#125; Integer rightDepth = depth(root.right); if (rightDepth == null) &#123; return null; &#125; if (Math.abs(leftDepth - rightDepth) &gt; 1) &#123; return null; &#125; return Math.max(leftDepth, rightDepth) + 1;&#125; 111. Minimum Depth of Binary Treehttps://leetcode.com/problems/minimum-depth-of-binary-tree/ 与求最大高度相比，求最小高度特别之处在于：如果左右有一个高度为 0，则另一个的高度即为返回值。 1234567891011121314public int minDepth(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; int leftDepth = minDepth(root.left); int rightDepth = minDepth(root.right); if (leftDepth == 0) &#123; return rightDepth + 1; &#125; if (rightDepth == 0) &#123; return leftDepth + 1; &#125; return Math.min(leftDepth, rightDepth) + 1; &#125; 572. Subtree of Another Treehttps://leetcode.com/problems/subtree-of-another-tree/ 我这里是想先层次遍历找到值相同的点后，再检验两个树是否相等。当然也可以使用isSubtree(s.left, t) || isSubtree(s.right, t)的形式递归判断。 123456789101112131415161718192021222324252627282930public boolean isSubtree(TreeNode s, TreeNode t) &#123; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(s); while (!queue.isEmpty()) &#123; TreeNode node = queue.poll(); if (node != null &amp;&amp; t != null &amp;&amp; node.val == t.val &amp;&amp; check(node, t)) &#123; return true; &#125; if (node != null &amp;&amp; node.left != null) &#123; queue.offer(node.left); &#125; if (node != null &amp;&amp; node.right != null) &#123; queue.offer(node.right); &#125; &#125; return false;&#125;private boolean check(TreeNode n1, TreeNode n2) &#123; if (n1 == null &amp;&amp; n2 == null) &#123; return true; &#125; if (n1 == null || n2 == null) &#123; return false; &#125; if (n1.val != n2.val) &#123; return false; &#125; return check(n1.left, n2.left) &amp;&amp; check(n1.right, n2.right);&#125; 递归的做法如下（可以看作是先序递归遍历）： 12345public boolean isSubtree(TreeNode s, TreeNode t) &#123; if (s == null) return false; if (check(s, t)) return true; return isSubtree(s.left, t) || isSubtree(s.right, t); &#125; 965. Univalued Binary Treehttps://leetcode.com/problems/univalued-binary-tree/ 12345678910111213141516171819202122public boolean isUnivalTree(TreeNode root) &#123; if (root == null) &#123; return true; &#125; int temp = root.val; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); while (!queue.isEmpty()) &#123; TreeNode node = queue.poll(); if (node.val != temp) &#123; return false; &#125; if (node.left != null) &#123; queue.offer(node.left); &#125; if (node.right != null) &#123; queue.offer(node.right); &#125; &#125; return true; &#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"tree","slug":"tree","permalink":"https://weilans.github.io/tags/tree/"}]},{"title":"[Leetcode单排] 树的遍历 (N94 N589 N590)","slug":"Leetcode单排-树的遍历-N94-N589-N590","date":"2019-08-09T08:15:52.000Z","updated":"2021-04-17T08:59:26.930Z","comments":true,"path":"2019/08/09/Leetcode单排-树的遍历-N94-N589-N590/","link":"","permalink":"https://weilans.github.io/2019/08/09/Leetcode单排-树的遍历-N94-N589-N590/","excerpt":"","text":"94. Binary Tree Inorder Traversalhttps://leetcode.com/problems/binary-tree-inorder-traversal/ 先简单回顾下二叉树的遍历，分为先序、中序、后序三种方式，每一种有都有递归和非递归两种方式。先回顾递归的方式。 递归1234567891011121314151617181920212223242526272829303132333435/** * 先序遍历 递归 */public void preOrderRecur(Node head) &#123; if (head == null) &#123; return; &#125; System.out.print(head.value + \" \"); preOrderRecur(head.left); preOrderRecur(head.right);&#125;/** * 中序遍历 递归 */public void inOrderRecur(Node head) &#123; if (head == null) &#123; return; &#125; inOrderRecur(head.left); System.out.print(head.value + \" \"); inOrderRecur(head.right);&#125;/** * 后序遍历 递归 */public void posOrderRecur(Node head) &#123; if (head == null) &#123; return; &#125; posOrderRecur(head.left); posOrderRecur(head.right); System.out.print(head.value + \" \");&#125; 虽然递归方式的代码的样子很简单，但还是需要好好理解的。如果把节点的访问顺序一个个的记录下来，会发现每个节点会访问三次。如果把处理时机放在第一次来到这个节点的时候就是先续遍历，放在第二次就是中序遍历，放在第三次就是后续遍历。 非递归先序遍历：先将头结点放入栈中，之后在 while 中不断弹出。弹出节点有右节点即将其放入栈中，之后有左子树将其放放入栈中。不使用队列的原因是：先序遍历虽然只能往下走，但是遍历完左子树之后还是需要回去的，所以非递归中序遍历需要用栈结构。 12345678910111213141516171819 /** * 先序遍历 非递归 */public void preOrderUnRecur(Node head) &#123; if (head != null) &#123; Stack&lt;Node&gt; stack = new Stack&lt;&gt;(); stack.add(head); while (!stack.isEmpty()) &#123; head = stack.pop(); System.out.print(head.value + \" \"); if (head.right != null) &#123; stack.push(head.right); &#125; if (head.left != null) &#123; stack.push(head.left); &#125; &#125; &#125;&#125; 中序遍历：当前节点一定会把自己的左边界都压到栈里去，其实简略概括为：当前节点不为空，当前节点压入栈，当前节点往左；当前节点为空，从栈顶拿一个打印，当前节点往右边跑。 中序直接从头部节点开始，不需要事先压栈。 123456789101112131415161718/** * 中序遍历 非递归 */public void inOrderUnRecur(Node head) &#123; if (head != null) &#123; Stack&lt;Node&gt; stack = new Stack&lt;Node&gt;(); while (!stack.isEmpty() || head != null) &#123; if (head != null) &#123; stack.push(head); head = head.left; &#125; else &#123; head = stack.pop(); System.out.print(head.value + \" \"); head = head.right; &#125; &#125; &#125;&#125; 后序遍历：左右中是中右左的逆序，而中左右即为先序遍历，所以中右左是容易实现的。所以可以将中右左弹出的元素压入另一个栈中即可，这就是双栈的做法。单栈的做法不好理解，就不展开了。 1234567891011121314151617181920212223/** * 后序遍历 非递归（双栈） */public void posOrderUnRecur1(Node head) &#123; if (head != null) &#123; Stack&lt;Node&gt; s1 = new Stack&lt;Node&gt;(); Stack&lt;Node&gt; s2 = new Stack&lt;Node&gt;(); s1.push(head); while (!s1.isEmpty()) &#123; head = s1.pop(); s2.push(head); if (head.left != null) &#123; s1.push(head.left); &#125; if (head.right != null) &#123; s1.push(head.right); &#125; &#125; while (!s2.isEmpty()) &#123; System.out.print(s2.pop().value + \" \"); &#125; &#125;&#125; 所以 92 题非递归就是如下的写法： 1234567891011121314151617181920class Solution &#123; public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; if (root == null) &#123; return new ArrayList&lt;&gt;(); &#125; List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); while (!stack.isEmpty() || root != null) &#123; if (root != null) &#123; stack.push(root); root = root.left; &#125; else &#123; TreeNode p = stack.pop(); result.add(p.val); root = p.right; &#125; &#125; return result; &#125;&#125; 589. N-ary Tree Preorder Traversalhttps://leetcode.com/problems/n-ary-tree-preorder-traversal/ 递归1234567891011121314151617181920public List&lt;Integer&gt; preorder(Node root) &#123; List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); if (root == null) &#123; return result; &#125; preorder(result, root); return result;&#125;private void preorder(List&lt;Integer&gt; result, Node cur) &#123; if (cur == null) &#123; return; &#125; result.add(cur.val); if (cur.children != null &amp;&amp; cur.children.size() != 0) &#123; for (Node child : cur.children) &#123; preorder(result, child); &#125; &#125;&#125; 非递归12345678910111213141516171819202122public List&lt;Integer&gt; preorder(Node root) &#123; List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); if (root == null) &#123; return result; &#125; Stack&lt;Node&gt; stack = new Stack&lt;&gt;(); stack.push(root); while (!stack.isEmpty()) &#123; Node node = stack.pop(); result.add(node.val); if (node.children != null &amp;&amp; node.children.size() != 0) &#123; // 先右后左 for (int i = node.children.size() - 1; i &gt;= 0; i--) &#123; Node child = node.children.get(i); if (child != null) &#123; stack.push(child); &#125; &#125; &#125; &#125; return result; &#125; 590. N-ary Tree Postorder Traversalhttps://leetcode.com/problems/n-ary-tree-postorder-traversal/ 递归1234567891011121314151617181920public List&lt;Integer&gt; postorder(Node root) &#123; List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); if (root == null) &#123; return result; &#125; postorder(result, root); return result;&#125;private void postorder(List&lt;Integer&gt; result, Node cur) &#123; if (cur == null) &#123; return; &#125; if (cur.children != null &amp;&amp; cur.children.size() != 0) &#123; for (Node child : cur.children) &#123; postorder(result, child); &#125; &#125; result.add(cur.val);&#125; 非递归(双栈)12345678910111213141516171819202122232425public List&lt;Integer&gt; postorder(Node root) &#123; List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); if (root == null) &#123; return result; &#125; Stack&lt;Node&gt; stack1 = new Stack&lt;&gt;(); Stack&lt;Node&gt; stack2 = new Stack&lt;&gt;(); stack1.push(root); while (!stack1.isEmpty()) &#123; Node node = stack1.pop(); stack2.push(node); if (node.children != null &amp;&amp; node.children.size() != 0) &#123; // 先左后右 for (Node child : node.children) &#123; if (child != null) &#123; stack1.push(child); &#125; &#125; &#125; &#125; while (!stack2.isEmpty()) &#123; result.add(stack2.pop().val); &#125; return result;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"tree","slug":"tree","permalink":"https://weilans.github.io/tags/tree/"}]},{"title":"[Leetcode单排] 划分为k个相等的子集 (N698)","slug":"Leetcode单排-划分为k个相等的子集-N698","date":"2019-08-04T15:54:41.000Z","updated":"2019-08-04T17:09:06.000Z","comments":true,"path":"2019/08/04/Leetcode单排-划分为k个相等的子集-N698/","link":"","permalink":"https://weilans.github.io/2019/08/04/Leetcode单排-划分为k个相等的子集-N698/","excerpt":"","text":"698. Partition to K Equal Sum Subsetshttps://leetcode.com/problems/partition-to-k-equal-sum-subsets/ （最近做了挺多的DFS题目，这道题没做出来 o.O||，还是菜啊 ）做法来自 小f讲解。这道题目本以为会有其他的方法，最后也只能不断暴力递归求解。递归时先建立指定个数的桶，每个桶内数字总和是相等的。partation方法的含义是每个下标在这几个桶内都能够放下，只要满足这个条件即返回成功。只要找到一种可行方式即可。 求总和时用了Arrays.stream().sum()方法结果耗时 47ms，换手动计算变成 13ms。所以数据集有限的情况下，算法题还是谨慎用流。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public boolean canPartitionKSubsets(int[] nums, int k) &#123; if (nums == null || nums.length == 0 || k &lt;= 0) &#123; return false; &#125; int sum = sum(nums); // 校验1：除有余数，无法均分 if (sum % k != 0) &#123; return false; &#125; Arrays.sort(nums); int subSum = sum / k; int index = nums.length - 1; // 校验2：最大值比平均值大，及无法均分 if (nums[index] &gt; subSum) &#123; return false; &#125; int subNum = k; while (index &gt;= 0 &amp;&amp; nums[index] == subSum) &#123; index--; subNum--; &#125; return partition(nums, subSum, index, new int[subNum]);&#125;private boolean partition(int[] num, int target, int index, int[] subSet) &#123; if (index &lt; 0) &#123; return true; &#125; // 当前值在这几个桶内是否有地方可放置 for (int i = 0; i &lt; subSet.length; i++) &#123; if (subSet[i] + num[index] &lt;= target) &#123; subSet[i] += num[index]; if (partition(num, target, index - 1, subSet)) &#123; return true; &#125; subSet[i] -= num[index]; &#125; &#125; return false;&#125;private int sum(int[] array) &#123; int sum = 0; for (int i : array) &#123; sum += i; &#125; return sum;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"}]},{"title":"[Leetcode单排] 01矩阵 (N542)","slug":"Leetcode单排-01矩阵-N542","date":"2019-08-04T14:07:00.000Z","updated":"2019-08-04T14:37:49.000Z","comments":true,"path":"2019/08/04/Leetcode单排-01矩阵-N542/","link":"","permalink":"https://weilans.github.io/2019/08/04/Leetcode单排-01矩阵-N542/","excerpt":"","text":"542. 01 Matrixhttps://leetcode.com/problems/01-matrix/ BFS问题，第一感觉是使用队列来做。先对原数组进行处理，将 0 的下标入队列，非零下标记为最大Integer值。之后由每个0的四周逐渐散开，覆盖掉其四周的 Integer.MAX_VALUE。这样对于处理过的坐标，后续其他 0 散开达到时，其距离一定比当前值大，也就不用处理了。 12345678910111213141516171819202122232425262728293031public int[][] updateMatrix(int[][] matrix) &#123; if (matrix == null || matrix.length == 0) &#123; return null; &#125; int row = matrix.length; int col = matrix[0].length; Queue&lt;int[]&gt; queue = new LinkedList&lt;&gt;(); for (int i = 0; i &lt; row; i++) &#123; for (int j = 0; j &lt; col; j++) &#123; if (matrix[i][j] == 0) &#123; queue.offer(new int[]&#123;i, j&#125;); &#125; else &#123; matrix[i][j] = Integer.MAX_VALUE; &#125; &#125; &#125; int[][] neigh = new int[][]&#123;&#123;0, 1&#125;, &#123;0, -1&#125;, &#123;1, 0&#125;, &#123;-1, 0&#125;&#125;; while (!queue.isEmpty()) &#123; int[] idx = queue.poll(); for (int[] nei : neigh) &#123; int i = idx[0] + nei[0]; int j = idx[1] + nei[1]; if (i &gt;= 0 &amp;&amp; i &lt; row &amp;&amp; j &gt;= 0 &amp;&amp; j &lt; col &amp;&amp; matrix[i][j] &gt; matrix[idx[0]][idx[1]] + 1) &#123; matrix[i][j] = matrix[idx[0]][idx[1]] + 1; queue.offer(new int[]&#123;i, j&#125;); &#125; &#125; &#125; return matrix;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"},{"name":"bfs","slug":"bfs","permalink":"https://weilans.github.io/tags/bfs/"}]},{"title":"[Leetcode单排] 运算表达式设优先级求值 (N241)","slug":"Leetcode单排-运算表达式设优先级求值-N241","date":"2019-08-04T08:46:02.000Z","updated":"2019-08-04T12:30:44.000Z","comments":true,"path":"2019/08/04/Leetcode单排-运算表达式设优先级求值-N241/","link":"","permalink":"https://weilans.github.io/2019/08/04/Leetcode单排-运算表达式设优先级求值-N241/","excerpt":"","text":"241. Different Ways to Add Parentheseshttps://leetcode.com/problems/different-ways-to-add-parentheses/ 自己做的感觉不太好，听了花花酱的讲解后写了一版Java的，时间和内存可以达到都是 100%。 这道题目的关键在于： 递归的方式是按照操作符拆成左右两边表达式，左边的 List 和 右边的 List 进行笛卡尔积处理（以该操作符处理）。 递归的终止条件是字符串本身是个数值，没有操作符，那结果就将其放入到一个新 List 中返回。 重复计算：以用例2*3-4*5来说，计算方式可以有(2*(3-(4*5)))以及((2*3)-(4*5))，这里面的4*5会重复计算到，所有可以使用 map 记住字符串的计算结果。 试了下不带缓存的版本：Runtime: 2 ms, faster than 75.34%；Memory Usage: 38.6 MB, less than 65.42%，效果依然是不错的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public List&lt;Integer&gt; diffWaysToCompute(String input) &#123; if (input == null || input.length() == 0) &#123; return new ArrayList&lt;&gt;(); &#125; return handle(input, new HashMap&lt;&gt;());&#125;private List&lt;Integer&gt; handle(String str, Map&lt;String, List&lt;Integer&gt;&gt; cache) &#123; if (cache.containsKey(str)) &#123; return cache.get(str); &#125; List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; str.length(); i++) &#123; char ch = str.charAt(i); if (ch != '+' &amp;&amp; ch != '-' &amp;&amp; ch != '*') &#123; continue; &#125; String left = str.substring(0, i); String right = str.substring(i + 1); List&lt;Integer&gt; leftList = handle(left, cache); List&lt;Integer&gt; rightList = handle(right, cache); for (Integer l : leftList) &#123; for (Integer r : rightList) &#123; result.add(calculate(ch, l, r)); &#125; &#125; &#125; // str 为数字 if (result.size() == 0) &#123; result.add(Integer.parseInt(str)); &#125; cache.put(str, result); return result;&#125;private Integer calculate(char ch, Integer left, Integer right) &#123; if (ch == '+') &#123; return left + right; &#125; if (ch == '-') &#123; return left - right; &#125; if (ch == '*') &#123; return left * right; &#125; throw new IllegalArgumentException(\"incorrect char\");&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"},{"name":"partition","slug":"partition","permalink":"https://weilans.github.io/tags/partition/"}]},{"title":"[Leetcode单排] 分割回文串 (N131)","slug":"Leetcode单排-分割回文串-N131","date":"2019-08-04T07:13:47.000Z","updated":"2019-08-04T12:20:52.000Z","comments":true,"path":"2019/08/04/Leetcode单排-分割回文串-N131/","link":"","permalink":"https://weilans.github.io/2019/08/04/Leetcode单排-分割回文串-N131/","excerpt":"","text":"131. Palindrome Partitioninghttps://leetcode.com/problems/palindrome-partitioning/ DFS 回溯 典型问题。基本同 N93 复原IP地址问题。 需要注意的是 handle方法里面 for 的终止条件，一开始写的是i &lt; str.length()，发现最后一个字符总是漏掉，主要是 substring 的第二个参数在截取的时候 exclude，i 这个值本身可以等于 length。 12345678910111213141516171819202122232425262728293031323334353637public List&lt;List&lt;String&gt;&gt; partition(String s) &#123; List&lt;List&lt;String&gt;&gt; result = new ArrayList&lt;&gt;(); if (s == null || s.length() == 0) &#123; return result; &#125; handle(s, 0, new ArrayList&lt;&gt;(), result); return result;&#125;private void handle(String str, int index, List&lt;String&gt; curList, List&lt;List&lt;String&gt;&gt; result) &#123; if (index == str.length()) &#123; result.add(new ArrayList&lt;&gt;(curList)); return; &#125; for (int i = index + 1; i &lt;= str.length(); i++) &#123; if (isPalindrome(str.substring(index, i))) &#123; curList.add(str.substring(index, i)); handle(str, i, curList, result); curList.remove(curList.size() - 1); &#125; &#125;&#125;private boolean isPalindrome(String str) &#123; if (str == null || str.length() == 0) &#123; return false; &#125; if (str.length() == 1) &#123; return true; &#125; for (int i = 0; i &lt; str.length() / 2; i++) &#123; if (str.charAt(i) != str.charAt(str.length() - i - 1)) &#123; return false; &#125; &#125; return true;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"},{"name":"partition","slug":"partition","permalink":"https://weilans.github.io/tags/partition/"}]},{"title":"[Leetcode单排] 复原IP地址 (N93)","slug":"Leetcode单排-复原IP地址-N93","date":"2019-08-04T06:02:33.000Z","updated":"2019-08-04T12:19:18.000Z","comments":true,"path":"2019/08/04/Leetcode单排-复原IP地址-N93/","link":"","permalink":"https://weilans.github.io/2019/08/04/Leetcode单排-复原IP地址-N93/","excerpt":"","text":"93. Restore IP Addresseshttps://leetcode.com/problems/restore-ip-addresses/ DFS 回溯 典型问题，只要稍微留意一下为 0 的情况就可以了。 需要留意的是终止条件fields == 4 || index == chars.length。之前误写的是fields &gt; 4 || index == chars.length，导致内存 less than 5%。本以为是递归数据结构用的不好，结果发现只要内存用得多，那就应该想到是递归本身条件写的有问题。改回等号后 less than 100%。 123456789101112131415161718192021222324252627282930public List&lt;String&gt; restoreIpAddresses(String s) &#123; List&lt;String&gt; result = new ArrayList&lt;&gt;(); if (s == null || s.length() == 0) &#123; return result; &#125; search(s.toCharArray(), 0,0, \"\", result); return result; &#125; private void search(char[] chars, int index, int fields, String cur, List&lt;String&gt; result) &#123; if (fields == 4 &amp;&amp; index == chars.length) &#123; result.add(cur.substring(0, cur.length() - 1)); return; &#125; // 注意终止条件 if (fields == 4 || index == chars.length) &#123; return; &#125; if (chars[index] == '0') &#123; search(chars, index + 1, fields + 1, cur + new String(chars, index, 1) + \".\", result); &#125; else &#123; if (index + 2 &lt; chars.length &amp;&amp; Integer.parseInt(new String(chars, index, 3)) &lt;= 255) &#123; search(chars, index + 3, fields + 1, cur + new String(chars, index, 3) + \".\", result); &#125; if (index + 1 &lt; chars.length) &#123; search(chars, index + 2, fields + 1, cur + new String(chars, index, 2) + \".\", result); &#125; search(chars, index + 1, fields + 1, cur + new String(chars, index, 1) + \".\", result); &#125; &#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"},{"name":"partition","slug":"partition","permalink":"https://weilans.github.io/tags/partition/"}]},{"title":"[Leetcode单排] 单词接龙 (N127)","slug":"Leetcode单排-单词接龙-N127","date":"2019-08-01T13:46:54.000Z","updated":"2019-08-04T14:07:54.000Z","comments":true,"path":"2019/08/01/Leetcode单排-单词接龙-N127/","link":"","permalink":"https://weilans.github.io/2019/08/01/Leetcode单排-单词接龙-N127/","excerpt":"","text":"127. Word Ladderhttps://leetcode.com/problems/word-ladder/ 这道题目一眼看上去很像用 DFS 去操作，但是很快就会发现实在操作不下去。从单个单词跳往下一个单词时，还是得 26 个字符替换着来。这道题需要使用 BFS 完成，可以借助队列。从 beginWord 开始，对每个位置都尝试用26种字符替换，如果新字符串在单词集合中，则继续开始下一轮。需要注意的是，单词在集合中出现的话，需要将该单词删除，比如第 N + 2 轮出现的某个单词在第 N 轮也出现的话，那第 N 轮的分支得到的轮次数自然更少。 1234567891011121314151617181920212223242526272829303132333435public int ladderLength(String beginWord, String endWord, List&lt;String&gt; wordList) &#123; if (!wordList.contains(endWord)) &#123; return 0; &#125; Set&lt;String&gt; wordSet = new HashSet&lt;&gt;(wordList); Queue&lt;String&gt; queue = new LinkedList&lt;&gt;(); queue.offer(beginWord); int len = beginWord.length(); int step = 0; while (!queue.isEmpty()) &#123; ++step; // 对上一轮压进的所有值进行处理 for (int size = queue.size(); size &gt; 0; size--) &#123; String word = queue.poll(); // 针对String，获得其更改一位且在wordSet存在的值 for (int i = 0; i &lt; len; i++) &#123; for (char j = 'a'; j &lt; 'z'; j++) &#123; char[] arr = word.toCharArray(); arr[i] = j; String tempWord = new String(arr); if (endWord.equals(tempWord)) &#123; return step + 1; &#125; if (!wordSet.contains(tempWord)) &#123; continue; &#125; wordSet.remove(tempWord); queue.offer(tempWord); &#125; &#125; &#125; &#125; return 0;&#125; 广度优先搜索做出来已经比较不容易了，但是性能一般，还有另一种优化解法：双向广度优先搜索。单词数量较多时，效率相差非常明显。 Runtime: 14 ms, faster than 94.73%; Memory Usage: 38.1 MB, less than 99.36% 从一个队列换成两个 Set，一个从头到尾，一个从尾到头，每轮比较两个 Set 的大小，遍历小的一方的字符串进行处理，并将新单词 Set 赋给该 Set。后续继续比较两个 Set 的大小，以此类推。 12345678910111213141516171819202122232425262728293031323334353637383940414243public int ladderLength(String beginWord, String endWord, List&lt;String&gt; wordList) &#123; if (!wordList.contains(endWord)) &#123; return 0; &#125; Set&lt;String&gt; wordSet = new HashSet&lt;&gt;(wordList); Set&lt;String&gt; set1 = new HashSet&lt;&gt;(); set1.add(beginWord); Set&lt;String&gt; set2 = new HashSet&lt;&gt;(); set2.add(endWord); int len = beginWord.length(); int step = 0; while (!set1.isEmpty() &amp;&amp; !set2.isEmpty()) &#123; step++; Set&lt;String&gt; tempSet = new HashSet&lt;&gt;(); boolean set1Big = set1.size() &gt; set2.size(); Set&lt;String&gt; smallSet = !set1Big ? set1 : set2; Set&lt;String&gt; bigSet = set1Big ? set1 : set2; for (String str : smallSet) &#123; for (int i = 0; i &lt; len; i++) &#123; for (char j = 'a'; j &lt; 'z'; j++) &#123; char[] arr = str.toCharArray(); arr[i] = j; String tempWord = new String(arr); if (bigSet.contains(tempWord)) &#123; return step + 1; &#125; if (!wordSet.contains(tempWord)) &#123; continue; &#125; wordSet.remove(tempWord); tempSet.add(tempWord); &#125; &#125; &#125; if (set1Big) &#123; set2 = tempSet; &#125; else &#123; set1 = tempSet; &#125; &#125; return 0;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"},{"name":"bfs","slug":"bfs","permalink":"https://weilans.github.io/tags/bfs/"}]},{"title":"Clojure in Action: Clojure 构件","slug":"Clojure-in-Action-Clojure-构件","date":"2019-07-31T02:35:52.000Z","updated":"2019-08-12T02:36:37.000Z","comments":true,"path":"2019/07/31/Clojure-in-Action-Clojure-构件/","link":"","permalink":"https://weilans.github.io/2019/07/31/Clojure-in-Action-Clojure-构件/","excerpt":"","text":"元数据元数据提供了在必要时为值添加标识的 一种手段。 123456789101112131415161718192021222324252627282930(def untrusted (with-meta &#123;:command \"delete-table\" :subject \"users\"&#125; &#123;:safe false :io true&#125;)); 可以使用读取器宏^&#123;&#125;简化元数据定义(def untrusted ^&#123;:safe false :io true&#125; &#123;:command \"delete-table\" :subject \"users\"&#125;)untrusted;=&gt; &#123;:command \"delete-table\", :subject \"users\"&#125;;检查与值关联的元数据，可以使用meta函数(meta untrusted);=&gt; &#123;:safe false, :io true&#125;;元数据不影响值的相等性。(def trusted &#123;:command \"delete-table\" :subject \"users\"&#125;) (= trusted untrusted);=&gt; true;元数据在读取时可以加入，而不可以在求值时加入。下列程序将元数据与以hash-map开头的列表关联，而不是与函数调用产生的哈希映射关联，所以这个元数据在运行时不可见。(def untrusted2 ^&#123;:safe false :io true&#125; (hash-map :command \"delete-table\" :subject \"users\"))(meta untrusted2);=&gt; nil; 从有元数据的新值中创建新值时，元数据被复制到新数据里(def still-untrusted (assoc untrusted :complete? false))still-untrusted;=&gt; &#123;:complete? false, :command \"delete-table\", :subject \"users\"&#125;(meta still-untrusted);=&gt; &#123;:safe false, :io true&#125; 函数与宏也可以在定义中包含元数据。 1234567891011121314151617(defn ^&#123;:safe true :console true :doc \"testing metadata for functions\"&#125; testing-meta [] (println \"Hello from meta!\"))(meta testing-meta);=&gt; nil(meta (var testing-meta));=&gt; &#123;:ns #&lt;Namespace user&gt;,; :name testing-meta,; :file \"NO_SOURCE_FILE\",; :line 1, :arglists ([]),; :console true,; :safe true,; :doc \"testing metadata for functions\"&#125; Java 类型提示调用Java方法时，需要通过类找到方法的实现。但是，Clojure 是动态语言，变量类型只有在运行时才知道。可以使用读取器宏^symbol 123456789101112131415(set! *warn-on-reflection* true) ; Warn us when reflection is needed.(defn string-length [x] (.length x))(time (reduce + (map string-length (repeat 10000 \"12345\"))));Reflection warning;\"Elapsed time: 45.751 msecs\";=&gt; 50000(defn fast-string-length [^String x] (.length x)) ; No reflection warning.(time (reduce + (map fast-string-length (repeat 10000 \"12345\"))));\"Elapsed time: 5.788 msecs\";=&gt; 50000(meta (first (first (:arglists (meta #'fast-string-length)))))=&gt; &#123;:tag String&#125; Clojure 编译器在类型推导上相当智能，所有核心函数已经在必要时做了类型提示，所以不经常需要采用类型提示。 原始类型没有可读的类名可提供引用，Clojure 为所有原始类型和原始类型数组定义了别名：只需要使用^byte这样的类型提示表示原始类型，^bytes这样的复数形式表示原始类型数组。 Java 异常处理12345678910111213141516(defn average [numbers] (let [total (apply + numbers)] (/ total (count numbers))))(average []);ArithmeticException Divide by zero clojure.lang.Numbers.divide (Numbers.java:156)(defn safe-average [numbers] (let [total (apply + numbers)] (try (/ total (count numbers)) (catch ArithmeticException e (println \"Divided by zero!\") 0))))(safe-average []);Divided by zero!;=&gt; 0 如果有表达式产生异常，则 根据异常类型执行对应的 catch子句，返回该子句的值。可选的finally子句总会被执行，用于保证必须的副作用，但不返回任何数值。 1234567(try (print \"Attempting division... \") (/ 1 0) (finally (println \"done.\")))Attempting division... done.;=&gt;Execution error (ArithmeticException) at user/eval1516 (form-init4016394056826807004.clj:3).Divide by zero 需要注意catch子句的顺序。 12345678910(try (print \"Attempting division... \") (/ 1 0) (catch RuntimeException e \"Runtime exception!\") (catch ArithmeticException e \"DIVIDE BY ZERO!\") (catch Throwable e \"Unknown exception encountered!\") (finally (println \"done.\")));Attempting division... done.;=&gt; \"Runtime exception!\" 异常可以使用throw形式抛出，在希望抛出的场合可以使用: (throw (Exception. &quot;this is an error&quot;))。 函数先决和后置条件在执行函数主体之前运行的检查由:pre指定，称为先决条件。:post键指定的条件称为后置条件，条件中的%指的就是函数的返回值。 1234567891011121314151617181920(defn item-total [price quantity discount-percentage] &#123;:pre [(&gt; price 0) (&gt; quantity 0)] :post [(&gt; % 0)]&#125; (-&gt;&gt; (/ discount-percentage 100) (- 1) (* price quantity) float))(item-total 100 2 0);=&gt; 200.0(item-total 100 2 10);=&gt; 180.0(item-total 100 -2 10);Execution error (AssertionError) at user/item-total (form-init4016394056826807004.clj:1).;Assert failed: (&gt; quantity 0)(item-total 100 2 110);Execution error (AssertionError) at user/item-total (form-init4016394056826807004.clj:1).;Assert failed: (&gt; % 0) 重载（多种参数数量）12345(defn total-cost ([item-cost number-of-items] (* item-cost number-of-items)) ([item-cost] (total-cost item-cost 1))) 可以从某种参数数量的函数中调用其他参数数量的版本。 可变参数函数在 Clojure 中使用&amp;符号实现变长参数功能。 12(defn total-all-numbers [&amp; numbers] (apply + numbers)) 可变参数函数中有一些不可变的参数。可变参数中的必要参数数量至少要与最长的固定参数相同。 1234567891011121314151617(defn many-arities ([] 0) ([a] 1) ([a b c] 3) ([a b c &amp; more] \"variadic\"))(many-arities);=&gt; 0(many-arities \"one argument\");=&gt; 1(many-arities \"two\" \"arguments\");Execution error (ArityException) at user/eval1554 (form-init4016394056826807004.clj:11).;Wrong number of args (2) passed to: user/many-arities(many-arities \"three\" \"argu-\" \"ments\");=&gt; 3(many-arities \"many\" \"more\" \"argu-\" \"ments\");=&gt; \"variadic\" 高阶参数every?接受一个返回布尔值的函数（判定函数）和一个序列 12345(def bools [true true true false false])(every? true? bools) ;=&gt; false(every? even? '(2 4 6));=&gt; true some接受一个判定和一个序列，返回获得的第一个逻辑true值，如果调用都不返回逻辑 true，则返回 nil。 12(some (fn [p] (= \"rob\" p)) [\"kyle\" \"siva\" \"rob\" \"celeste\"]);=&gt; true constantly接受一个值 v，返回一个可变参数函数，这个函数不管输入的参数为何，总是返回相同的值 v。 12345678(def two (constantly 2)) ; same as ;(def two (fn [&amp; more] 2));(defn two [&amp; more] 2);=&gt; #'clj-in-act.ch3/two(two 1);=&gt; 2(two :a :b :c);=&gt; 2 complement接受一个函数作为参数，返回与原始函数参数数量相同、完成相同工作但返回逻辑相反值的函数。 123456789101112(defn greater? [x y] (&gt; x y))(greater? 10 5);=&gt; true(greater? 10 20);=&gt; false(def smaller? (complement greater?))(smaller? 10 5);=&gt; false(smaller? 10 20);=&gt; true comp接受多个函数并返回由哪些函数组合而成的新函数。计算从右到左进行，新函数将其参数应用于原始组成函数中最右侧的一个，然后将结果应用到它左边的函数，直到所有函数都被调用。 1234567(def opp-zero-str (comp str not zero?)); (defn opp-zero-str [x] (str (not (zero? x))))(opp-zero-str 0);=&gt; \"false\"(opp-zero-str 1);=&gt; \"true\" partial接受函数 f 以及 f 的几个参数，然后partial返回一个新函数，接受 f 的其余参数。当以余下的参数调用新函数时，它以全部参数调用原始函数 f。 1234567(defn above-threshold? [threshold number] (&gt; number threshold))(filter (fn [x] (above-threshold? 5 x)) [1 2 3 4 5 6 7 8 9]);=&gt; (6 7 8 9)(filter (partial above-threshold? 5) [1 2 3 4 5 6 7 8 9]);=&gt; (6 7 8 9) memoize内存化可以避免函数为已处理过的参数计算结果。 1234567891011121314(defn slow-calc [n m] (Thread/sleep 1000) (* n m))(time (slow-calc 5 7));\"Elapsed time: 1000.097 msecs\";=&gt; 35(def fast-calc (memoize slow-calc))(time (fast-calc 5 7));\"Elapsed time: 1002.446198 msecs\";=&gt; 35(time (fast-calc 5 7));\"Elapsed time: 0.089624 msecs\";=&gt; 35 注意：memoize缓存没有限定大小，因而会不停缓存输入和结果。因此该函数只应该用于少量可能输入的函数，否则最终会把内存耗尽。更高级的内存化功能，可以使用clojure.core.memoize库。 匿名函数匿名函数使用fn创建。 123(defn sorter-using [ordering-fn] (fn [collection] (sort-by ordering-fn collection))) 同时可以使用#()创建一个匿名函数。%表示一个参数，如果超过一个参数，则可以使用%1、%2…还可以使用%&amp;表示除明确引用的%&amp;参数之外的参数。 12345678(#(vector %&amp;) 1 2 3 4 5);=&gt; [(1 2 3 4 5)](#(vector % %&amp;) 1 2 3 4 5);=&gt; [1 (2 3 4 5)](#(vector %1 %2 %&amp;) 1 2 3 4 5);=&gt; [1 2 (3 4 5)](#(vector %1 %2 %&amp;) 1 2);=&gt; [1 2 nil]","categories":[{"name":"clojure","slug":"clojure","permalink":"https://weilans.github.io/categories/clojure/"}],"tags":[{"name":"clojure","slug":"clojure","permalink":"https://weilans.github.io/tags/clojure/"}]},{"title":"[Leetcode单排] 单词搜索 (N79 N212)","slug":"Leetcode单排-单词搜索 (N79 N211)","date":"2019-07-30T12:56:39.000Z","updated":"2019-07-31T15:37:04.000Z","comments":true,"path":"2019/07/30/Leetcode单排-单词搜索 (N79 N211)/","link":"","permalink":"https://weilans.github.io/2019/07/30/Leetcode单排-单词搜索 (N79 N211)/","excerpt":"","text":"79. Word Searchhttps://leetcode-cn.com/problems/word-search/ 在二维数组中搜索具体的单词是否存在。这个题目有几个值得借鉴吸收的地方： 1、 当要在二维数组的特定点四周继续寻找时，不需要写函数计算这个点周围有几个可用点，可以直接在递归中判断是否 out of range； 2、要注意递归函数的具体功能含义。初始尝试时，找到开始点和递归方法写成了两个函数，实际上可以融合； 3、下面的做法没有采用单独的列表存储走过的元素，而是采用将值记录为0，这样就可以在递归中碰到这个点时必然不相等，就相当于排除了这个点。 123456789101112131415161718192021222324252627282930public boolean exist(char[][] board, String word) &#123; for (int i = 0; i &lt; board[0].length; i++) &#123; for (int j = 0; j &lt; board.length; j++) &#123; if (dfs(i, j, 0, word, board)) &#123; return true; &#125; &#125; &#125; return false;&#125;private boolean dfs(int x, int y, int i, String word, char[][] board) &#123; if (x &lt; 0 || y &lt; 0 || x &gt;= board[0].length || y &gt;= board.length) &#123; return false; &#125; if (board[y][x] != word.charAt(i)) &#123; return false; &#125; if (i == word.length() - 1) &#123; return true; &#125; char temp = board[y][x]; board[y][x] = '0'; boolean res = dfs(x + 1, y, i + 1, word, board) || dfs(x - 1, y, i + 1, word, board) || dfs(x, y + 1, i + 1, word, board) || dfs(x, y - 1, i + 1, word, board); board[y][x] = temp; return res;&#125; 下面这个是使用了访问变量的版本： 123456789101112131415161718192021222324252627282930313233public boolean exist(char[][] board, String word) &#123; boolean[][] visit = new boolean[board.length][]; for (int i = 0; i &lt; board.length; i++) &#123; visit[i] = new boolean[board[0].length]; &#125; for (int i = 0; i &lt; board[0].length; i++) &#123; for (int j = 0; j &lt; board.length; j++) &#123; if (dfs(i, j, 0, word, board, visit)) &#123; return true; &#125; &#125; &#125; return false;&#125;private boolean dfs(int x, int y, int i, String word, char[][] board, boolean[][] visit) &#123; if (x &lt; 0 || y &lt; 0 || x &gt;= board[0].length || y &gt;= board.length) &#123; return false; &#125; if (board[y][x] != word.charAt(i) || visit[y][x]) &#123; return false; &#125; if (i == word.length() - 1) &#123; return true; &#125; visit[y][x] = true; boolean res = dfs(x + 1, y, i + 1, word, board, visit) || dfs(x - 1, y, i + 1, word, board, visit) || dfs(x, y + 1, i + 1, word, board, visit) || dfs(x, y - 1, i + 1, word, board, visit); visit[y][x] = false; return res;&#125; 212. Word Search IIhttps://leetcode.com/problems/word-search-ii/ 与上题不同的是，这次是给一个字符串数组，结果是所有满足条件的字符串的集合，其实就是把上题中的单字符串换成字符串数组。如果基于上文中的解法直接加一层for循环：Your runtime beats 13.43 %, memory usage beats 90.76 %。 正确做法是基于 Trie 树，其实从一串字符串中进行筛选就应该想到使用前缀树。答案借鉴的这位的做法，这代码风格和我上一题基本一模一样。实际上需要以二维数组的每个字符去匹配 Trie 树，从顶向下找，看能包含几个字符串。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// 构建Trie树节点(26叉树)class TrieNode &#123; public TrieNode[] children = new TrieNode[26]; public String word = null;&#125;// 构建Trie树class Trie &#123; public TrieNode root = new TrieNode(); // 只需要插入方法即可 public void insert(String word) &#123; TrieNode node = root; for (int i = 0; i &lt; word.length(); ++i) &#123; int charNo = word.charAt(i) - 'a'; if (node.children[charNo] == null) &#123; node.children[charNo] = new TrieNode(); &#125; node = node.children[charNo]; &#125; node.word = word; &#125;&#125;public class Solution &#123; public List&lt;String&gt; findWords(char[][] board, String[] words) &#123; // 事先构造 Trie trie = new Trie(); for (String word : words) &#123; trie.insert(word); &#125; boolean[][] visited = new boolean[board.length][board[0].length]; Set&lt;String&gt; resultSet = new HashSet&lt;&gt;(); for (int i = 0; i &lt; board.length; ++i) &#123; for (int j = 0; j &lt; board[0].length; ++j) &#123; search(board, visited, i, j, board.length, board[0].length, trie.root, resultSet); &#125; &#125; return new ArrayList&lt;&gt;(resultSet); &#125; private void search(char[][] board, boolean[][] visit, int i, int j, int x, int y, TrieNode node, Set&lt;String&gt; result) &#123; if (i &lt; 0 || j &lt; 0 || i &gt;= x || j &gt;= y || visit[i][j]) &#123; return; &#125; node = node.children[board[i][j] - 'a']; if (node == null) &#123; return; &#125; if (node.word != null) &#123; result.add(node.word); // 此处没有 return，后续可能还存在字符串 &#125; visit[i][j] = true; search(board, visit, i - 1, j, x, y, node, result); search(board, visit, i + 1, j, x, y, node, result); search(board, visit, i, j - 1, x, y, node, result); search(board, visit, i, j + 1, x, y, node, result); visit[i][j] = false; &#125;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"}]},{"title":"Clojure in Action: 程序结构、程序流程","slug":"Clojure-in-Action-程序结构、程序流程","date":"2019-07-30T05:58:29.000Z","updated":"2019-07-30T12:40:51.000Z","comments":true,"path":"2019/07/30/Clojure-in-Action-程序结构、程序流程/","link":"","permalink":"https://weilans.github.io/2019/07/30/Clojure-in-Action-程序结构、程序流程/","excerpt":"","text":"程序结构函数定义defn宏展开为def和fn调用的组合。fn宏接受方括号中的一系列参数然后是程序主体，fn形式可以用于定义匿名函数。 1234567(defn addition-function [x y] (+ x y));; Expanded form:(def addition-function (fn [x y] (+ x y))) let 形式let形式接受一个向量作为其第一个参数，该向量包含偶数个形式，然后是在 let 求值时进行求值的 0 个或者多个形式。let 形式可以在代码中将一个符号和某个值绑定，从而引入局部命名对象。let 返回的是最后一个表达式的值。 12345(let [x 1 y 2 z (+ x y)] z);=&gt; 3 以下函数可以使用 let 将其分成几个部分，使代码清晰。 123456789(defn average-pets [] (/ (apply + (map :number-pets (vals users))) (count users))) (defn average-pets [] (let [user-data (vals users) pet-counts (map :number-pets user-data) total (apply + pet-counts)] (/ total (count users)))) 在 let 中如果不需要关注值，可以使用下划线标识符，下划线标识符本身没有什么特别之处，只是 clojure 的一个惯例。在解构中，下划线标识符更加实用：(let [[_ _ z] [1 2 3]] z)。 123456(defn average-pets [] (let [user-data (vals users) pet-counts (map :number-pets user-data) _ (println \"total pets:\" pet-counts) total (apply + pet-counts)] (/ total (count users)))) do纯函数语言中，程序是没有副作用的，函数的唯一行为就是计算一个值并返回。但是现实世界中必然充满了状态，也必然有副作用，例如向控制台或者日志文件中打印某些内容、在数据库中保存内容就是改变世界状态的副作用。为了将多个表达式转为一个形式，clojure 提供了 do形式。 12345(if (is-something-true?) (do (log-message \"in true branch\") (store-something-in-db) (return-useful-value))) 1(for [i (range 1 3)] (do (println i) i)) 程序流程条件if(if test consequent alternative) if形式接受一个测试表达式，若为真则求后续表达式(consequent)，若为假则则使用替代形式(alternative)。形式可以结合do形式使其完成多项工作。 12(if (&gt; 5 2) \"yes\" \"no\");=&gt; \"yes\" if-not12(if-not (&gt; 5 2) \"yes\" \"no\");=&gt; \"no\" condcond可以将嵌套的if条件数扁平化，(cond &amp; clauses)。 123456(def x 1)(cond (&gt; x 0) \"greater!\" (= x 0) \"zero!\" :default \"lesser!\");=&gt; \"greater!\" 子句（clauses）是成对的表达式。当一个表达式返回 true，求值相关的后续表达式并返回。 如果所有表达式都没有返回真值，则可以传入取真值的表达式（比如关键词 :default），然后求值相关的后续表达式并返回。 whenwhen宏是将一个if和一个隐式的do。 123456789(when (&gt; 5 2) (println \"five\") (println \"is\") (println \"greater\") \"done\");five;is;greater;=&gt; \"done\" 此处就没有必要将do包装这三个函数了，when宏会负责这项工作。 when-not123456789(when-not (&lt; 5 2) (println \"two\") (println \"is\") (println \"smaller\") \"done\");two;is;smaller;=&gt; \"done\" 逻辑函数and接受 0 个或多个形式，按顺序求值每个形式，如果任何一个返回 nil 或者 false，则返回该值。如果所有形式都不返回 false 或 nil，则 and 返回最后一个形式的值。如果没有任何值，则返回 true。 12345678910(and);=&gt; true(and :a :b :c);=&gt; :c(and :a nil :c);=&gt; nil(and :a false :c);=&gt; false(and 0 \"\");=&gt; \"\" or接受 0 个或多个形式并逐一求值，如果任何形式返回逻辑真值，则将该值返回。如果所有形式都不返回逻辑真值，则返回最后一个值。 12345678910(or);=&gt; nil(or :a :b :c);=&gt; :a(or :a nil :c);=&gt; :a(or nil false);=&gt; false(or false nil);=&gt; nil not该函数始终返回true或者false。 123456(not true);=&gt; false(not 1);=&gt; false(not nil);=&gt; true 比较函数&lt;、&lt;=、&gt;、&gt;=、=有一个额外特性：可以取任意数量的参数。 12345; &lt; 可检测是否以升序排列(&lt; 2 4 6 8);=&gt; true(&lt; 2 4 3 8);=&gt; false = 与 ===函数等同于 Java 的 equals，但适用于范围更广的对象，包括 nil、数值、序列。Clojure 中的 ==函数只能用于比较数值。=可以比较任意两个值，但比较三种不同类型的数值时结果不理想。 12345678(= 1 1N 1/1);=&gt; true(= 0.5 1/2);=&gt; false(= 0.5M 0.5);=&gt; false(= 0.5M 1/2);=&gt; false 如果对比不同类型的数值，则可以用==代替，但是所有参数必须是数值。 12345678910111213(== 1 1N 1/1);=&gt; true(== 1/2 0.5M 0.5);=&gt; true1.9999999999999999;=&gt; 2.0(== 2.0M 1.9999999999999999) ; == 不是对抗浮点精度和舍入问题的银弹;=&gt; true_(== :a 1);ClassCastException clojure.lang.Keyword cannot be cast to java.lang.Number clojure.lang.Numbers.equiv (Numbers.java:206)_(== nil 1);NullPointerException clojure.lang.Numbers.ops (Numbers.java:961) 如果你预计所有要对比的数据都是数值，且预期有不同类型的数字，则使用==，否则使用=。 函数式循环大部分函数式语言都不支持传统的for循环结构，因为for的典型实现需要改变循环计数器的值。作为替代，它们使用递归和函数应用。 whilewhile宏与命令式语言类似。 12(while (request-on-queue?) (handle-request (pop-request-queue))) loop/recurClojure 没有传统的for循环，其循环流程控制是使用loop和recur。 12345(defn fact-loop [n] (loop [current n fact 1] (if (= current 1) fact (recur (dec current) (* fact current) )))) loop建立和let形式完全相同的绑定，recur也有两个绑定值(def current)和(* fact current)，他们在计算之后重新与current和fact绑定。 recur看起来像递归，实际上不适用栈。recur仅能作用于代码尾部，如果企图从任何其他位置使用它，编译器会报错。 doseq 和 dotimes123456(defn run-report [user] (println \"Running report for\" user))(defn dispatch-reporting-jobs [all-users] (doseq [user all-users] (run-report user))) 上面这个例子中doseq的第一个项是一个新符号，以后将绑定到第二个项（必须是一个序列）中的每一个元素。形式的主体将对序列中的每个元素执行，然后整个形式将返回 nil。 dotimes与之类似，接受一个向量（包含一个符号和一个数值），向量中符号被设置为 0 到 (n-1) 的值，并对每个数值求取主体的值。 12(dotimes [x 5] (println \"X is\" x)) 将打印数字 0~4，返回 nil。 map 、filter、remove、reduce、for在前篇文章中的数据结构 — 序列中的“序列转换”一节中已提及。这里做一些补充。 map 12345678910(map inc [0 1 2 3]);=&gt; (1 2 3 4);; map 接受一个函数，其可以有任意多个参数以及相同数量的序列。每个序列为函数提供一个参数。(map + [0 1 2 3] [0 1 2 3]);=&gt; (0 2 4 6);; 返回值的长度等于最短序列的长度(map + [0 1 2 3] [0 1 2]);=&gt; (0 2 4) filter 12345(defn non-zero-expenses [expenses] (let [non-zero? (fn [e] (not (zero? e)))] (filter non-zero? expenses)))(non-zero-expenses [-2 -1 0 1 2 3]);=&gt; (-2 -1 1 2 3) remove filter判定保留哪些元素，remove判定抛弃哪些元素。两者刚好相反。 1234(defn non-zero-expenses [expenses] (remove zero? expenses))(non-zero-expenses [-2 -1 0 1 2 3]);=&gt; (-2 -1 1 2 3) reduce &amp; reductions reduce接受一个函数（有两个参数）和一个数据元素序列。函数参数应用到序列的前两个元素，产生第一个结果，之后使用这个结果和序列的下一个元素再次调用同一个函数。重复此过程直到处理完最后一个元素。 12345(defn factorial [n] (let [numbers (range 1 (+ n 1))] (reduce * numbers)))(factorial 5);=&gt; 120 reduce只返回最终的规约值，而reductions返回每个中间值组成的序列。 12345(defn factorial-steps [n] (let [numbers (range 1 (+ n 1))] (reductions * numbers)))(factorial-steps 5);=&gt; (1 2 6 24 120) for 可以使用的限定词：:let，:when，:while 123456789101112(for [x [0 1 2 3 4 5] :let [y (* x 3)] :when (even? y)] y);=&gt; (0 6 12)(def chessboard-labels (for [alpha \"abcdefgh\" num (range 1 9)] (str alpha num)))chessboard-labels;=&gt; (\"a1\" \"a2\" \"a3\" \"a4\" \"a5\" … \"h6\" \"h7\" \"h8\") 123456789101112131415161718(defn prime? [x] (let [divisors (range 2 (inc (int (Math/sqrt x)))) remainders (map (fn [d] (rem x d)) divisors)] (not (some zero? remainders))))(defn primes-less-than [n] (for [x (range 2 (inc n)) :when (prime? x)] x))(primes-less-than 50);=&gt; (2 3 5 7 11 13 17 19 23 29 31 37 41 43 47)(defn pairs-for-primes [n] (let [z (range 2 (inc n))] (for [x z y z :when (prime? (+ x y))] (list x y))))(pairs-for-primes 5);=&gt; ((2 3) (2 5) (3 2) (3 4) (4 3) (5 2)) 串行宏thread-first12(defn final-amount [principle rate time-periods] (* (Math/pow (+ 1 (/ rate 100)) time-periods) principle)) 以上函数定义不易理解，需要从里往外读。使用thread-first宏-&gt;改写如下。该宏所做的是取第一个参数，将其放在下一个表达式的第二个位置。之所以成为thread-first，是因为它将代码移到下一个形式首个参数的位置。之后，它取得整个结果表达式，并将其移到再下一个表达式的第二个位置。 123456(defn final-amount-&gt; [principle rate time-periods] (-&gt; rate (/ 100) (+ 1) (Math/pow time-periods) (* principle))) thread-lastthread-last宏-&gt;&gt;在取得第一个表达式结果后，将其移入下一个表达式最后的位置。之后，对所有表达式重复该 过程。 12345678(defn factorial [n] (reduce * (range 1 (+ 1 n))))(defn factorial-&gt;&gt; [n] (-&gt;&gt; n (+ 1) (range 1) (reduce *))) thread-last宏更常见的用途是处理数据元素序列以及使用 map、reduce、filter 这样的高阶函数。这些函数都接受序列作为最后一个元素，所以thread-last宏更为合适。 some-&gt;和some-&gt;&gt;和上述两个宏基本相同，但是如果表达式的任意一步的结果是 nil，则计算结束。 thread-asthread-as宏as-&gt;相比上两者，更加灵活：你为它提供一个名称，它将把各个连续形式的结果绑定到这个名称，以便下一步使用。 1234(as-&gt; &#123;\"a\" [1 2 3 4]&#125; &lt;&gt; (&lt;&gt; \"a\") (conj &lt;&gt; 10) (map inc &lt;&gt;)) 该例子展开后如下： 12345(let [&lt;&gt; &#123;\"a\" [1 2 3 4]&#125; &lt;&gt; (&lt;&gt; \"a\") &lt;&gt; (conj &lt;&gt; 10) &lt;&gt; (map inc &lt;&gt;)] &lt;&gt;) 条件式串行宏cond-&gt;和cond-&gt;&gt;除了每个形式都包含一个条件之外，和-&gt;以及-&gt;&gt;基本相同，如果一个条件为false，则对应的形式将会跳过，但是对下一对形式继续串行求值（cond则是在发现为真的判定后将立刻停止后续成对形式的求值，而cond-&gt;会对每个条件求值）。 123456(let [x 1 y 2] (cond-&gt; [] (odd? x) (conj \"x is odd\") (zero? (rem y 3)) (conj \"y is divisible by 3\") (even? y) (conj \"y is even\")));=&gt; [\"x is odd\" \"y is even\"] 其等价描述为： 123456(let [x 1 y 2] (as-&gt; [] &lt;&gt; (if (odd? x) (conj &lt;&gt; \"x is odd\") &lt;&gt;) (if (zero? (rem y 3)) (conj &lt;&gt; \"y is divisible by 3\") &lt;&gt;) (if (even? y) (conj &lt;&gt; \"y is even\") &lt;&gt;)));=&gt; [\"x is odd\" \"y is even\"]","categories":[{"name":"clojure","slug":"clojure","permalink":"https://weilans.github.io/categories/clojure/"}],"tags":[{"name":"clojure","slug":"clojure","permalink":"https://weilans.github.io/tags/clojure/"}]},{"title":"Java进程CPU高负载排查","slug":"Java进程CPU高负载排查","date":"2019-07-30T03:39:55.000Z","updated":"2019-11-06T10:24:41.000Z","comments":true,"path":"2019/07/30/Java进程CPU高负载排查/","link":"","permalink":"https://weilans.github.io/2019/07/30/Java进程CPU高负载排查/","excerpt":"","text":"Arthas 排查怕麻烦的话，直接使用Arthas排查，具体的线程排查命令可以使用：thread -n 3，表示当前最忙的前N个线程并打印堆栈（详细命令）。 123wget https://alibaba.github.io/arthas/arthas-boot.jarjava -jar arthas-boot.jar &lt;pid&gt;thread -n 3 jstack 排查 使用top将系统资源实时显示，输入大写P对CPU消耗进行排序，第一个就是CPU消耗最高的程序，获取 pid （或者也可以使用jps找到特定程序 pid）。 利用top -Hp pid（-H表示开启线程查看），之后输入大写P，按照CPU使用率对线程排序。 找出线程ID后转为16进制:printf &quot;%x\\n&quot; tid。 通过jstack pid &gt; jstack.log生成进程日志文件，在文件中搜索16进制的线程ID，就可以看到这个线程在干啥了。","categories":[{"name":"java","slug":"java","permalink":"https://weilans.github.io/categories/java/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://weilans.github.io/tags/jvm/"}]},{"title":"[Leetcode单排] 括号生成 (N22)","slug":"Leetcode单排-括号生成-N22","date":"2019-07-29T11:48:30.000Z","updated":"2019-07-29T12:16:18.000Z","comments":true,"path":"2019/07/29/Leetcode单排-括号生成-N22/","link":"","permalink":"https://weilans.github.io/2019/07/29/Leetcode单排-括号生成-N22/","excerpt":"","text":"22. Generate Parentheseshttps://leetcode.com/problems/generate-parentheses/ 给出一个整数 n，给出 n 对左右括号所有可能的排列结果。 设左右括号的个数分别为left和right，则需要满足以下规律：left &lt;= n &amp;&amp; right &lt;= right。所以在每一次递归中需要考虑两种变量的变化。以 left = 2, right = 0为例， 满足第一个条件，则求解handle(3,3,0,&quot;(((&quot;, result)分支下所有满足条件的情况，之后再考虑handle(3,2,1,&quot;(()&quot;, result)分支下所有满足条件结果。两个情况只要满足条件都要进行。 答案虽然比较短，但还是需要仔细咀嚼。 123456789101112131415161718192021public List&lt;String&gt; generateParenthesis(int n) &#123; List&lt;String&gt; result = new ArrayList&lt;&gt;(); if (n &lt;= 0) &#123; return result; &#125; handle(n, 0, 0, \"\", result); return result;&#125;private void handle(int n, int left, int right, String cur, List&lt;String&gt; result) &#123; if (left == n &amp;&amp; right == n) &#123; result.add(cur); return; &#125; if (left &lt; n) &#123; handle(n, left + 1, right, cur + \"(\", result); &#125; if (right &lt; left) &#123; handle(n, left, right + 1, cur + \")\", result); &#125;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"}]},{"title":"[Leetcode单排] 数独 (N37)","slug":"Leetcode单排-数独-N37","date":"2019-07-28T16:55:31.000Z","updated":"2019-07-28T17:50:08.000Z","comments":true,"path":"2019/07/29/Leetcode单排-数独-N37/","link":"","permalink":"https://weilans.github.io/2019/07/29/Leetcode单排-数独-N37/","excerpt":"","text":"37. Sudoku Solverhttps://leetcode.com/problems/sudoku-solver/ 这道题目你知道是回溯，知道是DFS，但是如果需要你完整的做出来，你会发现还是有各种各样的问题。下面这个做法来源于花花酱的讲解。 N皇后是每次递归是确定一行一列，但是这个题目你会发现连每个单元格都可能有N种可能，所以递归的时候不是定住行和列，而是以单元格进行递归。访问变量也从一维变成了两位。比如rows boolean[i][j]就是指第 i 行值为 j 的数是否已存在，而boxes[i][j]就是在第 i 个九宫格值为 j 的数是否已存在。 输入里面已经包含部分数值，所以开局先填充一波访问变量，之后正式开始递归。递归函数 fill的返回值是布尔类型，代表 x 和 y 确定时，board中的位置是否有满足条件的情况。在 for 循环里面只要有一个满足了条件则立刻结束。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849boolean[][] rows = new boolean[9][10];boolean[][] cols = new boolean[9][10];boolean[][] boxes = new boolean[9][10];public void solveSudoku(char[][] board) &#123; for (int i = 0; i &lt; 9; i++) &#123; for (int j = 0; j &lt; 9; j++) &#123; char c = board[i][j]; if (c != '.') &#123; int n = c - '0'; int bx = j / 3; int by = i / 3; rows[i][n] = true; cols[j][n] = true; boxes[by * 3 + bx][n] = true; &#125; &#125; &#125; fill(board, 0, 0);&#125;private boolean fill(char[][] board, int x, int y) &#123; if (y == 9) &#123; return true; &#125; int nextX = (x + 1) % 9; int nextY = (nextX == 0) ? y + 1 : y; if (board[y][x] != '.') &#123; return fill(board, nextX, nextY); &#125; // 每个单元格以 1-9 去试 for (int i = 1; i &lt;= 9; i++) &#123; int boxIndex = y / 3 * 3 + x /3; if (!rows[y][i] &amp;&amp; !cols[x][i] &amp;&amp; !boxes[boxIndex][i]) &#123; rows[y][i] = true; cols[x][i] = true; boxes[boxIndex][i] = true; board[y][x] = (char)(i + '0'); if (fill(board, nextX, nextY)) &#123; return true; &#125; board[y][x] = '.'; rows[y][i] = false; cols[x][i] = false; boxes[boxIndex][i] = false; &#125; &#125; return false;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"}]},{"title":"[Leetcode单排] N皇后 (N51 N52)","slug":"Leetcode单排-N皇后-N51-N52","date":"2019-07-28T12:58:36.000Z","updated":"2019-07-28T14:02:50.000Z","comments":true,"path":"2019/07/28/Leetcode单排-N皇后-N51-N52/","link":"","permalink":"https://weilans.github.io/2019/07/28/Leetcode单排-N皇后-N51-N52/","excerpt":"","text":"51. N-Queenshttps://leetcode.com/problems/n-queens/ N皇后问题，这里是将花花的讲解翻成 Java 版，花花的讲解已足够简明易懂。 每个棋子在每一行每一列必须是唯一的，这倒还好，关键在于每个棋子的所在斜线和反斜线都不包含棋子。难点就在于如何确认斜线处是否有棋子。而在标准做法中，斜线和反斜线各需要一个布尔数组就可以做到，只要找到 x 及 y 下标关系即可。 从第 0 行开始，确定第 0 行 Q 所在位置，之后递归行数加 1，以此类推。 因为担心递归函数中包含变量太多，故将三个布尔数组作为了全局变量。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758boolean[] cols;boolean[] diag1;boolean[] diag2;public List&lt;List&lt;String&gt;&gt; solveNQueens(int n) &#123; if (n &lt;= 0) &#123; return null; &#125; cols = new boolean[n]; // 左下-右上斜线 idx = x + y diag1 = new boolean[2 * n - 1]; // 左上-右下斜线 idx = x - y + (n -1) diag2 = new boolean[2 * n - 1]; List&lt;List&lt;String&gt;&gt; result = new ArrayList&lt;&gt;(); List&lt;String&gt; initial = buildInitialList(n); handle(n, 0, initial, result); return result;&#125;private void handle(int n, int row, List&lt;String&gt; cur, List&lt;List&lt;String&gt;&gt; result) &#123; if (row == n) &#123; result.add(new ArrayList&lt;&gt;(cur)); return; &#125; for (int j = 0; j &lt; n; j++) &#123; if (available(j, row, n)) &#123; update(j, row, n, true, cur); handle(n, row + 1, cur, result); update(j, row, n, false, cur); &#125; &#125;&#125;private boolean available(int x, int y, int n) &#123; return !(cols[x] || diag1[x + y] || diag2[x - y + (n - 1)]);&#125;private void update(int x, int y, int n, boolean state, List&lt;String&gt; cur) &#123; cols[x] = state; diag1[x + y] = state; diag2[x - y + (n - 1)] = state; char[] rowArray = cur.get(y).toCharArray(); rowArray[x] = state ? 'Q' : '.'; cur.set(y, new String(rowArray));&#125;private List&lt;String&gt; buildInitialList(int n) &#123; List&lt;String&gt; res = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; n; i++) &#123; StringBuilder sb = new StringBuilder(); for (int j = 0; j &lt; n; j++) &#123; sb.append('.'); &#125; res.add(sb.toString()); &#125; return res;&#125; 52. N-Queens IIhttps://leetcode.com/problems/n-queens-ii/ 52题和51题是一样的，只是这次是计算个数。这里是将 count 作为全局变量，其实可以将 handle 返回 count，亦或者 handle 在每次满足条件时返回 1，这几种做法皆可。（只要不是犯将 count 放到参数这种低级错误皆可）。 左程云的书 里面还有一种使用位运算做加速的超自然做法，暂且备注一下。 1234567891011121314151617181920212223242526272829303132int count = 0;public int totalNQueens(int n) &#123; if (n &lt;= 0) &#123; return 0; &#125; handle(0, n, new boolean[n], new boolean[2 * n - 1], new boolean[2 * n - 1]); return count;&#125;private void handle(int row, int n, boolean[] cols, boolean[] diag1, boolean[] diag2) &#123; if (row == n) &#123; ++count; &#125; for (int j = 0; j &lt; n; j++) &#123; if (available(j, row, n, cols, diag1, diag2)) &#123; modifyState(j, row, n, cols, diag1, diag2, true); handle(row + 1, n, cols, diag1, diag2); modifyState(j, row, n, cols, diag1, diag2, false); &#125; &#125;&#125;private boolean available(int x, int y, int n, boolean[] cols, boolean[] diag1, boolean[] diag2) &#123; return !(cols[x] || diag1[x + y] || diag2[x - y + (n - 1)]);&#125;private void modifyState(int x, int y, int n, boolean[] cols, boolean[] diag1, boolean[] diag2, boolean state) &#123; cols[x] = state; diag1[x + y] = state; diag2[x - y + (n - 1)] = state;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"}]},{"title":"[Leetcode单排] Subsets (N78 N90)","slug":"Leetcode单排-Subsets-N78-N90","date":"2019-07-27T15:10:06.000Z","updated":"2019-07-28T14:03:24.000Z","comments":true,"path":"2019/07/27/Leetcode单排-Subsets-N78-N90/","link":"","permalink":"https://weilans.github.io/2019/07/27/Leetcode单排-Subsets-N78-N90/","excerpt":"","text":"78. Subsetshttps://leetcode.com/problems/subsets/ 这两道取子集的题目基本上也没什么好讲的，基本的回溯方法即可，处理方式同排列和组合系列。 123456789101112131415161718public List&lt;List&lt;Integer&gt;&gt; subsets(int[] nums) &#123; if (nums == null || nums.length == 0) &#123; return new ArrayList&lt;&gt;(); &#125; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); handle(nums, 0, new ArrayList&lt;&gt;(), result); return result;&#125;private void handle(int[] nums, int start, List&lt;Integer&gt; cur, List&lt;List&lt;Integer&gt;&gt; result) &#123; result.add(new ArrayList&lt;&gt;(cur)); for (int i = start; i &lt; nums.length; i++) &#123; cur.add(nums[i]); // 注意别写成 start + 1 handle(nums, i + 1, cur, result); cur.remove(cur.size() - 1); &#125;&#125; 90. Subsets IIhttps://leetcode.com/problems/subsets-ii/ 12345678910111213141516171819202122public List&lt;List&lt;Integer&gt;&gt; subsetsWithDup(int[] nums) &#123; if (nums == null || nums.length == 0) &#123; return new ArrayList&lt;&gt;(); &#125; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); Arrays.sort(nums); handle(nums, 0, new ArrayList&lt;&gt;(), result); return result;&#125;private void handle(int[] nums, int start, List&lt;Integer&gt; cur, List&lt;List&lt;Integer&gt;&gt; result) &#123; result.add(new ArrayList&lt;&gt;(cur)); for (int i = start; i &lt; nums.length; i++) &#123; // 与 N40 中 for 循环里的 if 判断如出一辙 if (i &gt; start &amp;&amp; nums[i] == nums[i - 1]) &#123; continue; &#125; cur.add(nums[i]); handle(nums, i + 1, cur, result); cur.remove(cur.size() - 1); &#125;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"}]},{"title":"[Leetcode单排] Letter Combinations of a Phone Number(N17)","slug":"Leetcode单排-Letter-Combinations-of-a-Phone-Number (N17)","date":"2019-07-26T06:59:38.000Z","updated":"2019-07-28T14:04:00.000Z","comments":true,"path":"2019/07/26/Leetcode单排-Letter-Combinations-of-a-Phone-Number (N17)/","link":"","permalink":"https://weilans.github.io/2019/07/26/Leetcode单排-Letter-Combinations-of-a-Phone-Number (N17)/","excerpt":"","text":"17.Letter Combinations of a Phone Numberhttps://leetcode.com/problems/letter-combinations-of-a-phone-number/ 每个号码对应3或4个数字，输入一组号码，打印所有可能出现的排列。这道题很明显有BFS和DFS两类做法。 解法一当处理第n个数字时，实际上就是以n-1次的处理结果加上第n个数字对应的几个字符进行处理。 123456789101112131415161718192021/** * BFS 多层loop */public List&lt;String&gt; letterCombinations(String digits) &#123; if (digits == null || digits.length() == 0) &#123; return new ArrayList&lt;&gt;(); &#125; String digitArr[] = &#123;\"\", \"\", \"abc\", \"def\", \"ghi\", \"jkl\", \"mno\", \"pqrs\", \"tuv\", \"wxyz\"&#125;; List&lt;String&gt; result = new ArrayList&lt;&gt;(); result.add(\"\"); for (int i = 0; i &lt; digits.length(); i++) &#123; List&lt;String&gt; temp = new ArrayList&lt;&gt;(); for (String str : result) &#123; for (char c : digitArr[digits.charAt(i) - '0'].toCharArray()) &#123; temp.add(str + c); &#125; &#125; result = temp; &#125; return result;&#125; 在答案中看到另一种BFS的做法，他是以一个Queue作为载体。这种做法很巧妙，但是在写 while 和 for 中条件时还是比较容易出错的。 123456789101112131415161718/** * BFS 使用queue，易错点在于while条件以及for中数组的获取 */public List&lt;String&gt; letterCombinations2(String digits) &#123; if (digits == null || digits.length() == 0) &#123; return new ArrayList&lt;&gt;(); &#125; String digitArr[] = &#123;\"\", \"\", \"abc\", \"def\", \"ghi\", \"jkl\", \"mno\", \"pqrs\", \"tuv\", \"wxyz\"&#125;; LinkedList&lt;String&gt; result = new LinkedList&lt;&gt;(); result.add(\"\"); while (result.peek().length() != digits.length()) &#123; String peek = result.remove(); for (char c : digitArr[digits.charAt(peek.length()) - '0'].toCharArray()) &#123; result.add(peek + c); &#125; &#125; return result;&#125; 解法二在DFS中，表示当前结果的 String cur，在每次递归中都是一个新的String。一般在DFS的递归之后需要对表示当前结果的值进行回滚，而在这种场景下则不需要。 12345678910111213141516171819202122/** * DFS 递归 */public List&lt;String&gt; letterCombinations3(String digits) &#123; if (digits == null || digits.length() == 0) &#123; return new ArrayList&lt;&gt;(); &#125; String digitArr[] = &#123;\"\", \"\", \"abc\", \"def\", \"ghi\", \"jkl\", \"mno\", \"pqrs\", \"tuv\", \"wxyz\"&#125;; List&lt;String&gt; result = new ArrayList&lt;&gt;(); dfs(digits, digitArr, 0, \"\", result); return result;&#125;private void dfs(String digits, String[] digitArr, int i, String cur, List&lt;String&gt; result) &#123; if (i == digits.length()) &#123; result.add(cur); return; &#125; for (char c : digitArr[digits.charAt(i) - '0'].toCharArray()) &#123; dfs(digits, digitArr, i + 1, cur + c, result); &#125;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"},{"name":"bfs","slug":"bfs","permalink":"https://weilans.github.io/tags/bfs/"}]},{"title":"[Leetcode单排] 组合系列 (N39 N40 N77 N216)","slug":"Leetcode单排- 组合系列 (N39 N40 N77 N216)","date":"2019-07-25T14:18:06.000Z","updated":"2019-07-28T14:02:45.000Z","comments":true,"path":"2019/07/25/Leetcode单排- 组合系列 (N39 N40 N77 N216)/","link":"","permalink":"https://weilans.github.io/2019/07/25/Leetcode单排- 组合系列 (N39 N40 N77 N216)/","excerpt":"","text":"39. Combination Sumhttps://leetcode.com/problems/combination-sum/ 给定一个目标值，以及一个数组，若从数组中取出若干个值能组成目标值的话即满足条件。这个题目有个重要的前提：数组中的值以及目标值都是正数。同时，题目还要求结果集要去重。如果只进行简单回溯，答案是会出现重复的，比如7的组成就有[2,2,3],[2,3,2],[3,2,2]，而答案只需其中之一。 大部分答案的做法是将数组排序后，定一个start值，后续递归只从下标为start的开始。但是实际上，不对数组进行排序答案依然是对的，原因在于，答案中避免重复真正要防止的是情况是：在某一轮递归中放入该值后，想隔一轮后递归轮次中又出现该值。比如这一轮递归中元素选择2，下一轮为3，再下一轮再继续选择2那就会出现重复。相同元素出现的递归轮次必须是靠在一起的。而只要做到这一点，你排序也好，不排也好，实际上对于获取正确答案都没有影响，只要满足数组中元素按一定顺序参与递归即可。 123456789101112131415161718192021222324public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) &#123; if (candidates == null || candidates.length == 0) &#123; return null; &#125; Arrays.sort(candidates); // 排序可有可无? List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); handle(candidates, target, new ArrayList&lt;&gt;(), result, 0); return result;&#125;private void handle(int[] candidates, int curValue, List&lt;Integer&gt; curList, List&lt;List&lt;Integer&gt;&gt; result, int start) &#123; if (curValue == 0) &#123; result.add(new ArrayList&lt;&gt;(curList)); return; &#125; if (curValue &lt; 0) &#123; return; &#125; for (int i = start; i &lt; candidates.length; i++) &#123; curList.add(candidates[i]); handle(candidates, curValue - candidates[i], curList, result, i); curList.remove(curList.size() - 1); &#125;&#125; 那真的不用排序？当把不排序的代码丢进LeetCode判断时，答案虽是正确，但是时间排名较低。实际上，代码中一旦对数组进行排序，真正发挥排序作用是需要在for循环中加入这一段代码：if (candidates[i] &gt; curValue) { return; }，一旦判断当前下标值比目标curValue大，直接结束此轮判断，即进行一次剪枝，这次数据量非常大的时候能起到作用。按这种做法，时间空间排名都是top。 1234567891011121314151617181920212223242526272829public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) &#123; if (candidates == null || candidates.length == 0) &#123; return null; &#125; Arrays.sort(candidates); List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); handle(candidates, target, new ArrayList&lt;&gt;(), result, 0); return result;&#125;private void handle(int[] candidates, int curValue, List&lt;Integer&gt; curList, List&lt;List&lt;Integer&gt;&gt; result, int start) &#123; if (curValue == 0) &#123; result.add(new ArrayList&lt;&gt;(curList)); return; &#125; // for 循环中既有判断，此处可省 //if (curValue &lt; 0) &#123; // return; // &#125; for (int i = start; i &lt; candidates.length; i++) &#123; // 真正发挥排序作用的是这个判断 if (candidates[i] &gt; curValue) &#123; return; // break 或 return &#125; curList.add(candidates[i]); handle(candidates, curValue - candidates[i], curList, result, i); curList.remove(curList.size() - 1); &#125;&#125; 40. Combination Sum IIhttps://leetcode.com/problems/combination-sum-ii/submissions/ 与上题不同的是每个数字在每个组合中只能使用一次。整个流程大致上不变，只是有一些小变动，比如递归中每次下标为 i + 1，非 i。另外还有一个变动是剪枝去重的判断条件，即同一层中如果有相同元素则略过。 这个判断条件第一次写的时候，写成了 i &gt; 0而非 i &gt; s ，这样写会造成示例1的答案中少了[1,1,6]，这是因为 i = 1的时候，下标1和下标0的元素比较了。所以在每一次递归中，i 应该要比起始下标 s 大。 12345678910111213141516171819202122232425262728public List&lt;List&lt;Integer&gt;&gt; combinationSum2(int[] candidates, int target) &#123; if (candidates == null || candidates.length == 0) &#123; return null; &#125; Arrays.sort(candidates); List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); handle(candidates, target, 0, new ArrayList&lt;&gt;(), result); return result;&#125;private void handle(int[] candidates, int target, int s, List&lt;Integer&gt; cur, List&lt;List&lt;Integer&gt;&gt; result) &#123; if (target == 0) &#123; result.add(new ArrayList&lt;&gt;(cur)); return; &#125; for (int i = s; i &lt; candidates.length; i++) &#123; if (candidates[i] &gt; target) &#123; return; &#125; // 同一层中如果有相同元素则略过 if (i &gt; s &amp;&amp; candidates[i] == candidates[i - 1]) &#123; continue; &#125; cur.add(candidates[i]); handle(candidates, target - candidates[i], i + 1, cur, result); cur.remove(cur.size() - 1); &#125;&#125; 77. Combinationhttps://leetcode.com/problems/combinations/ 标准组合，从 n 里面取 k 个元素。要注意数组里没有相同数值，且数组间要避免重复，比如[1,4]和[4,1]就是重复的。所以只需将当前加入到 cur 中的值加1放入到下一层递归即可。 123456789101112131415161718192021public List&lt;List&lt;Integer&gt;&gt; combine(int n, int k) &#123; if (n &lt;= 0 || k &lt;= 0) &#123; return new ArrayList&lt;&gt;(); &#125; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); handle(n, k, 1, new ArrayList&lt;&gt;(), result); return result;&#125;private void handle(int n, int k, int start, List&lt;Integer&gt; cur, List&lt;List&lt;Integer&gt;&gt; result) &#123; if (cur.size() == k) &#123; result.add(new ArrayList&lt;&gt;(cur)); return; &#125; for (int i = start; i &lt;= n; i++) &#123; cur.add(i); // 注意 i + 1 别写成 start + 1 handle(n, k, i + 1, cur, result); cur.remove(cur.size() - 1); &#125;&#125; 216. Combination Sum IIIhttps://leetcode.com/problems/combination-sum-iii/submissions/ 同样没什么可讲的了，只是要注意可以进行适当的优化，比如if (k == curList.size())。 123456789101112131415161718192021222324public List&lt;List&lt;Integer&gt;&gt; combinationSum3(int k, int n) &#123; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); handle(k, n, 1, new ArrayList&lt;&gt;(), result); return result;&#125;private void handle(int k, int curTotal, int start, List&lt;Integer&gt; curList, List&lt;List&lt;Integer&gt;&gt; result) &#123; if (k == curList.size() &amp;&amp; curTotal == 0) &#123; result.add(new ArrayList&lt;&gt;(curList)); return; &#125; // optimize if (k == curList.size()) &#123; return; &#125; for (int i = start; i &lt;= 9; i++) &#123; if (curTotal &lt; i) &#123; return; &#125; curList.add(i); handle(k,curTotal - i, i + 1, curList, result); curList.remove(curList.size() - 1); &#125;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"},{"name":"combination","slug":"combination","permalink":"https://weilans.github.io/tags/combination/"}]},{"title":"[Leetcode单排] 排列系列（N46 N47 N784）","slug":"Leetcode单排- 排列系列 (N46 N47 N784)","date":"2019-07-25T12:28:24.000Z","updated":"2021-04-14T08:46:40.700Z","comments":true,"path":"2019/07/25/Leetcode单排- 排列系列 (N46 N47 N784)/","link":"","permalink":"https://weilans.github.io/2019/07/25/Leetcode单排- 排列系列 (N46 N47 N784)/","excerpt":"","text":"晚上注册了新LeetCode账号，正式开始了LeetCode的从零单排。 LeetCode刷题顺序初步先按照花花酱的题目分类来，现在还不习惯直接在网页上写，暂时先用IDE。万事开头难，先把第一个50题做完吧。 46. Permutationshttps://leetcode.com/problems/permutations/ 全排列算是比较基础的题了，想到的第一个词就是回溯。可以选择对数组中的元素进行重排序，也可以选择从数组中每次取一个值放到自己的临时List中，这也就是下面这两种方法。回溯需要注意的是如果操作的对象是可变的，在递归后需要把它变回来。当然如果在递归中传递的是新对象，则没这个必要了。 解法一123456789101112131415161718192021222324252627282930313233/** * 解法一：以数组中元素排序为准 */public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) &#123; if (nums == null || nums.length == 0) &#123; return new ArrayList&lt;&gt;(); &#125; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); permute(nums, 0, result); return result;&#125;private void permute(int[] nums, int i, List&lt;List&lt;Integer&gt;&gt; result) &#123; if (nums.length == i) &#123; List&lt;Integer&gt; cur = new ArrayList&lt;&gt;(); for (Integer integer : nums) &#123; cur.add(integer); &#125; result.add(cur); return; &#125; for (int j = i; j &lt; nums.length; j++) &#123; swap(nums, i, j); permute(nums, i + 1, result); swap(nums, i, j); &#125;&#125;private void swap(int[] nums, int m, int n) &#123; int temp = nums[m]; nums[m] = nums[n]; nums[n] = temp;&#125; 解法二12345678910111213141516171819202122232425262728293031/** * 解法二：以自定义List存放当前变量 */public List&lt;List&lt;Integer&gt;&gt; permute2(int[] nums) &#123; if (nums == null || nums.length == 0) &#123; return new ArrayList&lt;&gt;(); &#125; List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); permute2(nums, new ArrayList&lt;&gt;(), result); return result;&#125;/** * 查看是否包含某元素，除了直接使用contains判断外，很多人使用了boolean[] visited， * 递归前visited[i] = true，递归后还需visited[i] = false; * https://leetcode-cn.com/problems/permutations/solution/hui-su-suan-fa-python-dai-ma-java-dai-ma-by-liweiw/ */private void permute2(int[] nums, List&lt;Integer&gt; cur, List&lt;List&lt;Integer&gt;&gt; result) &#123; if (nums.length == cur.size()) &#123; result.add(new ArrayList&lt;&gt;(cur)); return; &#125; for (int i : nums) &#123; if (cur.contains(i)) &#123; continue; &#125; cur.add(i); permute2(nums, cur, result); cur.remove(cur.size() - 1); &#125;&#125; 47. Permutations IIhttps://leetcode.com/problems/permutations-ii/ 若数组中有重复元素，在全排列基础上要去除重复的结果。这个题目的解法不容易立即想到的，需要在全排列的树上完成剪枝的操作，而难点就在于判断树的哪颗节点该剪。 首先需要对整个数组进行排列，这是判断剪枝的前提。如果数组下标为i的元素的值与i-1元素的值相同，并且i-1元素并没有被访问过，那么下标为i的元素才可以被剪枝。其实难点在于理解前一个元素并没有被访问过，可以通过画图进行理解。 12345678910111213141516171819202122232425262728293031public List&lt;List&lt;Integer&gt;&gt; permuteUnique(int[] nums) &#123; if (nums == null || nums.length == 0) &#123; return new ArrayList&lt;&gt;(); &#125; // 排序 Arrays.sort(nums); List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;(); permute(nums, new ArrayList&lt;&gt;(), new boolean[nums.length], result); return result;&#125;/**注意剪枝规则*/private void permute(int[] nums, List&lt;Integer&gt; cur, boolean[] visit, List&lt;List&lt;Integer&gt;&gt; result) &#123; if (cur.size() == nums.length) &#123; result.add(new ArrayList&lt;&gt;(cur)); return; &#125; for (int i = 0; i &lt; nums.length; i++) &#123; if (visit[i]) &#123; continue; &#125; if (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; !visit[i - 1]) &#123; continue; &#125; visit[i] = true; cur.add(nums[i]); permute(nums, cur, visit, result); cur.remove(cur.size() - 1); visit[i] = false; &#125;&#125; 784. Letter Case Permutationhttps://leetcode.com/problems/letter-case-permutation/ 即输入一个String，里面的字符可以是数字、小写字母、大写字母。小写和大写可以相互转变，需要给出所有的 String 结果。答案也不难想，使用递归来做。 123456789101112131415161718192021222324public List&lt;String&gt; letterCasePermutation(String S) &#123; if (S == null || S.length() == 0) &#123; return null; &#125; List&lt;String&gt; result = new ArrayList&lt;&gt;(); handle(S.toCharArray(), 0, result); return result;&#125;private void handle(char[] chars, int i, List&lt;String&gt; result) &#123; if (i == chars.length) &#123; result.add(new String(chars)); return; &#125; if (Character.isDigit(chars[i])) &#123; handle(chars, i + 1, result); &#125; else &#123; chars[i] = Character.toLowerCase(chars[i]); handle(chars, i + 1, result); chars[i] = Character.toUpperCase(chars[i]); handle(chars, i + 1, result); &#125;&#125; 实际上第一遍做的时候，我是使用了一个 String 变量保存了当前结果，结果是对的，只是内存耗的稍多一点。当然这个变量是可以省的，只是需要更改字符数组。 1234567891011121314151617private void handle(char[] chars, int i, String cur, List&lt;String&gt; result) &#123; if (i == chars.length) &#123; result.add(cur); return; &#125; if (Character.isDigit(chars[i])) &#123; handle(chars, i + 1, cur + chars[i], result); &#125; if (Character.isLowerCase(chars[i])) &#123; handle(chars, i + 1, cur + chars[i], result); handle(chars, i + 1, cur + Character.toUpperCase(chars[i]), result); &#125; if (Character.isUpperCase(chars[i])) &#123; handle(chars, i + 1, cur + chars[i], result); handle(chars, i + 1, cur + Character.toLowerCase(chars[i]), result); &#125;&#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"https://weilans.github.io/categories/leetcode/"}],"tags":[{"name":"backtracking","slug":"backtracking","permalink":"https://weilans.github.io/tags/backtracking/"},{"name":"permutations","slug":"permutations","permalink":"https://weilans.github.io/tags/permutations/"},{"name":"dfs","slug":"dfs","permalink":"https://weilans.github.io/tags/dfs/"},{"name":"search","slug":"search","permalink":"https://weilans.github.io/tags/search/"}]},{"title":"Clojure in Action: 概述、数据结构","slug":"Clojure-in-Action-概述、数据结构","date":"2019-07-25T11:30:34.000Z","updated":"2019-08-01T09:43:36.000Z","comments":true,"path":"2019/07/25/Clojure-in-Action-概述、数据结构/","link":"","permalink":"https://weilans.github.io/2019/07/25/Clojure-in-Action-概述、数据结构/","excerpt":"","text":"Clojure 概述 关键词：JVM、Lisp、动态类型、函数式语言、不可变数据结构、Code as data 1. Clojure 是 Lisp 的一个变种Clojure 对所有函数甚至类似运算符的一切都使用前缀表示法。 2. Clojure 以JVM为宿主Clojure 代码直接编译为字节码供JVM运行； Clojure 默认加载 java.lang包下的所有类； Clojure 直接使用 Java 类型和标准程序库，如 Clojure 的集合实现接口与 Java 集合接口相同，重用 Java 类型和接口可以使 Java 代码无缝使用 Clojure 类型； 使用点运算符作为与Java 互操作的基础：(. Math abs -3)、(. &quot;foo&quot; toUpperCase)，静态成员可以重写为(Math/abs -3)，实例方法调用也可以使用(.toUpperCase &quot;foo&quot;)，创建类的实例可以使用(new Integer &quot;42&quot;)或(Integer. &quot;42&quot;)； Clojure 的不可变数据结构使共享可变状态的问题变得毫无意义。即使需要变更状态，Clojure 也提供了var（变量）、atom（原子）、ref（引用）、agent（代理）的并发数据结构。 3. Clojure 是一种函数式编程语言函数是第一等公民，函数可以作为参数传递给其他参数，也可以作为输出值返回。FP设计的函数式纯粹的，具备引用透明性，只要函数输入相同就始终返回相同输出； FP一般默认不可变数据结构，将不可变结构作为语言的默认状态保证了函数不会修改传递给他们的参数。Clojure的不可变数据结构避免了高代价复制。当对一个不可变数据结构进行更改，结果则为一个全新的结构。Clojrue隐式使用结构化共享和其他技术，确保执行复制的次数最少、不可变数据结构的操作便捷且节约内存。比如在一颗树上添加新值，会在通往根节点的路径上创建一组新的节点和引用； Clojure鼓励使用纯函数式编程：不可变数据结构、高阶函数和代替强制循环的递归，甚至可以选择集合的惰性求值和及早求值。当然，为了适应不同场景，Clojure也提供了对共享状态变更的方法。 Clojure 基础前期准备1. Clojure REPL（读取 - 求值 - 打印循环）1234567891011(+ 1 2) ;=&gt; 3(def my-addition (fn [operand1 operand2] (+ operand1 operand2)));=&gt; #'user/my-addition(my-addition 1 2);=&gt; 3(my-addition 100 30);=&gt; 130(+ 1 2) \"Two forms on one line!\";=&gt; 3;=&gt; \"Two forms on one line!\" 第二个表达式定义了一个命名空间限定的全局符号user/my-addition 。前缀#&#39;表明这是一个 Clojure 变量，变量是一个可变容器，其中包含唯一值，本例中为加法函数。 函数中没有显示的 return 语句。从函数中返回的值总是函数中最后一个求值的表达式。 最后三行是按照形式运行，Clojure 持续读取，直到发现一个完整的形式，然后求值并打印，此后如果缓冲区里仍有字符，它读取另一个形式、求值并打印。 2. 特殊 REPL 变量变量*1，*2，*3，*e保存最后一个、倒数第二个、倒数第三个成功读取的形式和最后一个错误。每当新形式求值成功，该值会保存在*1，旧*1被移动到*2，旧*2被移动到*3。 3. 文档查找 doc：返回具体的函数描述，该 宏需要你了解具体的实体名称。 find-doc：接受一个字符串（可以是正则），模糊查询复合条件的函数或宏文档。该函数在不确定名称时很实用。 apropos：工作方式与find-doc类似，只打印匹配搜索模式的函数名称。 4. 其他细节 前缀表示法。没有任何运算符，数学运算符就是 Clojure 函数。 空格。Clojure 不需要逗号来区分列表元素，当实用逗号时，Clojure 会把它们当成逗号忽略。当然，特定场景如哈希映射，使用逗号有助于程序员理解。 注释。单行注释使用分号表示。多行注释可以使用comment宏，该宏会忽略传入的形式，返回 nil。此外，宏#_会告诉reader忽略下一个Clojure形式。 12[1 2 3 #_ 4 5];=&gt; [1 2 3 5] Clojure 大小写敏感。 Clojure 数据结构1. nil / 真值 / 价值Clojure 的 nil等价于 Java 的 null ，在 nil 上调用一个函数可能报空指针异常。 除了 false 和 nil 之外，其他值都被视为真值。 2. 字符 / 字符串Clojure 字符是 Java 字符， 使用反斜杠宏表示字符: 12(type \\a);=&gt; java.lang.Character Clojure 字符串是 Java 字符串，使用双引号表示。（单引号则是另一个读取器宏，来表示 Symbol） 12(type \"hello\");=&gt; java.lang.String Java String API 在 Clojure 中依然很有用。 3. 数值Clojure 使用的整数是64位整数（Long），浮点数是64位浮点数（Double）。当需要更大的范围时，可以使用BigInteger,BigDecimal。此外，还有一个不常见的数值类型：比例（ratio），比例在两个整数相除时创建。 123456789101112(type 2);=&gt; java.lang.Long(type 3.14);=&gt; java.lang.Double(type 1/3);=&gt; clojure.lang.Ratio(type true);=&gt; java.lang.Boolean(type 123N);=&gt; clojure.lang.BigInt(type 0.5M);=&gt; java.math.BigDecimal 当不同数值类型在同一个算术运算中混合使用时，具有高传染性的数值类型将其类型传染给结果(long &lt; bigint &lt; ratio &lt; bigdec &lt; double) 12345678(+ 1 1N);=&gt; 2N(+ 1 1N 1/2);=&gt; 5/2(+ 1 1N 1/2 0.5M);=&gt; 3.0M(+ 1 1N 1/2 0.5M 0.5);=&gt; 3.5 溢出（overflow）：在 Clojure 中可能产生溢出的算术运算只有整数加法、减法和乘法（整数相除时，如果超过范围则生成一个比例）。 溢出发生时 Clojure 会抛出 ArtithmeticException异常。如果希望结果提升为大整数，则应该使用：+&#39;，-&#39;，*&#39;，inc&#39;，dec&#39;。 1234(inc 9223372036854775807);ArithmeticException integer overflow clojure.lang.Numbers.throwIntOverflow (Numbers.java:1424)(inc' 9223372036854775807);=&gt; 9223372036854775808N 4. 符号 / 关键字符号是 Clojure 中的标识符，代表值的名称。符号本身只包含可选命名空间的名称，但当一个表达式求值时，它们被所代表的值取代。 在一个程序中，符号通常被解析为不是符号的其他内容，但是可以通过一个前导的单引号引用符号，将其当成一个值而非标识符。 当为一个符号加上引号，就将这个引号当成数据而不是代码来处理，在实践中一般不会这么做，因为有另一种特殊类型：关键词，关键词从不引用其他值，求值的结果总是他们本身。关键词的典型用法是作为哈希映射中的键和枚举值。 5. 列表 主要函数：list，list?，conj，peek，pop，count Clojure 列表是单链表。只能从列表前端添加或删除元素，这意味着多个不同列表可以共享相同尾部，使列表成为最简单的不可变数据结构。 1234567891011121314151617181920212223242526(list 1 2 3 4 5);=&gt; (1 2 3 4 5)(list? *1);=&gt; true(conj (list 1 2 3 4 5) 6);=&gt; (6 1 2 3 4 5)(conj (list 1 2 3) 4 5 6);=&gt; (6 5 4 1 2 3)(conj (conj (conj (list 1 2 3) 4) 5) 6) ;=&gt; (6 5 4 1 2 3); 可以将列表当成一个栈来对待(peek (list 1 2 3));=&gt; 1(pop (list 1 2 3));=&gt; (2 3)(peek (list)) ;=&gt; nil(pop (list)) ;IllegalStateException Can't pop empty list clojure.lang.PersistentList$EmptyList.pop (PersistentList.java:183)(count (list));=&gt; 0(count (list 1 2 3 4));=&gt; 4 列表的特殊性：Clojure 会假定列表中出现的第一个符号表示函数（或者宏）名称。Clojure 视图以处理所有列表的相同方式来处理表(1,2,3) ，第一个元素被视为函数，而这里的整数 1 并不是函数。若希望将其作为数据而非代码，解决方式就是加上引号：&#39;(1,2,3)。 实践中一般不会在 Clojure 代码中使用列表作为数据，而是使用向量类型。 6. 向量 主要函数：vector，get，nth，assoc, conj,peek，pop，count，subvec，函数本身 向量可以使用vector函数创建，也可以使用方括号表示法创建，可以快速随机访问向量中的元素。获取其中元素中的方法有get和nth，差别在于没有找到相应值时，nth 会报出错误，get 返回 nil。 12345678910111213(vector 10 20 30 40 50);=&gt; [10 20 30 40 50](def the-vector [10 20 30 40 50]);=&gt; #'user/the-vector(get the-vector 2);=&gt; 30(nth the-vector 2);=&gt; 30(get the-vector 10);=&gt; nil(nth the-vector 10);IndexOutOfBoundsException clojure.lang.PersistentVector.arrayFor (PersistentVector.java:107) nth Get Vector as fn Vector is nil nil nil Throw exception Index out of range Throw exception Nil Throw exception Support ‘not found’ param yes Yes no 修改向量的方法中最常见的是 assoc。 1234567(assoc the-vector 2 25) ; 可以变更现有索引 ;=&gt; [10 20 25 40 50](assoc the-vector 5 60) ; 可以添加到尾部 ;=&gt; [10 20 30 40 50 60](assoc the-vector 6 70) ; 但是不能超过尾部 ;IndexOutOfBoundsException clojure.lang.PersistentVector.assocN (PersistentVector.java:137) conj函数同样适用于向量，但在向量中新元素将会被添加到最后，因为那是向量中最快速的插入位置。 12(conj [1 2 3 4 5] 6);=&gt; [1 2 3 4 5 6] peek和pop也适用于向量，方法会查看向量的尾部，而不是列表的表头。 12345678(peek [1 2]);=&gt; 2(pop [1 2]);=&gt; [1](peek []) ;=&gt; nil(pop []) ;IllegalStateException Can't pop empty vector clojure.lang.PersistentVector.pop (PersistentVector.java:381) 向量本身也是取单一参数的函数。(但向量函数不接受第二个参数) 12(the-vector 3);=&gt; 40 subvec会返回向量的一个子向量 (subvec avec start end?)。若未指定end，则默认为向量的末尾。 1234(subvec [1 2 3 4 5] 3);-&gt; [4 5](subvec [1 2 3 4 5] 1 3);-&gt; [2 3] 7. 映射 主要函数：hash-map，sorted-map，assoc，dissoc，select-keys，merge， merge-with，assoc-in，get-in，update-in，keys，vals，contains?，get，函数本身 一个映射就是一个键值对序列。映射可以使用hash-map函数构建。依据键获取对应的值时除了使用get函数外，映射本身也是一个函数。 123456789101112131415161718(def the-map &#123;:a 1 :b 2 :c 3&#125;);=&gt; #'user/the-map(hash-map :a 1 :b 2 :c 3);=&gt; &#123;:a 1, :c 3, :b 2&#125;(the-map :b);=&gt; 2(:b the-map);=&gt; 2(:z the-map 26) ; 若未找到关键字则返回一个默认值;=&gt; 26(get the-map :z 26) ;=&gt; 26(the-map :z 26) ;=&gt; 26(sorted-map :c 3 :b 2 :a 1);=&gt; &#123;:a 1, :b 2, :c 3&#125; 映射字面量和 hash-map 函数不完全等价，Clojure 实际上有哈希映射(hash-map)以及数组映射(array-map)。数组映射以有序方式保存键和值，以扫描的方式进行查找。如果使用 assoc 函数将太多键关联到一个数组映射，那将会得到一个哈希映射（而哈希映射变得太小不会反悔一个数组映射）。透明地替换数据结构的实现是 Clojure 提高性能的常用技巧。 此外，sorted-map不会按照存放的顺序返回，它会根据键来进行排序。 映射的修改方法有assoc和dissoc等。assoc 返回新增了一个键值对的映射表， dissoc 返回移除了某些键的映射表。 select-keys返回一个映射表，仅保留了参数传入的那些键。merge可以合并映射表。如果多个映射表包含了同一个键，那么最右边的获胜。merge-with与 merge 很类似，除了当两个或以上的映射表中有相同的键时，你能指定一个你自己的函数，来决定如何合并这个键对应的值。 1234567891011121314(def updated-map (assoc the-map :d 4));=&gt; #'user/updated-mapupdated-map;=&gt; &#123;:d 4, :a 1, :b 2, :c 3&#125;(dissoc updated-map :a);=&gt; &#123;:b 2, :c 3, :d 4&#125;(select-keys updated-map [:a :b]);=&gt; &#123;:a 1, :b 2&#125;(merge updated-map &#123;:m 666, :n 777&#125;);=&gt; &#123;:a 1, :b 2, :c 3, :d 4, :m 666, :n 777&#125;(merge &#123;:a 1 :b 2&#125; &#123;:a 3 :c 4&#125;);=&gt; &#123;:a 3, :b 2, :c 4&#125;(merge-with + &#123;:a 1 :b 2&#125; &#123;:a 3 :c 4&#125;);=&gt; &#123;:a 4, :b 2, :c 4&#125; 关于嵌套映射的使用。想要更改嵌套映射中的值需要先进入想要的位置，创建一个更改后的映射，并用 assoc 将更改的信息关联到这个中间映射，并一路返回到根。Clojure提供三个简化嵌套更新的函数。 1234567891011121314151617(def users &#123;:kyle &#123;:date-joined \"2009-01-01\" :summary &#123;:average &#123;:monthly 1000 :yearly 12000&#125;&#125;&#125;&#125;); assoc-in 可以设置新值，若不存在任何嵌套映射，在创建并正确关联。(assoc-in users [:kyle :summary :average :monthly] 3000);=&gt; &#123;:kyle &#123;:date-joined \"2009-01-01\", :summary &#123;:average &#123;:monthly 3000,; :yearly 12000&#125;&#125;&#125;&#125;; get-in 可以嵌套读取值(get-in users [:kyle :summary :average :monthly]);=&gt; 1000; update-in 可以更新嵌套映射中的值，其不提供新值，而是提供一个函数(update-in users [:kyle :summary :average :monthly] + 500);=&gt; &#123;:kyle &#123;:date-joined \"2009-01-01\", :summary &#123;:average &#123;:monthly 1500,; :yearly 12000&#125;&#125;&#125;&#125; keys将所有的键作为序列返回，vals则将所有的值作为序列返回。 1234(keys &#123;:sundance \"spaniel\", :darwin \"beagle\"&#125;);-&gt; (:sundance :darwin)(vals &#123;:sundance \"spaniel\", :darwin \"beagle\"&#125;);-&gt; (\"spaniel\" \"beagle\") 无法确认究竟是键对应的值为 nil，还是这个键在映射表中根本就不存在。contains?函数就可以解决这个问题。（(:z the-map 26) 这种形式也可以做到。） 123(def score &#123;:stu nil :joey 100&#125;)(contains? score :stu);-&gt; true 8. Set 主要函数：conj，disj，contains?，set， hash-set，sorted-set，union，intersection，difference，select Clojure set 工作方式和数学中的 set 是一样的，是一种集合，其中的元素无序且唯一。Clojure 支持两种不同的 set：排序的(sorted-set)和不排序的(hash-set)。sorted-set 会依据自然顺序对值进行排序。 123456789101112131415161718#&#123;:a :b :c&#125;;=&gt; #&#123;:c :b :a&#125;(conj #&#123;:a :b :c&#125; :d);=&gt; #&#123;:c :b :d :a&#125;(conj #&#123;:a :b :c&#125; :a);=&gt; #&#123;:c :b :a&#125;(disj #&#123;:a :b :c&#125; :a);=&gt; #&#123;:c :b&#125;(contains? #&#123;1 2 3&#125; 3);=&gt; true; set函数期望其第一个参数是个容器。而hash-set则接受可变的参数列表。(set [:a :b :c]);=&gt; #&#123;:c :b :a&#125;(hash-set 1 2 3);=&gt; #&#123;1 3 2&#125;(sorted-set 2 3 1);=&gt; #&#123;1 2 3&#125; clojure.set 集合函数需先调用(use &#39;clojure.set)。 union返回的集合，包含了所有输入集合中的元素。intersection返回的集合，其所有元素都曾同时出现于多个输入集合中。difference 返回的集合，其所有元素都出现于第一个输入集合，但却未出现于第二个中。select返回所有元素都能与给定谓词相匹配的一个集合。 123456789101112(def languages #&#123;\"java\" \"c\" \"d\" \"clojure\"&#125;)(def beverages #&#123;\"java\" \"chai\" \"pop\"&#125;)(use 'clojure.set)(union languages beverages);=&gt; #&#123;\"java\" \"c\" \"d\" \"clojure\" \"chai\" \"pop\"&#125;(difference languages beverages);=&gt; #&#123;\"c\" \"d\" \"clojure\"&#125;(intersection languages beverages);=&gt; #&#123;\"java\"&#125;(select #(= 1 (.length %)) languages);=&gt; #&#123;\"c\" \"d\"&#125; 差集和并集除了是集合论的一部分，也是关系代数的一部分，下面介绍了投影、笛卡尔积、连接、重命名等方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657; 音乐作品集内存数据库示例(def compositions #&#123;&#123;:name \"The Art of the Fugue\" :composer \"J. S. Bach\"&#125; &#123;:name \"Musical Offering\" :composer \"J. S. Bach\"&#125; &#123;:name \"Requiem\" :composer \"Giuseppe Verdi\"&#125; &#123;:name \"Requiem\" :composer \"W. A. Mozart\"&#125;&#125;)(def composers #&#123;&#123;:composer \"J. S. Bach\" :country \"Germany\"&#125; &#123;:composer \"W. A. Mozart\" :country \"Austria\"&#125; &#123;:composer \"Giuseppe Verdi\" :country \"Italy\"&#125;&#125;)(def nations #&#123;&#123;:nation \"Germany\" :language \"German\"&#125; &#123;:nation \"Austria\" :language \"German\"&#125; &#123;:nation \"Italy\" :language \"Italian\"&#125;&#125;)(select #(= (:name %) \"Requiem\") compositions);=&gt; #&#123;&#123;:name \"Requiem\", :composer \"W. A. Mozart\"&#125;; &#123;:name \"Requiem\", :composer \"Giuseppe Verdi\"&#125;&#125;; project函数返回的那些映射表中，仅包含与参数匹配的键。 (project relation keys)(project compositions [:name]);=&gt; #&#123;&#123;:name \"Musical Offering\"&#125;; &#123;:name \"Requiem\"&#125;; &#123;:name \"The Art of the Fugue\"&#125;&#125;; 笛卡尔积(for [m compositions c composers] (concat m c)); join 集合连接(join compositions composers);=&gt; #&#123;&#123;:composer \"W. A. Mozart\", :country \"Austria\", :name \"Requiem\"&#125;; &#123;:composer \"J. S. Bach\", :country \"Germany\", :name \"Musical Offering\"&#125;; &#123;:composer \"Giuseppe Verdi\", :country \"Italy\", :name \"Requiem\"&#125;; &#123;:composer \"J. S. Bach\", :country \"Germany\", :name \"The Art of the Fugue\"&#125;&#125;;如果两个关系中的键名不匹配，你可以传入一个keymap，将relation-1中的键名映射到relation-2中对应的键。;例如，你可以将使用:country的composers，与使用:nation的nations相连接。(join composers nations &#123;:country :nation&#125;);=&gt; #&#123;&#123;:composer \"W. A. Mozart\", :country \"Austria\", :nation \"Austria\", :language \"German\"&#125;; &#123;:composer \"J. S. Bach\", :country \"Germany\", :nation \"Germany\", :language \"German\"&#125;; &#123;:composer \"Giuseppe Verdi\", :country \"Italy\", :nation \"Italy\", :language \"Italian\"&#125;&#125;; 示例: 所有创作了安魂曲的作曲家们，家乡都在哪些国家(project (join (select #(= (:name %) \"Requiem\") compositions) composers) [:country]);=&gt; #&#123;&#123;:country \"Italy\"&#125; &#123;:country \"Austria\"&#125;&#125;; rename 可以给键(数据库的列)重命名(rename compositions &#123;:name :title&#125;);=&gt;#&#123;&#123;:composer \"Giuseppe Verdi\", :title \"Requiem\"&#125;; &#123;:composer \"W. A. Mozart\", :title \"Requiem\"&#125;; &#123;:composer \"J. S. Bach\", :title \"The Art of the Fugue\"&#125;; &#123;:composer \"J. S. Bach\", :title \"Musical Offering\"&#125;&#125; 9. 序列序列是一个接口(ISeq)，Clojure 数据结构、函数和宏都普遍实现这个接口，序列抽象使所有数据结构的外表和行为像列表一样。 first返回序列的第一个元素，rest返回排除第一个元素的序列，但是对所有集合类型采取相同的方式。 cons会在序列的开始位置(即使是向量也一样)添加一个元素。 序列抽象通常是惰性的，尽管 first、rest、cons的结果打印出来像一个列表，但它们并没有进行创建列表的额外工作。序列抽象使一切都像操纵真正的列表一样，但是避免真正地创建任何新数据结构或者进行任何不必要的工作。 12345678910111213141516171819202122(first (list 1 2 3));=&gt; 1(rest (list 1 2 3));=&gt; (2 3)(first [1 2 3]);=&gt; 1(rest [1 2 3]);=&gt; (2 3)(first &#123;:a 1 :b 2&#125;) ; 不保证项的顺序;=&gt; [:b 2](rest &#123;:a 1 :b 2&#125;);=&gt; ([:a 1])(first []) ; 空集合调用first返回nil;=&gt; nil(rest []) ; 空集合调用 rest 返回空序列;=&gt; ()(cons 1 [2 3 4 5]);=&gt; (1 2 3 4 5)(list? (cons 1 (list 2 3)));=&gt; false 一切皆序列 主要函数：first，rest，cons，seq， next 可被视为序列的容器，被称为可序化的，可序化的容器包括：所有的Clojure容器、所有的Java容器、Java数组和字符串、正则表达式的匹配结果、目录结构、输入/输出流、XML树。 除了序列三大核心first、rest、cons，还有seq，seq 函数会返回一个序列，该序列源自任何一个可序化的其他容器。next 函数也会返回一个序列，该序列由除第一个元素以外的其他所有元素组成。(next aseq)等价于 (seq (rest aseq))。 12345678910(seq nil);=&gt; nil(seq ());=&gt; nil(rest ());=&gt; ()(next ());=&gt; nil(seq (rest ()));=&gt; nil conj &amp; intoconj 会向容器添加一个或是多个元素，into 则会把容器中的所有元素添加至另一个容器。这两个方法的返回值类型不是序列，而是容器类型。添加数据时，conj和into都会根据底层数据结构的特点选取最高效的插入点。 1234567891011;对于列表而言，conj和into会在其前端进行添加。(conj '(1 2 3) :a);=&gt; (:a 1 2 3)(into '(1 2 3) '(:a :b :c));=&gt; (:c :b :a 1 2 3);而对于向量，conj和into则会把元素添加至末尾。(conj [1 2 3] :a);=&gt; [1 2 3 :a](into [1 2 3] [:a :b :c]);=&gt; [1 2 3 :a :b :c] 创建序列 主要函数：range，repeat，take，iterate， cycle，interleave，interpose 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950;ranage会生成一个从start开始到end结束的序列，每次的增量为step。 (range start? end step?)(range 10);=&gt; (0 1 2 3 4 5 6 7 8 9)(range 10 20);=&gt; (10 11 12 13 14 15 16 17 18 19)(range 1 25 2);=&gt; (1 3 5 7 9 11 13 15 17 19 21 23);repeat函数会重复n次元素x。 (repeat n x)(repeat 5 1);=&gt; (1 1 1 1 1)(repeat 10 \"x\");=&gt; (\"x\" \"x\" \"x\" \"x\" \"x\" \"x\" \"x\" \"x\" \"x\" \"x\");(iterate f x) iterate起始于值x，并持续地对每个值应用函数f，以计算下一个值，直至永远。;由于这是个无限序列，你需要另一个新函数 (take n sequence)。take会返回一个包含了容器中前n项元素的惰性序列。(take 10 (iterate inc 1));=&gt; (1 2 3 4 5 6 7 8 9 10);cycle函数接受一个容器，并无限的对其进行循环。 (cycle coll)(take 10 (cycle (range 3)));=&gt; (0 1 2 0 1 2 0 1 2 0);interleave函数接受多个容器作为参数，并产生一个新的容器，这个新容器会从每个参数容器中交错地提取元素，直至其中某个容器元素被耗尽。(defn whole-numbers [] (iterate inc 1))(interleave (whole-numbers) [\"A\" \"B\" \"C\" \"D\" \"E\"]);interpose函数，把输入序列中的每个元素用分隔符隔开，并作为新的序列返回。(interpose separator coll)(interpose \",\" [\"apples\" \"bananas\" \"grapes\"]);=&gt; (\"apples\" \",\" \"bananas\" \",\" \"grapes\");(apply f args* argseq)apply函数接受一个函数f、一些可选的args和一个序列argseq作为参数。之后会调用 f，并将args和argseq解开为一个参数列表传给f。(apply str (interpose \\, [\"apples\" \"bananas\" \"grapes\"]));=&gt; \"apples,bananas,grapes\";(join separator sequence)(use '[clojure.string :only (join)])(join \\, [\"apples\" \"bananas\" \"grapes\"]);=&gt; \"apples,bananas,grapes\";对应每种Clojure中的容器类型，都有一个可以接受任意数量参数的函数，用来创建该类型的容器。;hash-set与set与其工作方式稍有不同：set函数期望其第一个参数是个容器。而hash-set则接受可变的参数列表。(set [1 2 3]);=&gt; #&#123;1 3 2&#125;(hash-set 1 2 3);=&gt; #&#123;1 3 2&#125;;vector也有一个近亲vec，vec接受容器作为参数，而非可变的参数列表。(vec (range 3));=&gt; [0 1 2](vector 0 1 2);=&gt; [0 1 2] 过滤序列 主要函数：filter，take-while，drop-while，split-at， split-with 12345678910111213141516171819202122(defn whole-numbers [] (iterate inc 1));(filter pred coll) filter接受一个谓词和一个容器作为参数，并返回一个序列，这个序列的所有元素都经谓词判定为真。(take 10 (filter even? (whole-numbers)));=&gt; (2 4 6 8 10 12 14 16 18 20);使用take-while从序列中截取开头的一段，其每个元素都被谓词判定为真。 (take-while pred coll);字符串中逐个获取第一个元音字符之前的所有非元音字符(take-while (complement #&#123;\\a\\e\\i\\o\\u&#125;) \"the-quick-brown-fox\");=&gt; (\\t \\h);1、集合同时也可作为函数。所以你可以把#&#123;\\a\\e\\i\\o\\u&#125;读作“元音集”，或是“用于检测参数是否为元音的函数。”;2、complement 会反转另一个函数的行为。前例的那个反转函数用于检测参数是不是一个元音。;与take-while相对的是drop-while函数。drop-while 从序列的起始位置开始，逐个丢弃元素，直至谓词判定为真，然后返回序列剩余的部分。(drop-while (complement #&#123;\\a\\e\\i\\o\\u&#125;) \"the-quick-brown-fox\");=&gt; (\\e \\- \\q \\u \\i \\c \\k \\- \\b \\r \\o \\w \\n \\- \\f \\o \\x);split-at和split-with能把一个容器一分为二。(split-at index coll) (split-with pred coll);split-at接受一个索引作为参数，而split-with则接受一个谓词。(split-at 5 (range 10));=&gt;[(0 1 2 3 4) (5 6 7 8 9)](split-with #(&lt;= % 10) (range 0 20 2));=&gt;[(0 2 4 6 8 10) (12 14 16 18)] 序列谓词 主要函数：every?，some，not-every?，not-any? 1234567891011121314151617;every？要求其他谓词对序列中的每个元素都必须判定为真。(every? odd? [1 3 5]);=&gt; true(every? odd? [1 3 5 8]);=&gt; false;(some pred coll) 只要有一个元素被谓词判定为非假，some就会返回这个值，如果没有任何元素符合，则some返回nil。(some even? [1 2 3])-&gt; true(some even? [1 3 5])-&gt; nil;some 返回的是第一个符合项的值，而非 true。(some identity [nil false 1 nil 2]);=&gt; 1(not-every? even? (whole-numbers));=&gt; true(not-any? even? (whole-numbers));=&gt; false 序列转换 主要函数：map，reduce，sort，sort-by，for 123456789101112131415161718192021222324;映射函数map (map f coll) map接受一个源容器coll和一个函数f作为参数，并返回一个新的序列。(map #(format \"&lt;p&gt;%s&lt;/p&gt;\" %) [\"the\" \"quick\" \"brown\" \"fox\"]);=&gt; (\"&lt;p&gt;the&lt;/p&gt;\" \"&lt;p&gt;quick&lt;/p&gt;\" \"&lt;p&gt;brown&lt;/p&gt;\" \"&lt;p&gt;fox&lt;/p&gt;\");还可以传入多个容器给map。在这种情况下，f必须是一个多参函数。map会从每个容器分别取出一个值，作为参数来调用f，直到数量最少的那个容器被耗尽为止。(map #(format \"&lt;%s&gt;%s&lt;/%s&gt;\" %1 %2 %1) [\"h1\" \"h2\" \"h3\" \"h1\"] [\"the\" \"quick\" \"brown\" \"fox\"]);=&gt; (\"&lt;h1&gt;the&lt;/h1&gt;\" \"&lt;h2&gt;quick&lt;/h2&gt;\" \"&lt;h3&gt;brown&lt;/h3&gt;\" \"&lt;h1&gt;fox&lt;/h1&gt;\");归纳函数reduce (reduce f coll) reduce首先用coll的前两个元素作为参数来调用f，然后用得到的结果和第三个元素作为参数，继续调用f。(reduce + (range 1 11));=&gt; 55(reduce * (range 1 11));=&gt; 3628800;(sort comp? coll) (sort-by a-fn comp? coll) sort 会依据元素的自然顺序对容器进行排序，sort-by 则会对每个元素调用 a-fn，再依据得到的结果序列来进行排序。(sort [42 1 7 11]);=&gt; (1 7 11 42)(sort-by #(.toString %) [42 1 7 11]);=&gt;` (1 11 42 7);可以为sort或sort-by指定一个可选的比较函数comp。(sort &gt; [42 1 7 11]);=&gt; (42 11 7 1)(sort-by :grade &gt; [&#123;:grade 83&#125; &#123;:grade 90&#125; &#123;:grade 77&#125;]);=&gt; (&#123;:grade 90&#125; &#123;:grade 83&#125; &#123;:grade 77&#125;) Clojure把列表解析的概念泛化为了序列解析（sequence comprehension）。在Clojure中，是使用for宏来进行解析的。列表解析比诸如 map 和filter 这样的函数更加通用，而且，事实上它可以模拟之前的大多数过滤和转换函数。 1(for [binding-form coll-expr filter-expr? ...] expr) 123456789101112131415161718192021(defn whole-numbers [] (iterate inc 1))(for [word [\"the\" \"quick\" \"brown\" \"fox\"]] (format \"&lt;p&gt;%s&lt;/p&gt;\" word));=&gt; (\"&lt;p&gt;the&lt;/p&gt;\" \"&lt;p&gt;quick&lt;/p&gt;\" \"&lt;p&gt;brown&lt;/p&gt;\" \"&lt;p&gt;fox&lt;/p&gt;\");借助:when子句，解析也可以用来模拟filter函数。(take 10 (for [n (whole-numbers) :when (even? n)] n));=&gt; (2 4 6 8 10 12 14 16 18 20);只要:while字句的表达式保持为真，它就会继续进行求值。(for [n (whole-numbers) :while (even? n)] n);=&gt; ()(for [n (whole-numbers) :while (odd? n)] n);=&gt; (1)(for [n (whole-numbers) :while (&lt; n 5)] n);=&gt; (1 2 3 4);多个绑定表达式(for [file \"ABCDEFGH\" rank (range 1 9)] (format \"%c%d\" file rank));=&gt; (\"A1\" \"A2\" ...已省略... \"H7 \"\"H8\")(for [rank (range 1 9) file \"ABCDEFGH\"] (format \"%c%d\" file rank));=&gt; (\"A1\" \"B1\"... \"G8\" \"H8\") 序化正则表达式、文件系统、流 正则表达式： 12345678910(def matcher (re-matcher #\"\\d+\" \"abc12345def678\"));=&gt;#'user/matcher(re-find matcher);=&gt;\"12345\"(re-find matcher);=&gt; \"678\";; If you only want the first match, it is shorter to call re-find with the pattern and the string to search, rather than explicitly creating a matcher as above.(re-find #\"\\d+\" \"abc12345def\");=&gt;\"12345\" 使用正则更好的做法：(re-seq regexp string) re-seq 会把匹配结果暴露为一个不可变的序列。 12345678(re-seq #\"\\w+\" \"the quick brown fox\");=&gt; (\"the\" \"quick\" \"brown\" \"fox\")(sort (re-seq #\"\\w+\" \"the quick brown fox\"));=&gt; (\"brown\" \"fox\" \"quick\" \"the\")(drop 2 (re-seq #\"\\w+\" \"the quick brown fox\"));=&gt; (\"brown\" \"fox\")(map #(.toUpperCase %) (re-seq #\"\\w+\" \"the quick brown fox\"));=&gt; (\"THE\" \"QUICK\" \"BROWN\" \"FOX\") 文件系统： 12345678910(import '(java.io File)); 返回的是File数组，而非序列(.listFiles (File. \".\")); 返回序列(seq (.listFiles (File. \".\")) ); 想要获取name时可以使用map,一旦你决定使用诸如map这样的函数，再调用seq就会显得多余。序列库中的函数会替你调用seq。(map #(.getName %) (.listFiles (File. \".\")));遍历整个目录树。Clojure通过file-seq提供了一个深度优先的遍历方式(file-seq (File. \".\")) 流： 1234567(use '[clojure.java.io :only (reader)]); 统计文件多少行(with-open [rdr (reader \"src/examples/java.clj\")] (count (line-seq rdr))); 仅对非空行计数(with-open [rdr (reader \"src/examples/utils.clj\")] (count (filter #(re-find #\"\\S\" %) (line-seq rdr)))) 综合示例：获取clj代码行数 1234567891011(use '[clojure.java.io :only (reader)])(defn non-blank? [line] (if (re-find #\"\\S\" line) true false))(defn non-svn? [file] (not (.contains (.toString file) \".svn\")))(defn clojure-source? [file] (.endsWith (.toString file) \".clj\"))(defn clojure-loc [base-file] (reduce + (for [file (file-seq base-file) :when (and (clojure-source? file) (non-svn? file))] (with-open [rdr (reader file)] (count (filter non-blank? (line-seq rdr)))))))","categories":[{"name":"clojure","slug":"clojure","permalink":"https://weilans.github.io/categories/clojure/"}],"tags":[{"name":"clojure","slug":"clojure","permalink":"https://weilans.github.io/tags/clojure/"}]}]}